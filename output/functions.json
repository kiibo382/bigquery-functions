[
  {
    "name": "ABS",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nABS(X)\n```\n\n **Description** \n\nComputes absolute value. Returns an error if the argument is an integer and theoutput value cannot be represented as the same type; this happens only for thelargest negative input value, which has no positive representation.\n\n| X | ABS(X) |\n| --- | --- |\n| 25 | 25 |\n| -25 | 25 |\n| `+inf` | `+inf` |\n| `-inf` | `+inf` |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "ACOS",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nACOS(X)\n```\n\n **Description** \n\nComputes the principal value of the inverse cosine of X. The return value is inthe range [0,π]. Generates an error if X is a value outside of therange [-1, 1].\n\n| X | ACOS(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n| X < -1 | Error |\n| X > 1 | Error |\n\n"
  },
  {
    "name": "ACOSH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nACOSH(X)\n```\n\n **Description** \n\nComputes the inverse hyperbolic cosine of X. Generates an error if X is a valueless than 1.\n\n| X | ACOSH(X) |\n| --- | --- |\n| `+inf` | `+inf` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n| X < 1 | Error |\n\n"
  },
  {
    "name": "AEAD.DECRYPT_BYTES",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nAEAD.DECRYPT_BYTES(keyset, ciphertext, additional_data)\n```\n\n **Description** \n\nUses the matching key from`keyset`to decrypt`ciphertext`and verifies theintegrity of the data using`additional_data`. Returns an error if decryption orverification fails.\n\n`keyset`is a serialized`BYTES`value returned by one of the`KEYS`functions or a`STRUCT`returned by`KEYS.KEYSET_CHAIN`.`keyset`must contain the key that was used toencrypt`ciphertext`, and the key must be in an`'ENABLED'`state, or else thefunction returns an error.`AEAD.DECRYPT_BYTES`identifies the matching keyin`keyset`by finding the key with the key ID that matches the one encrypted in`ciphertext`.\n\n`ciphertext`is a`BYTES`value that is the result ofa call to`AEAD.ENCRYPT`where the input`plaintext`was of type`BYTES`.\n\nIf`ciphertext`includes an initialization vector (IV),it should be the first bytes of`ciphertext`. If`ciphertext`includes anauthentication tag, it should be the last bytes of`ciphertext`. If theIV and authentic tag are one (SIV), it should be the first bytes of`ciphertext`. The IV and authentication tag commonly require 16 bytes, but mayvary in size.\n\n`additional_data`is a`STRING`or`BYTES`value that binds the ciphertext toits context. This forces the ciphertext to be decrypted in the same context inwhich it was encrypted. This function casts any`STRING`value to`BYTES`.This must be the same as the`additional_data`provided to`AEAD.ENCRYPT`toencrypt`ciphertext`, ignoring its type, or else the function returns an error.\n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nThis example creates a table of unique IDs with associated plaintext values andkeysets. Then it uses these keysets to encrypt the plaintext values as`BYTES`and store them in a new table. Finally, ituses`AEAD.DECRYPT_BYTES`to decrypt the encrypted values and display them asplaintext.\n\nThe following statement creates a table`CustomerKeysets`containing a column ofunique IDs, a column of`AEAD_AES_GCM_256`keysets, and a column of favoriteanimals.\n\n```\nCREATE TABLE aead.CustomerKeysets ASSELECT  1 AS customer_id,  KEYS.NEW_KEYSET('AEAD_AES_GCM_256') AS keyset,  b'jaguar' AS favorite_animalUNION ALLSELECT  2 AS customer_id,  KEYS.NEW_KEYSET('AEAD_AES_GCM_256') AS keyset,  b'zebra' AS favorite_animalUNION ALLSELECT  3 AS customer_id,  KEYS.NEW_KEYSET('AEAD_AES_GCM_256') AS keyset,  b'nautilus' AS favorite_animal;\n```\n\nThe following statement creates a table`EncryptedCustomerData`containing acolumn of unique IDs and a column of ciphertext. The statement encrypts theplaintext`favorite_animal`using the keyset value from`CustomerKeysets`corresponding to each unique ID.\n\n```\nCREATE TABLE aead.EncryptedCustomerData ASSELECT  customer_id,  AEAD.ENCRYPT(keyset, favorite_animal, CAST(CAST(customer_id AS STRING) AS BYTES))   AS encrypted_animalFROM  aead.CustomerKeysets AS ck;\n```\n\nThe following query uses the keysets in the`CustomerKeysets`table to decryptdata in the`EncryptedCustomerData`table.\n\n```\nSELECT  ecd.customer_id,  AEAD.DECRYPT_BYTES(    (SELECT ck.keyset     FROM aead.CustomerKeysets AS ck     WHERE ecd.customer_id = ck.customer_id),    ecd.encrypted_animal,    CAST(CAST(customer_id AS STRING) AS BYTES)  ) AS favorite_animalFROM aead.EncryptedCustomerData AS ecd;\n```\n\n"
  },
  {
    "name": "AEAD.DECRYPT_STRING",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nAEAD.DECRYPT_STRING(keyset, ciphertext, additional_data)\n```\n\n **Description** \n\nLike[AEAD.DECRYPT_BYTES](#aeaddecrypt_bytes), but where`additional_data`isof type`STRING`.\n\n **Return Data Type** \n\n`STRING`\n\n"
  },
  {
    "name": "AEAD.ENCRYPT",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nAEAD.ENCRYPT(keyset, plaintext, additional_data)\n```\n\n **Description** \n\nEncrypts`plaintext`using the primary cryptographic key in`keyset`. Thealgorithm of the primary key must be`AEAD_AES_GCM_256`. Binds the ciphertext tothe context defined by`additional_data`. Returns`NULL`if any input is`NULL`.\n\n`keyset`is a serialized`BYTES`value returned by one of the`KEYS`functions or a`STRUCT`returned by`KEYS.KEYSET_CHAIN`.\n\n`plaintext`is the`STRING`or`BYTES`value to be encrypted.\n\n`additional_data`is a`STRING`or`BYTES`value that binds the ciphertext toits context. This forces the ciphertext to be decrypted in the same context inwhich it was encrypted.`plaintext`and`additional_data`must be of the sametype.`AEAD.ENCRYPT(keyset, string1, string2)`is equivalent to`AEAD.ENCRYPT(keyset, CAST(string1 AS BYTES), CAST(string2 AS BYTES))`.\n\nThe output is ciphertext`BYTES`. The ciphertext contains a[Tink-specific](https://github.com/google/tink/blob/master/docs/KEY-MANAGEMENT.md)prefix indicating the key used to perform the encryption.\n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nThe following query uses the keysets for each`customer_id`in the`CustomerKeysets`table to encrypt the value of the plaintext`favorite_animal`in the`PlaintextCustomerData`table corresponding to that`customer_id`. Theoutput contains a column of`customer_id`values and a column ofcorresponding ciphertext output as`BYTES`.\n\n```\nWITH CustomerKeysets AS (  SELECT 1 AS customer_id, KEYS.NEW_KEYSET('AEAD_AES_GCM_256') AS keyset UNION ALL  SELECT 2, KEYS.NEW_KEYSET('AEAD_AES_GCM_256') UNION ALL  SELECT 3, KEYS.NEW_KEYSET('AEAD_AES_GCM_256')), PlaintextCustomerData AS (  SELECT 1 AS customer_id, 'elephant' AS favorite_animal UNION ALL  SELECT 2, 'walrus' UNION ALL  SELECT 3, 'leopard')SELECT  pcd.customer_id,  AEAD.ENCRYPT(    (SELECT keyset     FROM CustomerKeysets AS ck     WHERE ck.customer_id = pcd.customer_id),    pcd.favorite_animal,    CAST(pcd.customer_id AS STRING)  ) AS encrypted_animalFROM PlaintextCustomerData AS pcd;\n```\n\n"
  },
  {
    "name": "ANY_VALUE",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nANY_VALUE(  expression  [ HAVING { MAX | MIN } expression2 ])[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns`expression`for some row chosen from the group. Which row is chosen isnondeterministic, not random. Returns`NULL`when the input produces norows. Returns`NULL`when`expression`is`NULL`for all rows in the group.\n\n`ANY_VALUE`behaves as if`RESPECT NULLS`is specified;rows for which`expression`is`NULL`are considered and may be selected.\n\nIf the`HAVING`clause is included in the`ANY_VALUE`function, the`OVER`clause can't be used with this function.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\nAny\n\n **Returned Data Types** \n\nMatches the input data type.\n\n **Examples** \n\n```\nSELECT ANY_VALUE(fruit) as any_valueFROM UNNEST([\"apple\", \"banana\", \"pear\"]) as fruit;/*-----------* | any_value | +-----------+ | apple     | *-----------*/\n```\n\n```\nSELECT  fruit,  ANY_VALUE(fruit) OVER (ORDER BY LENGTH(fruit) ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS any_valueFROM UNNEST([\"apple\", \"banana\", \"pear\"]) as fruit;/*--------+-----------* | fruit  | any_value | +--------+-----------+ | pear   | pear      | | apple  | pear      | | banana | apple     | *--------+-----------*/\n```\n\n```\nWITH  Store AS (    SELECT 20 AS sold, \"apples\" AS fruit    UNION ALL    SELECT 30 AS sold, \"pears\" AS fruit    UNION ALL    SELECT 30 AS sold, \"bananas\" AS fruit    UNION ALL    SELECT 10 AS sold, \"oranges\" AS fruit  )SELECT ANY_VALUE(fruit HAVING MAX sold) AS a_highest_selling_fruit FROM Store;/*-------------------------* | a_highest_selling_fruit | +-------------------------+ | pears                   | *-------------------------*/\n```\n\n```\nWITH  Store AS (    SELECT 20 AS sold, \"apples\" AS fruit    UNION ALL    SELECT 30 AS sold, \"pears\" AS fruit    UNION ALL    SELECT 30 AS sold, \"bananas\" AS fruit    UNION ALL    SELECT 10 AS sold, \"oranges\" AS fruit  )SELECT ANY_VALUE(fruit HAVING MIN sold) AS a_lowest_selling_fruit FROM Store;/*-------------------------* | a_lowest_selling_fruit  | +-------------------------+ | oranges                 | *-------------------------*/\n```\n\n"
  },
  {
    "name": "APPENDS",
    "arguments": [],
    "category": "Table functions (built in)",
    "description": "Gets all rows that are appended to a table for a given time range.For more information, see[APPENDS TVF](/bigquery/docs/change-history#appends-tvf).\n\n"
  },
  {
    "name": "APPROX_COUNT_DISTINCT",
    "arguments": [],
    "category": "Approximate aggregate functions",
    "description": "```\nAPPROX_COUNT_DISTINCT(  expression)\n```\n\n **Description** \n\nReturns the approximate result for`COUNT(DISTINCT expression)`. The valuereturned is a statistical estimate, not necessarily the actual value.\n\nThis function is less accurate than`COUNT(DISTINCT expression)`, but performsbetter on huge input.\n\n **Supported Argument Types** \n\nAny data type **except** :\n\n- `    ARRAY`\n- `    STRUCT`\n- `    INTERVAL`\n\n **Returned Data Types** \n\n`INT64`\n\n **Examples** \n\n```\nSELECT APPROX_COUNT_DISTINCT(x) as approx_distinctFROM UNNEST([0, 1, 1, 2, 3, 5]) as x;/*-----------------* | approx_distinct | +-----------------+ | 5               | *-----------------*/\n```\n\n"
  },
  {
    "name": "APPROX_QUANTILES",
    "arguments": [],
    "category": "Approximate aggregate functions",
    "description": "```\nAPPROX_QUANTILES(  [ DISTINCT ]  expression, number  [ { IGNORE | RESPECT } NULLS ])\n```\n\n **Description** \n\nReturns the approximate boundaries for a group of`expression`values, where`number`represents the number of quantiles to create. This function returns anarray of`number`+ 1 elements, sorted in ascending order, where thefirst element is the approximate minimum and the last element is the approximatemaximum.\n\nReturns`NULL`if there are zero input rows or`expression`evaluates to`NULL`for all rows.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n **Supported Argument Types** \n\n- `    expression`: Any supported data type **except** :\n    \n    \n    - `        ARRAY`\n    - `        STRUCT`\n    - `        INTERVAL`\n- `    number`:`    INT64`literal or query parameter.\n    \n    \n\n **Returned Data Types** \n\n`ARRAY&lt;T&gt;`where`T`is the type specified by`expression`.\n\n **Examples** \n\n```\nSELECT APPROX_QUANTILES(x, 2) AS approx_quantilesFROM UNNEST([1, 1, 1, 4, 5, 6, 7, 8, 9, 10]) AS x;/*------------------* | approx_quantiles | +------------------+ | [1, 5, 10]       | *------------------*/\n```\n\n```\nSELECT APPROX_QUANTILES(x, 100)[OFFSET(90)] AS percentile_90FROM UNNEST([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) AS x;/*---------------* | percentile_90 | +---------------+ | 9             | *---------------*/\n```\n\n```\nSELECT APPROX_QUANTILES(DISTINCT x, 2) AS approx_quantilesFROM UNNEST([1, 1, 1, 4, 5, 6, 7, 8, 9, 10]) AS x;/*------------------* | approx_quantiles | +------------------+ | [1, 6, 10]       | *------------------*/\n```\n\n```\nSELECT FORMAT(\"%T\", APPROX_QUANTILES(x, 2 RESPECT NULLS)) AS approx_quantilesFROM UNNEST([NULL, NULL, 1, 1, 1, 4, 5, 6, 7, 8, 9, 10]) AS x;/*------------------* | approx_quantiles | +------------------+ | [NULL, 4, 10]    | *------------------*/\n```\n\n```\nSELECT FORMAT(\"%T\", APPROX_QUANTILES(DISTINCT x, 2 RESPECT NULLS)) AS approx_quantilesFROM UNNEST([NULL, NULL, 1, 1, 1, 4, 5, 6, 7, 8, 9, 10]) AS x;/*------------------* | approx_quantiles | +------------------+ | [NULL, 6, 10]    | *------------------*/\n```\n\n"
  },
  {
    "name": "APPROX_TOP_COUNT",
    "arguments": [],
    "category": "Approximate aggregate functions",
    "description": "```\nAPPROX_TOP_COUNT(  expression, number)\n```\n\n **Description** \n\nReturns the approximate top elements of`expression`as an array of`STRUCT`s.The`number`parameter specifies the number of elements returned.\n\nEach`STRUCT`contains two fields. The first field (named`value`) contains aninput value. The second field (named`count`) contains an`INT64`specifying thenumber of times the value was returned.\n\nReturns`NULL`if there are zero input rows.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n **Supported Argument Types** \n\n- `    expression`: Any data type that the`    GROUP BY`clause supports.\n- `    number`:`    INT64`literal or query parameter.\n\n **Returned Data Types** \n\n`ARRAY&lt;STRUCT&gt;`\n\n **Examples** \n\n```\nSELECT APPROX_TOP_COUNT(x, 2) as approx_top_countFROM UNNEST([\"apple\", \"apple\", \"pear\", \"pear\", \"pear\", \"banana\"]) as x;/*-------------------------* | approx_top_count        | +-------------------------+ | [{pear, 3}, {apple, 2}] | *-------------------------*/\n```\n\n **NULL handling** \n\n`APPROX_TOP_COUNT`does not ignore`NULL`s in the input. For example:\n\n```\nSELECT APPROX_TOP_COUNT(x, 2) as approx_top_countFROM UNNEST([NULL, \"pear\", \"pear\", \"pear\", \"apple\", NULL]) as x;/*------------------------* | approx_top_count       | +------------------------+ | [{pear, 3}, {NULL, 2}] | *------------------------*/\n```\n\n"
  },
  {
    "name": "APPROX_TOP_SUM",
    "arguments": [],
    "category": "Approximate aggregate functions",
    "description": "```\nAPPROX_TOP_SUM(  expression, weight, number)\n```\n\n **Description** \n\nReturns the approximate top elements of`expression`, based on the sum of anassigned`weight`. The`number`parameter specifies the number of elementsreturned.\n\nIf the`weight`input is negative or`NaN`, this function returns an error.\n\nThe elements are returned as an array of`STRUCT`s.Each`STRUCT`contains two fields:`value`and`sum`.The`value`field contains the value of the input expression. The`sum`field isthe same type as`weight`, and is the approximate sum of the input weightassociated with the`value`field.\n\nReturns`NULL`if there are zero input rows.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n **Supported Argument Types** \n\n- `    expression`: Any data type that the`    GROUP BY`clause supports.\n- `    weight`: One of the following:\n    \n    \n    - `        INT64`\n    - `        NUMERIC`\n    - `        BIGNUMERIC`\n    - `        FLOAT64`\n- `    number`:`    INT64`literal or query parameter.\n    \n    \n\n **Returned Data Types** \n\n`ARRAY&lt;STRUCT&gt;`\n\n **Examples** \n\n```\nSELECT APPROX_TOP_SUM(x, weight, 2) AS approx_top_sum FROMUNNEST([  STRUCT(\"apple\" AS x, 3 AS weight),  (\"pear\", 2),  (\"apple\", 0),  (\"banana\", 5),  (\"pear\", 4)]);/*--------------------------* | approx_top_sum           | +--------------------------+ | [{pear, 6}, {banana, 5}] | *--------------------------*/\n```\n\n **NULL handling** \n\n`APPROX_TOP_SUM`does not ignore`NULL`values for the`expression`and`weight`parameters.\n\n```\nSELECT APPROX_TOP_SUM(x, weight, 2) AS approx_top_sum FROMUNNEST([STRUCT(\"apple\" AS x, NULL AS weight), (\"pear\", 0), (\"pear\", NULL)]);/*----------------------------* | approx_top_sum             | +----------------------------+ | [{pear, 0}, {apple, NULL}] | *----------------------------*/\n```\n\n```\nSELECT APPROX_TOP_SUM(x, weight, 2) AS approx_top_sum FROMUNNEST([STRUCT(\"apple\" AS x, 0 AS weight), (NULL, 2)]);/*-------------------------* | approx_top_sum          | +-------------------------+ | [{NULL, 2}, {apple, 0}] | *-------------------------*/\n```\n\n```\nSELECT APPROX_TOP_SUM(x, weight, 2) AS approx_top_sum FROMUNNEST([STRUCT(\"apple\" AS x, 0 AS weight), (NULL, NULL)]);/*----------------------------* | approx_top_sum             | +----------------------------+ | [{apple, 0}, {NULL, NULL}] | *----------------------------*/\n```\n\n\n<span id=\"array_functions\">\n## Array functions\n\n</span>\nGoogleSQL for BigQuery supports the following array functions.\n\n"
  },
  {
    "name": "ARRAY",
    "arguments": [],
    "category": "Array functions",
    "description": "```\nARRAY(subquery)\n```\n\n **Description** \n\nThe`ARRAY`function returns an`ARRAY`with one element for each row in a[subquery](/bigquery/docs/reference/standard-sql/subqueries).\n\nIf`subquery`produces aSQL table,the table must have exactly one column. Each element in the output`ARRAY`isthe value of the single column of a row in the table.\n\nIf`subquery`produces avalue table,then each element in the output`ARRAY`is the entire corresponding row of thevalue table.\n\n **Constraints** \n\n- Subqueries are unordered, so the elements of the output`    ARRAY`are notguaranteed to preserve any order in the source table for the subquery. However,if the subquery includes an`    ORDER BY`clause, the`    ARRAY`function will returnan`    ARRAY`that honors that clause.\n- If the subquery returns more than one column, the`    ARRAY`function returns anerror.\n- If the subquery returns an`    ARRAY`typed column or`    ARRAY`typed rows, the`    ARRAY`function returns an error that GoogleSQL does not support`    ARRAY`s with elements of type[ARRAY](/bigquery/docs/reference/standard-sql/data-types#array_type).\n- If the subquery returns zero rows, the`    ARRAY`function returns an empty`    ARRAY`. It never returns a`    NULL``    ARRAY`.\n\n **Return type** \n\n`ARRAY`\n\n **Examples** \n\n```\nSELECT ARRAY  (SELECT 1 UNION ALL   SELECT 2 UNION ALL   SELECT 3) AS new_array;/*-----------* | new_array | +-----------+ | [1, 2, 3] | *-----------*/\n```\n\nTo construct an`ARRAY`from a subquery that contains multiplecolumns, change the subquery to use`SELECT AS STRUCT`. Nowthe`ARRAY`function will return an`ARRAY`of`STRUCT`s. The`ARRAY`willcontain one`STRUCT`for each row in the subquery, and each of these`STRUCT`swill contain a field for each column in that row.\n\n```\nSELECT  ARRAY    (SELECT AS STRUCT 1, 2, 3     UNION ALL SELECT AS STRUCT 4, 5, 6) AS new_array;/*------------------------* | new_array              | +------------------------+ | [{1, 2, 3}, {4, 5, 6}] | *------------------------*/\n```\n\nSimilarly, to construct an`ARRAY`from a subquery that containsone or more`ARRAY`s, change the subquery to use`SELECT AS STRUCT`.\n\n```\nSELECT ARRAY  (SELECT AS STRUCT [1, 2, 3] UNION ALL   SELECT AS STRUCT [4, 5, 6]) AS new_array;/*----------------------------* | new_array                  | +----------------------------+ | [{[1, 2, 3]}, {[4, 5, 6]}] | *----------------------------*/\n```\n\n"
  },
  {
    "name": "ARRAY_AGG",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nARRAY_AGG(  [ DISTINCT ]  expression  [ { IGNORE | RESPECT } NULLS ]  [ ORDER BY key [ { ASC | DESC } ] [, ... ] ]  [ LIMIT n ])[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns an ARRAY of`expression`values.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nIf this function is used with the`OVER`clause, it's part of awindow function call. In a window function call,aggregate function clauses can't be used.To learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\nAn error is raised if an array in the final query result contains a`NULL`element.\n\n **Supported Argument Types** \n\nAll data types except ARRAY.\n\n **Returned Data Types** \n\nARRAY\n\nIf there are zero input rows, this function returns`NULL`.\n\n **Examples** \n\n```\nSELECT ARRAY_AGG(x) AS array_agg FROM UNNEST([2, 1,-2, 3, -2, 1, 2]) AS x;/*-------------------------* | array_agg               | +-------------------------+ | [2, 1, -2, 3, -2, 1, 2] | *-------------------------*/\n```\n\n```\nSELECT ARRAY_AGG(DISTINCT x) AS array_aggFROM UNNEST([2, 1, -2, 3, -2, 1, 2]) AS x;/*---------------* | array_agg     | +---------------+ | [2, 1, -2, 3] | *---------------*/\n```\n\n```\nSELECT ARRAY_AGG(x IGNORE NULLS) AS array_aggFROM UNNEST([NULL, 1, -2, 3, -2, 1, NULL]) AS x;/*-------------------* | array_agg         | +-------------------+ | [1, -2, 3, -2, 1] | *-------------------*/\n```\n\n```\nSELECT ARRAY_AGG(x ORDER BY ABS(x)) AS array_aggFROM UNNEST([2, 1, -2, 3, -2, 1, 2]) AS x;/*-------------------------* | array_agg               | +-------------------------+ | [1, 1, 2, -2, -2, 2, 3] | *-------------------------*/\n```\n\n```\nSELECT ARRAY_AGG(x LIMIT 5) AS array_aggFROM UNNEST([2, 1, -2, 3, -2, 1, 2]) AS x;/*-------------------* | array_agg         | +-------------------+ | [2, 1, -2, 3, -2] | *-------------------*/\n```\n\n```\nWITH vals AS  (    SELECT 1 x UNION ALL    SELECT -2 x UNION ALL    SELECT 3 x UNION ALL    SELECT -2 x UNION ALL    SELECT 1 x  )SELECT ARRAY_AGG(DISTINCT x ORDER BY x) as array_aggFROM vals;/*------------* | array_agg  | +------------+ | [-2, 1, 3] | *------------*/\n```\n\n```\nWITH vals AS  (    SELECT 1 x, 'a' y UNION ALL    SELECT 1 x, 'b' y UNION ALL    SELECT 2 x, 'a' y UNION ALL    SELECT 2 x, 'c' y  )SELECT x, ARRAY_AGG(y) as array_aggFROM valsGROUP BY x;/*---------------* | x | array_agg | +---------------+ | 1 | [a, b]    | | 2 | [a, c]    | *---------------*/\n```\n\n```\nSELECT  x,  ARRAY_AGG(x) OVER (ORDER BY ABS(x)) AS array_aggFROM UNNEST([2, 1, -2, 3, -2, 1, 2]) AS x;/*----+-------------------------* | x  | array_agg               | +----+-------------------------+ | 1  | [1, 1]                  | | 1  | [1, 1]                  | | 2  | [1, 1, 2, -2, -2, 2]    | | -2 | [1, 1, 2, -2, -2, 2]    | | -2 | [1, 1, 2, -2, -2, 2]    | | 2  | [1, 1, 2, -2, -2, 2]    | | 3  | [1, 1, 2, -2, -2, 2, 3] | *----+-------------------------*/\n```\n\n"
  },
  {
    "name": "ARRAY_CONCAT",
    "arguments": [],
    "category": "Array functions",
    "description": "```\nARRAY_CONCAT(array_expression[, ...])\n```\n\n **Description** \n\nConcatenates one or more arrays with the same element type into a single array.\n\nThe function returns`NULL`if any input argument is`NULL`.\n\n **Note:** You can also use the[|| concatenation operator](#operators)to concatenate arrays. **Return type** \n\n`ARRAY`\n\n **Examples** \n\n```\nSELECT ARRAY_CONCAT([1, 2], [3, 4], [5, 6]) as count_to_six;/*--------------------------------------------------* | count_to_six                                     | +--------------------------------------------------+ | [1, 2, 3, 4, 5, 6]                               | *--------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ARRAY_CONCAT_AGG",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nARRAY_CONCAT_AGG(  expression  [ ORDER BY key [ { ASC | DESC } ] [, ... ] ]  [ LIMIT n ])\n```\n\n **Description** \n\nConcatenates elements from`expression`of type`ARRAY`, returning a singlearray as a result.\n\nThis function ignores`NULL`input arrays, but respects the`NULL`elements innon-`NULL`input arrays. Anerror is raised, however, if an array in the final query result contains a`NULL`element. Returns`NULL`if there are zero input rows or`expression`evaluates to`NULL`for all rows.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n **Supported Argument Types** \n\n`ARRAY`\n\n **Returned Data Types** \n\n`ARRAY`\n\n **Examples** \n\n```\nSELECT FORMAT(\"%T\", ARRAY_CONCAT_AGG(x)) AS array_concat_agg FROM (  SELECT [NULL, 1, 2, 3, 4] AS x  UNION ALL SELECT NULL  UNION ALL SELECT [5, 6]  UNION ALL SELECT [7, 8, 9]);/*-----------------------------------* | array_concat_agg                  | +-----------------------------------+ | [NULL, 1, 2, 3, 4, 5, 6, 7, 8, 9] | *-----------------------------------*/\n```\n\n```\nSELECT FORMAT(\"%T\", ARRAY_CONCAT_AGG(x ORDER BY ARRAY_LENGTH(x))) AS array_concat_agg FROM (  SELECT [1, 2, 3, 4] AS x  UNION ALL SELECT [5, 6]  UNION ALL SELECT [7, 8, 9]);/*-----------------------------------* | array_concat_agg                  | +-----------------------------------+ | [5, 6, 7, 8, 9, 1, 2, 3, 4]       | *-----------------------------------*/\n```\n\n```\nSELECT FORMAT(\"%T\", ARRAY_CONCAT_AGG(x LIMIT 2)) AS array_concat_agg FROM (  SELECT [1, 2, 3, 4] AS x  UNION ALL SELECT [5, 6]  UNION ALL SELECT [7, 8, 9]);/*--------------------------* | array_concat_agg         | +--------------------------+ | [1, 2, 3, 4, 5, 6]       | *--------------------------*/\n```\n\n```\nSELECT FORMAT(\"%T\", ARRAY_CONCAT_AGG(x ORDER BY ARRAY_LENGTH(x) LIMIT 2)) AS array_concat_agg FROM (  SELECT [1, 2, 3, 4] AS x  UNION ALL SELECT [5, 6]  UNION ALL SELECT [7, 8, 9]);/*------------------* | array_concat_agg | +------------------+ | [5, 6, 7, 8, 9]  | *------------------*/\n```\n\n"
  },
  {
    "name": "ARRAY_LENGTH",
    "arguments": [],
    "category": "Array functions",
    "description": "```\nARRAY_LENGTH(array_expression)\n```\n\n **Description** \n\nReturns the size of the array. Returns 0 for an empty array. Returns`NULL`ifthe`array_expression`is`NULL`.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH items AS  (SELECT [\"coffee\", NULL, \"milk\" ] as list  UNION ALL  SELECT [\"cake\", \"pie\"] as list)SELECT ARRAY_TO_STRING(list, ', ', 'NULL'), ARRAY_LENGTH(list) AS sizeFROM itemsORDER BY size DESC;/*--------------------+------* | list               | size | +--------------------+------+ | coffee, NULL, milk | 3    | | cake, pie          | 2    | *--------------------+------*/\n```\n\n"
  },
  {
    "name": "ARRAY_REVERSE",
    "arguments": [],
    "category": "Array functions",
    "description": "```\nARRAY_REVERSE(value)\n```\n\n **Description** \n\nReturns the input`ARRAY`with elements in reverse order.\n\n **Return type** \n\n`ARRAY`\n\n **Examples** \n\n```\nWITH example AS (  SELECT [1, 2, 3] AS arr UNION ALL  SELECT [4, 5] AS arr UNION ALL  SELECT [] AS arr)SELECT  arr,  ARRAY_REVERSE(arr) AS reverse_arrFROM example;/*-----------+-------------* | arr       | reverse_arr | +-----------+-------------+ | [1, 2, 3] | [3, 2, 1]   | | [4, 5]    | [5, 4]      | | []        | []          | *-----------+-------------*/\n```\n\n"
  },
  {
    "name": "ARRAY_TO_STRING",
    "arguments": [],
    "category": "Array functions",
    "description": "```\nARRAY_TO_STRING(array_expression, delimiter[, null_text])\n```\n\n **Description** \n\nReturns a concatenation of the elements in`array_expression`as a`STRING`. The value for`array_expression`can either be an array of`STRING`or`BYTES`data types.\n\nIf the`null_text`parameter is used, the function replaces any`NULL`values inthe array with the value of`null_text`.\n\nIf the`null_text`parameter is not used, the function omits the`NULL`valueand its preceding delimiter.\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n```\nWITH items AS  (SELECT ['coffee', 'tea', 'milk' ] as list  UNION ALL  SELECT ['cake', 'pie', NULL] as list)SELECT ARRAY_TO_STRING(list, '--') AS textFROM items;/*--------------------------------* | text                           | +--------------------------------+ | coffee--tea--milk              | | cake--pie                      | *--------------------------------*/\n```\n\n```\nWITH items AS  (SELECT ['coffee', 'tea', 'milk' ] as list  UNION ALL  SELECT ['cake', 'pie', NULL] as list)SELECT ARRAY_TO_STRING(list, '--', 'MISSING') AS textFROM items;/*--------------------------------* | text                           | +--------------------------------+ | coffee--tea--milk              | | cake--pie--MISSING             | *--------------------------------*/\n```\n\n"
  },
  {
    "name": "ASCII",
    "arguments": [],
    "category": "String functions",
    "description": "```\nASCII(value)\n```\n\n **Description** \n\nReturns the ASCII code for the first character or byte in`value`. Returns`0`if`value`is empty or the ASCII code is`0`for the first characteror byte.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nSELECT ASCII('abcd') as A, ASCII('a') as B, ASCII('') as C, ASCII(NULL) as D;/*-------+-------+-------+-------* | A     | B     | C     | D     | +-------+-------+-------+-------+ | 97    | 97    | 0     | NULL  | *-------+-------+-------+-------*/\n```\n\n"
  },
  {
    "name": "ASIN",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nASIN(X)\n```\n\n **Description** \n\nComputes the principal value of the inverse sine of X. The return value is inthe range [-π/2,π/2]. Generates an error if X is outside ofthe range [-1, 1].\n\n| X | ASIN(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n| X < -1 | Error |\n| X > 1 | Error |\n\n"
  },
  {
    "name": "ASINH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nASINH(X)\n```\n\n **Description** \n\nComputes the inverse hyperbolic sine of X. Does not fail.\n\n| X | ASINH(X) |\n| --- | --- |\n| `+inf` | `+inf` |\n| `-inf` | `-inf` |\n| `NaN` | `NaN` |\n\n"
  },
  {
    "name": "ATAN",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nATAN(X)\n```\n\n **Description** \n\nComputes the principal value of the inverse tangent of X. The return value isin the range [-π/2,π/2]. Does not fail.\n\n| X | ATAN(X) |\n| --- | --- |\n| `+inf` | π/2 |\n| `-inf` | -π/2 |\n| `NaN` | `NaN` |\n\n"
  },
  {
    "name": "ATAN2",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nATAN2(X, Y)\n```\n\n **Description** \n\nCalculates the principal value of the inverse tangent of X/Y using the signs ofthe two arguments to determine the quadrant. The return value is in the range[-π,π].\n\n| X | Y | ATAN2(X, Y) |\n| --- | --- | --- |\n| `NaN` | Any value | `NaN` |\n| Any value | `NaN` | `NaN` |\n| 0.0 | 0.0 | 0.0 |\n| Positive Finite value | `-inf` | π |\n| Negative Finite value | `-inf` | -π |\n| Finite value | `+inf` | 0.0 |\n| `+inf` | Finite value | π/2 |\n| `-inf` | Finite value | -π/2 |\n| `+inf` | `-inf` | ¾π |\n| `-inf` | `-inf` | -¾π |\n| `+inf` | `+inf` | π/4 |\n| `-inf` | `+inf` | -π/4 |\n\n"
  },
  {
    "name": "ATANH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nATANH(X)\n```\n\n **Description** \n\nComputes the inverse hyperbolic tangent of X. Generates an error if X is outsideof the range (-1, 1).\n\n| X | ATANH(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n| X < -1 | Error |\n| X > 1 | Error |\n\n"
  },
  {
    "name": "AVG",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nAVG(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the average of non-`NULL`values in an aggregated group.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nIf this function is used with the`OVER`clause, it's part of awindow function call. In a window function call,aggregate function clauses can't be used.To learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n`AVG`can be used with differential privacy. For more information, see[Differentially private aggregate functions](#aggregate-dp-functions).\n\nCaveats:\n\n- If the aggregated group is empty or the argument is`    NULL`for all rows inthe group, returns`    NULL`.\n- If the argument is`    NaN`for any row in the group, returns`    NaN`.\n- If the argument is`    [+|-]Infinity`for any row in the group, returns either`    [+|-]Infinity`or`    NaN`.\n- If there is numeric overflow, produces an error.\n- If a[floating-point type](/bigquery/docs/reference/standard-sql/data-types#floating_point_types)is returned, the result is[non-deterministic](/bigquery/docs/reference/standard-sql/data-types#floating-point-semantics), which means you might receive adifferent result each time you use this function.\n\n **Supported Argument Types** \n\n- Any numeric input type\n- `    INTERVAL`\n\n **Returned Data Types** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` | `INTERVAL` |\n| --- | --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` | `INTERVAL` |\n\n **Examples** \n\n```\nSELECT AVG(x) as avgFROM UNNEST([0, 2, 4, 4, 5]) as x;/*-----* | avg | +-----+ | 3   | *-----*/\n```\n\n```\nSELECT AVG(DISTINCT x) AS avgFROM UNNEST([0, 2, 4, 4, 5]) AS x;/*------* | avg  | +------+ | 2.75 | *------*/\n```\n\n```\nSELECT  x,  AVG(x) OVER (ORDER BY x ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS avgFROM UNNEST([0, 2, NULL, 4, 4, 5]) AS x;/*------+------* | x    | avg  | +------+------+ | NULL | NULL | | 0    | 0    | | 2    | 1    | | 4    | 3    | | 4    | 4    | | 5    | 4.5  | *------+------*/\n```\n\n"
  },
  {
    "name": "AVG (DIFFERENTIAL_PRIVACY)",
    "arguments": [],
    "category": "Differentially private aggregate functions",
    "description": "```\nWITH DIFFERENTIAL_PRIVACY ...  AVG(    expression,    [contribution_bounds_per_group =&gt; (lower_bound, upper_bound)]  )\n```\n\n **Description** \n\nReturns the average of non-`NULL`, non-`NaN`values in the expression.This function first computes the average per privacy unit column, and thencomputes the final result by averaging these averages.\n\nThis function must be used with the[DIFFERENTIAL_PRIVACY clause](/bigquery/docs/reference/standard-sql/query-syntax#dp_clause)and can support the following arguments:\n\n- `    expression`: The input expression. This can be any numeric input type,such as`    INT64`.\n- `    contribution_bounds_per_group`: The[contribution bounds named argument](#dp_clamped_named).Perform clamping per each group separately before performing intermediategrouping on the privacy unit column.\n\n **Return type** \n\n`FLOAT64`\n\n **Examples** \n\nThe following differentially private query gets the average number of each itemrequested per professor. Smaller aggregations might not be included. This queryreferences a table called[professors](/bigquery/docs/reference/standard-sql/query-syntax#dp_example_tables).\n\n```\n-- With noise, using the epsilon parameter.SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=10, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    AVG(quantity, contribution_bounds_per_group =&gt; (0,100)) average_quantityFROM professorsGROUP BY item;-- These results will change each time you run the query.-- Smaller aggregations might be removed./*----------+------------------* | item     | average_quantity | +----------+------------------+ | pencil   | 38.5038356810269 | | pen      | 13.4725028762032 | *----------+------------------*/\n```\n\n```\n-- Without noise, using the epsilon parameter.-- (this un-noised version is for demonstration only)SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=1e20, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    AVG(quantity) average_quantityFROM professorsGROUP BY item;-- These results will not change when you run the query./*----------+------------------* | item     | average_quantity | +----------+------------------+ | scissors | 8                | | pencil   | 40               | | pen      | 18.5             | *----------+------------------*/\n```\n\n **Note:** For more information about when and when not to usenoise, see[Remove noise](/bigquery/docs/reference/standard-sql/query-syntax#eliminate_noise)."
  },
  {
    "name": "BIT_AND",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nBIT_AND(  expression)\n```\n\n **Description** \n\nPerforms a bitwise AND operation on`expression`and returns the result.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n **Supported Argument Types** \n\n- INT64\n\n **Returned Data Types** \n\nINT64\n\n **Examples** \n\n```\nSELECT BIT_AND(x) as bit_and FROM UNNEST([0xF001, 0x00A1]) as x;/*---------* | bit_and | +---------+ | 1       | *---------*/\n```\n\n"
  },
  {
    "name": "BIT_COUNT",
    "arguments": [],
    "category": "Bit functions",
    "description": "```\nBIT_COUNT(expression)\n```\n\n **Description** \n\nThe input,`expression`, must be aninteger or`BYTES`.\n\nReturns the number of bits that are set in the input`expression`.For signed integers, this is the number of bits in two's complement form.\n\n **Return Data Type** \n\n`INT64`\n\n **Example** \n\n```\nSELECT a, BIT_COUNT(a) AS a_bits, FORMAT(\"%T\", b) as b, BIT_COUNT(b) AS b_bitsFROM UNNEST([  STRUCT(0 AS a, b'' AS b), (0, b'\\x00'), (5, b'\\x05'), (8, b'\\x00\\x08'),  (0xFFFF, b'\\xFF\\xFF'), (-2, b'\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFE'),  (-1, b'\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF'),  (NULL, b'\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF')]) AS x;/*-------+--------+---------------------------------------------+--------* | a     | a_bits | b                                           | b_bits | +-------+--------+---------------------------------------------+--------+ | 0     | 0      | b\"\"                                         | 0      | | 0     | 0      | b\"\\x00\"                                     | 0      | | 5     | 2      | b\"\\x05\"                                     | 2      | | 8     | 1      | b\"\\x00\\x08\"                                 | 1      | | 65535 | 16     | b\"\\xff\\xff\"                                 | 16     | | -2    | 63     | b\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\"         | 63     | | -1    | 64     | b\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\"         | 64     | | NULL  | NULL   | b\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\" | 80     | *-------+--------+---------------------------------------------+--------*/\n```\n\n\n<span id=\"conversion_functions\">\n## Conversion functions\n\n</span>\nGoogleSQL for BigQuery supports conversion functions. These data typeconversions are explicit, but some conversions can happen implicitly. You canlearn more about implicit and explicit conversion[here](/bigquery/docs/reference/standard-sql/conversion_rules#conversion_rules).\n\n"
  },
  {
    "name": "BIT_OR",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nBIT_OR(  expression)\n```\n\n **Description** \n\nPerforms a bitwise OR operation on`expression`and returns the result.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n **Supported Argument Types** \n\n- INT64\n\n **Returned Data Types** \n\nINT64\n\n **Examples** \n\n```\nSELECT BIT_OR(x) as bit_or FROM UNNEST([0xF001, 0x00A1]) as x;/*--------* | bit_or | +--------+ | 61601  | *--------*/\n```\n\n"
  },
  {
    "name": "BIT_XOR",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nBIT_XOR(  [ DISTINCT ]  expression)\n```\n\n **Description** \n\nPerforms a bitwise XOR operation on`expression`and returns the result.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n **Supported Argument Types** \n\n- INT64\n\n **Returned Data Types** \n\nINT64\n\n **Examples** \n\n```\nSELECT BIT_XOR(x) AS bit_xor FROM UNNEST([5678, 1234]) AS x;/*---------* | bit_xor | +---------+ | 4860    | *---------*/\n```\n\n```\nSELECT BIT_XOR(x) AS bit_xor FROM UNNEST([1234, 5678, 1234]) AS x;/*---------* | bit_xor | +---------+ | 5678    | *---------*/\n```\n\n```\nSELECT BIT_XOR(DISTINCT x) AS bit_xor FROM UNNEST([1234, 5678, 1234]) AS x;/*---------* | bit_xor | +---------+ | 4860    | *---------*/\n```\n\n"
  },
  {
    "name": "BOOL",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nBOOL(json_expr)\n```\n\n **Description** \n\nConverts a JSON boolean to a SQL`BOOL`value.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON 'true'\n    ```\n    \n    If the JSON value is not a boolean, an error is produced. If the expressionis SQL`    NULL`, the function returns SQL`    NULL`.\n    \n    \n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\n```\nSELECT BOOL(JSON 'true') AS vacancy;/*---------* | vacancy | +---------+ | true    | *---------*/\n```\n\n```\nSELECT BOOL(JSON_QUERY(JSON '{\"hotel class\": \"5-star\", \"vacancy\": true}', \"$.vacancy\")) AS vacancy;/*---------* | vacancy | +---------+ | true    | *---------*/\n```\n\nThe following examples show how invalid requests are handled:\n\n```\n-- An error is thrown if JSON is not of type bool.SELECT BOOL(JSON '123') AS result; -- Throws an errorSELECT BOOL(JSON 'null') AS result; -- Throws an errorSELECT SAFE.BOOL(JSON '123') AS result; -- Returns a SQL NULL\n```\n\n"
  },
  {
    "name": "BYTE_LENGTH",
    "arguments": [],
    "category": "String functions",
    "description": "```\nBYTE_LENGTH(value)\n```\n\n **Description** \n\nGets the number of`BYTES`in a`STRING`or`BYTES`value,regardless of whether the value is a`STRING`or`BYTES`type.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH example AS  (SELECT 'абвгд' AS characters, b'абвгд' AS bytes)SELECT  characters,  BYTE_LENGTH(characters) AS string_example,  bytes,  BYTE_LENGTH(bytes) AS bytes_exampleFROM example;/*------------+----------------+-------+---------------* | characters | string_example | bytes | bytes_example | +------------+----------------+-------+---------------+ | абвгд      | 10             | абвгд | 10            | *------------+----------------+-------+---------------*/\n```\n\n"
  },
  {
    "name": "CAST",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS typename [format_clause])\n```\n\n **Description** \n\nCast syntax is used in a query to indicate that the result type of anexpression should be converted to some other type.\n\nWhen using`CAST`, a query can fail if GoogleSQL is unable to performthe cast. If you want to protect your queries from these types of errors, youcan use[SAFE_CAST](#safe_casting).\n\nCasts between supported types that do not successfully map from the originalvalue to the target domain produce runtime errors. For example, casting`BYTES`to`STRING`where the byte sequence is not valid UTF-8 results in aruntime error.\n\nSome casts can include a[format clause](/bigquery/docs/reference/standard-sql/format-elements#formatting_syntax), which providesinstructions for how to conduct thecast. For example, you couldinstruct a cast to convert a sequence of bytes to a BASE64-encoded stringinstead of a UTF-8-encoded string.\n\nThe structure of the format clause is unique to each type of cast and moreinformation is available in the section for that cast.\n\n **Examples** \n\nThe following query results in`\"true\"`if`x`is`1`,`\"false\"`for any othernon-`NULL`value, and`NULL`if`x`is`NULL`.\n\n```\nCAST(x=1 AS STRING)\n```\n\n"
  },
  {
    "name": "CAST AS ARRAY",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS ARRAY&lt;element_type&gt;)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`ARRAY`. The`expression`parameter can represent an expression for these data types:\n\n- `    ARRAY`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `ARRAY` | `ARRAY` | Must be the exact same array type. |\n\n"
  },
  {
    "name": "CAST AS BIGNUMERIC",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS BIGNUMERIC)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`BIGNUMERIC`. The`expression`parameter can represent an expression for these data types:\n\n- `    INT64`\n- `    FLOAT64`\n- `    NUMERIC`\n- `    BIGNUMERIC`\n- `    STRING`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| FLOAT64 | `BIGNUMERIC` | The floating point number will round[half away from zero](https://en.wikipedia.org/wiki/Rounding#Round_half_away_from_zero).      Casting a`NaN`,`+inf`or`-inf`will return an error. Casting a value outside the range      of`BIGNUMERIC`returns an overflow error. |\n| `STRING` | `BIGNUMERIC` | The numeric literal contained in the string must not exceed      the maximum precision or range of the`BIGNUMERIC`type, or an error will occur. If the number of      digits after the decimal point exceeds 38, then the resulting`BIGNUMERIC`value will round[half away from zero](https://en.wikipedia.org/wiki/Rounding#Round_half_away_from_zero)to have 38 digits after the decimal point. |\n\n"
  },
  {
    "name": "CAST AS BOOL",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS BOOL)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`BOOL`. The`expression`parameter can represent an expression for these data types:\n\n- `    INT64`\n- `    BOOL`\n- `    STRING`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| INT64 | `BOOL` | Returns`FALSE`if`x`is`0`,`TRUE`otherwise. |\n| `STRING` | `BOOL` | Returns`TRUE`if`x`is`\"true\"`and`FALSE`if`x`is`\"false\"`    \nAll other values of`x`are invalid and throw an error instead      of casting to a boolean.    \nA string is case-insensitive when converting      to a boolean. |\n\n"
  },
  {
    "name": "CAST AS BYTES",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS BYTES [format_clause])\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`BYTES`. The`expression`parameter can represent an expression for these data types:\n\n- `    BYTES`\n- `    STRING`\n\n **Format clause** \n\nWhen an expression of one type is cast to another type, you can use the[format clause](/bigquery/docs/reference/standard-sql/format-elements#formatting_syntax)to provide instructions for how to conductthe cast. You can use the format clause in this section if`expression`is a`STRING`.\n\n- [Format string as bytes](/bigquery/docs/reference/standard-sql/format-elements#format_string_as_bytes)\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `STRING` | `BYTES` | Strings are cast to bytes using UTF-8 encoding. For example,      the string \"©\", when cast to      bytes, would become a 2-byte sequence with the      hex values C2 and A9. |\n\n"
  },
  {
    "name": "CAST AS DATE",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS DATE [format_clause])\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`DATE`. The`expression`parameter can represent an expression for these data types:\n\n- `    STRING`\n- `    DATETIME`\n- `    TIMESTAMP`\n\n **Format clause** \n\nWhen an expression of one type is cast to another type, you can use the[format clause](/bigquery/docs/reference/standard-sql/format-elements#formatting_syntax)to provide instructions for how to conductthe cast. You can use the format clause in this section if`expression`is a`STRING`.\n\n- [Format string as date and time](/bigquery/docs/reference/standard-sql/format-elements#format_string_as_datetime)\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `STRING` | `DATE` | When casting from string to date, the string must conform to      the supported date literal format, and is independent of time zone. If the      string expression is invalid or represents a date that is outside of the      supported min/max range, then an error is produced. |\n| `TIMESTAMP` | `DATE` | Casting from a timestamp to date effectively truncates the timestamp as      of the default time zone. |\n\n"
  },
  {
    "name": "CAST AS DATETIME",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS DATETIME [format_clause])\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`DATETIME`. The`expression`parameter can represent an expression for these data types:\n\n- `    STRING`\n- `    DATETIME`\n- `    TIMESTAMP`\n\n **Format clause** \n\nWhen an expression of one type is cast to another type, you can use the[format clause](/bigquery/docs/reference/standard-sql/format-elements#formatting_syntax)to provide instructions for how to conductthe cast. You can use the format clause in this section if`expression`is a`STRING`.\n\n- [Format string as date and time](/bigquery/docs/reference/standard-sql/format-elements#format_string_as_datetime)\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `STRING` | `DATETIME` | When casting from string to datetime, the string must conform to the      supported datetime literal format, and is independent of time zone. If      the string expression is invalid or represents a datetime that is outside      of the supported min/max range, then an error is produced. |\n| `TIMESTAMP` | `DATETIME` | Casting from a timestamp to datetime effectively truncates the timestamp      as of the default time zone. |\n\n"
  },
  {
    "name": "CAST AS FLOAT64",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS FLOAT64)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to floating point types.The`expression`parameter can represent an expression for these data types:\n\n- `    INT64`\n- `    FLOAT64`\n- `    NUMERIC`\n- `    BIGNUMERIC`\n- `    STRING`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| INT64 | FLOAT64 | Returns a close but potentially not exact floating point value. |\n| `NUMERIC` | FLOAT64 | `NUMERIC`will convert to the closest floating point number      with a possible loss of precision. |\n| `BIGNUMERIC` | FLOAT64 | `BIGNUMERIC`will convert to the closest floating point number      with a possible loss of precision. |\n| `STRING` | FLOAT64 | Returns`x`as a floating point value, interpreting it as      having the same form as a valid floating point literal.      Also supports casts from`\"[+,-]inf\"`to`[,-]Infinity`,`\"[+,-]infinity\"`to`[,-]Infinity`, and`\"[+,-]nan\"`to`NaN`.      Conversions are case-insensitive. |\n\n"
  },
  {
    "name": "CAST AS INT64",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS INT64)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to integer types.The`expression`parameter can represent an expression for these data types:\n\n- `    INT64`\n- `    FLOAT64`\n- `    NUMERIC`\n- `    BIGNUMERIC`\n- `    BOOL`\n- `    STRING`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| FLOAT64 | INT64 | Returns the closest integer value.    \nHalfway cases such as 1.5 or -0.5 round away from zero. |\n| `BOOL` | INT64 | Returns`1`if`x`is`TRUE`,`0`otherwise. |\n| `STRING` | INT64 | A hex string can be cast to an integer. For example,`0x123`to`291`or`-0x123`to`-291`. |\n\n **Examples** \n\nIf you are working with hex strings (`0x123`), you can cast those strings asintegers:\n\n```\nSELECT '0x123' as hex_value, CAST('0x123' as INT64) as hex_to_int;/*-----------+------------* | hex_value | hex_to_int | +-----------+------------+ | 0x123     | 291        | *-----------+------------*/\n```\n\n```\nSELECT '-0x123' as hex_value, CAST('-0x123' as INT64) as hex_to_int;/*-----------+------------* | hex_value | hex_to_int | +-----------+------------+ | -0x123    | -291       | *-----------+------------*/\n```\n\n"
  },
  {
    "name": "CAST AS INTERVAL",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS INTERVAL)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`INTERVAL`. The`expression`parameter can represent an expression for these data types:\n\n- `    STRING`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `STRING` | `INTERVAL` | When casting from string to interval, the string must conform to either[ISO 8601 Duration](https://en.wikipedia.org/wiki/ISO_8601#Durations)standard or to interval literal      format 'Y-M D H:M:S.F'. Partial interval literal formats are also accepted      when they are not ambiguous, for example 'H:M:S'.      If the string expression is invalid or represents an interval that is      outside of the supported min/max range, then an error is produced. |\n\n **Examples** \n\n```\nSELECT input, CAST(input AS INTERVAL) AS outputFROM UNNEST([  '1-2 3 10:20:30.456',  '1-2',  '10:20:30',  'P1Y2M3D',  'PT10H20M30,456S']) input/*--------------------+--------------------* | input              | output             | +--------------------+--------------------+ | 1-2 3 10:20:30.456 | 1-2 3 10:20:30.456 | | 1-2                | 1-2 0 0:0:0        | | 10:20:30           | 0-0 0 10:20:30     | | P1Y2M3D            | 1-2 3 0:0:0        | | PT10H20M30,456S    | 0-0 0 10:20:30.456 | *--------------------+--------------------*/\n```\n\n"
  },
  {
    "name": "CAST AS NUMERIC",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS NUMERIC)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`NUMERIC`. The`expression`parameter can represent an expression for these data types:\n\n- `    INT64`\n- `    FLOAT64`\n- `    NUMERIC`\n- `    BIGNUMERIC`\n- `    STRING`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `FLOAT64` | `NUMERIC` | The floating point number will round[half away from zero](https://en.wikipedia.org/wiki/Rounding#Round_half_away_from_zero).      Casting a`NaN`,`+inf`or`-inf`will return an error. Casting a value outside the range      of`NUMERIC`returns an overflow error. |\n| `STRING` | `NUMERIC` | The numeric literal contained in the string must not exceed      the maximum precision or range of the`NUMERIC`type, or an error will occur. If the number of digits      after the decimal point exceeds nine, then the resulting`NUMERIC`value will round[half away from zero](https://en.wikipedia.org/wiki/Rounding#Round_half_away_from_zero).      to have nine digits after the decimal point. |\n\n"
  },
  {
    "name": "CAST AS RANGE",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS RANGE)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`RANGE`. The`expression`parameter can represent an expression for these data types:\n\n- `    STRING`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `STRING` | `RANGE` | When casting from string to range, the string must conform to the      supported range literal format. If the string expression is invalid or      represents a range that is outside of the supported subtype min/max range,      then an error is produced. |\n\n **Examples** \n\n```\nSELECT CAST(  '[2020-01-01, 2020-01-02)'  AS RANGE&lt;DATE&gt;) AS string_to_range/*----------------------------------------* | string_to_range                        | +----------------------------------------+ | [DATE '2020-01-01', DATE '2020-01-02') | *----------------------------------------*/\n```\n\n```\nSELECT CAST(  '[2014-09-27 12:30:00.45, 2016-10-17 11:15:00.33)'  AS RANGE&lt;DATETIME&gt;) AS string_to_range/*------------------------------------------------------------------------* | string_to_range                                                        | +------------------------------------------------------------------------+ | [DATETIME '2014-09-27 12:30:00.45', DATETIME '2016-10-17 11:15:00.33') | *------------------------------------------------------------------------*/\n```\n\n```\nSELECT CAST(  '[2014-09-27 12:30:00+08, 2016-10-17 11:15:00+08)'  AS RANGE&lt;TIMESTAMP&gt;) AS string_to_range-- Results depend upon where this query was executed./*---------------------------------------------------------------------------* | string_to_range                                                           | +---------------------------------------------------------------------------+ | [TIMESTAMP '2014-09-27 12:30:00+08', TIMESTAMP '2016-10-17 11:15:00 UTC') | *---------------------------------------------------------------------------*/\n```\n\n```\nSELECT CAST(  '[UNBOUNDED, 2020-01-02)'  AS RANGE&lt;DATE&gt;) AS string_to_range/*--------------------------------* | string_to_range                | +--------------------------------+ | [UNBOUNDED, DATE '2020-01-02') | *--------------------------------*/\n```\n\n```\nSELECT CAST(  '[2020-01-01, NULL)'  AS RANGE&lt;DATE&gt;) AS string_to_range/*--------------------------------* | string_to_range                | +--------------------------------+ | [DATE '2020-01-01', UNBOUNDED) | *--------------------------------*/\n```\n\n"
  },
  {
    "name": "CAST AS STRING",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS STRING [format_clause [AT TIME ZONE timezone_expr]])\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`STRING`. The`expression`parameter can represent an expression for these data types:\n\n- `    INT64`\n- `    FLOAT64`\n- `    NUMERIC`\n- `    BIGNUMERIC`\n- `    BOOL`\n- `    BYTES`\n- `    TIME`\n- `    DATE`\n- `    DATETIME`\n- `    TIMESTAMP`\n- `    RANGE`\n- `    INTERVAL`\n- `    STRING`\n\n **Format clause** \n\nWhen an expression of one type is cast to another type, you can use the[format clause](/bigquery/docs/reference/standard-sql/format-elements#formatting_syntax)to provide instructions for how to conductthe cast. You can use the format clause in this section if`expression`is oneof these data types:\n\n- `    INT64`\n- `    FLOAT64`\n- `    NUMERIC`\n- `    BIGNUMERIC`\n- `    BYTES`\n- `    TIME`\n- `    DATE`\n- `    DATETIME`\n- `    TIMESTAMP`\n\nThe format clause for`STRING`has an additional optional clause called`AT TIME ZONE timezone_expr`, which you can use to specify a specific time zoneto use during formatting of a`TIMESTAMP`. If this optional clause is notincluded when formatting a`TIMESTAMP`, your current time zone is used.\n\nFor more information, see the following topics:\n\n- [Format bytes as string](/bigquery/docs/reference/standard-sql/format-elements#format_bytes_as_string)\n- [Format date and time as string](/bigquery/docs/reference/standard-sql/format-elements#format_date_time_as_string)\n- [Format numeric type as string](/bigquery/docs/reference/standard-sql/format-elements#format_numeric_type_as_string)\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| FLOAT64 | `STRING` | Returns an approximate string representation. A returned`NaN`or`0`will not be signed.    \n |\n| `BOOL` | `STRING` | Returns`\"true\"`if`x`is`TRUE`,`\"false\"`otherwise. |\n| `BYTES` | `STRING` | Returns`x`interpreted as a UTF-8 string.    \nFor example, the bytes literal`b'\\xc2\\xa9'`, when cast to a string,      is interpreted as UTF-8 and becomes the unicode character \"©\".    \nAn error occurs if`x`is not valid UTF-8. |\n| `TIME` | `STRING` | Casting from a time type to a string is independent of time zone and      is of the form`HH:MM:SS`. |\n| `DATE` | `STRING` | Casting from a date type to a string is independent of time zone and is      of the form`YYYY-MM-DD`. |\n| `DATETIME` | `STRING` | Casting from a datetime type to a string is independent of time zone and      is of the form`YYYY-MM-DD HH:MM:SS`. |\n| `TIMESTAMP` | `STRING` | When casting from timestamp types to string, the timestamp is interpreted      using the default time zone, UTC. The number of      subsecond digits produced depends on the number of trailing zeroes in the      subsecond part: the CAST function will truncate zero, three, or six      digits. |\n| `INTERVAL` | `STRING` | Casting from an interval to a string is of the form`Y-M D H:M:S`. |\n\n **Examples** \n\n```\nSELECT CAST(CURRENT_DATE() AS STRING) AS current_date/*---------------* | current_date  | +---------------+ | 2021-03-09    | *---------------*/\n```\n\n```\nSELECT CAST(CURRENT_DATE() AS STRING FORMAT 'DAY') AS current_day/*-------------* | current_day | +-------------+ | MONDAY      | *-------------*/\n```\n\n```\nSELECT CAST(  TIMESTAMP '2008-12-25 00:00:00+00:00'  AS STRING FORMAT 'YYYY-MM-DD HH24:MI:SS TZH:TZM') AS date_time_to_string-- Results depend upon where this query was executed./*------------------------------* | date_time_to_string          | +------------------------------+ | 2008-12-24 16:00:00 -08:00   | *------------------------------*/\n```\n\n```\nSELECT CAST(  TIMESTAMP '2008-12-25 00:00:00+00:00'  AS STRING FORMAT 'YYYY-MM-DD HH24:MI:SS TZH:TZM'  AT TIME ZONE 'Asia/Kolkata') AS date_time_to_string-- Because the time zone is specified, the result is always the same./*------------------------------* | date_time_to_string          | +------------------------------+ | 2008-12-25 05:30:00 +05:30   | *------------------------------*/\n```\n\n```\nSELECT CAST(INTERVAL 3 DAY AS STRING) AS interval_to_string/*--------------------* | interval_to_string | +--------------------+ | 0-0 3 0:0:0        | *--------------------*/\n```\n\n```\nSELECT CAST(  INTERVAL \"1-2 3 4:5:6.789\" YEAR TO SECOND  AS STRING) AS interval_to_string/*--------------------* | interval_to_string | +--------------------+ | 1-2 3 4:5:6.789    | *--------------------*/\n```\n\n"
  },
  {
    "name": "CAST AS STRUCT",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS STRUCT)\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`STRUCT`. The`expression`parameter can represent an expression for these data types:\n\n- `    STRUCT`\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `STRUCT` | `STRUCT` | Allowed if the following conditions are met:    \n1. The two structs have the same number of          fields.\n1. The original struct field types can be          explicitly cast to the corresponding target          struct field types (as defined by field          order, not field name).\n\n |\n\n"
  },
  {
    "name": "CAST AS TIME",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS TIME [format_clause])\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to TIME. The`expression`parameter can represent an expression for these data types:\n\n- `    STRING`\n- `    TIME`\n- `    DATETIME`\n- `    TIMESTAMP`\n\n **Format clause** \n\nWhen an expression of one type is cast to another type, you can use the[format clause](/bigquery/docs/reference/standard-sql/format-elements#formatting_syntax)to provide instructions for how to conductthe cast. You can use the format clause in this section if`expression`is a`STRING`.\n\n- [Format string as date and time](/bigquery/docs/reference/standard-sql/format-elements#format_string_as_datetime)\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `STRING` | `TIME` | When casting from string to time, the string must conform to      the supported time literal format, and is independent of time zone. If the      string expression is invalid or represents a time that is outside of the      supported min/max range, then an error is produced. |\n\n"
  },
  {
    "name": "CAST AS TIMESTAMP",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nCAST(expression AS TIMESTAMP [format_clause [AT TIME ZONE timezone_expr]])\n```\n\n **Description** \n\nGoogleSQL supports[casting](#cast)to`TIMESTAMP`. The`expression`parameter can represent an expression for these data types:\n\n- `    STRING`\n- `    DATETIME`\n- `    TIMESTAMP`\n\n **Format clause** \n\nWhen an expression of one type is cast to another type, you can use the[format clause](/bigquery/docs/reference/standard-sql/format-elements#formatting_syntax)to provide instructions for how to conductthe cast. You can use the format clause in this section if`expression`is a`STRING`.\n\n- [Format string as date and time](/bigquery/docs/reference/standard-sql/format-elements#format_string_as_datetime)\n\nThe format clause for`TIMESTAMP`has an additional optional clause called`AT TIME ZONE timezone_expr`, which you can use to specify a specific time zoneto use during formatting. If this optional clause is not included, yourcurrent time zone is used.\n\n **Conversion rules** \n\n| From | To | Rule(s) when casting`x` |\n| --- | --- | --- |\n| `STRING` | `TIMESTAMP` | When casting from string to a timestamp,`string_expression`must conform to the supported timestamp literal formats, or else a runtime      error occurs. The`string_expression`may itself contain a      time zone.    \n    \nIf there is a time zone in the`string_expression`, that      time zone is used for conversion, otherwise the default time zone,      UTC, is used. If the string has fewer than six digits,      then it is implicitly widened.    \n    \nAn error is produced if the`string_expression`is invalid,      has more than six subsecond digits (i.e., precision greater than      microseconds), or represents a time outside of the supported timestamp      range. |\n| `DATE` | `TIMESTAMP` | Casting from a date to a timestamp interprets`date_expression`as of midnight (start of the day) in the default time zone,      UTC. |\n| `DATETIME` | `TIMESTAMP` | Casting from a datetime to a timestamp interprets`datetime_expression`in the default time zone,      UTC.    \n    \nMost valid datetime values have exactly one corresponding timestamp      in each time zone. However, there are certain combinations of valid      datetime values and time zones that have zero or two corresponding      timestamp values. This happens in a time zone when clocks are set forward      or set back, such as for Daylight Savings Time.      When there are two valid timestamps, the earlier one is used.      When there is no valid timestamp, the length of the gap in time      (typically one hour) is added to the datetime. |\n\n **Examples** \n\nThe following example casts a string-formatted timestamp as a timestamp:\n\n```\nSELECT CAST(\"2020-06-02 17:00:53.110+00:00\" AS TIMESTAMP) AS as_timestamp-- Results depend upon where this query was executed./*-----------------------------* | as_timestamp                | +-----------------------------+ | 2020-06-03 00:00:53.110 UTC | *-----------------------------*/\n```\n\nThe following examples cast a string-formatted date and time as a timestamp.These examples return the same output as the previous example.\n\n```\nSELECT CAST('06/02/2020 17:00:53.110' AS TIMESTAMP FORMAT 'MM/DD/YYYY HH24:MI:SS.FF3' AT TIME ZONE 'UTC') AS as_timestamp\n```\n\n```\nSELECT CAST('06/02/2020 17:00:53.110' AS TIMESTAMP FORMAT 'MM/DD/YYYY HH24:MI:SS.FF3' AT TIME ZONE '+00') AS as_timestamp\n```\n\n```\nSELECT CAST('06/02/2020 17:00:53.110 +00' AS TIMESTAMP FORMAT 'MM/DD/YYYY HH24:MI:SS.FF3 TZH') AS as_timestamp\n```\n\n"
  },
  {
    "name": "CATEGORIES",
    "arguments": [],
    "category": "Geography functions",
    "description": "The geography functions are grouped into the following categories based on theirbehavior:\n\n| Category | Functions | Description |\n| --- | --- | --- |\n| Constructors | [ST_GEOGPOINT](#st_geogpoint)    \n[ST_MAKELINE](#st_makeline)    \n[ST_MAKEPOLYGON](#st_makepolygon)    \n[ST_MAKEPOLYGONORIENTED](#st_makepolygonoriented) | Functions that build new        geography values from coordinates        or existing geographies. |\n| Parsers | [ST_GEOGFROM](#st_geogfrom)    \n[ST_GEOGFROMGEOJSON](#st_geogfromgeojson)    \n[ST_GEOGFROMTEXT](#st_geogfromtext)    \n[ST_GEOGFROMWKB](#st_geogfromwkb)    \n[ST_GEOGPOINTFROMGEOHASH](#st_geogpointfromgeohash)    \n | Functions that create geographies        from an external format such as[WKT](https://en.wikipedia.org/wiki/Well-known_text)and[GeoJSON](https://en.wikipedia.org/wiki/GeoJSON). |\n| Formatters | [ST_ASBINARY](#st_asbinary)    \n[ST_ASGEOJSON](#st_asgeojson)    \n[ST_ASTEXT](#st_astext)    \n[ST_GEOHASH](#st_geohash) | Functions that export geographies        to an external format such as WKT. |\n| Transformations | [ST_BOUNDARY](#st_boundary)    \n[ST_BUFFER](#st_buffer)    \n[ST_BUFFERWITHTOLERANCE](#st_bufferwithtolerance)    \n[ST_CENTROID](#st_centroid)    \n[ST_CENTROID_AGG](#st_centroid_agg)(Aggregate)    \n[ST_CLOSESTPOINT](#st_closestpoint)    \n[ST_CONVEXHULL](#st_convexhull)    \n[ST_DIFFERENCE](#st_difference)    \n[ST_EXTERIORRING](#st_exteriorring)    \n[ST_INTERIORRINGS](#st_interiorrings)    \n[ST_INTERSECTION](#st_intersection)    \n[ST_LINEINTERPOLATEPOINT](#st_lineinterpolatepoint)    \n[ST_LINESUBSTRING](#st_linesubstring)    \n[ST_SIMPLIFY](#st_simplify)    \n[ST_SNAPTOGRID](#st_snaptogrid)    \n[ST_UNION](#st_union)    \n[ST_UNION_AGG](#st_union_agg)(Aggregate)    \n | Functions that generate a new        geography based on input. |\n| Accessors | [ST_DIMENSION](#st_dimension)    \n[ST_DUMP](#st_dump)    \n[ST_ENDPOINT](#st_endpoint)    \n[ST_GEOMETRYTYPE](#st_geometrytype)    \n[ST_ISCLOSED](#st_isclosed)    \n[ST_ISCOLLECTION](#st_iscollection)    \n[ST_ISEMPTY](#st_isempty)    \n[ST_ISRING](#st_isring)    \n[ST_NPOINTS](#st_npoints)    \n[ST_NUMGEOMETRIES](#st_numgeometries)    \n[ST_NUMPOINTS](#st_numpoints)    \n[ST_POINTN](#st_pointn)    \n[ST_STARTPOINT](#st_startpoint)    \n[ST_X](#st_x)    \n[ST_Y](#st_y)    \n | Functions that provide access to        properties of a geography without        side-effects. |\n| Predicates | [ST_CONTAINS](#st_contains)    \n[ST_COVEREDBY](#st_coveredby)    \n[ST_COVERS](#st_covers)    \n[ST_DISJOINT](#st_disjoint)    \n[ST_DWITHIN](#st_dwithin)    \n[ST_EQUALS](#st_equals)    \n[ST_INTERSECTS](#st_intersects)    \n[ST_INTERSECTSBOX](#st_intersectsbox)    \n[ST_TOUCHES](#st_touches)    \n[ST_WITHIN](#st_within)    \n | Functions that return`TRUE`or`FALSE`for some spatial        relationship between two        geographies or some property of        a geography. These functions        are commonly used in filter        clauses. |\n| Measures | [ST_ANGLE](#st_angle)    \n[ST_AREA](#st_area)    \n[ST_AZIMUTH](#st_azimuth)    \n[ST_BOUNDINGBOX](#st_boundingbox)    \n[ST_DISTANCE](#st_distance)    \n[ST_EXTENT](#st_extent)(Aggregate)    \n[ST_HAUSDORFFDISTANCE](#st_hausdorffdistance)    \n[ST_LINELOCATEPOINT](#st_linelocatepoint)    \n[ST_LENGTH](#st_length)    \n[ST_MAXDISTANCE](#st_maxdistance)    \n[ST_PERIMETER](#st_perimeter)    \n | Functions that compute measurements        of one or more geographies. |\n| Clustering | [ST_CLUSTERDBSCAN](#st_clusterdbscan) | Functions that perform clustering on geographies. |\n| S2 functions | [S2_CELLIDFROMPOINT](#s2_cellidfrompoint)    \n[S2_COVERINGCELLIDS](#s2_coveringcellids)    \n | Functions for working with S2 cell coverings of GEOGRAPHY. |\n\n"
  },
  {
    "name": "CATEGORIES",
    "arguments": [],
    "category": "JSON functions",
    "description": "The JSON functions are grouped into the following categories based on theirbehavior:\n\n| Category | Functions | Description |\n| --- | --- | --- |\n| <span id=\"extractors\"></span>Standard extractors | [JSON_QUERY](#json_query)    \n[JSON_VALUE](#json_value)    \n[JSON_QUERY_ARRAY](#json_query_array)    \n[JSON_VALUE_ARRAY](#json_value_array)    \n | Functions that extract JSON data. |\n| <span id=\"extractors_legacy\"></span>Legacy extractors | [JSON_EXTRACT](#json_extract)    \n[JSON_EXTRACT_SCALAR](#json_extract_scalar)    \n[JSON_EXTRACT_ARRAY](#json_extract_array)    \n[JSON_EXTRACT_STRING_ARRAY](#json_extract_string_array)    \n | Functions that extract JSON data.    \nWhile these functions are supported by GoogleSQL, we recommend        using the[standard extractor functions](#extractors). |\n| <span id=\"lax_converters\"></span>Lax converters | [LAX_BOOL](#lax_bool)    \n[LAX_FLOAT64](#lax_double)    \n[LAX_INT64](#lax_int64)    \n[LAX_STRING](#lax_string)    \n | Functions that flexibly convert a JSON value to a scalar SQL value        without returning errors. |\n| <span id=\"converters\"></span>Converters | [BOOL](#bool_for_json)    \n[FLOAT64](#double_for_json)    \n[INT64](#int64_for_json)    \n[STRING](#string_for_json)    \n | Functions that convert a JSON value to a scalar SQL value. |\n| <span id=\"other_converters\"></span>Other converters | [PARSE_JSON](#parse_json)    \n[TO_JSON](#to_json)    \n[TO_JSON_STRING](#to_json_string)    \n | Other conversion functions from or to JSON. |\n| <span id=\"constructors\"></span>Constructors | [JSON_ARRAY](#json_array)    \n[JSON_OBJECT](#json_object)    \n | Functions that create JSON. |\n| <span id=\"mutators\"></span>Mutators | [JSON_ARRAY_APPEND](#json_array_append)    \n[JSON_ARRAY_INSERT](#json_array_insert)    \n[JSON_REMOVE](#json_remove)    \n[JSON_SET](#json_set)    \n[JSON_STRIP_NULLS](#json_strip_nulls)    \n | Functions that mutate existing JSON. |\n| <span id=\"accessors\"></span>Accessors | [JSON_TYPE](#json_type)    \n | Functions that provide access to JSON properties. |\n\n"
  },
  {
    "name": "CATEGORIES",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "| Category | Functions |\n| --- | --- |\n| Trigonometric | [ACOS](#acos)  [ACOSH](#acosh)  [ASIN](#asin)  [ASINH](#asinh)  [ATAN](#atan)  [ATAN2](#atan2)  [ATANH](#atanh)  [COS](#cos)  [COSH](#cosh)  [COT](#cot)  [COTH](#coth)  [CSC](#csc)  [CSCH](#csch)  [SEC](#sec)  [SECH](#sech)  [SIN](#sin)  [SINH](#sinh)  [TAN](#tan)  [TANH](#tanh)   |\n| Exponential and    \nlogarithmic | [EXP](#exp)  [LN](#ln)  [LOG](#log)  [LOG10](#log10)   |\n| Rounding and    \ntruncation | [CEIL](#ceil)  [CEILING](#ceiling)  [FLOOR](#floor)  [ROUND](#round)  [TRUNC](#trunc)   |\n| Power and    \nroot | [CBRT](#cbrt)  [POW](#pow)  [POWER](#power)  [SQRT](#sqrt)   |\n| Sign | [ABS](#abs)  [SIGN](#sign)   |\n| Distance | [COSINE_DISTANCE](#cosine_distance)  [EUCLIDEAN_DISTANCE](#euclidean_distance)   |\n| Comparison | [GREATEST](#greatest)  [LEAST](#least)   |\n| Random number generator | [RAND](#rand)   |\n| Arithmetic and error handling | [DIV](#div)  [IEEE_DIVIDE](#ieee_divide)  [IS_INF](#is_inf)  [IS_NAN](#is_nan)  [MOD](#mod)  [SAFE_ADD](#safe_add)  [SAFE_DIVIDE](#safe_divide)  [SAFE_MULTIPLY](#safe_multiply)  [SAFE_NEGATE](#safe_negate)  [SAFE_SUBTRACT](#safe_subtract)   |\n| Bucket | [RANGE_BUCKET](#range_bucket)   |\n\n"
  },
  {
    "name": "CBRT",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCBRT(X)\n```\n\n **Description** \n\nComputes the cube root of`X`.`X`can be any data typethat[coerces to FLOAT64](/bigquery/docs/reference/standard-sql/conversion_rules#conversion_rules).Supports the`SAFE.`prefix.\n\n| X | CBRT(X) |\n| --- | --- |\n| `+inf` | `inf` |\n| `-inf` | `-inf` |\n| `NaN` | `NaN` |\n| `0` | `0` |\n| `NULL` | `NULL` |\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nSELECT CBRT(27) AS cube_root;/*--------------------* | cube_root          | +--------------------+ | 3.0000000000000004 | *--------------------*/\n```\n\n"
  },
  {
    "name": "CEIL",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCEIL(X)\n```\n\n **Description** \n\nReturns the smallest integral value that is not less than X.\n\n| X | CEIL(X) |\n| --- | --- |\n| 2.0 | 2.0 |\n| 2.3 | 3.0 |\n| 2.8 | 3.0 |\n| 2.5 | 3.0 |\n| -2.3 | -2.0 |\n| -2.8 | -2.0 |\n| -2.5 | -2.0 |\n| 0 | 0 |\n| `+inf` | `+inf` |\n| `-inf` | `-inf` |\n| `NaN` | `NaN` |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "CEILING",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCEILING(X)\n```\n\n **Description** \n\nSynonym of CEIL(X)\n\n"
  },
  {
    "name": "CHARACTER_LENGTH",
    "arguments": [],
    "category": "String functions",
    "description": "```\nCHARACTER_LENGTH(value)\n```\n\n **Description** \n\nSynonym for[CHAR_LENGTH](#char_length).\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH example AS  (SELECT 'абвгд' AS characters)SELECT  characters,  CHARACTER_LENGTH(characters) AS char_length_exampleFROM example;/*------------+---------------------* | characters | char_length_example | +------------+---------------------+ | абвгд      |                   5 | *------------+---------------------*/\n```\n\n"
  },
  {
    "name": "CHAR_LENGTH",
    "arguments": [],
    "category": "String functions",
    "description": "```\nCHAR_LENGTH(value)\n```\n\n **Description** \n\nGets the number of characters in a`STRING`value.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH example AS  (SELECT 'абвгд' AS characters)SELECT  characters,  CHAR_LENGTH(characters) AS char_length_exampleFROM example;/*------------+---------------------* | characters | char_length_example | +------------+---------------------+ | абвгд      |                   5 | *------------+---------------------*/\n```\n\n"
  },
  {
    "name": "CHR",
    "arguments": [],
    "category": "String functions",
    "description": "```\nCHR(value)\n```\n\n **Description** \n\nTakes a Unicode[code point](https://en.wikipedia.org/wiki/Code_point)and returnsthe character that matches the code point. Each valid code point should fallwithin the range of [0, 0xD7FF] and [0xE000, 0x10FFFF]. Returns an empty stringif the code point is`0`. If an invalid Unicode code point is specified, anerror is returned.\n\nTo work with an array of Unicode code points, see[CODE_POINTS_TO_STRING](#code_points_to_string)\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n```\nSELECT CHR(65) AS A, CHR(255) AS B, CHR(513) AS C, CHR(1024)  AS D;/*-------+-------+-------+-------* | A     | B     | C     | D     | +-------+-------+-------+-------+ | A     | ÿ     | ȁ     | Ѐ     | *-------+-------+-------+-------*/\n```\n\n```\nSELECT CHR(97) AS A, CHR(0xF9B5) AS B, CHR(0) AS C, CHR(NULL) AS D;/*-------+-------+-------+-------* | A     | B     | C     | D     | +-------+-------+-------+-------+ | a     | 例    |       | NULL  | *-------+-------+-------+-------*/\n```\n\n"
  },
  {
    "name": "CLAMP VALUES IN A DIFFERENTIALLY PRIVATE AGGREGATE FUNCTION",
    "arguments": [],
    "category": "Differentially private aggregate functions",
    "description": "In[differentially private queries](/bigquery/docs/reference/standard-sql/query-syntax#dp_clause),aggregation clamping is used to limit the contribution of outliers. You canclamp explicitly or implicitly as follows:\n\n- [Clamp explicitly in the DIFFERENTIAL_PRIVACY clause](#dp_clamped_named).\n- [Clamp implicitly in the DIFFERENTIAL_PRIVACY clause](#dp_clamped_named_implicit).\n\n\n<span id=\"dp_clamped_named_implicit\">\n#### Implicitly clamp values\n\n</span>\nIf you don't include the contribution bounds named argument with the`DIFFERENTIAL_PRIVACY`clause, clamping is implicit, whichmeans bounds are derived from the data itself in a differentially private way.\n\nImplicit bounding works best when computed using large datasets. For moreinformation, see[Implicit bounding limitations for small datasets](/bigquery/docs/differential-privacy#implicit_limits).\n\n **Details** \n\nIn differentially private aggregate functions, explicit clamping is optional.If you don't include this clause, clamping is implicit,which means bounds are derived from the data itself in a differentiallyprivate way. The process is somewhat random, so aggregations with identicalranges can have different bounds.\n\nImplicit bounds are determined for each aggregation. So if someaggregations have a wide range of values, and others have a narrow range ofvalues, implicit bounding can identify different bounds for differentaggregations as appropriate. Implicit bounds might be an advantage or adisadvantage depending on your use case. Different bounds for differentaggregations can result in lower error. Different bounds also means thatdifferent aggregations have different levels of uncertainty, which might not bedirectly comparable.[Explicit bounds](#dp_clamped_named), on the other hand,apply uniformly to all aggregations and should be derived from publicinformation.\n\nWhen clamping is implicit, part of the total epsilon is spent picking bounds.This leaves less epsilon for aggregations, so these aggregations are noisier.\n\n **Example** \n\nThe following anonymized query clamps each aggregate contribution for eachdifferential privacy ID and within a derived range from the data itself.As long as all or most values fall within this range, your resultswill be accurate. This query references a view called[view_on_professors](/bigquery/docs/reference/standard-sql/query-syntax#dp_example_views).\n\n```\n--Without noise (this un-noised version is for demonstration only)SELECT WITH DIFFERENTIAL_PRIVACY  OPTIONS (    epsilon = 1e20,    delta = .01,    privacy_unit_column=id  )  item,  AVG(quantity) average_quantityFROM view_on_professorsGROUP BY item;/*----------+------------------* | item     | average_quantity | +----------+------------------+ | scissors | 8                | | pencil   | 72               | | pen      | 18.5             | *----------+------------------*/\n```\n\n\n<span id=\"dp_clamped_named\">\n#### Explicitly clamp values\n\n</span>\n```\ncontribution_bounds_per_group =&gt; (lower_bound,upper_bound)\n```\n\n```\ncontribution_bounds_per_row =&gt; (lower_bound,upper_bound)\n```\n\nUse the contribution bounds named argument to explicitly clampvalues per group or per row between a lower and upper bound in a`DIFFERENTIAL_PRIVACY`clause.\n\nInput values:\n\n- `    contribution_bounds_per_row`: Contributions per privacy unit are clampedon a per-row (per-record) basis. This means the following:\n    - Upper and lower bounds are applied to column values in individualrows produced by the input subquery independently.\n    - The maximum possible contribution per privacy unit (and per grouping set)is the product of the per-row contribution limit and`        max_groups_contributed`differential privacy parameter.\n- `    contribution_bounds_per_group`: Contributions per privacy unit are clampedon a unique set of entity-specified`    GROUP BY`keys. The upper and lowerbounds are applied to values per group after the values are aggregated perprivacy unit.\n- `    lower_bound`: Numeric literal that represents the smallest value toinclude in an aggregation.\n- `    upper_bound`: Numeric literal that represents the largest value toinclude in an aggregation.\n\n`NUMERIC`and`BIGNUMERIC`arguments are not allowed.\n\n **Details** \n\nIn differentially private aggregate functions, clamping explicitly clamps thetotal contribution from each privacy unit column to within a specifiedrange.\n\nExplicit bounds are uniformly applied to all aggregations.  So even if someaggregations have a wide range of values, and others have a narrow range ofvalues, the same bounds are applied to all of them.  On the other hand, when[implicit bounds](#dp_clamped_named_implicit)are inferred from the data, the boundsapplied to each aggregation can be different.\n\nExplicit bounds should be chosen to reflect public information.For example, bounding ages between 0 and 100 reflects public informationbecause the age of most people generally falls within this range.\n\n **Important:** The results of the query reveal the explicit bounds. Do not useexplicit bounds based on the entity data; explicit bounds should be based onpublic information. **Examples** \n\nThe following anonymized query clamps each aggregate contribution for eachdifferential privacy ID and within a specified range (`0`and`100`).As long as all or most values fall within this range, your resultswill be accurate. This query references a view called[view_on_professors](/bigquery/docs/reference/standard-sql/query-syntax#dp_example_views).\n\n```\n--Without noise (this un-noised version is for demonstration only)SELECT WITH DIFFERENTIAL_PRIVACY  OPTIONS (    epsilon = 1e20,    delta = .01,    privacy_unit_column=id  )  item,  AVG(quantity, contribution_bounds_per_group=&gt;(0,100)) AS average_quantityFROM view_on_professorsGROUP BY item;/*----------+------------------* | item     | average_quantity | +----------+------------------+ | scissors | 8                | | pencil   | 40               | | pen      | 18.5             | *----------+------------------*/\n```\n\nNotice what happens when most or all values fall outside of the clamped range.To get accurate results, ensure that the difference between the upper and lowerbound is as small as possible, and that most inputs are between the upper andlower bound.\n\n```\n--Without noise (this un-noised version is for demonstration only)SELECT WITH DIFFERENTIAL_PRIVACY  OPTIONS (    epsilon = 1e20,    delta = .01,    privacy_unit_column=id  )  item,  AVG(quantity, contribution_bounds_per_group=&gt;(50,100)) AS average_quantityFROM view_on_professorsGROUP BY item;/*----------+------------------* | item     | average_quantity | +----------+------------------+ | scissors | 54               | | pencil   | 58               | | pen      | 51               | *----------+------------------*/\n```\n\n **Note:** For more information about when and when not to usenoise, see[Remove noise](/bigquery/docs/reference/standard-sql/query-syntax#eliminate_noise).\n<span id=\"dlp_encryption_functions\">\n## DLP encryption functions\n\n</span>\n **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-sql-preview-support@google.com](mailto:bigquery-sql-preview-support@google.com).GoogleSQL for BigQuery supports the following DLP functionsthat allow interoperable encryption and decryption between BigQuery and[Cloud Data Loss Prevention (Cloud DLP)](https://cloud.google.com/dlp/docs),using[AES-SIV](https://cloud.google.com/dlp/docs/pseudonymization#aes-siv).\n\n"
  },
  {
    "name": "CODE_POINTS_TO_BYTES",
    "arguments": [],
    "category": "String functions",
    "description": "```\nCODE_POINTS_TO_BYTES(ascii_code_points)\n```\n\n **Description** \n\nTakes an array of extended ASCII[code points](https://en.wikipedia.org/wiki/Code_point)as`ARRAY&lt;INT64&gt;`and returns`BYTES`.\n\nTo convert from`BYTES`to an array of code points, see[TO_CODE_POINTS](#to_code_points).\n\n **Return type** \n\n`BYTES`\n\n **Examples** \n\nThe following is a basic example using`CODE_POINTS_TO_BYTES`.\n\n```\nSELECT CODE_POINTS_TO_BYTES([65, 98, 67, 100]) AS bytes;-- Note that the result of CODE_POINTS_TO_BYTES is of type BYTES, displayed as a base64-encoded string.-- In BYTES format, b'AbCd' is the result./*----------* | bytes    | +----------+ | QWJDZA== | *----------*/\n```\n\nThe following example uses a rotate-by-13 places (ROT13) algorithm to encode astring.\n\n```\nSELECT CODE_POINTS_TO_BYTES(ARRAY_AGG(  (SELECT      CASE        WHEN chr BETWEEN b'a' and b'z'          THEN TO_CODE_POINTS(b'a')[offset(0)] +            MOD(code+13-TO_CODE_POINTS(b'a')[offset(0)],26)        WHEN chr BETWEEN b'A' and b'Z'          THEN TO_CODE_POINTS(b'A')[offset(0)] +            MOD(code+13-TO_CODE_POINTS(b'A')[offset(0)],26)        ELSE code      END   FROM     (SELECT code, CODE_POINTS_TO_BYTES([code]) chr)  ) ORDER BY OFFSET)) AS encoded_stringFROM UNNEST(TO_CODE_POINTS(b'Test String!')) code WITH OFFSET;-- Note that the result of CODE_POINTS_TO_BYTES is of type BYTES, displayed as a base64-encoded string.-- In BYTES format, b'Grfg Fgevat!' is the result./*------------------* | encoded_string   | +------------------+ | R3JmZyBGZ2V2YXQh | *------------------*/\n```\n\n"
  },
  {
    "name": "CODE_POINTS_TO_STRING",
    "arguments": [],
    "category": "String functions",
    "description": "```\nCODE_POINTS_TO_STRING(unicode_code_points)\n```\n\n **Description** \n\nTakes an array of Unicode[code points](https://en.wikipedia.org/wiki/Code_point)as`ARRAY&lt;INT64&gt;`and returns a`STRING`.\n\nTo convert from a string to an array of code points, see[TO_CODE_POINTS](#to_code_points).\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\nThe following are basic examples using`CODE_POINTS_TO_STRING`.\n\n```\nSELECT CODE_POINTS_TO_STRING([65, 255, 513, 1024]) AS string;/*--------* | string | +--------+ | AÿȁЀ   | *--------*/\n```\n\n```\nSELECT CODE_POINTS_TO_STRING([97, 0, 0xF9B5]) AS string;/*--------* | string | +--------+ | a例    | *--------*/\n```\n\n```\nSELECT CODE_POINTS_TO_STRING([65, 255, NULL, 1024]) AS string;/*--------* | string | +--------+ | NULL   | *--------*/\n```\n\nThe following example computes the frequency of letters in a set of words.\n\n```\nWITH Words AS (  SELECT word  FROM UNNEST(['foo', 'bar', 'baz', 'giraffe', 'llama']) AS word)SELECT  CODE_POINTS_TO_STRING([code_point]) AS letter,  COUNT(*) AS letter_countFROM Words,  UNNEST(TO_CODE_POINTS(word)) AS code_pointGROUP BY 1ORDER BY 2 DESC;/*--------+--------------* | letter | letter_count | +--------+--------------+ | a      | 5            | | f      | 3            | | r      | 2            | | b      | 2            | | l      | 2            | | o      | 2            | | g      | 1            | | z      | 1            | | e      | 1            | | m      | 1            | | i      | 1            | *--------+--------------*/\n```\n\n"
  },
  {
    "name": "COLLATE",
    "arguments": [],
    "category": "String functions",
    "description": "```\nCOLLATE(value, collate_specification)\n```\n\nTakes a`STRING`and a[collation specification](/bigquery/docs/reference/standard-sql/collation-concepts#collate_spec_details). Returnsa`STRING`with a collation specification. If`collate_specification`is empty,returns a value with collation removed from the`STRING`.\n\nThe collation specification defines how the resulting`STRING`can be comparedand sorted. To learn more, see[Working with collation](/bigquery/docs/reference/standard-sql/collation-concepts#working_with_collation).\n\n- `    collation_specification`must be a string literal, otherwise an error isthrown.\n- Returns`    NULL`if`    value`is`    NULL`.\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\nIn this example, the weight of`a`is less than the weight of`Z`. Thisis because the collate specification,`und:ci`assigns more weight to`Z`.\n\n```\nWITH Words AS (  SELECT    COLLATE('a', 'und:ci') AS char1,    COLLATE('Z', 'und:ci') AS char2)SELECT ( Words.char1 &lt; Words.char2 ) AS a_less_than_ZFROM Words;/*----------------* | a_less_than_Z  | +----------------+ | TRUE           | *----------------*/\n```\n\nIn this example, the weight of`a`is greater than the weight of`Z`. Thisis because the default collate specification assigns more weight to`a`.\n\n```\nWITH Words AS (  SELECT    'a' AS char1,    'Z' AS char2)SELECT ( Words.char1 &lt; Words.char2 ) AS a_less_than_ZFROM Words;/*----------------* | a_less_than_Z  | +----------------+ | FALSE          | *----------------*/\n```\n\n"
  },
  {
    "name": "CONCAT",
    "arguments": [],
    "category": "String functions",
    "description": "```\nCONCAT(value1[, ...])\n```\n\n **Description** \n\nConcatenates one or more values into a single result. All values must be`BYTES`or data types that can be cast to`STRING`.\n\nThe function returns`NULL`if any input argument is`NULL`.\n\n **Note:** You can also use the[|| concatenation operator](#operators)to concatenatevalues into a string. **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nSELECT CONCAT('T.P.', ' ', 'Bar') as author;/*---------------------* | author              | +---------------------+ | T.P. Bar            | *---------------------*/\n```\n\n```\nSELECT CONCAT('Summer', ' ', 1923) as release_date;/*---------------------* | release_date        | +---------------------+ | Summer 1923         | *---------------------*/\n```\n\n```\nWith Employees AS  (SELECT    'John' AS first_name,    'Doe' AS last_name  UNION ALL  SELECT    'Jane' AS first_name,    'Smith' AS last_name  UNION ALL  SELECT    'Joe' AS first_name,    'Jackson' AS last_name)SELECT  CONCAT(first_name, ' ', last_name)  AS full_nameFROM Employees;/*---------------------* | full_name           | +---------------------+ | John Doe            | | Jane Smith          | | Joe Jackson         | *---------------------*/\n```\n\n"
  },
  {
    "name": "CONTAINS_SUBSTR",
    "arguments": [],
    "category": "String functions",
    "description": "```\nCONTAINS_SUBSTR(expression, search_value_literal[, json_scope=&gt;json_scope_value])json_scope_value:  { 'JSON_VALUES' | 'JSON_KEYS' | 'JSON_KEYS_AND_VALUES' }\n```\n\n **Description** \n\nPerforms a normalized, case-insensitive search to see if a value exists as asubstring in an expression. Returns`TRUE`if the value exists, otherwisereturns`FALSE`.\n\nBefore values are compared, they are[normalized and case folded with NFKC normalization](#normalize_and_casefold). Wildcard searches are notsupported.\n\n **Arguments** \n\n- `    search_value_literal`: The value to search for. It must be a`    STRING`literal or a`    STRING`constant expression.\n- `    expression`: The data to search over. The expression can be a column ortable reference. A table reference is evaluated as a`    STRUCT`whose fieldsare the columns of the table. A column reference is evaluated as one thefollowing data types:\n    \n    \n    - `        STRING`\n    - `        INT64`\n    - `        BOOL`\n    - `        NUMERIC`\n    - `        BIGNUMERIC`\n    - `        TIMESTAMP`\n    - `        TIME`\n    - `        DATE`\n    - `        DATETIME`\n    - `        ARRAY`\n    - `        STRUCT`When the expression is evaluated, the result is cast to a`    STRING`, and thenthe function looks for the search value in the result.\n    \n    You can perform a cross-field search on an expression that evaluates to a`    STRUCT`or`    ARRAY`. If the expression evaluates to a`    STRUCT`, thecross-field search is recursive and includes all subfields inside the`    STRUCT`.\n    \n    In a cross-field search, each field and subfield is individually convertedto a string and searched for the value. The function returns`    TRUE`if atleast one field includes the search value; otherwise, if at least one fieldis`    NULL`, it returns`    NULL`; otherwise, if the search value is not foundand all fields are non-`    NULL`, it returns`    FALSE`.\n    \n    If the expression is`    NULL`, the return value is`    NULL`.\n    \n    \n- `    json_scope`: This optional[mandatory-named argument](/bigquery/docs/reference/standard-sql/functions-reference#named_arguments)takes one of the following values to indicate the scope of`    JSON`data to besearched. It has no effect if`    expression`is not`    JSON`or does notcontain a`    JSON`field.\n    \n    \n    - `        'JSON_VALUES'`: Only the`        JSON`values are searched. If`        json_scope`isnot provided, this is used by default.\n    - `        'JSON_KEYS'`: Only the`        JSON`keys are searched.\n    - `        'JSON_KEYS_AND_VALUES'`: The`        JSON`keys and values are searched.\n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\nThe following query returns`TRUE`because this case-insensitive matchwas found:`blue house`and`Blue house`.\n\n```\nSELECT CONTAINS_SUBSTR('the blue house', 'Blue house') AS result;/*--------* | result | +--------+ | true   | *--------*/\n```\n\nThe following query returns`TRUE`similar to the above example, but in thiscase the search value is a constant expression with CONCAT function.\n\n```\nSELECT CONTAINS_SUBSTR('the blue house', CONCAT('Blue ', 'house')) AS result;/*--------* | result | +--------+ | true   | *--------*/\n```\n\nThe following query returns`FALSE`because`blue`was not foundin`the red house`.\n\n```\nSELECT CONTAINS_SUBSTR('the red house', 'blue') AS result;/*--------* | result | +--------+ | false  | *--------*/\n```\n\nThe following query returns`TRUE`because`Ⅸ`and`IX`represent the samenormalized value.\n\n```\nSELECT '\\u2168 day' AS a, 'IX' AS b, CONTAINS_SUBSTR('\\u2168', 'IX') AS result;/*----------------------* | a      | b  | result | +----------------------+ | Ⅸ day | IX | true   | *----------------------*/\n```\n\nThe following query returns`TRUE`because`35`was found inside a`STRUCT`field.\n\n```\nSELECT CONTAINS_SUBSTR((23, 35, 41), '35') AS result;/*--------* | result | +--------+ | true   | *--------*/\n```\n\nThe following query returns`TRUE`because`jk`was found during arecursive search inside a`STRUCT`.\n\n```\nSELECT CONTAINS_SUBSTR(('abc', ['def', 'ghi', 'jkl'], 'mno'), 'jk');/*--------* | result | +--------+ | true   | *--------*/\n```\n\nThe following query returns`TRUE`because`NULL`s are ignored whena match is found found inside a`STRUCT`or`ARRAY`.\n\n```\nSELECT CONTAINS_SUBSTR((23, NULL, 41), '41') AS result;/*--------* | result | +--------+ | true   | *--------*/\n```\n\nThe following query returns`NULL`because a`NULL`existed in a`STRUCT`thatdid not result in a match.\n\n```\nSELECT CONTAINS_SUBSTR((23, NULL, 41), '35') AS result;/*--------* | result | +--------+ | null   | *--------*/\n```\n\nIn the following query, an error is thrown because the search value cannot bea literal`NULL`.\n\n```\nSELECT CONTAINS_SUBSTR('hello', NULL) AS result;-- Throws an error\n```\n\nThe following examples reference a table called`Recipes`that you can emulatewith a`WITH`clause like this:\n\n```\nWITH Recipes AS (SELECT 'Blueberry pancakes' as Breakfast, 'Egg salad sandwich' as Lunch, 'Potato dumplings' as Dinner UNION ALL  SELECT 'Potato pancakes', 'Toasted cheese sandwich', 'Beef stroganoff' UNION ALL  SELECT 'Ham scramble', 'Steak avocado salad', 'Tomato pasta' UNION ALL  SELECT 'Avocado toast', 'Tomato soup', 'Blueberry salmon' UNION ALL  SELECT 'Corned beef hash', 'Lentil potato soup', 'Glazed ham')SELECT * FROM Recipes;/*-------------------+-------------------------+------------------* | Breakfast         | Lunch                   | Dinner           | +-------------------+-------------------------+------------------+ | Bluberry pancakes | Egg salad sandwich      | Potato dumplings | | Potato pancakes   | Toasted cheese sandwich | Beef stroganoff  | | Ham scramble      | Steak avocado salad     | Tomato pasta     | | Avocado toast     | Tomato soup             | Blueberry samon  | | Corned beef hash  | Lentil potato soup      | Glazed ham       | *-------------------+-------------------------+------------------*/\n```\n\nThe following query searches across all columns of the`Recipes`table for thevalue`toast`and returns the rows that contain this value.\n\n```\nSELECT * FROM Recipes WHERE CONTAINS_SUBSTR(Recipes, 'toast');/*-------------------+-------------------------+------------------* | Breakfast         | Lunch                   | Dinner           | +-------------------+-------------------------+------------------+ | Potato pancakes   | Toasted cheese sandwich | Beef stroganoff  | | Avocado toast     | Tomato soup             | Blueberry samon  | *-------------------+-------------------------+------------------*/\n```\n\nThe following query searches the`Lunch`and`Dinner`columns of the`Recipe`table for the value`potato`and returns the row if either columncontains this value.\n\n```\nSELECT * FROM Recipes WHERE CONTAINS_SUBSTR((Lunch, Dinner), 'potato');/*-------------------+-------------------------+------------------* | Breakfast         | Lunch                   | Dinner           | +-------------------+-------------------------+------------------+ | Bluberry pancakes | Egg salad sandwich      | Potato dumplings | | Corned beef hash  | Lentil potato soup      | Glazed ham       | *-------------------+-------------------------+------------------*/\n```\n\nThe following query searches across all columns of the`Recipes`tableexcept for the`Lunch`and`Dinner`columns. It returns the rows of anycolumns other than`Lunch`or`Dinner`that contain the value`potato`.\n\n```\nSELECT *FROM RecipesWHERE CONTAINS_SUBSTR(  (SELECT AS STRUCT Recipes.* EXCEPT (Lunch, Dinner)),  'potato');/*-------------------+-------------------------+------------------* | Breakfast         | Lunch                   | Dinner           | +-------------------+-------------------------+------------------+ | Potato pancakes   | Toasted cheese sandwich | Beef stroganoff  | *-------------------+-------------------------+------------------*/\n```\n\nThe following query searches for the value`lunch`in the JSON`{\"lunch\":\"soup\"}`and returns`FALSE`because the default`json_scope`is`\"JSON_VALUES\"`, and`lunch`is a`JSON`key, not a`JSON`value.\n\n```\nSELECT CONTAINS_SUBSTR(JSON '{\"lunch\":\"soup\"}',\"lunch\") AS result;/*--------* | result | +--------+ | FALSE  | *--------*/\n```\n\nThe following query searches for the value`lunch`in the values of the JSON`{\"lunch\":\"soup\"}`and returns`FALSE`because`lunch`is a`JSON`key, not a`JSON`value.\n\n```\nSELECT CONTAINS_SUBSTR(JSON '{\"lunch\":\"soup\"}',                       \"lunch\",                       json_scope=&gt;\"JSON_VALUES\") AS result;/*--------* | result | +--------+ | FALSE  | *--------*/\n```\n\nThe following query searches for the value`lunch`in the keys and values of theJSON`{\"lunch\":\"soup\"}`and returns`TRUE`because`lunch`is a`JSON`key.\n\n```\nSELECT CONTAINS_SUBSTR(JSON '{\"lunch\":\"soup\"}',                       \"lunch\",                       json_scope=&gt;\"JSON_KEYS_AND_VALUES\") AS result;/*--------* | result | +--------+ | TRUE   | *--------*/\n```\n\nThe following query searches for the value`lunch`in the keys of the JSON`{\"lunch\":\"soup\"}`and returns`TRUE`because`lunch`is a`JSON`key.\n\n```\nSELECT CONTAINS_SUBSTR(JSON '{\"lunch\":\"soup\"}',                       \"lunch\",                       json_scope=&gt;\"JSON_KEYS\") AS result;/*--------* | result | +--------+ | TRUE   | *--------*/\n```\n\n"
  },
  {
    "name": "CORR",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nCORR(  X1, X2)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the[Pearson coefficient](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient)of correlation of a set of number pairs. For each number pair, the first numberis the dependent variable and the second number is the independent variable.The return result is between`-1`and`1`. A result of`0`indicates nocorrelation.\n\nAll numeric types are supported. If theinput is`NUMERIC`or`BIGNUMERIC`then the internal aggregation isstable with the final output converted to a`FLOAT64`.Otherwise the input is converted to a`FLOAT64`before aggregation, resulting in a potentially unstable result.\n\nThis function ignores any input pairs that contain one or more`NULL`values. Ifthere are fewer than two input pairs without`NULL`values, this functionreturns`NULL`.\n\n`NaN`is produced if:\n\n- Any input value is`    NaN`\n- Any input value is positive infinity or negative infinity.\n- The variance of`    X1`or`    X2`is`    0`.\n- The covariance of`    X1`and`    X2`is`    0`.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nSELECT CORR(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 5.0 AS x),      (3.0, 9.0),      (4.0, 7.0)]);/*--------------------* | results            | +--------------------+ | 0.6546536707079772 | *--------------------*/\n```\n\n```\nSELECT CORR(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 5.0 AS x),      (3.0, 9.0),      (4.0, NULL)]);/*---------* | results | +---------+ | 1       | *---------*/\n```\n\n```\nSELECT CORR(y, x) AS resultsFROM UNNEST([STRUCT(1.0 AS y, NULL AS x),(9.0, 3.0)])/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT CORR(y, x) AS resultsFROM UNNEST([STRUCT(1.0 AS y, NULL AS x),(9.0, NULL)])/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT CORR(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 5.0 AS x),      (3.0, 9.0),      (4.0, 7.0),      (5.0, 1.0),      (7.0, CAST('Infinity' as FLOAT64))])/*---------* | results | +---------+ | NaN     | *---------*/\n```\n\n```\nSELECT CORR(x, y) AS resultsFROM  (    SELECT 0 AS x, 0 AS y    UNION ALL    SELECT 0 AS x, 0 AS y  )/*---------* | results | +---------+ | NaN     | *---------*/\n```\n\n"
  },
  {
    "name": "COS",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCOS(X)\n```\n\n **Description** \n\nComputes the cosine of X where X is specified in radians. Never fails.\n\n| X | COS(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n\n"
  },
  {
    "name": "COSH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCOSH(X)\n```\n\n **Description** \n\nComputes the hyperbolic cosine of X where X is specified in radians.Generates an error if overflow occurs.\n\n| X | COSH(X) |\n| --- | --- |\n| `+inf` | `+inf` |\n| `-inf` | `+inf` |\n| `NaN` | `NaN` |\n\n"
  },
  {
    "name": "COSINE_DISTANCE",
    "arguments": [],
    "category": "Mathematical functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bq-search-team@google.com](mailto:bq-search-team@google.com).```\nCOSINE_DISTANCE(vector1, vector2)\n```\n\n **Description** \n\nComputes the[cosine distance](https://en.wikipedia.org/wiki/Cosine_similarity#Cosine_distance)between two vectors.\n\n **Definitions** \n\n- `    vector1`: A vector that is represented by an`    ARRAY&lt;T&gt;`value or a sparse vector that isrepresented by an`    ARRAY&lt;STRUCT&lt;dimension,magnitude&gt;&gt;`value.\n- `    vector2`: A vector that is represented by an`    ARRAY&lt;T&gt;`value or a sparse vector that isrepresented by an`    ARRAY&lt;STRUCT&lt;dimension,magnitude&gt;&gt;`value.\n\n **Details** \n\n- `    ARRAY&lt;T&gt;`can be used to represent a vector. Each zero-based index in thisarray represents a dimension. The value for each element in this arrayrepresents a magnitude.\n    \n    `    T`can represent the following and must be the same for bothvectors:\n    \n    \n    - `        FLOAT64`In the following example vector, there are four dimensions. The magnitudeis`    10.0`for dimension`    0`,`    55.0`for dimension`    1`,`    40.0`fordimension`    2`, and`    34.0`for dimension`    3`:\n    \n    \n    ```\n    [10.0, 55.0, 40.0, 34.0]\n    ```\n    \n    \n- `    ARRAY&lt;STRUCT&lt;dimension,magnitude&gt;&gt;`can be used to represent asparse vector. With a sparse vector, you only need to includedimension-magnitude pairs for non-zero magnitudes. If a magnitude isn'tpresent in the sparse vector, the magnitude is implicitly understood to bezero.\n    \n    For example, if you have a vector with 10,000 dimensions, but only 10dimensions have non-zero magnitudes, then the vector is a sparse vector.As a result, it's more efficient to describe a sparse vector by onlymentioning its non-zero magnitudes.\n    \n    In`    ARRAY&lt;STRUCT&lt;dimension,magnitude&gt;&gt;`,`    STRUCT&lt;dimension,magnitude&gt;`represents a dimension-magnitude pair for each non-zero magnitude in asparse vector. These parts need to be included for each dimension-magnitudepair:\n    \n    \n    - `        dimension`: A`        STRING`or`        INT64`value that represents adimension in a vector.\n        \n        \n    - `        magnitude`: A`        FLOAT64`value that represents anon-zero magnitude for a specific dimension in a vector.\n        \n        You don't need to include empty dimension-magnitude pairs in asparse vector. For example, the following sparse vector andnon-sparse vector are equivalent:\n    \n    \n    ```\n    -- sparse vector ARRAY&lt;STRUCT&lt;INT64, FLOAT64&gt;&gt;[(1, 10.0), (2: 30.0), (5, 40.0)]\n    ```\n    \n    \n    ```\n    -- vector ARRAY&lt;FLOAT64&gt;[0.0, 10.0, 30.0, 0.0, 0.0, 40.0]\n    ```\n    \n    In a sparse vector, dimension-magnitude pairs don't need to be in anyparticular order. The following sparse vectors are equivalent:\n    \n    \n    ```\n    [('a', 10.0), ('b': 30.0), ('d': 40.0)]\n    ```\n    \n    \n    ```\n    [('d': 40.0), ('a', 10.0), ('b': 30.0)]\n    ```\n    \n    \n- Both  non-sparse vectorsin this function must share the same dimensions, and if they don't, an erroris produced.\n    \n    \n- A vector can't be a zero vector. A vector is a zero vector if it hasno dimensions or all dimensions have a magnitude of`    0`, such as`    []`or`    [0.0, 0.0]`. If a zero vector is encountered, an error is produced.\n    \n    \n- An error is produced if a magnitude in a vector is`    NULL`.\n    \n    \n- If a vector is`    NULL`,`    NULL`is returned.\n    \n    \n\n **Return type** \n\n`FLOAT64`\n\n **Examples** \n\nIn the following example, non-sparsevectorsare used to compute the cosine distance:\n\n```\nSELECT COSINE_DISTANCE([1.0, 2.0], [3.0, 4.0]) AS results;/*----------* | results  | +----------+ | 0.016130 | *----------*/\n```\n\nIn the following example, sparse vectors are used to compute thecosine distance:\n\n```\nSELECT COSINE_DISTANCE( [(1, 1.0), (2, 2.0)], [(2, 4.0), (1, 3.0)]) AS results; /*----------*  | results  |  +----------+  | 0.016130 |  *----------*/\n```\n\nThe ordering of numeric values in a vector doesn't impact the resultsproduced by this function. For example these queries produce the same resultseven though the numeric values in each vector is in a different order:\n\n```\nSELECT COSINE_DISTANCE([1.0, 2.0], [3.0, 4.0]) AS results;\n```\n\n```\nSELECT COSINE_DISTANCE([2.0, 1.0], [4.0, 3.0]) AS results;\n```\n\n```\nSELECT COSINE_DISTANCE([(1, 1.0), (2, 2.0)], [(1, 3.0), (2, 4.0)]) AS results;\n```\n\n```\n/*----------*  | results  |  +----------+  | 0.016130 |  *----------*/\n```\n\nIn the following example, the function can't compute cosine distance againstthe first vector, which is a zero vector:\n\n```\n-- ERRORSELECT COSINE_DISTANCE([0.0, 0.0], [3.0, 4.0]) AS results;\n```\n\n```\n-- ERRORSELECT COSINE_DISTANCE([(1, 0.0), (2, 0.0)], [(1, 3.0), (2, 4.0)]) AS results;\n```\n\nBoth non-sparse vectors must have the samedimensions. If not, an error is produced. In the following example, thefirst vector has two dimensions and the second vector has three:\n\n```\n-- ERRORSELECT COSINE_DISTANCE([9.0, 7.0], [8.0, 4.0, 5.0]) AS results;\n```\n\nIf you use sparse vectors and you repeat a dimension, an error isproduced:\n\n```\n-- ERRORSELECT COSINE_DISTANCE(  [(1, 9.0), (2, 7.0), (2, 8.0)], [(1, 8.0), (2, 4.0), (3, 5.0)]) AS results;\n```\n\n"
  },
  {
    "name": "COT",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCOT(X)\n```\n\n **Description** \n\nComputes the cotangent for the angle of`X`, where`X`is specified in radians.`X`can be any data typethat[coerces to FLOAT64](/bigquery/docs/reference/standard-sql/conversion_rules#conversion_rules).Supports the`SAFE.`prefix.\n\n| X | COT(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n| `0` | `Error` |\n| `NULL` | `NULL` |\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nSELECT COT(1) AS a, SAFE.COT(0) AS b;/*---------------------+------* | a                   | b    | +---------------------+------+ | 0.64209261593433065 | NULL | *---------------------+------*/\n```\n\n"
  },
  {
    "name": "COTH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCOTH(X)\n```\n\n **Description** \n\nComputes the hyperbolic cotangent for the angle of`X`, where`X`is specifiedin radians.`X`can be any data typethat[coerces to FLOAT64](/bigquery/docs/reference/standard-sql/conversion_rules#conversion_rules).Supports the`SAFE.`prefix.\n\n| X | COTH(X) |\n| --- | --- |\n| `+inf` | `1` |\n| `-inf` | `-1` |\n| `NaN` | `NaN` |\n| `0` | `Error` |\n| `NULL` | `NULL` |\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nSELECT COTH(1) AS a, SAFE.COTH(0) AS b;/*----------------+------* | a              | b    | +----------------+------+ | 1.313035285499 | NULL | *----------------+------*/\n```\n\n"
  },
  {
    "name": "COUNT",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "1.\n\n```\nCOUNT(*)[OVER over_clause]\n```\n\n2.\n\n```\nCOUNT(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\n1. Returns the number of rows in the input.\n1. Returns the number of rows with`    expression`evaluated to any value otherthan`    NULL`.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\nThis function with DISTINCT supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n`COUNT`can be used with differential privacy. For more information, see[Differentially private aggregate functions](#aggregate-dp-functions).\n\n **Supported Argument Types** \n\n`expression`can be any data type. If`DISTINCT`is present,`expression`can only be a data type that is[groupable](/bigquery/docs/reference/standard-sql/data-types#data_type_properties).\n\n **Return Data Types** \n\nINT64\n\n **Examples** \n\nYou can use the`COUNT`function to return the number of rows in a table or thenumber of distinct values of an expression. For example:\n\n```\nSELECT  COUNT(*) AS count_star,  COUNT(DISTINCT x) AS count_dist_xFROM UNNEST([1, 4, 4, 5]) AS x;/*------------+--------------* | count_star | count_dist_x | +------------+--------------+ | 4          | 3            | *------------+--------------*/\n```\n\n```\nSELECT  x,  COUNT(*) OVER (PARTITION BY MOD(x, 3)) AS count_star,  COUNT(DISTINCT x) OVER (PARTITION BY MOD(x, 3)) AS count_dist_xFROM UNNEST([1, 4, 4, 5]) AS x;/*------+------------+--------------* | x    | count_star | count_dist_x | +------+------------+--------------+ | 1    | 3          | 2            | | 4    | 3          | 2            | | 4    | 3          | 2            | | 5    | 1          | 1            | *------+------------+--------------*/\n```\n\n```\nSELECT  x,  COUNT(*) OVER (PARTITION BY MOD(x, 3)) AS count_star,  COUNT(x) OVER (PARTITION BY MOD(x, 3)) AS count_xFROM UNNEST([1, 4, NULL, 4, 5]) AS x;/*------+------------+---------* | x    | count_star | count_x | +------+------------+---------+ | NULL | 1          | 0       | | 1    | 3          | 3       | | 4    | 3          | 3       | | 4    | 3          | 3       | | 5    | 1          | 1       | *------+------------+---------*/\n```\n\nIf you want to count the number of distinct values of an expression for which acertain condition is satisfied, this is one recipe that you can use:\n\n```\nCOUNT(DISTINCT IF(condition, expression, NULL))\n```\n\nHere,`IF`will return the value of`expression`if`condition`is`TRUE`, or`NULL`otherwise. The surrounding`COUNT(DISTINCT ...)`will ignore the`NULL`values, so it will count only the distinct values of`expression`for which`condition`is`TRUE`.\n\nFor example, to count the number of distinct positive values of`x`:\n\n```\nSELECT COUNT(DISTINCT IF(x &gt; 0, x, NULL)) AS distinct_positiveFROM UNNEST([1, -2, 4, 1, -5, 4, 1, 3, -6, 1]) AS x;/*-------------------* | distinct_positive | +-------------------+ | 3                 | *-------------------*/\n```\n\nOr to count the number of distinct dates on which a certain kind of eventoccurred:\n\n```\nWITH Events AS (  SELECT DATE '2021-01-01' AS event_date, 'SUCCESS' AS event_type  UNION ALL  SELECT DATE '2021-01-02' AS event_date, 'SUCCESS' AS event_type  UNION ALL  SELECT DATE '2021-01-02' AS event_date, 'FAILURE' AS event_type  UNION ALL  SELECT DATE '2021-01-03' AS event_date, 'SUCCESS' AS event_type  UNION ALL  SELECT DATE '2021-01-04' AS event_date, 'FAILURE' AS event_type  UNION ALL  SELECT DATE '2021-01-04' AS event_date, 'FAILURE' AS event_type)SELECT  COUNT(DISTINCT IF(event_type = 'FAILURE', event_date, NULL))    AS distinct_dates_with_failuresFROM Events;/*------------------------------* | distinct_dates_with_failures | +------------------------------+ | 2                            | *------------------------------*/\n```\n\n"
  },
  {
    "name": "COUNT (DIFFERENTIAL_PRIVACY)",
    "arguments": [],
    "category": "Differentially private aggregate functions",
    "description": "- [Signature 1](#dp_count_signature1): Returns the number of rows in adifferentially private`    FROM`clause.\n- [Signature 2](#dp_count_signature2): Returns the number of non-`    NULL`values in an expression.\n\n\n<span id=\"dp_count_signature1\">\n#### Signature 1\n\n</span>\n```\nWITH DIFFERENTIAL_PRIVACY ...  COUNT(    *,    [contribution_bounds_per_group =&gt; (lower_bound, upper_bound)]  )\n```\n\n **Description** \n\nReturns the number of rows in the[differentially private](/bigquery/docs/differential-privacy#dp_from)`FROM`clause. The final resultis an aggregation across a privacy unit column.\n\nThis function must be used with the[DIFFERENTIAL_PRIVACY clause](/bigquery/docs/reference/standard-sql/query-syntax#dp_clause)and can support the following argument:\n\n- `    contribution_bounds_per_group`: The[contribution bounds named argument](#dp_clamped_named).Perform clamping per each group separately before performing intermediategrouping on the privacy unit column.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\nThe following differentially private query counts the number of requests foreach item. This query references a table called[professors](/bigquery/docs/reference/standard-sql/query-syntax#dp_example_tables).\n\n```\n-- With noise, using the epsilon parameter.SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=10, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    COUNT(*, contribution_bounds_per_group=&gt;(0, 100)) times_requestedFROM professorsGROUP BY item;-- These results will change each time you run the query.-- Smaller aggregations might be removed./*----------+-----------------* | item     | times_requested | +----------+-----------------+ | pencil   | 5               | | pen      | 2               | *----------+-----------------*/\n```\n\n```\n-- Without noise, using the epsilon parameter.-- (this un-noised version is for demonstration only)SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=1e20, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    COUNT(*, contribution_bounds_per_group=&gt;(0, 100)) times_requestedFROM professorsGROUP BY item;-- These results will not change when you run the query./*----------+-----------------* | item     | times_requested | +----------+-----------------+ | scissors | 1               | | pencil   | 4               | | pen      | 3               | *----------+-----------------*/\n```\n\n **Note:** For more information about when and when not to usenoise, see[Remove noise](/bigquery/docs/reference/standard-sql/query-syntax#eliminate_noise).\n<span id=\"dp_count_signature2\">\n#### Signature 2\n\n</span>\n```\nWITH DIFFERENTIAL_PRIVACY ...  COUNT(    expression,    [contribution_bounds_per_group =&gt; (lower_bound, upper_bound)]  )\n```\n\n **Description** \n\nReturns the number of non-`NULL`expression values. The final result is anaggregation across a privacy unit column.\n\nThis function must be used with the[DIFFERENTIAL_PRIVACY clause](/bigquery/docs/reference/standard-sql/query-syntax#dp_clause)and can support these arguments:\n\n- `    expression`: The input expression. This expression can be anynumeric input type, such as`    INT64`.\n- `    contribution_bounds_per_group`: The[contribution bounds named argument](#dp_clamped_named).Perform clamping per each group separately before performing intermediategrouping on the privacy unit column.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\nThe following differentially private query counts the number of requests madefor each type of item. This query references a table called[professors](/bigquery/docs/reference/standard-sql/query-syntax#dp_example_tables).\n\n```\n-- With noise, using the epsilon parameter.SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=10, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    COUNT(item, contribution_bounds_per_group =&gt; (0,100)) times_requestedFROM professorsGROUP BY item;-- These results will change each time you run the query.-- Smaller aggregations might be removed./*----------+-----------------* | item     | times_requested | +----------+-----------------+ | pencil   | 5               | | pen      | 2               | *----------+-----------------*/\n```\n\n```\n-- Without noise, using the epsilon parameter.-- (this un-noised version is for demonstration only)SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=1e20, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    COUNT(item, contribution_bounds_per_group =&gt; (0,100)) times_requestedFROM professorsGROUP BY item;-- These results will not change when you run the query./*----------+-----------------* | item     | times_requested | +----------+-----------------+ | scissors | 1               | | pencil   | 4               | | pen      | 3               | *----------+-----------------*/\n```\n\n **Note:** For more information about when and when not to usenoise, see[Remove noise](/bigquery/docs/reference/standard-sql/query-syntax#eliminate_noise)."
  },
  {
    "name": "COUNTIF",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nCOUNTIF(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the count of`TRUE`values for`expression`. Returns`0`if there arezero input rows, or if`expression`evaluates to`FALSE`or`NULL`for all rows.\n\nSince`expression`must be a`BOOL`, the form`COUNTIF(DISTINCT ...)`isgenerally not useful: there is only one distinct value of`TRUE`. So`COUNTIF(DISTINCT ...)`will return 1 if`expression`evaluates to`TRUE`forone or more input rows, or 0 otherwise.Usually when someone wants to combine`COUNTIF`and`DISTINCT`, theywant to count the number of distinct values of an expression for which a certaincondition is satisfied. One recipe to achieve this is the following:\n\n```\nCOUNT(DISTINCT IF(condition, expression, NULL))\n```\n\nNote that this uses`COUNT`, not`COUNTIF`; the`IF`part has been moved inside.To learn more, see the examples for[COUNT](#count).\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\nBOOL\n\n **Return Data Types** \n\nINT64\n\n **Examples** \n\n```\nSELECT COUNTIF(x&lt;0) AS num_negative, COUNTIF(x&gt;0) AS num_positiveFROM UNNEST([5, -2, 3, 6, -10, -7, 4, 0]) AS x;/*--------------+--------------* | num_negative | num_positive | +--------------+--------------+ | 3            | 4            | *--------------+--------------*/\n```\n\n```\nSELECT  x,  COUNTIF(x&lt;0) OVER (ORDER BY ABS(x) ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS num_negativeFROM UNNEST([5, -2, 3, 6, -10, NULL, -7, 4, 0]) AS x;/*------+--------------* | x    | num_negative | +------+--------------+ | NULL | 0            | | 0    | 1            | | -2   | 1            | | 3    | 1            | | 4    | 0            | | 5    | 0            | | 6    | 1            | | -7   | 2            | | -10  | 2            | *------+--------------*/\n```\n\n"
  },
  {
    "name": "COVAR_POP",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nCOVAR_POP(  X1, X2)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the population[covariance](https://en.wikipedia.org/wiki/Covariance)ofa set of number pairs. The first number is the dependent variable; the secondnumber is the independent variable. The return result is between`-Inf`and`+Inf`.\n\nAll numeric types are supported. If theinput is`NUMERIC`or`BIGNUMERIC`then the internal aggregation isstable with the final output converted to a`FLOAT64`.Otherwise the input is converted to a`FLOAT64`before aggregation, resulting in a potentially unstable result.\n\nThis function ignores any input pairs that contain one or more`NULL`values. Ifthere is no input pair without`NULL`values, this function returns`NULL`.If there is exactly one input pair without`NULL`values, this function returns`0`.\n\n`NaN`is produced if:\n\n- Any input value is`    NaN`\n- Any input value is positive infinity or negative infinity.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nSELECT COVAR_POP(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 1.0 AS x),      (2.0, 6.0),      (9.0, 3.0),      (2.0, 6.0),      (9.0, 3.0)])/*---------------------* | results             | +---------------------+ | -1.6800000000000002 | *---------------------*/\n```\n\n```\nSELECT COVAR_POP(y, x) AS resultsFROM UNNEST([STRUCT(1.0 AS y, NULL AS x),(9.0, 3.0)])/*---------* | results | +---------+ | 0       | *---------*/\n```\n\n```\nSELECT COVAR_POP(y, x) AS resultsFROM UNNEST([STRUCT(1.0 AS y, NULL AS x),(9.0, NULL)])/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT COVAR_POP(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 1.0 AS x),      (2.0, 6.0),      (9.0, 3.0),      (2.0, 6.0),      (NULL, 3.0)])/*---------* | results | +---------+ | -1      | *---------*/\n```\n\n```\nSELECT COVAR_POP(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 1.0 AS x),      (2.0, 6.0),      (9.0, 3.0),      (2.0, 6.0),      (CAST('Infinity' as FLOAT64), 3.0)])/*---------* | results | +---------+ | NaN     | *---------*/\n```\n\n"
  },
  {
    "name": "COVAR_SAMP",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nCOVAR_SAMP(  X1, X2)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the sample[covariance](https://en.wikipedia.org/wiki/Covariance)of aset of number pairs. The first number is the dependent variable; the secondnumber is the independent variable. The return result is between`-Inf`and`+Inf`.\n\nAll numeric types are supported. If theinput is`NUMERIC`or`BIGNUMERIC`then the internal aggregation isstable with the final output converted to a`FLOAT64`.Otherwise the input is converted to a`FLOAT64`before aggregation, resulting in a potentially unstable result.\n\nThis function ignores any input pairs that contain one or more`NULL`values. Ifthere are fewer than two input pairs without`NULL`values, this functionreturns`NULL`.\n\n`NaN`is produced if:\n\n- Any input value is`    NaN`\n- Any input value is positive infinity or negative infinity.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nSELECT COVAR_SAMP(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 1.0 AS x),      (2.0, 6.0),      (9.0, 3.0),      (2.0, 6.0),      (9.0, 3.0)])/*---------* | results | +---------+ | -2.1    | *---------*/\n```\n\n```\nSELECT COVAR_SAMP(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 1.0 AS x),      (2.0, 6.0),      (9.0, 3.0),      (2.0, 6.0),      (NULL, 3.0)])/*----------------------* | results              | +----------------------+ | --1.3333333333333333 | *----------------------*/\n```\n\n```\nSELECT COVAR_SAMP(y, x) AS resultsFROM UNNEST([STRUCT(1.0 AS y, NULL AS x),(9.0, 3.0)])/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT COVAR_SAMP(y, x) AS resultsFROM UNNEST([STRUCT(1.0 AS y, NULL AS x),(9.0, NULL)])/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT COVAR_SAMP(y, x) AS resultsFROM  UNNEST(    [      STRUCT(1.0 AS y, 1.0 AS x),      (2.0, 6.0),      (9.0, 3.0),      (2.0, 6.0),      (CAST('Infinity' as FLOAT64), 3.0)])/*---------* | results | +---------+ | NaN     | *---------*/\n```\n\n"
  },
  {
    "name": "CSC",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCSC(X)\n```\n\n **Description** \n\nComputes the cosecant of the input angle, which is in radians.`X`can be any data typethat[coerces to FLOAT64](/bigquery/docs/reference/standard-sql/conversion_rules#conversion_rules).Supports the`SAFE.`prefix.\n\n| X | CSC(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n| `0` | `Error` |\n| `NULL` | `NULL` |\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nSELECT CSC(100) AS a, CSC(-1) AS b, SAFE.CSC(0) AS c;/*----------------+-----------------+------* | a              | b               | c    | +----------------+-----------------+------+ | -1.97485753142 | -1.188395105778 | NULL | *----------------+-----------------+------*/\n```\n\n"
  },
  {
    "name": "CSCH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nCSCH(X)\n```\n\n **Description** \n\nComputes the hyperbolic cosecant of the input angle, which is in radians.`X`can be any data typethat[coerces to FLOAT64](/bigquery/docs/reference/standard-sql/conversion_rules#conversion_rules).Supports the`SAFE.`prefix.\n\n| X | CSCH(X) |\n| --- | --- |\n| `+inf` | `0` |\n| `-inf` | `0` |\n| `NaN` | `NaN` |\n| `0` | `Error` |\n| `NULL` | `NULL` |\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nSELECT CSCH(0.5) AS a, CSCH(-2) AS b, SAFE.CSCH(0) AS c;/*----------------+----------------+------* | a              | b              | c    | +----------------+----------------+------+ | 1.919034751334 | -0.27572056477 | NULL | *----------------+----------------+------*/\n```\n\n"
  },
  {
    "name": "CUME_DIST",
    "arguments": [],
    "category": "Numbering functions",
    "description": "```\nCUME_DIST()OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]\n```\n\n **Description** \n\nReturn the relative rank of a row defined as NP/NR. NP is defined to be thenumber of rows that either precede or are peers with the current row. NR is thenumber of rows in the partition.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 2:59:01', 'F30-34')SELECT name,  finish_time,  division,  CUME_DIST() OVER (PARTITION BY division ORDER BY finish_time ASC) AS finish_rankFROM finishers;/*-----------------+------------------------+----------+-------------* | name            | finish_time            | division | finish_rank | +-----------------+------------------------+----------+-------------+ | Sophia Liu      | 2016-10-18 09:51:45+00 | F30-34   | 0.25        | | Meghan Lederer  | 2016-10-18 09:59:01+00 | F30-34   | 0.75        | | Nikki Leith     | 2016-10-18 09:59:01+00 | F30-34   | 0.75        | | Jen Edwards     | 2016-10-18 10:06:36+00 | F30-34   | 1           | | Lisa Stelzner   | 2016-10-18 09:54:11+00 | F35-39   | 0.25        | | Lauren Matthews | 2016-10-18 10:01:17+00 | F35-39   | 0.5         | | Desiree Berry   | 2016-10-18 10:05:42+00 | F35-39   | 0.75        | | Suzy Slane      | 2016-10-18 10:06:24+00 | F35-39   | 1           | *-----------------+------------------------+----------+-------------*/\n```\n\n"
  },
  {
    "name": "CURRENT_DATE",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nCURRENT_DATE()\n```\n\n```\nCURRENT_DATE(time_zone_expression)\n```\n\n```\nCURRENT_DATE\n```\n\n **Description** \n\nReturns the current date as a`DATE`object. Parentheses are optional whencalled with no arguments.\n\nThis function supports the following arguments:\n\n- `    time_zone_expression`: A`    STRING`expression that represents a[time zone](#timezone_definitions). If no time zone is specified, thedefault time zone, UTC, is used. If this expression isused and it evaluates to`    NULL`, this function returns`    NULL`.\n\nThe current date is recorded at the start of the querystatement which contains this function, not when this specific function isevaluated.\n\n **Return Data Type** \n\n`DATE`\n\n **Examples** \n\nThe following query produces the current date in the default time zone:\n\n```\nSELECT CURRENT_DATE() AS the_date;/*--------------* | the_date     | +--------------+ | 2016-12-25   | *--------------*/\n```\n\nThe following queries produce the current date in a specified time zone:\n\n```\nSELECT CURRENT_DATE('America/Los_Angeles') AS the_date;/*--------------* | the_date     | +--------------+ | 2016-12-25   | *--------------*/\n```\n\n```\nSELECT CURRENT_DATE('-08') AS the_date;/*--------------* | the_date     | +--------------+ | 2016-12-25   | *--------------*/\n```\n\nThe following query produces the current date in the default time zone.Parentheses are not needed if the function has no arguments.\n\n```\nSELECT CURRENT_DATE AS the_date;/*--------------* | the_date     | +--------------+ | 2016-12-25   | *--------------*/\n```\n\nWhen a column named`current_date`is present, the column name and the functioncall without parentheses are ambiguous. To ensure the function call, addparentheses; to ensure the column name, qualify it with its[range variable](/bigquery/docs/reference/standard-sql/query-syntax#range_variables). For example, thefollowing query will select the function in the`the_date`column and the tablecolumn in the`current_date`column.\n\n```\nWITH t AS (SELECT 'column value' AS `current_date`)SELECT current_date() AS the_date, t.current_date FROM t;/*------------+--------------* | the_date   | current_date | +------------+--------------+ | 2016-12-25 | column value | *------------+--------------*/\n```\n\n"
  },
  {
    "name": "CURRENT_DATETIME",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nCURRENT_DATETIME([time_zone])\n```\n\n```\nCURRENT_DATETIME\n```\n\n **Description** \n\nReturns the current time as a`DATETIME`object. Parentheses are optional whencalled with no arguments.\n\nThis function supports an optional`time_zone`parameter.See[Time zone definitions](#timezone_definitions)forinformation on how to specify a time zone.\n\nThe current date and time is recorded at the start of the querystatement which contains this function, not when this specific function isevaluated.\n\n **Return Data Type** \n\n`DATETIME`\n\n **Example** \n\n```\nSELECT CURRENT_DATETIME() as now;/*----------------------------* | now                        | +----------------------------+ | 2016-05-19T10:38:47.046465 | *----------------------------*/\n```\n\nWhen a column named`current_datetime`is present, the column name and thefunction call without parentheses are ambiguous. To ensure the function call,add parentheses; to ensure the column name, qualify it with its[range variable](/bigquery/docs/reference/standard-sql/query-syntax#range_variables). For example, thefollowing query will select the function in the`now`column and the tablecolumn in the`current_datetime`column.\n\n```\nWITH t AS (SELECT 'column value' AS `current_datetime`)SELECT current_datetime() as now, t.current_datetime FROM t;/*----------------------------+------------------* | now                        | current_datetime | +----------------------------+------------------+ | 2016-05-19T10:38:47.046465 | column value     | *----------------------------+------------------*/\n```\n\n"
  },
  {
    "name": "CURRENT_TIME",
    "arguments": [],
    "category": "Time functions",
    "description": "```\nCURRENT_TIME([time_zone])\n```\n\n```\nCURRENT_TIME\n```\n\n **Description** \n\nReturns the current time as a`TIME`object. Parentheses are optional whencalled with no arguments.\n\nThis function supports an optional`time_zone`parameter.See[Time zone definitions](#timezone_definitions)for informationon how to specify a time zone.\n\nThe current time is recorded at the start of the querystatement which contains this function, not when this specific function isevaluated.\n\n **Return Data Type** \n\n`TIME`\n\n **Example** \n\n```\nSELECT CURRENT_TIME() as now;/*----------------------------* | now                        | +----------------------------+ | 15:31:38.776361            | *----------------------------*/\n```\n\nWhen a column named`current_time`is present, the column name and the functioncall without parentheses are ambiguous. To ensure the function call, addparentheses; to ensure the column name, qualify it with its[range variable](/bigquery/docs/reference/standard-sql/query-syntax#range_variables). For example, thefollowing query will select the function in the`now`column and the tablecolumn in the`current_time`column.\n\n```\nWITH t AS (SELECT 'column value' AS `current_time`)SELECT current_time() as now, t.current_time FROM t;/*-----------------+--------------* | now             | current_time | +-----------------+--------------+ | 15:31:38.776361 | column value | *-----------------+--------------*/\n```\n\n"
  },
  {
    "name": "CURRENT_TIMESTAMP",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nCURRENT_TIMESTAMP()\n```\n\n```\nCURRENT_TIMESTAMP\n```\n\n **Description** \n\nReturns the current date and time as a timestamp object. The timestamp iscontinuous, non-ambiguous, has exactly 60 seconds per minute and does not repeatvalues over the leap second. Parentheses are optional.\n\nThis function handles leap seconds by smearing them across a window of 20 hoursaround the inserted leap second.\n\nThe current date and time is recorded at the start of the querystatement which contains this function, not when this specific function isevaluated.\n\n **Supported Input Types** \n\nNot applicable\n\n **Result Data Type** \n\n`TIMESTAMP`\n\n **Examples** \n\n```\nSELECT CURRENT_TIMESTAMP() AS now;/*--------------------------------* | now                            | +--------------------------------+ | 2020-06-02 23:57:12.120174 UTC | *--------------------------------*/\n```\n\nWhen a column named`current_timestamp`is present, the column name and thefunction call without parentheses are ambiguous. To ensure the function call,add parentheses; to ensure the column name, qualify it with its[range variable](/bigquery/docs/reference/standard-sql/query-syntax#range_variables). For example, thefollowing query selects the function in the`now`column and the tablecolumn in the`current_timestamp`column.\n\n```\nWITH t AS (SELECT 'column value' AS `current_timestamp`)SELECT current_timestamp() AS now, t.current_timestamp FROM t;/*--------------------------------+-------------------* | now                            | current_timestamp | +--------------------------------+-------------------+ | 2020-06-02 23:57:12.120174 UTC | column value      | *--------------------------------+-------------------*/\n```\n\n"
  },
  {
    "name": "DATE",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nDATE(year, month, day)\n```\n\n```\nDATE(timestamp_expression)\n```\n\n```\nDATE(timestamp_expression, time_zone_expression)\n```\n\n```\nDATE(datetime_expression)\n```\n\n **Description** \n\nConstructs or extracts a date.\n\nThis function supports the following arguments:\n\n- `    year`: The`    INT64`value for year.\n- `    month`: The`    INT64`value for month.\n- `    day`: The`    INT64`value for day.\n- `    timestamp_expression`: A`    TIMESTAMP`expression that contains the date.\n- `    time_zone_expression`: A`    STRING`expression that represents a[time zone](#timezone_definitions). If no time zone is specified with`    timestamp_expression`, the default time zone, UTC, isused.\n- `    datetime_expression`: A`    DATETIME`expression that contains the date.\n\n **Return Data Type** \n\n`DATE`\n\n **Example** \n\n```\nSELECT  DATE(2016, 12, 25) AS date_ymd,  DATE(DATETIME '2016-12-25 23:59:59') AS date_dt,  DATE(TIMESTAMP '2016-12-25 05:30:00+07', 'America/Los_Angeles') AS date_tstz;/*------------+------------+------------* | date_ymd   | date_dt    | date_tstz  | +------------+------------+------------+ | 2016-12-25 | 2016-12-25 | 2016-12-24 | *------------+------------+------------*/\n```\n\n"
  },
  {
    "name": "DATETIME",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\n1. DATETIME(year, month, day, hour, minute, second)2. DATETIME(date_expression[, time_expression])3. DATETIME(timestamp_expression [, time_zone])\n```\n\n **Description** \n\n1. Constructs a`    DATETIME`object using`    INT64`valuesrepresenting the year, month, day, hour, minute, and second.\n1. Constructs a`    DATETIME`object using a DATE object and an optional`    TIME`object.\n1. Constructs a`    DATETIME`object using a`    TIMESTAMP`object. It supports anoptional parameter to[specify a time zone](#timezone_definitions).If no time zone is specified, the default time zone, UTC,is used.\n\n **Return Data Type** \n\n`DATETIME`\n\n **Example** \n\n```\nSELECT  DATETIME(2008, 12, 25, 05, 30, 00) as datetime_ymdhms,  DATETIME(TIMESTAMP \"2008-12-25 05:30:00+00\", \"America/Los_Angeles\") as datetime_tstz;/*---------------------+---------------------* | datetime_ymdhms     | datetime_tstz       | +---------------------+---------------------+ | 2008-12-25T05:30:00 | 2008-12-24T21:30:00 | *---------------------+---------------------*/\n```\n\n"
  },
  {
    "name": "DATETIME_ADD",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nDATETIME_ADD(datetime_expression, INTERVAL int64_expression part)\n```\n\n **Description** \n\nAdds`int64_expression`units of`part`to the`DATETIME`object.\n\n`DATETIME_ADD`supports the following values for`part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n- `    DAY`\n- `    WEEK`. Equivalent to 7`    DAY`s.\n- `    MONTH`\n- `    QUARTER`\n- `    YEAR`\n\nSpecial handling is required for MONTH, QUARTER, and YEAR parts when thedate is at (or near) the last day of the month. If the resulting month has fewerdays than the original DATETIME's day, then the result day is the last day ofthe new month.\n\n **Return Data Type** \n\n`DATETIME`\n\n **Example** \n\n```\nSELECT  DATETIME \"2008-12-25 15:30:00\" as original_date,  DATETIME_ADD(DATETIME \"2008-12-25 15:30:00\", INTERVAL 10 MINUTE) as later;/*-----------------------------+------------------------* | original_date               | later                  | +-----------------------------+------------------------+ | 2008-12-25T15:30:00         | 2008-12-25T15:40:00    | *-----------------------------+------------------------*/\n```\n\n"
  },
  {
    "name": "DATETIME_BUCKET",
    "arguments": [],
    "category": "Time series functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nDATETIME_BUCKET(datetime_in_bucket, bucket_width)\n```\n\n```\nDATETIME_BUCKET(datetime_in_bucket, bucket_width, bucket_origin_datetime)\n```\n\n **Description** \n\nGets the lower bound of the datetime bucket that contains a datetime.\n\n **Definitions** \n\n- `    datetime_in_bucket`: A`    DATETIME`value that you can use to look up adatetime bucket.\n- `    bucket_width`: An`    INTERVAL`value that represents the width ofa datetime bucket. A[single interval](/bigquery/docs/reference/standard-sql/data-types#single_datetime_part_interval)with[date and time parts](/bigquery/docs/reference/standard-sql/data-types#interval_datetime_parts)is supported.\n- `    bucket_origin_datetime`: A`    DATETIME`value that represents a point intime. All buckets expand left and right from this point. If this argumentis not set,`    1950-01-01 00:00:00`is used by default.\n\n **Return type** \n\n`DATETIME`\n\n **Examples** \n\nIn the following example, the origin is omitted and the default origin,`1950-01-01 00:00:00`is used. All buckets expand in both directions from theorigin, and the size of each bucket is 12 hours. The lower bound of the bucketin which`my_datetime`belongs is returned:\n\n```\nWITH some_datetimes AS (  SELECT DATETIME '1949-12-30 13:00:00' AS my_datetime UNION ALL  SELECT DATETIME '1949-12-31 00:00:00' UNION ALL  SELECT DATETIME '1949-12-31 13:00:00' UNION ALL  SELECT DATETIME '1950-01-01 00:00:00' UNION ALL  SELECT DATETIME '1950-01-01 13:00:00' UNION ALL  SELECT DATETIME '1950-01-02 00:00:00')SELECT DATETIME_BUCKET(my_datetime, INTERVAL 12 HOUR) AS bucket_lower_boundFROM some_datetimes;/*---------------------+ | bucket_lower_bound  | +---------------------+ | 1949-12-30T12:00:00 | | 1949-12-31T00:00:00 | | 1949-12-31T12:00:00 | | 1950-01-01T00:00:00 | | 1950-01-01T12:00:00 | | 1950-01-02T00:00:00 | +---------------------*/-- Some datetime buckets that originate from 1950-01-01 00:00:00:-- + Bucket: ...-- + Bucket: [1949-12-30 00:00:00, 1949-12-30 12:00:00)-- + Bucket: [1949-12-30 12:00:00, 1950-01-01 00:00:00)-- + Origin: [1950-01-01 00:00:00]-- + Bucket: [1950-01-01 00:00:00, 1950-01-01 12:00:00)-- + Bucket: [1950-01-01 12:00:00, 1950-02-00 00:00:00)-- + Bucket: ...\n```\n\nIn the following example, the origin has been changed to`2000-12-24 12:00:00`,and all buckets expand in both directions from this point. The size of eachbucket is seven days. The lower bound of the bucket in which`my_datetime`belongs is returned:\n\n```\nWITH some_datetimes AS (  SELECT DATETIME '2000-12-20 00:00:00' AS my_datetime UNION ALL  SELECT DATETIME '2000-12-21 00:00:00' UNION ALL  SELECT DATETIME '2000-12-22 00:00:00' UNION ALL  SELECT DATETIME '2000-12-23 00:00:00' UNION ALL  SELECT DATETIME '2000-12-24 00:00:00' UNION ALL  SELECT DATETIME '2000-12-25 00:00:00')SELECT DATETIME_BUCKET(  my_datetime,  INTERVAL 7 DAY,  DATETIME '2000-12-22 12:00:00') AS bucket_lower_boundFROM some_datetimes;/*--------------------+ | bucket_lower_bound | +--------------------+ | 2000-12-15T12:00:00 | | 2000-12-15T12:00:00 | | 2000-12-15T12:00:00 | | 2000-12-22T12:00:00 | | 2000-12-22T12:00:00 | | 2000-12-22T12:00:00 | +--------------------*/-- Some datetime buckets that originate from 2000-12-22 12:00:00:-- + Bucket: ...-- + Bucket: [2000-12-08 12:00:00, 2000-12-15 12:00:00)-- + Bucket: [2000-12-15 12:00:00, 2000-12-22 12:00:00)-- + Origin: [2000-12-22 12:00:00]-- + Bucket: [2000-12-22 12:00:00, 2000-12-29 12:00:00)-- + Bucket: [2000-12-29 12:00:00, 2000-01-05 12:00:00)-- + Bucket: ...\n```\n\n"
  },
  {
    "name": "DATETIME_DIFF",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nDATETIME_DIFF(datetime_expression_a, datetime_expression_b, part)\n```\n\n **Description** \n\nReturns the whole number of specified`part`intervals between two`DATETIME`objects (`datetime_expression_a`-`datetime_expression_b`).If the first`DATETIME`is earlier than the second one,the output is negative. Throws an error if the computation overflows theresult type, such as if the difference inmicrosecondsbetween the two`DATETIME`objects would overflow an`INT64`value.\n\n`DATETIME_DIFF`supports the following values for`part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n- `    DAY`\n- `    WEEK`: This date part begins on Sunday.\n- `    WEEK(&lt;WEEKDAY&gt;)`: This date part begins on`    WEEKDAY`. Valid values for`    WEEKDAY`are`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`, and`    SATURDAY`.\n- `    ISOWEEK`: Uses[ISO 8601 week](https://en.wikipedia.org/wiki/ISO_week_date)boundaries. ISO weeks begin on Monday.\n- `    MONTH`, except when the first twoarguments are`    TIMESTAMP`values.\n- `    QUARTER`\n- `    YEAR`\n- `    ISOYEAR`: Uses the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering year boundary. The ISO year boundary is the Monday of thefirst week whose Thursday belongs to the corresponding Gregorian calendaryear.\n\n **Note:** The behavior of the this function follows the type of arguments passed in.For example,`DATETIME_DIFF(TIMESTAMP, TIMESTAMP, PART)`behaves like`TIMESTAMP_DIFF(TIMESTAMP, TIMESTAMP, PART)`. **Return Data Type** \n\n`INT64`\n\n **Example** \n\n```\nSELECT  DATETIME \"2010-07-07 10:20:00\" as first_datetime,  DATETIME \"2008-12-25 15:30:00\" as second_datetime,  DATETIME_DIFF(DATETIME \"2010-07-07 10:20:00\",    DATETIME \"2008-12-25 15:30:00\", DAY) as difference;/*----------------------------+------------------------+------------------------* | first_datetime             | second_datetime        | difference             | +----------------------------+------------------------+------------------------+ | 2010-07-07T10:20:00        | 2008-12-25T15:30:00    | 559                    | *----------------------------+------------------------+------------------------*/\n```\n\n```\nSELECT  DATETIME_DIFF(DATETIME '2017-10-15 00:00:00',    DATETIME '2017-10-14 00:00:00', DAY) as days_diff,  DATETIME_DIFF(DATETIME '2017-10-15 00:00:00',    DATETIME '2017-10-14 00:00:00', WEEK) as weeks_diff;/*-----------+------------* | days_diff | weeks_diff | +-----------+------------+ | 1         | 1          | *-----------+------------*/\n```\n\nThe example above shows the result of`DATETIME_DIFF`for two`DATETIME`s thatare 24 hours apart.`DATETIME_DIFF`with the part`WEEK`returns 1 because`DATETIME_DIFF`counts the number of part boundaries in this range of`DATETIME`s. Each`WEEK`begins on Sunday, so there is one part boundary betweenSaturday,`2017-10-14 00:00:00`and Sunday,`2017-10-15 00:00:00`.\n\nThe following example shows the result of`DATETIME_DIFF`for two dates indifferent years.`DATETIME_DIFF`with the date part`YEAR`returns 3 because itcounts the number of Gregorian calendar year boundaries between the two`DATETIME`s.`DATETIME_DIFF`with the date part`ISOYEAR`returns 2 because thesecond`DATETIME`belongs to the ISO year 2015. The first Thursday of the 2015calendar year was 2015-01-01, so the ISO year 2015 begins on the precedingMonday, 2014-12-29.\n\n```\nSELECT  DATETIME_DIFF('2017-12-30 00:00:00',    '2014-12-30 00:00:00', YEAR) AS year_diff,  DATETIME_DIFF('2017-12-30 00:00:00',    '2014-12-30 00:00:00', ISOYEAR) AS isoyear_diff;/*-----------+--------------* | year_diff | isoyear_diff | +-----------+--------------+ | 3         | 2            | *-----------+--------------*/\n```\n\nThe following example shows the result of`DATETIME_DIFF`for two days insuccession. The first date falls on a Monday and the second date falls on aSunday.`DATETIME_DIFF`with the date part`WEEK`returns 0 because this timepart uses weeks that begin on Sunday.`DATETIME_DIFF`with the date part`WEEK(MONDAY)`returns 1.`DATETIME_DIFF`with the date part`ISOWEEK`also returns 1 because ISO weeks begin on Monday.\n\n```\nSELECT  DATETIME_DIFF('2017-12-18', '2017-12-17', WEEK) AS week_diff,  DATETIME_DIFF('2017-12-18', '2017-12-17', WEEK(MONDAY)) AS week_weekday_diff,  DATETIME_DIFF('2017-12-18', '2017-12-17', ISOWEEK) AS isoweek_diff;/*-----------+-------------------+--------------* | week_diff | week_weekday_diff | isoweek_diff | +-----------+-------------------+--------------+ | 0         | 1                 | 1            | *-----------+-------------------+--------------*/\n```\n\n"
  },
  {
    "name": "DATETIME_SUB",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nDATETIME_SUB(datetime_expression, INTERVAL int64_expression part)\n```\n\n **Description** \n\nSubtracts`int64_expression`units of`part`from the`DATETIME`.\n\n`DATETIME_SUB`supports the following values for`part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n- `    DAY`\n- `    WEEK`. Equivalent to 7`    DAY`s.\n- `    MONTH`\n- `    QUARTER`\n- `    YEAR`\n\nSpecial handling is required for`MONTH`,`QUARTER`, and`YEAR`parts when thedate is at (or near) the last day of the month. If the resulting month has fewerdays than the original`DATETIME`'s day, then the result day is the last day ofthe new month.\n\n **Return Data Type** \n\n`DATETIME`\n\n **Example** \n\n```\nSELECT  DATETIME \"2008-12-25 15:30:00\" as original_date,  DATETIME_SUB(DATETIME \"2008-12-25 15:30:00\", INTERVAL 10 MINUTE) as earlier;/*-----------------------------+------------------------* | original_date               | earlier                | +-----------------------------+------------------------+ | 2008-12-25T15:30:00         | 2008-12-25T15:20:00    | *-----------------------------+------------------------*/\n```\n\n"
  },
  {
    "name": "DATETIME_TRUNC",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nDATETIME_TRUNC(datetime_expression, date_time_part)\n```\n\n **Description** \n\nTruncates a`DATETIME`value to the granularity of`date_time_part`.The`DATETIME`value is always rounded to the beginning of`date_time_part`,which can be one of the following:\n\n- `    MICROSECOND`: If used, nothing is truncated from the value.\n- `    MILLISECOND`: The nearest lessor or equal millisecond.\n- `    SECOND`: The nearest lessor or equal second.\n- `    MINUTE`: The nearest lessor or equal minute.\n- `    HOUR`: The nearest lessor or equal hour.\n- `    DAY`: The day in the Gregorian calendar year that contains the`    DATETIME`value.\n- `    WEEK`: The first day of the week in the week that contains the`    DATETIME`value. Weeks begin on Sundays.`    WEEK`is equivalent to`    WEEK(SUNDAY)`.\n- `    WEEK(WEEKDAY)`: The first day of the week in the week that contains the`    DATETIME`value. Weeks begin on`    WEEKDAY`.`    WEEKDAY`must be one of thefollowing:`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`,or`    SATURDAY`.\n- `    ISOWEEK`: The first day of the[ISO 8601 week](https://en.wikipedia.org/wiki/ISO_week_date)in theISO week that contains the`    DATETIME`value. The ISO week begins onMonday. The first ISO week of each ISO year contains the first Thursday of thecorresponding Gregorian calendar year.\n- `    MONTH`: The first day of the month in the month that contains the`    DATETIME`value.\n- `    QUARTER`: The first day of the quarter in the quarter that contains the`    DATETIME`value.\n- `    YEAR`: The first day of the year in the year that contains the`    DATETIME`value.\n- `    ISOYEAR`: The first day of the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering yearin the ISO year that contains the`    DATETIME`value. The ISO year is theMonday of the first week whose Thursday belongs to the correspondingGregorian calendar year.\n\n **Return Data Type** \n\n`DATETIME`\n\n **Examples** \n\n```\nSELECT  DATETIME \"2008-12-25 15:30:00\" as original,  DATETIME_TRUNC(DATETIME \"2008-12-25 15:30:00\", DAY) as truncated;/*----------------------------+------------------------* | original                   | truncated              | +----------------------------+------------------------+ | 2008-12-25T15:30:00        | 2008-12-25T00:00:00    | *----------------------------+------------------------*/\n```\n\nIn the following example, the original`DATETIME`falls on a Sunday. Because the`part`is`WEEK(MONDAY)`,`DATE_TRUNC`returns the`DATETIME`for thepreceding Monday.\n\n```\nSELECT datetime AS original, DATETIME_TRUNC(datetime, WEEK(MONDAY)) AS truncatedFROM (SELECT DATETIME(TIMESTAMP \"2017-11-05 00:00:00+00\", \"UTC\") AS datetime);/*---------------------+---------------------* | original            | truncated           | +---------------------+---------------------+ | 2017-11-05T00:00:00 | 2017-10-30T00:00:00 | *---------------------+---------------------*/\n```\n\nIn the following example, the original`datetime_expression`is in the Gregoriancalendar year 2015. However,`DATETIME_TRUNC`with the`ISOYEAR`date parttruncates the`datetime_expression`to the beginning of the ISO year, not theGregorian calendar year. The first Thursday of the 2015 calendar year was2015-01-01, so the ISO year 2015 begins on the preceding Monday, 2014-12-29.Therefore the ISO year boundary preceding the`datetime_expression`2015-06-15 00:00:00 is 2014-12-29.\n\n```\nSELECT  DATETIME_TRUNC('2015-06-15 00:00:00', ISOYEAR) AS isoyear_boundary,  EXTRACT(ISOYEAR FROM DATETIME '2015-06-15 00:00:00') AS isoyear_number;/*---------------------+----------------* | isoyear_boundary    | isoyear_number | +---------------------+----------------+ | 2014-12-29T00:00:00 | 2015           | *---------------------+----------------*/\n```\n\n"
  },
  {
    "name": "DATE_ADD",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nDATE_ADD(date_expression, INTERVAL int64_expression date_part)\n```\n\n **Description** \n\nAdds a specified time interval to a DATE.\n\n`DATE_ADD`supports the following`date_part`values:\n\n- `    DAY`\n- `    WEEK`. Equivalent to 7`    DAY`s.\n- `    MONTH`\n- `    QUARTER`\n- `    YEAR`\n\nSpecial handling is required for MONTH, QUARTER, and YEAR parts whenthe date is at (or near) the last day of the month. If the resultingmonth has fewer days than the original date's day, then the resultingdate is the last date of that month.\n\n **Return Data Type** \n\nDATE\n\n **Example** \n\n```\nSELECT DATE_ADD(DATE '2008-12-25', INTERVAL 5 DAY) AS five_days_later;/*--------------------* | five_days_later    | +--------------------+ | 2008-12-30         | *--------------------*/\n```\n\n"
  },
  {
    "name": "DATE_BUCKET",
    "arguments": [],
    "category": "Time series functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nDATE_BUCKET(date_in_bucket, bucket_width)\n```\n\n```\nDATE_BUCKET(date_in_bucket, bucket_width, bucket_origin_date)\n```\n\n **Description** \n\nGets the lower bound of the date bucket that contains a date.\n\n **Definitions** \n\n- `    date_in_bucket`: A`    DATE`value that you can use to look up a date bucket.\n- `    bucket_width`: An`    INTERVAL`value that represents the width ofa date bucket. A[single interval](/bigquery/docs/reference/standard-sql/data-types#single_datetime_part_interval)with[date parts](/bigquery/docs/reference/standard-sql/data-types#interval_datetime_parts)is supported.\n- `    bucket_origin_date`: A`    DATE`value that represents a point in time. Allbuckets expand left and right from this point. If this argument is not set,`    1950-01-01`is used by default.\n\n **Return type** \n\n`DATE`\n\n **Examples** \n\nIn the following example, the origin is omitted and the default origin,`1950-01-01`is used. All buckets expand in both directions from the origin,and the size of each bucket is two days. The lower bound of the bucket inwhich`my_date`belongs is returned.\n\n```\nWITH some_dates AS (  SELECT DATE '1949-12-29' AS my_date UNION ALL  SELECT DATE '1949-12-30' UNION ALL  SELECT DATE '1949-12-31' UNION ALL  SELECT DATE '1950-01-01' UNION ALL  SELECT DATE '1950-01-02' UNION ALL  SELECT DATE '1950-01-03')SELECT DATE_BUCKET(my_date, INTERVAL 2 DAY) AS bucket_lower_boundFROM some_dates;/*--------------------+ | bucket_lower_bound | +--------------------+ | 1949-12-28         | | 1949-12-30         | | 1949-12-30         | | 1950-12-01         | | 1950-12-01         | | 1950-12-03         | +--------------------*/-- Some date buckets that originate from 1950-01-01:-- + Bucket: ...-- + Bucket: [1949-12-28, 1949-12-30)-- + Bucket: [1949-12-30, 1950-01-01)-- + Origin: [1950-01-01]-- + Bucket: [1950-01-01, 1950-01-03)-- + Bucket: [1950-01-03, 1950-01-05)-- + Bucket: ...\n```\n\nIn the following example, the origin has been changed to`2000-12-24`,and all buckets expand in both directions from this point. The size of eachbucket is seven days. The lower bound of the bucket in which`my_date`belongsis returned:\n\n```\nWITH some_dates AS (  SELECT DATE '2000-12-20' AS my_date UNION ALL  SELECT DATE '2000-12-21' UNION ALL  SELECT DATE '2000-12-22' UNION ALL  SELECT DATE '2000-12-23' UNION ALL  SELECT DATE '2000-12-24' UNION ALL  SELECT DATE '2000-12-25')SELECT DATE_BUCKET(  my_date,  INTERVAL 7 DAY,  DATE '2000-12-24') AS bucket_lower_boundFROM some_dates;/*--------------------+ | bucket_lower_bound | +--------------------+ | 2000-12-17         | | 2000-12-17         | | 2000-12-17         | | 2000-12-17         | | 2000-12-24         | | 2000-12-24         | +--------------------*/-- Some date buckets that originate from 2000-12-24:-- + Bucket: ...-- + Bucket: [2000-12-10, 2000-12-17)-- + Bucket: [2000-12-17, 2000-12-24)-- + Origin: [2000-12-24]-- + Bucket: [2000-12-24, 2000-12-31)-- + Bucket: [2000-12-31, 2000-01-07)-- + Bucket: ...\n```\n\n"
  },
  {
    "name": "DATE_DIFF",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nDATE_DIFF(date_expression_a, date_expression_b, date_part)\n```\n\n **Description** \n\nReturns the whole number of specified`date_part`intervals between two`DATE`objects (`date_expression_a`-`date_expression_b`).If the first`DATE`is earlier than the second one,the output is negative.\n\n`DATE_DIFF`supports the following`date_part`values:\n\n- `    DAY`\n- `    WEEK`This date part begins on Sunday.\n- `    WEEK(&lt;WEEKDAY&gt;)`: This date part begins on`    WEEKDAY`. Valid values for`    WEEKDAY`are`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`, and`    SATURDAY`.\n- `    ISOWEEK`: Uses[ISO 8601 week](https://en.wikipedia.org/wiki/ISO_week_date)boundaries. ISO weeks begin on Monday.\n- `    MONTH`, except when the first twoarguments are`    TIMESTAMP`values.\n- `    QUARTER`\n- `    YEAR`\n- `    ISOYEAR`: Uses the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering year boundary. The ISO year boundary is the Monday of thefirst week whose Thursday belongs to the corresponding Gregorian calendaryear.\n\n **Note:** The behavior of the this function follows the type of arguments passed in.For example,`DATE_DIFF(TIMESTAMP, TIMESTAMP, PART)`behaves like`TIMESTAMP_DIFF(TIMESTAMP, TIMESTAMP, PART)`. **Return Data Type** \n\nINT64\n\n **Example** \n\n```\nSELECT DATE_DIFF(DATE '2010-07-07', DATE '2008-12-25', DAY) AS days_diff;/*-----------* | days_diff | +-----------+ | 559       | *-----------*/\n```\n\n```\nSELECT  DATE_DIFF(DATE '2017-10-15', DATE '2017-10-14', DAY) AS days_diff,  DATE_DIFF(DATE '2017-10-15', DATE '2017-10-14', WEEK) AS weeks_diff;/*-----------+------------* | days_diff | weeks_diff | +-----------+------------+ | 1         | 1          | *-----------+------------*/\n```\n\nThe example above shows the result of`DATE_DIFF`for two days in succession.`DATE_DIFF`with the date part`WEEK`returns 1 because`DATE_DIFF`counts thenumber of date part boundaries in this range of dates. Each`WEEK`begins onSunday, so there is one date part boundary between Saturday, 2017-10-14and Sunday, 2017-10-15.\n\nThe following example shows the result of`DATE_DIFF`for two dates in differentyears.`DATE_DIFF`with the date part`YEAR`returns 3 because it counts thenumber of Gregorian calendar year boundaries between the two dates.`DATE_DIFF`with the date part`ISOYEAR`returns 2 because the second date belongs to theISO year 2015. The first Thursday of the 2015 calendar year was 2015-01-01, sothe ISO year 2015 begins on the preceding Monday, 2014-12-29.\n\n```\nSELECT  DATE_DIFF('2017-12-30', '2014-12-30', YEAR) AS year_diff,  DATE_DIFF('2017-12-30', '2014-12-30', ISOYEAR) AS isoyear_diff;/*-----------+--------------* | year_diff | isoyear_diff | +-----------+--------------+ | 3         | 2            | *-----------+--------------*/\n```\n\nThe following example shows the result of`DATE_DIFF`for two days insuccession. The first date falls on a Monday and the second date falls on aSunday.`DATE_DIFF`with the date part`WEEK`returns 0 because this date partuses weeks that begin on Sunday.`DATE_DIFF`with the date part`WEEK(MONDAY)`returns 1.`DATE_DIFF`with the date part`ISOWEEK`also returns 1 becauseISO weeks begin on Monday.\n\n```\nSELECT  DATE_DIFF('2017-12-18', '2017-12-17', WEEK) AS week_diff,  DATE_DIFF('2017-12-18', '2017-12-17', WEEK(MONDAY)) AS week_weekday_diff,  DATE_DIFF('2017-12-18', '2017-12-17', ISOWEEK) AS isoweek_diff;/*-----------+-------------------+--------------* | week_diff | week_weekday_diff | isoweek_diff | +-----------+-------------------+--------------+ | 0         | 1                 | 1            | *-----------+-------------------+--------------*/\n```\n\n"
  },
  {
    "name": "DATE_FROM_UNIX_DATE",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nDATE_FROM_UNIX_DATE(int64_expression)\n```\n\n **Description** \n\nInterprets`int64_expression`as the number of days since 1970-01-01.\n\n **Return Data Type** \n\nDATE\n\n **Example** \n\n```\nSELECT DATE_FROM_UNIX_DATE(14238) AS date_from_epoch;/*-----------------* | date_from_epoch | +-----------------+ | 2008-12-25      | *-----------------+*/\n```\n\n"
  },
  {
    "name": "DATE_SUB",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nDATE_SUB(date_expression, INTERVAL int64_expression date_part)\n```\n\n **Description** \n\nSubtracts a specified time interval from a DATE.\n\n`DATE_SUB`supports the following`date_part`values:\n\n- `    DAY`\n- `    WEEK`. Equivalent to 7`    DAY`s.\n- `    MONTH`\n- `    QUARTER`\n- `    YEAR`\n\nSpecial handling is required for MONTH, QUARTER, and YEAR parts whenthe date is at (or near) the last day of the month. If the resultingmonth has fewer days than the original date's day, then the resultingdate is the last date of that month.\n\n **Return Data Type** \n\nDATE\n\n **Example** \n\n```\nSELECT DATE_SUB(DATE '2008-12-25', INTERVAL 5 DAY) AS five_days_ago;/*---------------* | five_days_ago | +---------------+ | 2008-12-20    | *---------------*/\n```\n\n"
  },
  {
    "name": "DATE_TRUNC",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nDATE_TRUNC(date_expression, date_part)\n```\n\n **Description** \n\nTruncates a`DATE`value to the granularity of`date_part`. The`DATE`valueis always rounded to the beginning of`date_part`, which can be one of thefollowing:\n\n- `    DAY`: The day in the Gregorian calendar year that contains the`    DATE`value.\n- `    WEEK`: The first day of the week in the week that contains the`    DATE`value. Weeks begin on Sundays.`    WEEK`is equivalent to`    WEEK(SUNDAY)`.\n- `    WEEK(WEEKDAY)`: The first day of the week in the week that contains the`    DATE`value. Weeks begin on`    WEEKDAY`.`    WEEKDAY`must be one of thefollowing:`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`,or`    SATURDAY`.\n- `    ISOWEEK`: The first day of the[ISO 8601 week](https://en.wikipedia.org/wiki/ISO_week_date)in theISO week that contains the`    DATE`value. The ISO week begins onMonday. The first ISO week of each ISO year contains the first Thursday of thecorresponding Gregorian calendar year.\n- `    MONTH`: The first day of the month in the month that contains the`    DATE`value.\n- `    QUARTER`: The first day of the quarter in the quarter that contains the`    DATE`value.\n- `    YEAR`: The first day of the year in the year that contains the`    DATE`value.\n- `    ISOYEAR`: The first day of the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering yearin the ISO year that contains the`    DATE`value. The ISO year is theMonday of the first week whose Thursday belongs to the correspondingGregorian calendar year.\n\n **Return Data Type** \n\nDATE\n\n **Examples** \n\n```\nSELECT DATE_TRUNC(DATE '2008-12-25', MONTH) AS month;/*------------* | month      | +------------+ | 2008-12-01 | *------------*/\n```\n\nIn the following example, the original date falls on a Sunday. Becausethe`date_part`is`WEEK(MONDAY)`,`DATE_TRUNC`returns the`DATE`for thepreceding Monday.\n\n```\nSELECT date AS original, DATE_TRUNC(date, WEEK(MONDAY)) AS truncatedFROM (SELECT DATE('2017-11-05') AS date);/*------------+------------* | original   | truncated  | +------------+------------+ | 2017-11-05 | 2017-10-30 | *------------+------------*/\n```\n\nIn the following example, the original`date_expression`is in the Gregoriancalendar year 2015. However,`DATE_TRUNC`with the`ISOYEAR`date parttruncates the`date_expression`to the beginning of the ISO year, not theGregorian calendar year. The first Thursday of the 2015 calendar year was2015-01-01, so the ISO year 2015 begins on the preceding Monday, 2014-12-29.Therefore the ISO year boundary preceding the`date_expression`2015-06-15 is2014-12-29.\n\n```\nSELECT  DATE_TRUNC('2015-06-15', ISOYEAR) AS isoyear_boundary,  EXTRACT(ISOYEAR FROM DATE '2015-06-15') AS isoyear_number;/*------------------+----------------* | isoyear_boundary | isoyear_number | +------------------+----------------+ | 2014-12-29       | 2015           | *------------------+----------------*/\n```\n\n"
  },
  {
    "name": "DENSE_RANK",
    "arguments": [],
    "category": "Numbering functions",
    "description": "```\nDENSE_RANK()OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]\n```\n\n **Description** \n\nReturns the ordinal (1-based) rank of each row within the window partition.All peer rows receive the same rank value, and the subsequent rank value isincremented by one.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH Numbers AS (SELECT 1 as x  UNION ALL SELECT 2  UNION ALL SELECT 2  UNION ALL SELECT 5  UNION ALL SELECT 8  UNION ALL SELECT 10  UNION ALL SELECT 10)SELECT x,  DENSE_RANK() OVER (ORDER BY x ASC) AS dense_rankFROM Numbers/*-------------------------* | x          | dense_rank | +-------------------------+ | 1          | 1          | | 2          | 2          | | 2          | 2          | | 5          | 3          | | 8          | 4          | | 10         | 5          | | 10         | 5          | *-------------------------*/\n```\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 2:59:01', 'F30-34')SELECT name,  finish_time,  division,  DENSE_RANK() OVER (PARTITION BY division ORDER BY finish_time ASC) AS finish_rankFROM finishers;/*-----------------+------------------------+----------+-------------* | name            | finish_time            | division | finish_rank | +-----------------+------------------------+----------+-------------+ | Sophia Liu      | 2016-10-18 09:51:45+00 | F30-34   | 1           | | Meghan Lederer  | 2016-10-18 09:59:01+00 | F30-34   | 2           | | Nikki Leith     | 2016-10-18 09:59:01+00 | F30-34   | 2           | | Jen Edwards     | 2016-10-18 10:06:36+00 | F30-34   | 3           | | Lisa Stelzner   | 2016-10-18 09:54:11+00 | F35-39   | 1           | | Lauren Matthews | 2016-10-18 10:01:17+00 | F35-39   | 2           | | Desiree Berry   | 2016-10-18 10:05:42+00 | F35-39   | 3           | | Suzy Slane      | 2016-10-18 10:06:24+00 | F35-39   | 4           | *-----------------+------------------------+----------+-------------*/\n```\n\n"
  },
  {
    "name": "DETERMINISTIC_DECRYPT_BYTES",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nDETERMINISTIC_DECRYPT_BYTES(keyset, ciphertext, additional_data)\n```\n\n **Description** \n\nUses the matching key from`keyset`to decrypt`ciphertext`and verifies theintegrity of the data using`additional_data`. Returns an error if decryptionfails.\n\n`keyset`is a serialized`BYTES`value or a`STRUCT`value returned by one of the`KEYS`functions.`keyset`must containthe key that was used to encrypt`ciphertext`, the key must be in an`'ENABLED'`state, and the key must be of type`DETERMINISTIC_AEAD_AES_SIV_CMAC_256`, orelse the function returns an error.`DETERMINISTIC_DECRYPT_BYTES`identifies thematching key in`keyset`by finding the key with the key ID that matches the oneencrypted in`ciphertext`.\n\n`ciphertext`is a`BYTES`value that is the result of a call to`DETERMINISTIC_ENCRYPT`where the input`plaintext`was of type`BYTES`.\n\nThe ciphertext must follow Tink's[wire format](https://developers.google.com/tink/wire-format#deterministic_aead). The firstbyte of`ciphertext`should contain a Tink key version followed by a 4 byte keyhint. If`ciphertext`includes an initialization vector (IV), it should be thenext bytes of`ciphertext`. If`ciphertext`includes an authentication tag, itshould be the last bytes of`ciphertext`. If the IV and authentic tag are one(SIV), it should be the first bytes of`ciphertext`. The IV and authenticationtag commonly require 16 bytes, but may vary in size.\n\n`additional_data`is a`STRING`or`BYTES`value that binds the ciphertext toits context. This forces the ciphertext to be decrypted in the same context inwhich it was encrypted. This function casts any`STRING`value to`BYTES`. Thismust be the same as the`additional_data`provided to`DETERMINISTIC_ENCRYPT`toencrypt`ciphertext`, ignoring its type, or else the function returns an error.\n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nThis example creates a table of unique IDs with associated plaintext values andkeysets. Then it uses these keysets to encrypt the plaintext values as`BYTES`and store them in a new table. Finally, it uses`DETERMINISTIC_DECRYPT_BYTES`todecrypt the encrypted values and display them as plaintext.\n\nThe following statement creates a table`CustomerKeysets`containing a column ofunique IDs, a column of`DETERMINISTIC_AEAD_AES_SIV_CMAC_256`keysets, and acolumn of favorite animals.\n\n```\nCREATE TABLE deterministic.CustomerKeysets ASSELECT  1 AS customer_id,  KEYS.NEW_KEYSET('DETERMINISTIC_AEAD_AES_SIV_CMAC_256') AS keyset,  b'jaguar' AS favorite_animalUNION ALLSELECT  2 AS customer_id,  KEYS.NEW_KEYSET('DETERMINISTIC_AEAD_AES_SIV_CMAC_256') AS keyset,  b'zebra' AS favorite_animalUNION ALLSELECT  3 AS customer_id,  KEYS.NEW_KEYSET('DETERMINISTIC_AEAD_AES_SIV_CMAC_256') AS keyset,  b'nautilus' AS favorite_animal;\n```\n\nThe following statement creates a table`EncryptedCustomerData`containing acolumn of unique IDs and a column of ciphertext. The statement encrypts theplaintext`favorite_animal`using the keyset value from`CustomerKeysets`corresponding to each unique ID.\n\n```\nCREATE TABLE deterministic.EncryptedCustomerData ASSELECT  customer_id,  DETERMINISTIC_ENCRYPT(ck.keyset, favorite_animal, CAST(CAST(customer_id AS STRING) AS BYTES))   AS encrypted_animalFROM  deterministic.CustomerKeysets AS ck;\n```\n\nThe following query uses the keysets in the`CustomerKeysets`table to decryptdata in the`EncryptedCustomerData`table.\n\n```\nSELECT  ecd.customer_id,  DETERMINISTIC_DECRYPT_BYTES(    (SELECT ck.keyset     FROM deterministic.CustomerKeysets AS ck     WHERE ecd.customer_id = ck.customer_id),    ecd.encrypted_animal,    CAST(CAST(ecd.customer_id AS STRING) AS BYTES)  ) AS favorite_animalFROM deterministic.EncryptedCustomerData AS ecd;\n```\n\n"
  },
  {
    "name": "DETERMINISTIC_DECRYPT_STRING",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nDETERMINISTIC_DECRYPT_STRING(keyset, ciphertext, additional_data)\n```\n\n **Description** \n\nLike[DETERMINISTIC_DECRYPT_BYTES](#deterministic_decrypt_bytes), but where`plaintext`is of type`STRING`.\n\n **Return Data Type** \n\n`STRING`\n\n"
  },
  {
    "name": "DETERMINISTIC_ENCRYPT",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nDETERMINISTIC_ENCRYPT(keyset, plaintext, additional_data)\n```\n\n **Description** \n\nEncrypts`plaintext`using the primary cryptographic key in`keyset`using[deterministic AEAD](https://developers.google.com/tink/deterministic-aead). The algorithm of the primary key mustbe`DETERMINISTIC_AEAD_AES_SIV_CMAC_256`. Binds the ciphertext to the contextdefined by`additional_data`. Returns`NULL`if any input is`NULL`.\n\n`keyset`is a serialized`BYTES`value or a`STRUCT`value returned by one of the`KEYS`functions.\n\n`plaintext`is the`STRING`or`BYTES`value to be encrypted.\n\n`additional_data`is a`STRING`or`BYTES`value that binds the ciphertext toits context. This forces the ciphertext to be decrypted in the same context inwhich it was encrypted.`plaintext`and`additional_data`must be of the sametype.`DETERMINISTIC_ENCRYPT(keyset, string1, string2)`is equivalent to`DETERMINISTIC_ENCRYPT(keyset, CAST(string1 AS BYTES), CAST(string2 AS BYTES))`.\n\nThe output is ciphertext`BYTES`. The ciphertext contains a[Tink-specific](https://github.com/google/tink/blob/master/docs/KEY-MANAGEMENT.md)prefix indicating the key used to perform the encryption.Given an identical`keyset`and`plaintext`, this function returns the sameciphertext each time it is invoked (including across queries).\n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nThe following query uses the keysets for each`customer_id`in the`CustomerKeysets`table to encrypt the value of the plaintext`favorite_animal`in the`PlaintextCustomerData`table corresponding to that`customer_id`. Theoutput contains a column of`customer_id`values and a column of correspondingciphertext output as`BYTES`.\n\n```\nWITH CustomerKeysets AS (  SELECT 1 AS customer_id,  KEYS.NEW_KEYSET('DETERMINISTIC_AEAD_AES_SIV_CMAC_256') AS keyset UNION ALL  SELECT 2, KEYS.NEW_KEYSET('DETERMINISTIC_AEAD_AES_SIV_CMAC_256') UNION ALL  SELECT 3, KEYS.NEW_KEYSET('DETERMINISTIC_AEAD_AES_SIV_CMAC_256')), PlaintextCustomerData AS (  SELECT 1 AS customer_id, 'elephant' AS favorite_animal UNION ALL  SELECT 2, 'walrus' UNION ALL  SELECT 3, 'leopard')SELECT  pcd.customer_id,  DETERMINISTIC_ENCRYPT(    (SELECT keyset     FROM CustomerKeysets AS ck     WHERE ck.customer_id = pcd.customer_id),    pcd.favorite_animal,    CAST(pcd.customer_id AS STRING)  ) AS encrypted_animalFROM PlaintextCustomerData AS pcd;\n```\n\n"
  },
  {
    "name": "DIFFERENCES BETWEEN THE JSON AND JSON-FORMATTED STRING TYPES",
    "arguments": [],
    "category": "JSON functions",
    "description": "Many JSON functions accept two input types:\n\n- [JSON](/bigquery/docs/reference/standard-sql/data-types#json_type)type\n- `    STRING`type\n\nThe`STRING`version of the extraction functions behaves differently than the`JSON`version, mainly because`JSON`type values are always validated whereasJSON-formatted`STRING`type values are not.\n\n\n<span id=\"non-validation_of_string_inputs\">\n#### Non-validation of`STRING`inputs\n\n</span>\nThe following`STRING`is invalid JSON because it is missing a trailing`}`:\n\n```\n{\"hello\": \"world\"\n```\n\nThe JSON function reads the input from the beginning and stops as soon as thefield to extract is found, without reading the remainder of the input. A parsingerror is not produced.\n\nWith the`JSON`type, however,`JSON '{\"hello\": \"world\"'`returns a parsingerror.\n\nFor example:\n\n```\nSELECT JSON_VALUE('{\"hello\": \"world\"', \"$.hello\") AS hello;/*-------* | hello | +-------+ | world | *-------*/\n```\n\n```\nSELECT JSON_VALUE(JSON '{\"hello\": \"world\"', \"$.hello\") AS hello;-- An error is returned: Invalid JSON literal: syntax error while parsing-- object - unexpected end of input; expected '}'\n```\n\n\n<span id=\"no_strict_validation_of_extracted_values\">\n#### No strict validation of extracted values\n\n</span>\nIn the following examples, duplicated keys are not removed when using aJSON-formatted string. Similarly, keys order is preserved. For the`JSON`type,`JSON '{\"key\": 1, \"key\": 2}'`will result in`JSON '{\"key\":1}'`duringparsing.\n\n```\nSELECT JSON_QUERY('{\"key\": 1, \"key\": 2}', \"$\") AS string;/*-------------------* | string            | +-------------------+ | {\"key\":1,\"key\":2} | *-------------------*/\n```\n\n```\nSELECT JSON_QUERY(JSON '{\"key\": 1, \"key\": 2}', \"$\") AS json;/*-----------* | json      | +-----------+ | {\"key\":1} | *-----------*/\n```\n\n\n<span id=\"json_null\">\n#### JSON`null`\n\n</span>\nWhen using a JSON-formatted`STRING`type in a JSON function, a JSON`null`value is extracted as a SQL`NULL`value.\n\nWhen using a JSON type in a JSON function, a JSON`null`value returns a JSON`null`value.\n\n```\nWITH t AS (  SELECT '{\"name\": null}' AS json_string, JSON '{\"name\": null}' AS json)SELECT JSON_QUERY(json_string, \"$.name\") AS name_string,  JSON_QUERY(json_string, \"$.name\") IS NULL AS name_string_is_null,  JSON_QUERY(json, \"$.name\") AS name_json,  JSON_QUERY(json, \"$.name\") IS NULL AS name_json_is_nullFROM t;/*-------------+---------------------+-----------+-------------------* | name_string | name_string_is_null | name_json | name_json_is_null | +-------------+---------------------+-----------+-------------------+ | NULL        | true                | null      | false             | *-------------+---------------------+-----------+-------------------*/\n```\n\n\n<span id=\"mathematical_functions\">\n## Mathematical functions\n\n</span>\nGoogleSQL for BigQuery supports mathematical functions.All mathematical functions have the following behaviors:\n\n- They return`    NULL`if any of the input parameters is`    NULL`.\n- They return`    NaN`if any of the arguments is`    NaN`.\n\n"
  },
  {
    "name": "DIV",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nDIV(X, Y)\n```\n\n **Description** \n\nReturns the result of integer division of X by Y. Division by zero returnsan error. Division by -1 may overflow.\n\n| X | Y | DIV(X, Y) |\n| --- | --- | --- |\n| 20 | 4 | 5 |\n| 12 | -7 | -1 |\n| 20 | 3 | 6 |\n| 0 | 20 | 0 |\n| 20 | 0 | Error |\n\n **Return Data Type** \n\nThe return data type is determined by the argument types with the followingtable.\n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` |\n| --- | --- | --- | --- |\n| `INT64` | `INT64` | `NUMERIC` | `BIGNUMERIC` |\n| `NUMERIC` | `NUMERIC` | `NUMERIC` | `BIGNUMERIC` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` |\n\n"
  },
  {
    "name": "DLP_DETERMINISTIC_DECRYPT",
    "arguments": [],
    "category": "DLP encryption functions",
    "description": "```\nDLP_DETERMINISTIC_DECRYPT(key, ciphertext, context)\n```\n\n```\nDLP_DETERMINISTIC_DECRYPT(key, ciphertext, context, surrogate)\n```\n\n **Description** \n\nThis function decrypts`ciphertext`using an encryption key derived from`key`and`context`. Optionally, you can use`surrogate`to prepend the decryptionresult.\n\n **Definitions** \n\n- `    key`: A serialized`    BYTES`value returned by[DLP_KEY_CHAIN](#dlp_key_chain).`    key`must be set to`    ENABLED`in Cloud KMS. Forinformation about how to generate a wrapped key, see[gcloud kms encrypt](https://cloud.google.com/sdk/gcloud/reference/kms/encrypt).\n- `    ciphertext`: The`    STRING`value to decrypt.\n- `    context`: A`    STRING`value that is used with aCloud KMS key to derive a data encryption key. For more information,see[CryptoDeterministicConfig:context](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.deidentifyTemplates#cryptodeterministicconfig).\n- `    surrogate`: A`    STRING`value that you can prepend to output.\n\n **Return data type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT  DLP_DETERMINISTIC_DECRYPT(    DLP_KEY_CHAIN(      'gcp-kms://projects/myproject/locations/us-central1/keyRings/keyringtest/cryptoKeys/testkey',      b'\\123\\044\\290\\876....'),    'your_surrogate(36)AdFnA6r5doSDWxPwW/W4vBaa4iOvDagC8z8=',    '',    'your_surrogate') AS results/*-----------* | results   | +-----------+ | plaintext | *-----------*/\n```\n\n"
  },
  {
    "name": "DLP_DETERMINISTIC_ENCRYPT",
    "arguments": [],
    "category": "DLP encryption functions",
    "description": "```\nDLP_DETERMINISTIC_ENCRYPT(key, plaintext, context)\n```\n\n```\nDLP_DETERMINISTIC_ENCRYPT(key, plaintext, context, surrogate)\n```\n\n **Description** \n\nThis function derives a data encryption key from`key`and`context`, and thenencrypts`plaintext`. Optionally, you can use`surrogate`to prepend theencryption result.\n\n **Definitions** \n\n- `    key`: A serialized`    BYTES`value that is returned by[DLP_KEY_CHAIN](#dlp_key_chain).`    key`must be set to`    ENABLED`in Cloud KMS. Forinformation about how to generate a wrapped key, see[gcloud kms encrypt](https://cloud.google.com/sdk/gcloud/reference/kms/encrypt).\n- `    plaintext`: The`    STRING`value to encrypt.\n- `    context`: A user-provided`    STRING`value that is used with aCloud KMS key to derive a data encryption key. For more information,see[CryptoDeterministicConfig:context](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.deidentifyTemplates#cryptodeterministicconfig).\n- `    surrogate`: A`    STRING`value that you can prepend to output.\n\n **Return data type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT  DLP_DETERMINISTIC_ENCRYPT(    DLP_KEY_CHAIN(      'gcp-kms://projects/my_project/locations/us-central1/keyRings/keyringtest/cryptoKeys/testkey',      b'\\123\\044\\290\\876....'),    plaintext,    '',    'test') AS results/*--------------------------------------* | results                              | +--------------------------------------+ | AXDEwUnZsTf/NzxoHaC8AZXcawWuma7L39A= | *--------------------------------------*/\n```\n\n"
  },
  {
    "name": "DLP_KEY_CHAIN",
    "arguments": [],
    "category": "DLP encryption functions",
    "description": "```\nDLP_KEY_CHAIN(kms_resource_name, wrapped_key)\n```\n\n **Description** \n\nYou can use this function instead of the`key`argument forDLP deterministic encryption functions. This function letsyou use the[AES-SIV encryption functions](https://cloud.google.com/dlp/docs/pseudonymization#aes-siv)without including`plaintext`keys in a query.\n\n **Definitions** \n\n- `    kms_resource_name`: A`    STRING`literal that contains the resource path to theCloud KMS key.`    kms_resource_name`cannot be`    NULL`and must residein the same Cloud region where this function is executed. This argument isused to derive the data encryption key in the`    DLP_DETERMINISTIC_DECRYPT`and`    DLP_DETERMINISTIC_ENCRYPT`functions. A Cloud KMS key looks likethis:\n    \n    \n    ```\n    gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key\n    ```\n    \n    \n- `    wrapped_key`: A`    BYTES`literal that represents a secret text chosen by theuser. This secret text can be 16, 24, or 32 bytes. For information abouthow to generate a wrapped key, see[gcloud kms encrypt](https://cloud.google.com/sdk/gcloud/reference/kms/encrypt).\n    \n    \n\n **Return data type** \n\n`STRUCT`\n\n **Example** \n\n```\nSELECT  DLP_DETERMINISTIC_ENCRYPT(    DLP_KEY_CHAIN(      'gcp-kms://projects/my_project/locations/us-central1/keyRings/keyringtest/cryptoKeys/testkey',      b'\\123\\044\\290\\876....'),    plaintext,    '',    'test') AS results/*--------------------------------------* | results                              | +--------------------------------------+ | AXDEwUnZsTf/NzxoHaC8AZXcawWuma7L39A= | *--------------------------------------*/\n```\n\n\n<span id=\"geography_functions\">\n## Geography functions\n\n</span>\nGoogleSQL for BigQuery supports geography functions.Geography functions operate on or generate GoogleSQL`GEOGRAPHY`values. The signature of most geographyfunctions starts with`ST_`. GoogleSQL for BigQuery supports the following functionsthat can be used to analyze geographical data, determine spatial relationshipsbetween geographical features, and construct or manipulate`GEOGRAPHY`s.\n\nAll GoogleSQL geography functions return`NULL`if any input argumentis`NULL`.\n\n"
  },
  {
    "name": "EDIT_DISTANCE",
    "arguments": [],
    "category": "String functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bq-search-team@google.com](mailto:bq-search-team@google.com).```\nEDIT_DISTANCE(value1, value2, [max_distance =&gt; max_distance_value])\n```\n\n **Description** \n\nComputes the[Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance)between two`STRING`or`BYTES`values.\n\n **Definitions** \n\n- `    value1`: The first`    STRING`or`    BYTES`value to compare.\n- `    value2`: The second`    STRING`or`    BYTES`value to compare.\n- `    max_distance`: Optional mandatory-named argument. Takes a non-negative`    INT64`value that represents the maximum distance between the two valuesto compute.\n    \n    If this distance is exceeded, the function returns this value.The default value for this argument is the maximum size of`    value1`and`    value2`.\n    \n    \n\n **Details** \n\nIf`value1`or`value2`is`NULL`,`NULL`is returned.\n\nYou can only compare values of the same type. Otherwise, an error is produced.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\nIn the following example, the first character in both strings is different:\n\n```\nSELECT EDIT_DISTANCE('a', 'b') AS results;/*---------* | results | +---------+ | 1       | *---------*/\n```\n\nIn the following example, the first and second characters in both strings aredifferent:\n\n```\nSELECT EDIT_DISTANCE('aa', 'b') AS results;/*---------* | results | +---------+ | 2       | *---------*/\n```\n\nIn the following example, only the first character in both strings isdifferent:\n\n```\nSELECT EDIT_DISTANCE('aa', 'ba') AS results;/*---------* | results | +---------+ | 1       | *---------*/\n```\n\nIn the following example, the last six characters are different, but becausethe maximum distance is`2`, this function exits early and returns`2`, themaximum distance:\n\n```\nSELECT EDIT_DISTANCE('abcdefg', 'a', max_distance =&gt; 2) AS results;/*---------* | results | +---------+ | 2       | *---------*/\n```\n\n"
  },
  {
    "name": "ENDS_WITH",
    "arguments": [],
    "category": "String functions",
    "description": "```\nENDS_WITH(value, suffix)\n```\n\n **Description** \n\nTakes two`STRING`or`BYTES`values. Returns`TRUE`if`suffix`is a suffix of`value`.\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\n```\nWITH items AS  (SELECT 'apple' as item  UNION ALL  SELECT 'banana' as item  UNION ALL  SELECT 'orange' as item)SELECT  ENDS_WITH(item, 'e') as exampleFROM items;/*---------* | example | +---------+ |    True | |   False | |    True | *---------*/\n```\n\n"
  },
  {
    "name": "ERROR",
    "arguments": [],
    "category": "Debugging functions",
    "description": "```\nERROR(error_message)\n```\n\n **Description** \n\nReturns an error.\n\n **Definitions** \n\n- `    error_message`: A`    STRING`value that represents the error message toproduce. Any whitespace characters beyond asingle space are trimmed from the results.\n\n **Details** \n\n`ERROR`is treated like any other expression that mayresult in an error: there is no special guarantee of evaluation order.\n\n **Return Data Type** \n\nGoogleSQL infers the return type in context.\n\n **Examples** \n\nIn the following example, the query returns an error message if the value of therow does not match one of two defined values.\n\n```\nSELECT  CASE    WHEN value = 'foo' THEN 'Value is foo.'    WHEN value = 'bar' THEN 'Value is bar.'    ELSE ERROR(CONCAT('Found unexpected value: ', value))  END AS new_valueFROM (  SELECT 'foo' AS value UNION ALL  SELECT 'bar' AS value UNION ALL  SELECT 'baz' AS value);-- Found unexpected value: baz\n```\n\nIn the following example, GoogleSQL may evaluate the`ERROR`functionbefore or after thecondition, because GoogleSQLgenerally provides no ordering guarantees between`WHERE`clause conditions andthere are no special guarantees for the`ERROR`function.\n\n```\nSELECT *FROM (SELECT -1 AS x)WHERE x &gt; 0 AND ERROR('Example error');\n```\n\nIn the next example, the`WHERE`clause evaluates an`IF`condition, whichensures that GoogleSQL only evaluates the`ERROR`function if thecondition fails.\n\n```\nSELECT *FROM (SELECT -1 AS x)WHERE IF(x &gt; 0, true, ERROR(FORMAT('Error: x must be positive but is %t', x)));-- Error: x must be positive but is -1\n```\n\n\n<span id=\"aggregate-dp-functions\">\n## Differentially private aggregate functions\n\n</span>\n **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-sql-preview-support@google.com](mailto:bigquery-sql-preview-support@google.com).GoogleSQL for BigQuery supports differentially private aggregate functions.For an explanation of how aggregate functions work, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nYou can only use differentially private aggregate functions with[differentially private queries](/bigquery/docs/differential-privacy)in a[differential privacy clause](/bigquery/docs/reference/standard-sql/query-syntax#dp_clause).\n\n **Note:** In this topic, the privacy parameters in the examples are notrecommendations. You should work with your privacy or security officer todetermine the optimal privacy parameters for your dataset and organization."
  },
  {
    "name": "EUCLIDEAN_DISTANCE",
    "arguments": [],
    "category": "Mathematical functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bq-search-team@google.com](mailto:bq-search-team@google.com).```\nEUCLIDEAN_DISTANCE(vector1, vector2)\n```\n\n **Description** \n\nComputes the[Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance)between two vectors.\n\n **Definitions** \n\n- `    vector1`: A vector that is represented by an`    ARRAY&lt;T&gt;`value or a sparse vector that isrepresented by an`    ARRAY&lt;STRUCT&lt;dimension,magnitude&gt;&gt;`value.\n- `    vector2`: A vector that is represented by an`    ARRAY&lt;T&gt;`value or a sparse vector that isrepresented by an`    ARRAY&lt;STRUCT&lt;dimension,magnitude&gt;&gt;`value.\n\n **Details** \n\n- `    ARRAY&lt;T&gt;`can be used to represent a vector. Each zero-based index in thisarray represents a dimension. The value for each element in this arrayrepresents a magnitude.\n    \n    `    T`can represent the following and must be the same for bothvectors:\n    \n    \n    - `        FLOAT64`In the following example vector, there are four dimensions. The magnitudeis`    10.0`for dimension`    0`,`    55.0`for dimension`    1`,`    40.0`fordimension`    2`, and`    34.0`for dimension`    3`:\n    \n    \n    ```\n    [10.0, 55.0, 40.0, 34.0]\n    ```\n    \n    \n- `    ARRAY&lt;STRUCT&lt;dimension,magnitude&gt;&gt;`can be used to represent asparse vector. With a sparse vector, you only need to includedimension-magnitude pairs for non-zero magnitudes. If a magnitude isn'tpresent in the sparse vector, the magnitude is implicitly understood to bezero.\n    \n    For example, if you have a vector with 10,000 dimensions, but only 10dimensions have non-zero magnitudes, then the vector is a sparse vector.As a result, it's more efficient to describe a sparse vector by onlymentioning its non-zero magnitudes.\n    \n    In`    ARRAY&lt;STRUCT&lt;dimension,magnitude&gt;&gt;`,`    STRUCT&lt;dimension,magnitude&gt;`represents a dimension-magnitude pair for each non-zero magnitude in asparse vector. These parts need to be included for each dimension-magnitudepair:\n    \n    \n    - `        dimension`: A`        STRING`or`        INT64`value that represents adimension in a vector.\n        \n        \n    - `        magnitude`: A`        FLOAT64`value that represents anon-zero magnitude for a specific dimension in a vector.\n        \n        You don't need to include empty dimension-magnitude pairs in asparse vector. For example, the following sparse vector andnon-sparse vector are equivalent:\n    \n    \n    ```\n    -- sparse vector ARRAY&lt;STRUCT&lt;INT64, FLOAT64&gt;&gt;[(1, 10.0), (2: 30.0), (5, 40.0)]\n    ```\n    \n    \n    ```\n    -- vector ARRAY&lt;FLOAT64&gt;[0.0, 10.0, 30.0, 0.0, 0.0, 40.0]\n    ```\n    \n    In a sparse vector, dimension-magnitude pairs don't need to be in anyparticular order. The following sparse vectors are equivalent:\n    \n    \n    ```\n    [('a', 10.0), ('b': 30.0), ('d': 40.0)]\n    ```\n    \n    \n    ```\n    [('d': 40.0), ('a', 10.0), ('b': 30.0)]\n    ```\n    \n    \n- Both  non-sparse vectorsin this function must share the same dimensions, and if they don't, an erroris produced.\n    \n    \n- A vector can be a zero vector. A vector is a zero vector if it hasno dimensions or all dimensions have a magnitude of`    0`, such as`    []`or`    [0.0, 0.0]`.\n    \n    \n- An error is produced if a magnitude in a vector is`    NULL`.\n    \n    \n- If a vector is`    NULL`,`    NULL`is returned.\n    \n    \n\n **Return type** \n\n`FLOAT64`\n\n **Examples** \n\nIn the following example, non-sparse vectorsare used to compute the Euclidean distance:\n\n```\nSELECT EUCLIDEAN_DISTANCE([1.0, 2.0], [3.0, 4.0]) AS results;/*----------* | results  | +----------+ | 2.828    | *----------*/\n```\n\nIn the following example, sparse vectors are used to compute theEuclidean distance:\n\n```\nSELECT EUCLIDEAN_DISTANCE( [(1, 1.0), (2, 2.0)], [(2, 4.0), (1, 3.0)]) AS results; /*----------*  | results  |  +----------+  | 2.828    |  *----------*/\n```\n\nThe ordering of magnitudes in a vector doesn't impact the resultsproduced by this function. For example these queries produce the same resultseven though the magnitudes in each vector is in a different order:\n\n```\nSELECT EUCLIDEAN_DISTANCE([1.0, 2.0], [3.0, 4.0]);\n```\n\n```\nSELECT EUCLIDEAN_DISTANCE([2.0, 1.0], [4.0, 3.0]);\n```\n\n```\nSELECT EUCLIDEAN_DISTANCE([(1, 1.0), (2, 2.0)], [(1, 3.0), (2, 4.0)]) AS results;\n```\n\n```\n/*----------*  | results  |  +----------+  | 2.828    |  *----------*/\n```\n\nBoth non-sparse vectors must have the samedimensions. If not, an error is produced. In the following example, the firstvector has two dimensions and the second vector has three:\n\n```\n-- ERRORSELECT EUCLIDEAN_DISTANCE([9.0, 7.0], [8.0, 4.0, 5.0]) AS results;\n```\n\nIf you use sparse vectors and you repeat a dimension, an error isproduced:\n\n```\n-- ERRORSELECT EUCLIDEAN_DISTANCE(  [(1, 9.0), (2, 7.0), (2, 8.0)], [(1, 8.0), (2, 4.0), (3, 5.0)]) AS results;\n```\n\n"
  },
  {
    "name": "EXP",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nEXP(X)\n```\n\n **Description** \n\nComputes *e* to the power of X, also called the natural exponential function. Ifthe result underflows, this function returns a zero. Generates an error if theresult overflows.\n\n| X | EXP(X) |\n| --- | --- |\n| 0.0 | 1.0 |\n| `+inf` | `+inf` |\n| `-inf` | 0.0 |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "EXTERNAL_OBJECT_TRANSFORM",
    "arguments": [],
    "category": "Table functions (built in)",
    "description": "```\nEXTERNAL_OBJECT_TRANSFORM(TABLE object_table_name, transform_types_array)\n```\n\n **Description** \n\nThis function returns a transformed object table with the original columns plusone or more additional columns, depending on the`transform_types`valuesspecified.\n\nThis function only supports[object tables](https://cloud.google.com/bigquery/docs/object-table-introduction)as inputs. Subqueries or any other types of tables are not supported.\n\n`object_table_name`is the name of the object table to be transformed, inthe format`dataset_name.object_table_name`.\n\n`transform_types_array`is an array of`STRING`literals. Currently, the onlysupported`transform_types_array`value is`SIGNED_URL`. Specifying`SIGNED_URL`creates read-only signed URLs for the objects in the identified object table,which are returned in a`signed_url`column. Generated signed URLs arevalid for 6 hours.\n\n **Return Type** \n\nTABLE\n\n **Example** \n\nRun the following query to return URIs and signed URLs for the objects in the`mydataset.myobjecttable`object table.\n\n```\nSELECT uri, signed_urlFROM EXTERNAL_OBJECT_TRANSFORM(TABLE mydataset.myobjecttable, ['SIGNED_URL']);--The preceding statement returns results similar to the following:/*-----------------------------------------------------------------------------------------------------------------------------* |  uri                                 | signed_url                                                                           | +-----------------------------------------------------------------------------------------------------------------------------+ | gs://myobjecttable/1234_Main_St.jpeg | https://storage.googleapis.com/mybucket/1234_Main_St.jpeg?X-Goog-Algorithm=1234abcd… | +-----------------------------------------------------------------------------------------------------------------------------+ | gs://myobjecttable/345_River_Rd.jpeg | https://storage.googleapis.com/mybucket/345_River_Rd.jpeg?X-Goog-Algorithm=2345bcde… | *-----------------------------------------------------------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "EXTRACT",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nEXTRACT(part FROM date_expression)\n```\n\n **Description** \n\nReturns the value corresponding to the specified date part. The`part`mustbe one of:\n\n- `    DAYOFWEEK`: Returns values in the range [1,7] with Sunday as the first dayof the week.\n- `    DAY`\n- `    DAYOFYEAR`\n- `    WEEK`: Returns the week number of the date in the range [0, 53]. Weeks beginwith Sunday, and dates prior to the first Sunday of the year are in week 0.\n- `    WEEK(&lt;WEEKDAY&gt;)`: Returns the week number of the date in the range [0, 53].Weeks begin on`    WEEKDAY`. Dates prior tothe first`    WEEKDAY`of the year are in week 0. Valid values for`    WEEKDAY`are`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`, and`    SATURDAY`.\n- `    ISOWEEK`: Returns the[ISO 8601 week](https://en.wikipedia.org/wiki/ISO_week_date)number of the`    date_expression`.`    ISOWEEK`s begin on Monday. Return valuesare in the range [1, 53]. The first`    ISOWEEK`of each ISO year begins on theMonday before the first Thursday of the Gregorian calendar year.\n- `    MONTH`\n- `    QUARTER`: Returns values in the range [1,4].\n- `    YEAR`\n- `    ISOYEAR`: Returns the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering year, which is the Gregorian calendar year containing theThursday of the week to which`    date_expression`belongs.\n\n **Return Data Type** \n\nINT64\n\n **Examples** \n\nIn the following example,`EXTRACT`returns a value corresponding to the`DAY`date part.\n\n```\nSELECT EXTRACT(DAY FROM DATE '2013-12-25') AS the_day;/*---------* | the_day | +---------+ | 25      | *---------*/\n```\n\nIn the following example,`EXTRACT`returns values corresponding to differentdate parts from a column of dates near the end of the year.\n\n```\nSELECT  date,  EXTRACT(ISOYEAR FROM date) AS isoyear,  EXTRACT(ISOWEEK FROM date) AS isoweek,  EXTRACT(YEAR FROM date) AS year,  EXTRACT(WEEK FROM date) AS weekFROM UNNEST(GENERATE_DATE_ARRAY('2015-12-23', '2016-01-09')) AS dateORDER BY date;/*------------+---------+---------+------+------* | date       | isoyear | isoweek | year | week | +------------+---------+---------+------+------+ | 2015-12-23 | 2015    | 52      | 2015 | 51   | | 2015-12-24 | 2015    | 52      | 2015 | 51   | | 2015-12-25 | 2015    | 52      | 2015 | 51   | | 2015-12-26 | 2015    | 52      | 2015 | 51   | | 2015-12-27 | 2015    | 52      | 2015 | 52   | | 2015-12-28 | 2015    | 53      | 2015 | 52   | | 2015-12-29 | 2015    | 53      | 2015 | 52   | | 2015-12-30 | 2015    | 53      | 2015 | 52   | | 2015-12-31 | 2015    | 53      | 2015 | 52   | | 2016-01-01 | 2015    | 53      | 2016 | 0    | | 2016-01-02 | 2015    | 53      | 2016 | 0    | | 2016-01-03 | 2015    | 53      | 2016 | 1    | | 2016-01-04 | 2016    | 1       | 2016 | 1    | | 2016-01-05 | 2016    | 1       | 2016 | 1    | | 2016-01-06 | 2016    | 1       | 2016 | 1    | | 2016-01-07 | 2016    | 1       | 2016 | 1    | | 2016-01-08 | 2016    | 1       | 2016 | 1    | | 2016-01-09 | 2016    | 1       | 2016 | 1    | *------------+---------+---------+------+------*/\n```\n\nIn the following example,`date_expression`falls on a Sunday.`EXTRACT`calculates the first column using weeks that begin on Sunday, and it calculatesthe second column using weeks that begin on Monday.\n\n```\nWITH table AS (SELECT DATE('2017-11-05') AS date)SELECT  date,  EXTRACT(WEEK(SUNDAY) FROM date) AS week_sunday,  EXTRACT(WEEK(MONDAY) FROM date) AS week_monday FROM table;/*------------+-------------+-------------* | date       | week_sunday | week_monday | +------------+-------------+-------------+ | 2017-11-05 | 45          | 44          | *------------+-------------+-------------*/\n```\n\n"
  },
  {
    "name": "EXTRACT",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nEXTRACT(part FROM datetime_expression)\n```\n\n **Description** \n\nReturns a value that corresponds to thespecified`part`from a supplied`datetime_expression`.\n\nAllowed`part`values are:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n- `    DAYOFWEEK`: Returns values in the range [1,7] with Sunday as the first day ofof the week.\n- `    DAY`\n- `    DAYOFYEAR`\n- `    WEEK`: Returns the week number of the date in the range [0, 53].  Weeks beginwith Sunday, and dates prior to the first Sunday of the year are in week 0.\n- `    WEEK(&lt;WEEKDAY&gt;)`: Returns the week number of`    datetime_expression`in therange [0, 53]. Weeks begin on`    WEEKDAY`.`    datetime`s prior to the first`    WEEKDAY`of the year are in week 0. Validvalues for`    WEEKDAY`are`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`, and`    SATURDAY`.\n- `    ISOWEEK`: Returns the[ISO 8601 week](https://en.wikipedia.org/wiki/ISO_week_date)number of the`    datetime_expression`.`    ISOWEEK`s begin on Monday. Return valuesare in the range [1, 53]. The first`    ISOWEEK`of each ISO year begins on theMonday before the first Thursday of the Gregorian calendar year.\n- `    MONTH`\n- `    QUARTER`\n- `    YEAR`\n- `    ISOYEAR`: Returns the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering year, which is the Gregorian calendar year containing theThursday of the week to which`    date_expression`belongs.\n- `    DATE`\n- `    TIME`\n\nReturned values truncate lower order time periods. For example, when extractingseconds,`EXTRACT`truncates the millisecond and microsecond values.\n\n **Return Data Type** \n\n`INT64`, except in the following cases:\n\n- If`    part`is`    DATE`, returns a`    DATE`object.\n- If`    part`is`    TIME`, returns a`    TIME`object.\n\n **Examples** \n\nIn the following example,`EXTRACT`returns a value corresponding to the`HOUR`time part.\n\n```\nSELECT EXTRACT(HOUR FROM DATETIME(2008, 12, 25, 15, 30, 00)) as hour;/*------------------* | hour             | +------------------+ | 15               | *------------------*/\n```\n\nIn the following example,`EXTRACT`returns values corresponding to differenttime parts from a column of datetimes.\n\n```\nWITH Datetimes AS (  SELECT DATETIME '2005-01-03 12:34:56' AS datetime UNION ALL  SELECT DATETIME '2007-12-31' UNION ALL  SELECT DATETIME '2009-01-01' UNION ALL  SELECT DATETIME '2009-12-31' UNION ALL  SELECT DATETIME '2017-01-02' UNION ALL  SELECT DATETIME '2017-05-26')SELECT  datetime,  EXTRACT(ISOYEAR FROM datetime) AS isoyear,  EXTRACT(ISOWEEK FROM datetime) AS isoweek,  EXTRACT(YEAR FROM datetime) AS year,  EXTRACT(WEEK FROM datetime) AS weekFROM DatetimesORDER BY datetime;/*---------------------+---------+---------+------+------* | datetime            | isoyear | isoweek | year | week | +---------------------+---------+---------+------+------+ | 2005-01-03T12:34:56 | 2005    | 1       | 2005 | 1    | | 2007-12-31T00:00:00 | 2008    | 1       | 2007 | 52   | | 2009-01-01T00:00:00 | 2009    | 1       | 2009 | 0    | | 2009-12-31T00:00:00 | 2009    | 53      | 2009 | 52   | | 2017-01-02T00:00:00 | 2017    | 1       | 2017 | 1    | | 2017-05-26T00:00:00 | 2017    | 21      | 2017 | 21   | *---------------------+---------+---------+------+------*/\n```\n\nIn the following example,`datetime_expression`falls on a Sunday.`EXTRACT`calculates the first column using weeks that begin on Sunday, and it calculatesthe second column using weeks that begin on Monday.\n\n```\nWITH table AS (SELECT DATETIME(TIMESTAMP \"2017-11-05 00:00:00+00\", \"UTC\") AS datetime)SELECT  datetime,  EXTRACT(WEEK(SUNDAY) FROM datetime) AS week_sunday,  EXTRACT(WEEK(MONDAY) FROM datetime) AS week_mondayFROM table;/*---------------------+-------------+---------------* | datetime            | week_sunday | week_monday   | +---------------------+-------------+---------------+ | 2017-11-05T00:00:00 | 45          | 44            | *---------------------+-------------+---------------*/\n```\n\n"
  },
  {
    "name": "EXTRACT",
    "arguments": [],
    "category": "Interval functions",
    "description": "```\nEXTRACT(part FROM interval_expression)\n```\n\n **Description** \n\nReturns the value corresponding to the specified date part. The`part`must beone of`YEAR`,`MONTH`,`DAY`,`HOUR`,`MINUTE`,`SECOND`,`MILLISECOND`or`MICROSECOND`.\n\n **Return Data Type** \n\n`INTERVAL`\n\n **Examples** \n\nIn the following example, different parts of two intervals are extracted.\n\n```\nSELECT  EXTRACT(YEAR FROM i) AS year,  EXTRACT(MONTH FROM i) AS month,  EXTRACT(DAY FROM i) AS day,  EXTRACT(HOUR FROM i) AS hour,  EXTRACT(MINUTE FROM i) AS minute,  EXTRACT(SECOND FROM i) AS second,  EXTRACT(MILLISECOND FROM i) AS milli,  EXTRACT(MICROSECOND FROM i) AS microFROM  UNNEST([INTERVAL '1-2 3 4:5:6.789999' YEAR TO SECOND,          INTERVAL '0-13 370 48:61:61' YEAR TO SECOND]) AS i/*------+-------+-----+------+--------+--------+-------+--------* | year | month | day | hour | minute | second | milli | micro  | +------+-------+-----+------+--------+--------+-------+--------+ | 1    | 2     | 3   | 4    | 5      | 6      | 789   | 789999 | | 1    | 1     | 370 | 49   | 2      | 1      | 0     | 0      | *------+-------+-----+------+--------+--------+-------+--------*/\n```\n\nWhen a negative sign precedes the time part in an interval, the negative signdistributes over the hours, minutes, and seconds. For example:\n\n```\nSELECT  EXTRACT(HOUR FROM i) AS hour,  EXTRACT(MINUTE FROM i) AS minuteFROM  UNNEST([INTERVAL '10 -12:30' DAY TO MINUTE]) AS i/*------+--------* | hour | minute | +------+--------+ | -12  | -30    | *------+--------*/\n```\n\nWhen a negative sign precedes the year and month part in an interval, thenegative sign distributes over the years and months. For example:\n\n```\nSELECT  EXTRACT(YEAR FROM i) AS year,  EXTRACT(MONTH FROM i) AS monthFROM  UNNEST([INTERVAL '-22-6 10 -12:30' YEAR TO MINUTE]) AS i/*------+--------* | year | month  | +------+--------+ | -22  | -6     | *------+--------*/\n```\n\n"
  },
  {
    "name": "EXTRACT",
    "arguments": [],
    "category": "Time functions",
    "description": "```\nEXTRACT(part FROM time_expression)\n```\n\n **Description** \n\nReturns a value that corresponds to the specified`part`froma supplied`time_expression`.\n\nAllowed`part`values are:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n\nReturned values truncate lower order time periods. For example, when extractingseconds,`EXTRACT`truncates the millisecond and microsecond values.\n\n **Return Data Type** \n\n`INT64`\n\n **Example** \n\nIn the following example,`EXTRACT`returns a value corresponding to the`HOUR`time part.\n\n```\nSELECT EXTRACT(HOUR FROM TIME \"15:30:00\") as hour;/*------------------* | hour             | +------------------+ | 15               | *------------------*/\n```\n\n"
  },
  {
    "name": "EXTRACT",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nEXTRACT(part FROM timestamp_expression [AT TIME ZONE time_zone])\n```\n\n **Description** \n\nReturns a value that corresponds to the specified`part`froma supplied`timestamp_expression`. This function supports an optional`time_zone`parameter. See[Time zone definitions](#timezone_definitions)for informationon how to specify a time zone.\n\nAllowed`part`values are:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n- `    DAYOFWEEK`: Returns values in the range [1,7] with Sunday as the first day ofof the week.\n- `    DAY`\n- `    DAYOFYEAR`\n- `    WEEK`: Returns the week number of the date in the range [0, 53].  Weeks beginwith Sunday, and dates prior to the first Sunday of the year are in week 0.\n- `    WEEK(&lt;WEEKDAY&gt;)`: Returns the week number of`    timestamp_expression`in therange [0, 53]. Weeks begin on`    WEEKDAY`.`    datetime`s prior to the first`    WEEKDAY`of the year are in week 0. Valid values for`    WEEKDAY`are`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`, and`    SATURDAY`.\n- `    ISOWEEK`: Returns the[ISO 8601 week](https://en.wikipedia.org/wiki/ISO_week_date)number of the`    datetime_expression`.`    ISOWEEK`s begin on Monday. Return valuesare in the range [1, 53]. The first`    ISOWEEK`of each ISO year begins on theMonday before the first Thursday of the Gregorian calendar year.\n- `    MONTH`\n- `    QUARTER`\n- `    YEAR`\n- `    ISOYEAR`: Returns the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering year, which is the Gregorian calendar year containing theThursday of the week to which`    date_expression`belongs.\n- `    DATE`\n- `    DATETIME`\n- `    TIME`\n\nReturned values truncate lower order time periods. For example, when extractingseconds,`EXTRACT`truncates the millisecond and microsecond values.\n\n **Return Data Type** \n\n`INT64`, except in the following cases:\n\n- If`    part`is`    DATE`, the function returns a`    DATE`object.\n\n **Examples** \n\nIn the following example,`EXTRACT`returns a value corresponding to the`DAY`time part.\n\n```\nWITH Input AS (SELECT TIMESTAMP(\"2008-12-25 05:30:00+00\") AS timestamp_value)SELECT  EXTRACT(DAY FROM timestamp_value AT TIME ZONE \"UTC\") AS the_day_utc,  EXTRACT(DAY FROM timestamp_value AT TIME ZONE \"America/Los_Angeles\") AS the_day_californiaFROM Input/*-------------+--------------------* | the_day_utc | the_day_california | +-------------+--------------------+ | 25          | 24                 | *-------------+--------------------*/\n```\n\nIn the following example,`EXTRACT`returns values corresponding to differenttime parts from a column of type`TIMESTAMP`.\n\n```\nWITH Timestamps AS (  SELECT TIMESTAMP(\"2005-01-03 12:34:56+00\") AS timestamp_value UNION ALL  SELECT TIMESTAMP(\"2007-12-31 12:00:00+00\") UNION ALL  SELECT TIMESTAMP(\"2009-01-01 12:00:00+00\") UNION ALL  SELECT TIMESTAMP(\"2009-12-31 12:00:00+00\") UNION ALL  SELECT TIMESTAMP(\"2017-01-02 12:00:00+00\") UNION ALL  SELECT TIMESTAMP(\"2017-05-26 12:00:00+00\"))SELECT  timestamp_value,  EXTRACT(ISOYEAR FROM timestamp_value) AS isoyear,  EXTRACT(ISOWEEK FROM timestamp_value) AS isoweek,  EXTRACT(YEAR FROM timestamp_value) AS year,  EXTRACT(WEEK FROM timestamp_value) AS weekFROM TimestampsORDER BY timestamp_value;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------+---------+---------+------+------* | timestamp_value         | isoyear | isoweek | year | week | +-------------------------+---------+---------+------+------+ | 2005-01-03 12:34:56 UTC | 2005    | 1       | 2005 | 1    | | 2007-12-31 12:00:00 UTC | 2008    | 1       | 2007 | 52   | | 2009-01-01 12:00:00 UTC | 2009    | 1       | 2009 | 0    | | 2009-12-31 12:00:00 UTC | 2009    | 53      | 2009 | 52   | | 2017-01-02 12:00:00 UTC | 2017    | 1       | 2017 | 1    | | 2017-05-26 12:00:00 UTC | 2017    | 21      | 2017 | 21   | *-------------------------+---------+---------+------+------*/\n```\n\nIn the following example,`timestamp_expression`falls on a Monday.`EXTRACT`calculates the first column using weeks that begin on Sunday, and it calculatesthe second column using weeks that begin on Monday.\n\n```\nWITH table AS (SELECT TIMESTAMP(\"2017-11-05 00:00:00+00\") AS timestamp_value)SELECT  timestamp_value,  EXTRACT(WEEK(SUNDAY) FROM timestamp_value) AS week_sunday,  EXTRACT(WEEK(MONDAY) FROM timestamp_value) AS week_mondayFROM table;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------+-------------+---------------* | timestamp_value         | week_sunday | week_monday   | +-------------------------+-------------+---------------+ | 2017-11-05 00:00:00 UTC | 45          | 44            | *-------------------------+-------------+---------------*/\n```\n\n"
  },
  {
    "name": "FARM_FINGERPRINT",
    "arguments": [],
    "category": "Hash functions",
    "description": "```\nFARM_FINGERPRINT(value)\n```\n\n **Description** \n\nComputes the fingerprint of the`STRING`or`BYTES`input using the`Fingerprint64`function from the[open-source FarmHash library](https://github.com/google/farmhash). The outputof this function for a particular input will never change.\n\n **Return type** \n\nINT64\n\n **Examples** \n\n```\nWITH example AS (  SELECT 1 AS x, \"foo\" AS y, true AS z UNION ALL  SELECT 2 AS x, \"apple\" AS y, false AS z UNION ALL  SELECT 3 AS x, \"\" AS y, true AS z)SELECT  *,  FARM_FINGERPRINT(CONCAT(CAST(x AS STRING), y, CAST(z AS STRING)))    AS row_fingerprintFROM example;/*---+-------+-------+----------------------* | x | y     | z     | row_fingerprint      | +---+-------+-------+----------------------+ | 1 | foo   | true  | -1541654101129638711 | | 2 | apple | false | 2794438866806483259  | | 3 |       | true  | -4880158226897771312 | *---+-------+-------+----------------------*/\n```\n\n"
  },
  {
    "name": "FIRST_VALUE",
    "arguments": [],
    "category": "Navigation functions",
    "description": "```\nFIRST_VALUE (value_expression [{RESPECT | IGNORE} NULLS])OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the value of the`value_expression`for the first row in the currentwindow frame.\n\nThis function includes`NULL`values in the calculation unless`IGNORE NULLS`ispresent. If`IGNORE NULLS`is present, the function excludes`NULL`values fromthe calculation.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\n`value_expression`can be any data type that an expression can return.\n\n **Return Data Type** \n\nSame type as`value_expression`.\n\n **Examples** \n\nThe following example computes the fastest time for each division.\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  FORMAT_TIMESTAMP('%X', finish_time) AS finish_time,  division,  FORMAT_TIMESTAMP('%X', fastest_time) AS fastest_time,  TIMESTAMP_DIFF(finish_time, fastest_time, SECOND) AS delta_in_secondsFROM (  SELECT name,  finish_time,  division,  FIRST_VALUE(finish_time)    OVER (PARTITION BY division ORDER BY finish_time ASC    ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS fastest_time  FROM finishers);/*-----------------+-------------+----------+--------------+------------------* | name            | finish_time | division | fastest_time | delta_in_seconds | +-----------------+-------------+----------+--------------+------------------+ | Carly Forte     | 03:08:58    | F25-29   | 03:08:58     | 0                | | Sophia Liu      | 02:51:45    | F30-34   | 02:51:45     | 0                | | Nikki Leith     | 02:59:01    | F30-34   | 02:51:45     | 436              | | Jen Edwards     | 03:06:36    | F30-34   | 02:51:45     | 891              | | Meghan Lederer  | 03:07:41    | F30-34   | 02:51:45     | 956              | | Lauren Reasoner | 03:10:14    | F30-34   | 02:51:45     | 1109             | | Lisa Stelzner   | 02:54:11    | F35-39   | 02:54:11     | 0                | | Lauren Matthews | 03:01:17    | F35-39   | 02:54:11     | 426              | | Desiree Berry   | 03:05:42    | F35-39   | 02:54:11     | 691              | | Suzy Slane      | 03:06:24    | F35-39   | 02:54:11     | 733              | *-----------------+-------------+----------+--------------+------------------*/\n```\n\n"
  },
  {
    "name": "FLOAT64",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nFLOAT64(json_expr[, wide_number_mode=&gt;{ 'exact' | 'round' }])\n```\n\n **Description** \n\nConverts a JSON number to a SQL`FLOAT64`value.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '9.8'\n    ```\n    \n    If the JSON value is not a number, an error is produced. If the expressionis a SQL`    NULL`, the function returns SQL`    NULL`.\n    \n    \n- `    wide_number_mode`: Optional mandatory-named argument,which defines what happens with a number that cannot berepresented as a`    FLOAT64`without loss ofprecision. This argument accepts one of the two case-sensitive values:\n    \n    \n    - `        exact`: The function fails if the result cannot be represented as a`        FLOAT64`without loss of precision.\n    - `        round`(default): The numeric value stored in JSON will be rounded to`        FLOAT64`. If such rounding is not possible,the function fails.\n\n **Return type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nSELECT FLOAT64(JSON '9.8') AS velocity;/*----------* | velocity | +----------+ | 9.8      | *----------*/\n```\n\n```\nSELECT FLOAT64(JSON_QUERY(JSON '{\"vo2_max\": 39.1, \"age\": 18}', \"$.vo2_max\")) AS vo2_max;/*---------* | vo2_max | +---------+ | 39.1    | *---------*/\n```\n\n```\nSELECT FLOAT64(JSON '18446744073709551615', wide_number_mode=&gt;'round') as result;/*------------------------* | result                 | +------------------------+ | 1.8446744073709552e+19 | *------------------------*/\n```\n\n```\nSELECT FLOAT64(JSON '18446744073709551615') as result;/*------------------------* | result                 | +------------------------+ | 1.8446744073709552e+19 | *------------------------*/\n```\n\nThe following examples show how invalid requests are handled:\n\n```\n-- An error is thrown if JSON is not of type FLOAT64.SELECT FLOAT64(JSON '\"strawberry\"') AS result;SELECT FLOAT64(JSON 'null') AS result;-- An error is thrown because `wide_number_mode` is case-sensitive and not \"exact\" or \"round\".SELECT FLOAT64(JSON '123.4', wide_number_mode=&gt;'EXACT') as result;SELECT FLOAT64(JSON '123.4', wide_number_mode=&gt;'exac') as result;-- An error is thrown because the number cannot be converted to DOUBLE without loss of precisionSELECT FLOAT64(JSON '18446744073709551615', wide_number_mode=&gt;'exact') as result;-- Returns a SQL NULLSELECT SAFE.FLOAT64(JSON '\"strawberry\"') AS result;\n```\n\n"
  },
  {
    "name": "FLOOR",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nFLOOR(X)\n```\n\n **Description** \n\nReturns the largest integral value that is not greater than X.\n\n| X | FLOOR(X) |\n| --- | --- |\n| 2.0 | 2.0 |\n| 2.3 | 2.0 |\n| 2.8 | 2.0 |\n| 2.5 | 2.0 |\n| -2.3 | -3.0 |\n| -2.8 | -3.0 |\n| -2.5 | -3.0 |\n| 0 | 0 |\n| `+inf` | `+inf` |\n| `-inf` | `-inf` |\n| `NaN` | `NaN` |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "FORMAT",
    "arguments": [],
    "category": "String functions",
    "description": "```\nFORMAT(format_string_expression, data_type_expression[, ...])\n```\n\n **Description** \n\n`FORMAT`formats a data type expression as a string.\n\n- `    format_string_expression`: Can contain zero or more[format specifiers](#format_specifiers). Each format specifier is introducedby the`    %`symbol, and must map to one or more of the remaining arguments.In general, this is a one-to-one mapping, except when the`    *`specifier ispresent. For example,`    %.*i`maps to two arguments—a length argumentand a signed integer argument.  If the number of arguments related to theformat specifiers is not the same as the number of arguments, an error occurs.\n- `    data_type_expression`: The value to format as a string. This can be anyGoogleSQL data type.\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n| Description | Statement | Result |\n| --- | --- | --- |\n| Simple integer | FORMAT('%d', 10) | 10 |\n| Integer with left blank padding | FORMAT('|%10d|', 11) | |           11| |\n| Integer with left zero padding | FORMAT('+%010d+', 12) | +0000000012+ |\n| Integer with commas | FORMAT(\"%'d\", 123456789) | 123,456,789 |\n| STRING | FORMAT('-%s-', 'abcd efg') | -abcd efg- |\n| FLOAT64 | FORMAT('%f %E', 1.1, 2.2) | 1.100000 2.200000E+00 |\n| DATE | FORMAT('%t', date '2015-09-01') | 2015-09-01 |\n| TIMESTAMP | FORMAT('%t', timestamp '2015-09-01 12:34:56America/Los_Angeles') | 2015‑09‑01 19:34:56+00 |\n\nThe`FORMAT()`function does not provide fully customizable formatting for alltypes and values, nor formatting that is sensitive to locale.\n\nIf custom formatting is necessary for a type, you must first format it usingtype-specific format functions, such as`FORMAT_DATE()`or`FORMAT_TIMESTAMP()`.For example:\n\n```\nSELECT FORMAT('date: %s!', FORMAT_DATE('%B %d, %Y', date '2015-01-02'));\n```\n\nReturns\n\n```\ndate: January 02, 2015!\n```\n\n\n<span id=\"format_specifiers\">\n#### Supported format specifiers\n\n</span>\n```\n%[flags][width][.precision]specifier\n```\n\nA[format specifier](#format_specifier_list)adds formatting when casting avalue to a string. It can optionally contain these sub-specifiers:\n\n- [Flags](#flags)\n- [Width](#width)\n- [Precision](#precision)\n\nAdditional information about format specifiers:\n\n- [%g and %G behavior](#g_and_g_behavior)\n- [%p and %P behavior](#p_and_p_behavior)\n- [%t and %T behavior](#t_and_t_behavior)\n- [Error conditions](#error_format_specifiers)\n- [NULL argument handling](#null_format_specifiers)\n- [Additional semantic rules](#rules_format_specifiers)\n\n\n<span id=\"format_specifier_list\">\n##### Format specifiers\n\n</span>\n| Specifier | Description | Examples | Types |\n| --- | --- | --- | --- |\n| `d`or`i` | Decimal integer | 392 | `INT64`    \n |\n| `o` | Octal    \n    \nNote: If an`INT64`value is negative, an error is produced. | 610 | `INT64`    \n |\n| `x` | Hexadecimal integer    \n    \nNote: If an`INT64`value is negative, an error is produced. | 7fa | `INT64`    \n |\n| `X` | Hexadecimal integer (uppercase)    \n    \nNote: If an`INT64`value is negative, an error is produced. | 7FA | `INT64`    \n |\n| `f` | Decimal notation, in [-](integer part).(fractional part) for finite        values, and in lowercase for non-finite values | 392.650000    \ninf    \nnan | `NUMERIC`    \n`BIGNUMERIC`    \n`FLOAT64`    \n |\n| `F` | Decimal notation, in [-](integer part).(fractional part) for finite        values, and in uppercase for non-finite values | 392.650000    \nINF    \nNAN | `NUMERIC`    \n`BIGNUMERIC`    \n`FLOAT64`    \n |\n| `e` | Scientific notation (mantissa/exponent), lowercase | 3.926500e+02    \ninf    \nnan | `NUMERIC`    \n`BIGNUMERIC`    \n`FLOAT64`    \n |\n| `E` | Scientific notation (mantissa/exponent), uppercase | 3.926500E+02    \nINF    \nNAN | `NUMERIC`    \n`BIGNUMERIC`    \n`FLOAT64`    \n |\n| `g` | Either decimal notation or scientific notation, depending on the input        value's exponent and the specified precision. Lowercase.        See[%g and %G behavior](#g_and_g_behavior)for details. | 392.65    \n3.9265e+07    \ninf    \nnan | `NUMERIC`    \n`BIGNUMERIC`    \n`FLOAT64`    \n |\n| `G` | Either decimal notation or scientific notation, depending on the input      value's exponent and the specified precision. Uppercase.      See[%g and %G behavior](#g_and_g_behavior)for details. | 392.65    \n3.9265E+07    \nINF    \nNAN | `NUMERIC`    \n`BIGNUMERIC`    \n`FLOAT64`    \n |\n| `p` | Produces a one-line printable string representing JSON.            See[%p and %P behavior](#p_and_p_behavior). | ```\n{\"month\":10,\"year\":2019}\n```\n\n | `JSON`    \n |\n| `P` | Produces a multi-line printable string representing JSON.            See[%p and %P behavior](#p_and_p_behavior). | ```\n{  \"month\": 10,  \"year\": 2019}\n```\n\n | `JSON`    \n |\n| `s` | String of characters | sample | `STRING`    \n |\n| `t` | Returns a printable string representing the value. Often looks      similar to casting the argument to`STRING`.      See[%t and %T behavior](#t_and_t_behavior). | sample    \n2014‑01‑01 | Any type |\n| `T` | Produces a string that is a valid GoogleSQL constant with a      similar type to the value's type (maybe wider, or maybe string).      See[%t and %T behavior](#t_and_t_behavior). | 'sample'    \nb'bytes sample'    \n1234    \n2.3    \ndate '2014‑01‑01' | Any type |\n| `%` | '%%' produces a single '%' | % | n/a |\n\nThe format specifier can optionally contain the sub-specifiers identified abovein the specifier prototype.\n\nThese sub-specifiers must comply with the following specifications.\n\n\n<span id=\"flags\">\n##### Flags\n\n</span>\n| Flags | Description |\n| --- | --- |\n| `-` | Left-justify within the given field width; Right justification is thedefault (see width sub-specifier) |\n| `+` | Forces to precede the result with a plus or minus sign (`+`or`-`) even for positive numbers. By default, only negative numbersare preceded with a`-`sign |\n| <space> | If no sign is going to be written, a blank space is inserted before thevalue |\n| `#` | - For `%o`, `%x`, and `%X`, this flag means to precede the          value with 0, 0x or 0X respectively for values different than zero.\n- For `%f`, `%F`, `%e`, and `%E`, this flag means to add the decimal          point even when there is no fractional part, unless the value          is non-finite.\n- For `%g` and `%G`, this flag means to add the decimal point even          when there is no fractional part unless the value is non-finite, and          never remove the trailing zeros after the decimal point.\n\n |\n| `0` | Left-pads the number with zeroes (0) instead of spaces when padding is      specified (see width sub-specifier) |\n| `'` | Formats integers using the appropriating grouping character.       For example:\n\n |\n\nFlags may be specified in any order. Duplicate flags are not an error. Whenflags are not relevant for some element type, they are ignored.\n\n\n<span id=\"width\">\n##### Width\n\n</span>\n| Width | Description |\n| --- | --- |\n| <number> | Minimum number of characters to be printed. If the value to be printed      is shorter than this number, the result is padded with blank spaces.      The value is not truncated even if the result is larger |\n| `*` | The width is not specified in the format string, but as an additional      integer value argument preceding the argument that has to be formatted |\n\n\n<span id=\"precision\">\n##### Precision\n\n</span>\n| Precision | Description |\n| --- | --- |\n| `.`<number> | - For integer specifiers `%d`, `%i`, `%o`, `%u`, `%x`, and `%X`:          precision specifies the          minimum number of digits to be written. If the value to be written is          shorter than this number, the result is padded with trailing zeros.          The value is not truncated even if the result is longer. A precision          of 0 means that no character is written for the value 0.\n- For specifiers `%a`, `%A`, `%e`, `%E`, `%f`, and `%F`: this is the          number of digits to be printed after the decimal point. The default          value is 6.\n- For specifiers `%g` and `%G`: this is the number of significant digits          to be printed, before the removal of the trailing zeros after the          decimal point. The default value is 6.\n\n |\n| `.*` | The precision is not specified in the format string, but as an      additional integer value argument preceding the argument that has to be      formatted |\n\n\n<span id=\"g_and_g_behavior\">\n##### %g and %G behavior\n\n</span>\nThe`%g`and`%G`format specifiers choose either the decimal notation (likethe`%f`and`%F`specifiers) or the scientific notation (like the`%e`and`%E`specifiers), depending on the input value's exponent and the specified[precision](#precision).\n\nLet p stand for the specified[precision](#precision)(defaults to 6; 1 if thespecified precision is less than 1). The input value is first converted toscientific notation with precision = (p - 1). If the resulting exponent part xis less than -4 or no less than p, the scientific notation with precision =(p - 1) is used; otherwise the decimal notation with precision = (p - 1 - x) isused.\n\nUnless[# flag](#flags)is present, the trailing zeros after the decimal pointare removed, and the decimal point is also removed if there is no digit afterit.\n\n\n<span id=\"p_and_p_behavior\">\n##### %p and %P behavior\n\n</span>\nThe`%p`format specifier produces a one-line printable string. The`%P`format specifier produces a multi-line printable string. You can use theseformat specifiers with the following data types:\n\n|  **Type**  |  **%p**  |  **%P**  |\n| --- | --- | --- |\n| JSON | JSON input:\n\n```\nJSON '{  \"month\": 10,  \"year\": 2019}'\n```\n\nProduces a one-line printable string representing JSON:\n\n```\n{\"month\":10,\"year\":2019}\n```\n\n | JSON input:\n\n```\nJSON '{  \"month\": 10,  \"year\": 2019}'\n```\n\nProduces a multi-line printable string representing JSON:\n\n```\n{  \"month\": 10,  \"year\": 2019}\n```\n\n |\n\n\n<span id=\"t_and_t_behavior\">\n##### %t and %T behavior\n\n</span>\nThe`%t`and`%T`format specifiers are defined for all types. The[width](#width),[precision](#precision), and[flags](#flags)act as they dofor`%s`: the[width](#width)is the minimum width and the`STRING`will bepadded to that size, and[precision](#precision)is the maximum widthof content to show and the`STRING`will be truncated to that size, prior topadding to width.\n\nThe`%t`specifier is always meant to be a readable form of the value.\n\nThe`%T`specifier is always a valid SQL literal of a similar type, such as awider numeric type.The literal will not include casts or a type name, except for the special caseof non-finite floating point values.\n\nThe`STRING`is formatted as follows:\n\n|  **Type**  |  **%t**  |  **%T**  |\n| --- | --- | --- |\n| `NULL`of any type | NULL | NULL |\n| `INT64`    \n | 123 | 123 |\n| NUMERIC | 123.0 *(always with .0)*  | NUMERIC \"123.0\" |\n| FLOAT64 | 123.0 *(always with .0)*     \n123e+10    \n`inf`    \n`-inf`    \n`NaN` | 123.0 *(always with .0)*     \n123e+10    \nCAST(\"inf\" AS <type>)    \nCAST(\"-inf\" AS <type>)    \nCAST(\"nan\" AS <type>) |\n| STRING | unquoted string value | quoted string literal |\n| BYTES | unquoted escaped bytes    \ne.g., abc\\x01\\x02 | quoted bytes literal    \ne.g., b\"abc\\x01\\x02\" |\n| BOOL | boolean value | boolean value |\n| DATE | 2011-02-03 | DATE \"2011-02-03\" |\n| TIMESTAMP | 2011-02-03 04:05:06+00 | TIMESTAMP \"2011-02-03 04:05:06+00\" |\n| INTERVAL | 1-2 3 4:5:6.789 | INTERVAL \"1-2 3 4:5:6.789\" YEAR TO SECOND |\n| ARRAY | [value, value, ...]    \nwhere values are formatted with %t | [value, value, ...]    \nwhere values are formatted with %T |\n| STRUCT | (value, value, ...)    \nwhere fields are formatted with %t | (value, value, ...)    \nwhere fields are formatted with %T    \n    \nSpecial cases:    \nZero fields: STRUCT()    \nOne field: STRUCT(value) |\n| JSON | one-line printable string representing JSON.    \n```\n{\"name\":\"apple\",\"stock\":3}\n```\n\n | one-line printable string representing a JSON literal.    \n```\nJSON '{\"name\":\"apple\",\"stock\":3}'\n```\n\n |\n\n\n<span id=\"error_format_specifiers\">\n##### Error conditions\n\n</span>\nIf a format specifier is invalid, or is not compatible with the relatedargument type, or the wrong number or arguments are provided, then an error isproduced.  For example, the following`&lt;format_string&gt;`expressions are invalid:\n\n```\nFORMAT('%s', 1)\n```\n\n```\nFORMAT('%')\n```\n\n\n<span id=\"null_format_specifiers\">\n##### NULL argument handling\n\n</span>\nA`NULL`format string results in a`NULL`output`STRING`. Any other argumentsare ignored in this case.\n\nThe function generally produces a`NULL`value if a`NULL`argument is present.For example,`FORMAT('%i', NULL_expression)`produces a`NULL STRING`asoutput.\n\nHowever, there are some exceptions: if the format specifier is %t or %T(both of which produce`STRING`s that effectively match CAST and literal valuesemantics), a`NULL`value produces 'NULL' (without the quotes) in the result`STRING`. For example, the function:\n\n```\nFORMAT('00-%t-00', NULL_expression);\n```\n\nReturns\n\n```\n00-NULL-00\n```\n\n\n<span id=\"rules_format_specifiers\">\n##### Additional semantic rules\n\n</span>\n`FLOAT64`values can be`+/-inf`or`NaN`.When an argument has one of those values, the result of the format specifiers`%f`,`%F`,`%e`,`%E`,`%g`,`%G`, and`%t`are`inf`,`-inf`, or`nan`(or the same in uppercase) as appropriate.  This is consistent with howGoogleSQL casts these values to`STRING`.  For`%T`,GoogleSQL returns quoted strings for`FLOAT64`values that don't have non-string literalrepresentations.\n\n"
  },
  {
    "name": "FORMAT_DATE",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nFORMAT_DATE(format_string, date_expr)\n```\n\n **Description** \n\nFormats the`date_expr`according to the specified`format_string`.\n\nSee[Supported Format Elements For DATE](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)for a list of format elements that this function supports.\n\n **Return Data Type** \n\nSTRING\n\n **Examples** \n\n```\nSELECT FORMAT_DATE('%x', DATE '2008-12-25') AS US_format;/*------------* | US_format  | +------------+ | 12/25/08   | *------------*/\n```\n\n```\nSELECT FORMAT_DATE('%b-%d-%Y', DATE '2008-12-25') AS formatted;/*-------------* | formatted   | +-------------+ | Dec-25-2008 | *-------------*/\n```\n\n```\nSELECT FORMAT_DATE('%b %Y', DATE '2008-12-25') AS formatted;/*-------------* | formatted   | +-------------+ | Dec 2008    | *-------------*/\n```\n\n"
  },
  {
    "name": "FORMAT_DATETIME",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nFORMAT_DATETIME(format_string, datetime_expression)\n```\n\n **Description** \n\nFormats a`DATETIME`object according to the specified`format_string`. See[Supported Format Elements For DATETIME](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)for a list of format elements that this function supports.\n\n **Return Data Type** \n\n`STRING`\n\n **Examples** \n\n```\nSELECT  FORMAT_DATETIME(\"%c\", DATETIME \"2008-12-25 15:30:00\")  AS formatted;/*--------------------------* | formatted                | +--------------------------+ | Thu Dec 25 15:30:00 2008 | *--------------------------*/\n```\n\n```\nSELECT  FORMAT_DATETIME(\"%b-%d-%Y\", DATETIME \"2008-12-25 15:30:00\")  AS formatted;/*-------------* | formatted   | +-------------+ | Dec-25-2008 | *-------------*/\n```\n\n```\nSELECT  FORMAT_DATETIME(\"%b %Y\", DATETIME \"2008-12-25 15:30:00\")  AS formatted;/*-------------* | formatted   | +-------------+ | Dec 2008    | *-------------*/\n```\n\n"
  },
  {
    "name": "FORMAT_TIME",
    "arguments": [],
    "category": "Time functions",
    "description": "```\nFORMAT_TIME(format_string, time_object)\n```\n\n **Description** Formats a`TIME`object according to the specified`format_string`. See[Supported Format Elements For TIME](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)for a list of format elements that this function supports.\n\n **Return Data Type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT FORMAT_TIME(\"%R\", TIME \"15:30:00\") as formatted_time;/*----------------* | formatted_time | +----------------+ | 15:30          | *----------------*/\n```\n\n"
  },
  {
    "name": "FORMAT_TIMESTAMP",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nFORMAT_TIMESTAMP(format_string, timestamp[, time_zone])\n```\n\n **Description** \n\nFormats a timestamp according to the specified`format_string`.\n\nSee[Format elements for date and time parts](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)for a list of format elements that this function supports.\n\n **Return Data Type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT FORMAT_TIMESTAMP(\"%c\", TIMESTAMP \"2050-12-25 15:30:55+00\", \"UTC\")  AS formatted;/*--------------------------* | formatted                | +--------------------------+ | Sun Dec 25 15:30:55 2050 | *--------------------------*/\n```\n\n```\nSELECT FORMAT_TIMESTAMP(\"%b-%d-%Y\", TIMESTAMP \"2050-12-25 15:30:55+00\")  AS formatted;/*-------------* | formatted   | +-------------+ | Dec-25-2050 | *-------------*/\n```\n\n```\nSELECT FORMAT_TIMESTAMP(\"%b %Y\", TIMESTAMP \"2050-12-25 15:30:55+00\")  AS formatted;/*-------------* | formatted   | +-------------+ | Dec 2050    | *-------------*/\n```\n\n```\nSELECT FORMAT_TIMESTAMP(\"%Y-%m-%dT%H:%M:%SZ\", TIMESTAMP \"2050-12-25 15:30:55\", \"UTC\")  AS formatted;/*+---------------------* |      formatted       | +----------------------+ | 2050-12-25T15:30:55Z | *----------------------*/\n```\n\n"
  },
  {
    "name": "FROM_BASE32",
    "arguments": [],
    "category": "String functions",
    "description": "```\nFROM_BASE32(string_expr)\n```\n\n **Description** \n\nConverts the base32-encoded input`string_expr`into`BYTES`format. To convert`BYTES`to a base32-encoded`STRING`, use[TO_BASE32](#to_base32).\n\n **Return type** \n\n`BYTES`\n\n **Example** \n\n```\nSELECT FROM_BASE32('MFRGGZDF74======') AS byte_data;-- Note that the result of FROM_BASE32 is of type BYTES, displayed as a base64-encoded string./*-----------* | byte_data | +-----------+ | YWJjZGX/  | *-----------*/\n```\n\n"
  },
  {
    "name": "FROM_BASE64",
    "arguments": [],
    "category": "String functions",
    "description": "```\nFROM_BASE64(string_expr)\n```\n\n **Description** \n\nConverts the base64-encoded input`string_expr`into`BYTES`format. To convert`BYTES`to a base64-encoded`STRING`,use [TO_BASE64][string-link-to-base64].\n\nThere are several base64 encodings in common use that vary in exactly whichalphabet of 65 ASCII characters are used to encode the 64 digits and padding.See[RFC 4648](https://tools.ietf.org/html/rfc4648#section-4)for details. Thisfunction expects the alphabet`[A-Za-z0-9+/=]`.\n\n **Return type** \n\n`BYTES`\n\n **Example** \n\n```\nSELECT FROM_BASE64('/+A=') AS byte_data;-- Note that the result of FROM_BASE64 is of type BYTES, displayed as a base64-encoded string./*-----------* | byte_data | +-----------+ | /+A=      | *-----------*/\n```\n\nTo work with an encoding using a different base64 alphabet, you might need tocompose`FROM_BASE64`with the`REPLACE`function. For instance, the`base64url`url-safe and filename-safe encoding commonly used in web programminguses`-_=`as the last characters rather than`+/=`. To decode a`base64url`-encoded string, replace`-`and`_`with`+`and`/`respectively.\n\n```\nSELECT FROM_BASE64(REPLACE(REPLACE('_-A=', '-', '+'), '_', '/')) AS binary;-- Note that the result of FROM_BASE64 is of type BYTES, displayed as a base64-encoded string./*--------* | binary | +--------+ | /+A=   | *--------*/\n```\n\n"
  },
  {
    "name": "FROM_HEX",
    "arguments": [],
    "category": "String functions",
    "description": "```\nFROM_HEX(string)\n```\n\n **Description** \n\nConverts a hexadecimal-encoded`STRING`into`BYTES`format. Returns an errorif the input`STRING`contains characters outside the range`(0..9, A..F, a..f)`. The lettercase of the characters does not matter. If theinput`STRING`has an odd number of characters, the function acts as if theinput has an additional leading`0`. To convert`BYTES`to a hexadecimal-encoded`STRING`, use[TO_HEX](#to_hex).\n\n **Return type** \n\n`BYTES`\n\n **Example** \n\n```\nWITH Input AS (  SELECT '00010203aaeeefff' AS hex_str UNION ALL  SELECT '0AF' UNION ALL  SELECT '666f6f626172')SELECT hex_str, FROM_HEX(hex_str) AS bytes_strFROM Input;-- Note that the result of FROM_HEX is of type BYTES, displayed as a base64-encoded string./*------------------+--------------* | hex_str          | bytes_str    | +------------------+--------------+ | 0AF              | AAECA6ru7/8= | | 00010203aaeeefff | AK8=         | | 666f6f626172     | Zm9vYmFy     | *------------------+--------------*/\n```\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [AEAD.DECRYPT_BYTES](#aeaddecrypt_bytes) | Uses the matching key from a keyset to decrypt a`BYTES`ciphertext. |\n| [AEAD.DECRYPT_STRING](#aeaddecrypt_string) | Uses the matching key from a keyset to decrypt a`BYTES`ciphertext into a`STRING`plaintext. |\n| [AEAD.ENCRYPT](#aeadencrypt) | Encrypts`STRING`plaintext, using the primary cryptographic key    in a keyset. |\n| [DETERMINISTIC_DECRYPT_BYTES](#deterministic_decrypt_bytes) | Uses the matching key from a keyset to decrypt a`BYTES`ciphertext, using deterministic AEAD. |\n| [DETERMINISTIC_DECRYPT_STRING](#deterministic_decrypt_string) | Uses the matching key from a keyset to decrypt a`BYTES`ciphertext into a`STRING`plaintext, using deterministic AEAD. |\n| [DETERMINISTIC_ENCRYPT](#deterministic_encrypt) | Encrypts`STRING`plaintext, using the primary cryptographic key    in a keyset, using deterministic AEAD encryption. |\n| [KEYS.ADD_KEY_FROM_RAW_BYTES](#keysadd_key_from_raw_bytes) | Adds a key to a keyset, and return the new keyset as a serialized`BYTES`value. |\n| [KEYS.KEYSET_CHAIN](#keyskeyset_chain) | Produces a Tink keyset that is encrypted with a Cloud KMS key. |\n| [KEYS.KEYSET_FROM_JSON](#keyskeyset_from_json) | Converts a`STRING`JSON keyset to a serialized`BYTES`value. |\n| [KEYS.KEYSET_LENGTH](#keyskeyset_length) | Gets the number of keys in the provided keyset. |\n| [KEYS.KEYSET_TO_JSON](#keyskeyset_to_json) | Gets a JSON`STRING`representation of a keyset. |\n| [KEYS.NEW_KEYSET](#keysnew_keyset) | Gets a serialized keyset containing a new key based on the key type. |\n| [KEYS.NEW_WRAPPED_KEYSET](#keysnew_wrapped_keyset) | Creates a new keyset and encrypts it with a Cloud KMS key. |\n| [KEYS.REWRAP_KEYSET](#keysrewrap_keyset) | Re-encrypts a wrapped keyset with a new Cloud KMS key. |\n| [KEYS.ROTATE_KEYSET](#keysrotate_keyset) | Adds a new primary cryptographic key to a keyset, based on the key type. |\n| [KEYS.ROTATE_WRAPPED_KEYSET](#keysrotate_wrapped_keyset) | Rewraps a keyset and rotates it. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [ANY_VALUE](#any_value) | Gets an expression for some row. |\n| [ARRAY_AGG](#array_agg) | Gets an array of values. |\n| [ARRAY_CONCAT_AGG](#array_concat_agg) | Concatenates arrays and returns a single array as a result. |\n| [AVG](#avg) | Gets the average of non-`NULL`values. |\n| [BIT_AND](#bit_and) | Performs a bitwise AND operation on an expression. |\n| [BIT_OR](#bit_or) | Performs a bitwise OR operation on an expression. |\n| [BIT_XOR](#bit_xor) | Performs a bitwise XOR operation on an expression. |\n| [COUNT](#count) | Gets the number of rows in the input, or the number of rows with an    expression evaluated to any value other than`NULL`. |\n| [COUNTIF](#countif) | Gets the count of`TRUE`values for an expression. |\n| [GROUPING](#grouping) | Checks if a groupable value in the`GROUP BY`clause is    aggregated. |\n| [LOGICAL_AND](#logical_and) | Gets the logical AND of all non-`NULL`expressions. |\n| [LOGICAL_OR](#logical_or) | Gets the logical OR of all non-`NULL`expressions. |\n| [MAX](#max) | Gets the maximum non-`NULL`value. |\n| [MAX_BY](#max_by) | Synonym for`ANY_VALUE(x HAVING MAX y)`. |\n| [MIN](#min) | Gets the minimum non-`NULL`value. |\n| [MIN_BY](#min_by) | Synonym for`ANY_VALUE(x HAVING MIN y)`. |\n| [STRING_AGG](#string_agg) | Concatenates non-`NULL``STRING`or`BYTES`values. |\n| [SUM](#sum) | Gets the sum of non-`NULL`values. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Approximate aggregate functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [APPROX_COUNT_DISTINCT](#approx_count_distinct) | Gets the approximate result for`COUNT(DISTINCT expression)`. |\n| [APPROX_QUANTILES](#approx_quantiles) | Gets the approximate quantile boundaries. |\n| [APPROX_TOP_COUNT](#approx_top_count) | Gets the approximate top elements and their approximate count. |\n| [APPROX_TOP_SUM](#approx_top_sum) | Gets the approximate top elements and sum, based on the approximate sum    of an assigned weight. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Array functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [ARRAY](#array) | Produces an array with one element for each row in a subquery. |\n| [ARRAY_CONCAT](#array_concat) | Concatenates one or more arrays with the same element type into a    single array. |\n| [ARRAY_LENGTH](#array_length) | Gets the number of elements in an array. |\n| [ARRAY_REVERSE](#array_reverse) | Reverses the order of elements in an array. |\n| [ARRAY_TO_STRING](#array_to_string) | Produces a concatenation of the elements in an array as a`STRING`value. |\n| [GENERATE_ARRAY](#generate_array) | Generates an array of values in a range. |\n| [GENERATE_DATE_ARRAY](#generate_date_array) | Generates an array of dates in a range. |\n| [GENERATE_TIMESTAMP_ARRAY](#generate_timestamp_array) | Generates an array of timestamps in a range. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Bit functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [BIT_COUNT](#bit_count) | Gets the number of bits that are set in an input expression. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Conversion functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [CAST](#cast) | Convert the results of an expression to the given type. |\n| [PARSE_BIGNUMERIC](#parse_bignumeric) | Converts a`STRING`value to a`BIGNUMERIC`value. |\n| [PARSE_NUMERIC](#parse_numeric) | Converts a`STRING`value to a`NUMERIC`value. |\n| [SAFE_CAST](#safe_casting) | Similar to the`CAST`function, but returns`NULL`when a runtime error is produced. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Date functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [CURRENT_DATE](#current_date) | Returns the current date as a`DATE`value. |\n| [DATE](#date) | Constructs a`DATE`value. |\n| [DATE_ADD](#date_add) | Adds a specified time interval to a`DATE`value. |\n| [DATE_DIFF](#date_diff) | Gets the number of intervals between two`DATE`values. |\n| [DATE_FROM_UNIX_DATE](#date_from_unix_date) | Interprets an`INT64`expression as the number of days    since 1970-01-01. |\n| [DATE_SUB](#date_sub) | Subtracts a specified time interval from a`DATE`value. |\n| [DATE_TRUNC](#date_trunc) | Truncates a`DATE`value. |\n| [EXTRACT](#extract) | Extracts part of a date from a`DATE`value. |\n| [FORMAT_DATE](#format_date) | Formats a`DATE`value according to a specified format string. |\n| [LAST_DAY](#last_day) | Gets the last day in a specified time period that contains a`DATE`value. |\n| [PARSE_DATE](#parse_date) | Converts a`STRING`value to a`DATE`value. |\n| [UNIX_DATE](#unix_date) | Converts a`DATE`value to the number of days since 1970-01-01. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Datetime functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [CURRENT_DATETIME](#current_datetime) | Returns the current date and time as a`DATETIME`value. |\n| [DATETIME](#datetime) | Constructs a`DATETIME`value. |\n| [DATETIME_ADD](#datetime_add) | Adds a specified time interval to a`DATETIME`value. |\n| [DATETIME_DIFF](#datetime_diff) | Gets the number of intervals between two`DATETIME`values. |\n| [DATETIME_SUB](#datetime_sub) | Subtracts a specified time interval from a`DATETIME`value. |\n| [DATETIME_TRUNC](#datetime_trunc) | Truncates a`DATETIME`value. |\n| [EXTRACT](#extract) | Extracts part of a date and time from a`DATETIME`value. |\n| [FORMAT_DATETIME](#format_datetime) | Formats a`DATETIME`value according to a specified    format string. |\n| [LAST_DAY](#last_day) | Gets the last day in a specified time period that contains a`DATETIME`value. |\n| [PARSE_DATETIME](#parse_datetime) | Converts a`STRING`value to a`DATETIME`value. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Debugging functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [ERROR](#error) | Produces an error with a custom error message. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Differentially private aggregate functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [AVG](#dp_avg) | `DIFFERENTIAL_PRIVACY`-supported`AVG`.    \n    \nGets the differentially-private average of non-`NULL`,    non-`NaN`values in a query with a`DIFFERENTIAL_PRIVACY`clause. |\n| [COUNT](#dp_count) | `DIFFERENTIAL_PRIVACY`-supported`COUNT`.    \n    \nSignature 1: Gets the differentially-private count of rows in a query with a`DIFFERENTIAL_PRIVACY`clause.    \n    \nSignature 2: Gets the differentially-private count of rows with a    non-`NULL`expression in a query with a`DIFFERENTIAL_PRIVACY`clause. |\n| [PERCENTILE_CONT](#dp_percentile_cont) | `DIFFERENTIAL_PRIVACY`-supported`PERCENTILE_CONT`.    \n    \nComputes a differentially-private percentile across privacy unit columns    in a query with a`DIFFERENTIAL_PRIVACY`clause. |\n| [SUM](#dp_sum) | `DIFFERENTIAL_PRIVACY`-supported`SUM`.    \n    \nGets the differentially-private sum of non-`NULL`,    non-`NaN`values in a query with a`DIFFERENTIAL_PRIVACY`clause. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "DLP encryption functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [DLP_DETERMINISTIC_ENCRYPT](#dlp_deterministic_encrypt) | Encrypts data with a DLP compatible algorithm. |\n| [DLP_DETERMINISTIC_DECRYPT](#dlp_deterministic_decrypt) | Decrypts DLP-encrypted data. |\n| [DLP_KEY_CHAIN](#dlp_key_chain) | Gets a data encryption key that is wrapped by Cloud Key Management Service. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Geography functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [S2_CELLIDFROMPOINT](#s2_cellidfrompoint) | Gets the S2 cell ID covering a point`GEOGRAPHY`value. |\n| [S2_COVERINGCELLIDS](#s2_coveringcellids) | Gets an array of S2 cell IDs that cover a`GEOGRAPHY`value. |\n| [ST_ANGLE](#st_angle) | Takes three point`GEOGRAPHY`values, which represent two    intersecting lines, and returns the angle between these lines. |\n| [ST_AREA](#st_area) | Gets the area covered by the polygons in a`GEOGRAPHY`value. |\n| [ST_ASBINARY](#st_asbinary) | Converts a`GEOGRAPHY`value to a`BYTES`WKB geography value. |\n| [ST_ASGEOJSON](#st_asgeojson) | Converts a`GEOGRAPHY`value to a`STRING`GeoJSON geography value. |\n| [ST_ASTEXT](#st_astext) | Converts a`GEOGRAPHY`value to a`STRING`WKT geography value. |\n| [ST_AZIMUTH](#st_azimuth) | Gets the azimuth of a line segment formed by two    point`GEOGRAPHY`values. |\n| [ST_BOUNDARY](#st_boundary) | Gets the union of component boundaries in a`GEOGRAPHY`value. |\n| [ST_BOUNDINGBOX](#st_boundingbox) | Gets the bounding box for a`GEOGRAPHY`value. |\n| [ST_BUFFER](#st_buffer) | Gets the buffer around a`GEOGRAPHY`value, using a specific    number of segments. |\n| [ST_BUFFERWITHTOLERANCE](#st_bufferwithtolerance) | Gets the buffer around a`GEOGRAPHY`value, using tolerance. |\n| [ST_CENTROID](#st_centroid) | Gets the centroid of a`GEOGRAPHY`value. |\n| [ST_CENTROID_AGG](#st_centroid_agg) | Gets the centroid of a set of`GEOGRAPHY`values. |\n| [ST_CLOSESTPOINT](#st_closestpoint) | Gets the point on a`GEOGRAPHY`value which is closest to any    point in a second`GEOGRAPHY`value. |\n| [ST_CLUSTERDBSCAN](#st_clusterdbscan) | Performs DBSCAN clustering on a group of`GEOGRAPHY`values and    produces a 0-based cluster number for this row. |\n| [ST_CONTAINS](#st_contains) | Checks if one`GEOGRAPHY`value contains another`GEOGRAPHY`value. |\n| [ST_CONVEXHULL](#st_convexhull) | Returns the convex hull for a`GEOGRAPHY`value. |\n| [ST_COVEREDBY](#st_coveredby) | Checks if all points of a`GEOGRAPHY`value are on the boundary    or interior of another`GEOGRAPHY`value. |\n| [ST_COVERS](#st_covers) | Checks if all points of a`GEOGRAPHY`value are on the boundary    or interior of another`GEOGRAPHY`value. |\n| [ST_DIFFERENCE](#st_difference) | Gets the point set difference between two`GEOGRAPHY`values. |\n| [ST_DIMENSION](#st_dimension) | Gets the dimension of the highest-dimensional element in a`GEOGRAPHY`value. |\n| [ST_DISJOINT](#st_disjoint) | Checks if two`GEOGRAPHY`values are disjoint (do not intersect). |\n| [ST_DISTANCE](#st_distance) | Gets the shortest distance in meters between two`GEOGRAPHY`values. |\n| [ST_DUMP](#st_dump) | Returns an array of simple`GEOGRAPHY`components in a`GEOGRAPHY`value. |\n| [ST_DWITHIN](#st_dwithin) | Checks if any points in two`GEOGRAPHY`values are within a given    distance. |\n| [ST_ENDPOINT](#st_endpoint) | Gets the last point of a linestring`GEOGRAPHY`value. |\n| [ST_EQUALS](#st_equals) | Checks if two`GEOGRAPHY`values represent the same`GEOGRAPHY`value. |\n| [ST_EXTENT](#st_extent) | Gets the bounding box for a group of`GEOGRAPHY`values. |\n| [ST_EXTERIORRING](#st_exteriorring) | Returns a linestring`GEOGRAPHY`value that corresponds to the    outermost ring of a polygon`GEOGRAPHY`value. |\n| [ST_GEOGFROM](#st_geogfrom) | Converts a`STRING`or`BYTES`value    into a`GEOGRAPHY`value. |\n| [ST_GEOGFROMGEOJSON](#st_geogfromgeojson) | Converts a`STRING`GeoJSON geometry value into a`GEOGRAPHY`value. |\n| [ST_GEOGFROMTEXT](#st_geogfromtext) | Converts a`STRING`WKT geometry value into a`GEOGRAPHY`value. |\n| [ST_GEOGFROMWKB](#st_geogfromwkb) | Converts a`BYTES`or hexadecimal-text`STRING`WKT    geometry value into a`GEOGRAPHY`value. |\n| [ST_GEOGPOINT](#st_geogpoint) | Creates a point`GEOGRAPHY`value for a given longitude and    latitude. |\n| [ST_GEOGPOINTFROMGEOHASH](#st_geogpointfromgeohash) | Gets a point`GEOGRAPHY`value that is in the middle of a    bounding box defined in a`STRING`GeoHash value. |\n| [ST_GEOHASH](#st_geohash) | Converts a point`GEOGRAPHY`value to a`STRING`GeoHash value. |\n| [ST_GEOMETRYTYPE](#st_geometrytype) | Gets the Open Geospatial Consortium (OGC) geometry type for a`GEOGRAPHY`value. |\n| [ST_HAUSDORFFDISTANCE](#st_hausdorffdistance) | Gets the discrete Hausdorff distance between two geometries. |\n| [ST_INTERIORRINGS](#st_interiorrings) | Gets the interior rings of a polygon`GEOGRAPHY`value. |\n| [ST_INTERSECTION](#st_intersection) | Gets the point set intersection of two`GEOGRAPHY`values. |\n| [ST_INTERSECTS](#st_intersects) | Checks if at least one point appears in two`GEOGRAPHY`values. |\n| [ST_INTERSECTSBOX](#st_intersectsbox) | Checks if a`GEOGRAPHY`value intersects a rectangle. |\n| [ST_ISCLOSED](#st_isclosed) | Checks if all components in a`GEOGRAPHY`value are closed. |\n| [ST_ISCOLLECTION](#st_iscollection) | Checks if the total number of points, linestrings, and polygons is    greater than one in a`GEOGRAPHY`value. |\n| [ST_ISEMPTY](#st_isempty) | Checks if a`GEOGRAPHY`value is empty. |\n| [ST_ISRING](#st_isring) | Checks if a`GEOGRAPHY`value is a closed, simple    linestring. |\n| [ST_LENGTH](#st_length) | Gets the total length of lines in a`GEOGRAPHY`value. |\n| [ST_LINEINTERPOLATEPOINT](#st_lineinterpolatepoint) | Gets a point at a specific fraction in a linestring`GEOGRAPHY`value. |\n| [ST_LINELOCATEPOINT](#st_linelocatepoint) | Gets a section of a linestring`GEOGRAPHY`value between the    start point and a point`GEOGRAPHY`value. |\n| [ST_LINESUBSTRING](#st_linesubstring) | Gets a segment of a single linestring at a specific starting and    ending fraction. |\n| [ST_MAKELINE](#st_makeline) | Creates a linestring`GEOGRAPHY`value by concatenating the point    and linestring vertices of`GEOGRAPHY`values. |\n| [ST_MAKEPOLYGON](#st_makepolygon) | Constructs a polygon`GEOGRAPHY`value by combining    a polygon shell with polygon holes. |\n| [ST_MAKEPOLYGONORIENTED](#st_makepolygonoriented) | Constructs a polygon`GEOGRAPHY`value, using an array of    linestring`GEOGRAPHY`values. The vertex ordering of each    linestring determines the orientation of each polygon ring. |\n| [ST_MAXDISTANCE](#st_maxdistance) | Gets the longest distance between two non-empty`GEOGRAPHY`values. |\n| [ST_NPOINTS](#st_npoints) | An alias of`ST_NUMPOINTS`. |\n| [ST_NUMGEOMETRIES](#st_numgeometries) | Gets the number of geometries in a`GEOGRAPHY`value. |\n| [ST_NUMPOINTS](#st_numpoints) | Gets the number of vertices in the a`GEOGRAPHY`value. |\n| [ST_PERIMETER](#st_perimeter) | Gets the length of the boundary of the polygons in a`GEOGRAPHY`value. |\n| [ST_POINTN](#st_pointn) | Gets the point at a specific index of a linestring`GEOGRAPHY`value. |\n| [ST_SIMPLIFY](#st_simplify) | Converts a`GEOGRAPHY`value into a simplified`GEOGRAPHY`value, using tolerance. |\n| [ST_SNAPTOGRID](#st_snaptogrid) | Produces a`GEOGRAPHY`value, where each vertex has    been snapped to a longitude/latitude grid. |\n| [ST_STARTPOINT](#st_startpoint) | Gets the first point of a linestring`GEOGRAPHY`value. |\n| [ST_TOUCHES](#st_touches) | Checks if two`GEOGRAPHY`values intersect and their interiors    have no elements in common. |\n| [ST_UNION](#st_union) | Gets the point set union of multiple`GEOGRAPHY`values. |\n| [ST_UNION_AGG](#st_union_agg) | Aggregates over`GEOGRAPHY`values and gets their    point set union. |\n| [ST_WITHIN](#st_within) | Checks if one`GEOGRAPHY`value contains another`GEOGRAPHY`value. |\n| [ST_X](#st_x) | Gets the longitude from a point`GEOGRAPHY`value. |\n| [ST_Y](#st_y) | Gets the latitude from a point`GEOGRAPHY`value. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Hash functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [FARM_FINGERPRINT](#farm_fingerprint) | Computes the fingerprint of a`STRING`or`BYTES`value, using the FarmHash Fingerprint64 algorithm. |\n| [MD5](#md5) | Computes the hash of a`STRING`or`BYTES`value, using the MD5 algorithm. |\n| [SHA1](#sha1) | Computes the hash of a`STRING`or`BYTES`value, using the SHA-1 algorithm. |\n| [SHA256](#sha256) | Computes the hash of a`STRING`or`BYTES`value, using the SHA-256 algorithm. |\n| [SHA512](#sha512) | Computes the hash of a`STRING`or`BYTES`value, using the SHA-512 algorithm. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "HyperLogLog++ functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [HLL_COUNT.EXTRACT](#hll_countextract) | Extracts a cardinality estimate of an HLL++ sketch. |\n| [HLL_COUNT.INIT](#hll_countinit) | Aggregates values of the same underlying type into a new HLL++ sketch. |\n| [HLL_COUNT.MERGE](#hll_countmerge) | Merges HLL++ sketches of the same underlying type into a new sketch, and    then gets the cardinality of the new sketch. |\n| [HLL_COUNT.MERGE_PARTIAL](#hll_countmerge_partial) | Merges HLL++ sketches of the same underlying type into a new sketch. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Interval functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [EXTRACT](#extract) | Extracts part of an`INTERVAL`value. |\n| [JUSTIFY_DAYS](#justify_days) | Normalizes the day part of an`INTERVAL`value. |\n| [JUSTIFY_HOURS](#justify_hours) | Normalizes the time part of an`INTERVAL`value. |\n| [JUSTIFY_INTERVAL](#justify_interval) | Normalizes the day and time parts of an`INTERVAL`value. |\n| [MAKE_INTERVAL](#make_interval) | Constructs an`INTERVAL`value. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "JSON functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [BOOL](#bool_for_json) | Converts a JSON boolean to a SQL`BOOL`value. |\n| [FLOAT64](#double_for_json) | Converts a JSON number to a SQL`FLOAT64`value. |\n| [INT64](#int64_for_json) | Converts a JSON number to a SQL`INT64`value. |\n| [JSON_ARRAY](#json_array) | Creates a JSON array. |\n| [JSON_ARRAY_APPEND](#json_array_append) | Appends JSON data to the end of a JSON array. |\n| [JSON_ARRAY_INSERT](#json_array_insert) | Inserts JSON data into a JSON array. |\n| [JSON_EXTRACT](#json_extract) | (Deprecated)    Extracts a JSON value and converts it to a SQL    JSON-formatted`STRING`or`JSON`value. |\n| [JSON_EXTRACT_ARRAY](#json_extract_array) | (Deprecated)    Extracts a JSON array and converts it to    a SQL`ARRAY&lt;JSON-formatted STRING&gt;`or`ARRAY&lt;JSON&gt;`value. |\n| [JSON_EXTRACT_SCALAR](#json_extract_scalar) | (Deprecated)    Extracts a JSON scalar value and converts it to a SQL`STRING`value. |\n| [JSON_EXTRACT_STRING_ARRAY](#json_extract_string_array) | (Deprecated)    Extracts a JSON array of scalar values and converts it to a SQL`ARRAY&lt;STRING&gt;`value. |\n| [JSON_OBJECT](#json_object) | Creates a JSON object. |\n| [JSON_QUERY](#json_query) | Extracts a JSON value and converts it to a SQL    JSON-formatted`STRING`or`JSON`value. |\n| [JSON_QUERY_ARRAY](#json_query_array) | Extracts a JSON array and converts it to    a SQL`ARRAY&lt;JSON-formatted STRING&gt;`or`ARRAY&lt;JSON&gt;`value. |\n| [JSON_REMOVE](#json_remove) | Produces JSON with the specified JSON data removed. |\n| [JSON_SET](#json_set) | Inserts or replaces JSON data. |\n| [JSON_STRIP_NULLS](#json_strip_nulls) | Removes JSON nulls from JSON objects and JSON arrays. |\n| [JSON_TYPE](#json_type) | Gets the JSON type of the outermost JSON value and converts the name of    this type to a SQL`STRING`value. |\n| [JSON_VALUE](#json_value) | Extracts a JSON scalar value and converts it to a SQL`STRING`value. |\n| [JSON_VALUE_ARRAY](#json_value_array) | Extracts a JSON array of scalar values and converts it to a SQL`ARRAY&lt;STRING&gt;`value. |\n| [LAX_BOOL](#lax_bool) | Attempts to convert a JSON value to a SQL`BOOL`value. |\n| [LAX_FLOAT64](#lax_double) | Attempts to convert a JSON value to a    SQL`FLOAT64`value. |\n| [LAX_INT64](#lax_int64) | Attempts to convert a JSON value to a SQL`INT64`value. |\n| [LAX_STRING](#lax_string) | Attempts to convert a JSON value to a SQL`STRING`value. |\n| [PARSE_JSON](#parse_json) | Converts a JSON-formatted`STRING`value to a`JSON`value. |\n| [STRING](#string_for_json) | Converts a JSON string to a SQL`STRING`value. |\n| [TO_JSON](#to_json) | Converts a SQL value to a JSON value. |\n| [TO_JSON_STRING](#to_json_string) | Converts a SQL value to a JSON-formatted`STRING`value. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [ABS](#abs) | Computes the absolute value of`X`. |\n| [ACOS](#acos) | Computes the inverse cosine of`X`. |\n| [ACOSH](#acosh) | Computes the inverse hyperbolic cosine of`X`. |\n| [ASIN](#asin) | Computes the inverse sine of`X`. |\n| [ASINH](#asinh) | Computes the inverse hyperbolic sine of`X`. |\n| [ATAN](#atan) | Computes the inverse tangent of`X`. |\n| [ATAN2](#atan2) | Computes the inverse tangent of`X/Y`, using the signs of`X`and`Y`to determine the quadrant. |\n| [ATANH](#atanh) | Computes the inverse hyperbolic tangent of`X`. |\n| [CBRT](#cbrt) | Computes the cube root of`X`. |\n| [CEIL](#ceil) | Gets the smallest integral value that is not less than`X`. |\n| [CEILING](#ceiling) | Synonym of`CEIL`. |\n| [COS](#cos) | Computes the cosine of`X`. |\n| [COSH](#cosh) | Computes the hyperbolic cosine of`X`. |\n| [COSINE_DISTANCE](#cosine_distance) | Computes the cosine distance between two vectors. |\n| [COT](#cot) | Computes the cotangent of`X`. |\n| [COTH](#coth) | Computes the hyperbolic cotangent of`X`. |\n| [CSC](#csc) | Computes the cosecant of`X`. |\n| [CSCH](#csch) | Computes the hyperbolic cosecant of`X`. |\n| [DIV](#div) | Divides integer`X`by integer`Y`. |\n| [EXP](#exp) | Computes`e`to the power of`X`. |\n| [EUCLIDEAN_DISTANCE](#euclidean_distance) | Computes the Euclidean distance between two vectors. |\n| [FLOOR](#floor) | Gets the largest integral value that is not greater than`X`. |\n| [GREATEST](#greatest) | Gets the greatest value among`X1,...,XN`. |\n| [IEEE_DIVIDE](#ieee_divide) | Divides`X`by`Y`, but does not generate errors for    division by zero or overflow. |\n| [IS_INF](#is_inf) | Checks if`X`is positive or negative infinity. |\n| [IS_NAN](#is_nan) | Checks if`X`is a`NaN`value. |\n| [LEAST](#least) | Gets the least value among`X1,...,XN`. |\n| [LN](#ln) | Computes the natural logarithm of`X`. |\n| [LOG](#log) | Computes the natural logarithm of`X`or the logarithm of`X`to base`Y`. |\n| [LOG10](#log10) | Computes the natural logarithm of`X`to base 10. |\n| [MOD](#mod) | Gets the remainder of the division of`X`by`Y`. |\n| [POW](#pow) | Produces the value of`X`raised to the power of`Y`. |\n| [POWER](#power) | Synonym of`POW`. |\n| [RAND](#rand) | Generates a pseudo-random value of type`FLOAT64`in the range of`[0, 1)`. |\n| [RANGE_BUCKET](#range_bucket) | Scans through a sorted array and returns the 0-based position    of a point's upper bound. |\n| [ROUND](#round) | Rounds`X`to the nearest integer or rounds`X`to`N`decimal places after the decimal point. |\n| [SAFE_ADD](#safe_add) | Equivalent to the addition operator (`X + Y`), but returns`NULL`if overflow occurs. |\n| [SAFE_DIVIDE](#safe_divide) | Equivalent to the division operator (`X / Y`), but returns`NULL`if an error occurs. |\n| [SAFE_MULTIPLY](#safe_multiply) | Equivalent to the multiplication operator (`X * Y`),    but returns`NULL`if overflow occurs. |\n| [SAFE_NEGATE](#safe_negate) | Equivalent to the unary minus operator (`-X`), but returns`NULL`if overflow occurs. |\n| [SAFE_SUBTRACT](#safe_subtract) | Equivalent to the subtraction operator (`X - Y`), but    returns`NULL`if overflow occurs. |\n| [SEC](#sec) | Computes the secant of`X`. |\n| [SECH](#sech) | Computes the hyperbolic secant of`X`. |\n| [SIGN](#sign) | Produces -1 , 0, or +1 for negative, zero, and positive arguments    respectively. |\n| [SIN](#sin) | Computes the sine of`X`. |\n| [SINH](#sinh) | Computes the hyperbolic sine of`X`. |\n| [SQRT](#sqrt) | Computes the square root of`X`. |\n| [TAN](#tan) | Computes the tangent of`X`. |\n| [TANH](#tanh) | Computes the hyperbolic tangent of`X`. |\n| [TRUNC](#trunc) | Rounds a number like`ROUND(X)`or`ROUND(X, N)`,    but always rounds towards zero and never overflows. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Navigation functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [FIRST_VALUE](#first_value) | Gets a value for the first row in the current window frame. |\n| [LAG](#lag) | Gets a value for a preceding row. |\n| [LAST_VALUE](#last_value) | Gets a value for the last row in the current window frame. |\n| [LEAD](#lead) | Gets a value for a subsequent row. |\n| [NTH_VALUE](#nth_value) | Gets a value for the Nth row of the current window frame. |\n| [PERCENTILE_CONT](#percentile_cont) | Computes the specified percentile for a value, using    linear interpolation. |\n| [PERCENTILE_DISC](#percentile_disc) | Computes the specified percentile for a discrete value. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Net functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [NET.HOST](#nethost) | Gets the hostname from a URL. |\n| [NET.IP_FROM_STRING](#netip_from_string) | Converts an IPv4 or IPv6 address from a`STRING`value to    a`BYTES`value in network byte order. |\n| [NET.IP_NET_MASK](#netip_net_mask) | Gets a network mask. |\n| [NET.IP_TO_STRING](#netip_to_string) | Converts an IPv4 or IPv6 address from a`BYTES`value in    network byte order to a`STRING`value. |\n| [NET.IP_TRUNC](#netip_trunc) | Converts a`BYTES`IPv4 or IPv6 address in    network byte order to a`BYTES`subnet address. |\n| [NET.IPV4_FROM_INT64](#netipv4_from_int64) | Converts an IPv4 address from an`INT64`value to a`BYTES`value in network byte order. |\n| [NET.IPV4_TO_INT64](#netipv4_to_int64) | Converts an IPv4 address from a`BYTES`value in network    byte order to an`INT64`value. |\n| [NET.PUBLIC_SUFFIX](#netpublic_suffix) | Gets the public suffix from a URL. |\n| [NET.REG_DOMAIN](#netreg_domain) | Gets the registered or registrable domain from a URL. |\n| [NET.SAFE_IP_FROM_STRING](#netsafe_ip_from_string) | Similar to the`NET.IP_FROM_STRING`, but returns`NULL`instead of producing an error if the input is invalid. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Numbering functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [CUME_DIST](#cume_dist) | Gets the cumulative distribution (relative position (0,1]) of each row    within a window. |\n| [DENSE_RANK](#dense_rank) | Gets the dense rank (1-based, no gaps) of each row within a window. |\n| [NTILE](#ntile) | Gets the quantile bucket number (1-based) of each row within a window. |\n| [PERCENT_RANK](#percent_rank) | Gets the percentile rank (from 0 to 1) of each row within a window. |\n| [RANK](#rank) | Gets the rank (1-based) of each row within a window. |\n| [ROW_NUMBER](#row_number) | Gets the sequential row number (1-based) of each row within a window. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Range functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [GENERATE_RANGE_ARRAY](#generate_range_array) | Splits a range into an array of subranges. |\n| [RANGE](#range) | Constructs a range of`DATE`,`DATETIME`,    or`TIMESTAMP`values. |\n| [RANGE_CONTAINS](#range_contains) | Signature 1: Checks if one range is in another range.    \n    \nSignature 2: Checks if a value is in a range. |\n| [RANGE_END](#range_end) | Gets the upper bound of a range. |\n| [RANGE_INTERSECT](#range_intersect) | Gets a segment of two ranges that intersect. |\n| [RANGE_OVERLAPS](#range_overlaps) | Checks if two ranges overlap. |\n| [RANGE_START](#range_start) | Gets the lower bound of a range. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Search functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [SEARCH](#search) | Checks to see whether a table or other    search data contains a set of search terms. |\n| [VECTOR_SEARCH](#vector_search) | Performs a vector search on embeddings to find semantically similar    entities. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Security functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [SESSION_USER](#session_user) | Get the email address or principal identifier of the user that is running    the query. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [CORR](#corr) | Computes the Pearson coefficient of correlation of a set of number pairs. |\n| [COVAR_POP](#covar_pop) | Computes the population covariance of a set of number pairs. |\n| [COVAR_SAMP](#covar_samp) | Computes the sample covariance of a set of number pairs. |\n| [STDDEV](#stddev) | An alias of the`STDDEV_SAMP`function. |\n| [STDDEV_POP](#stddev_pop) | Computes the population (biased) standard deviation of the values. |\n| [STDDEV_SAMP](#stddev_samp) | Computes the sample (unbiased) standard deviation of the values. |\n| [VAR_POP](#var_pop) | Computes the population (biased) variance of the values. |\n| [VAR_SAMP](#var_samp) | Computes the sample (unbiased) variance of the values. |\n| [VARIANCE](#variance) | An alias of`VAR_SAMP`. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "String functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [ASCII](#ascii) | Gets the ASCII code for the first character or byte in a`STRING`or`BYTES`value. |\n| [BYTE_LENGTH](#byte_length) | Gets the number of`BYTES`in a`STRING`or`BYTES`value. |\n| [CHAR_LENGTH](#char_length) | Gets the number of characters in a`STRING`value. |\n| [CHARACTER_LENGTH](#character_length) | Synonym for`CHAR_LENGTH`. |\n| [CHR](#chr) | Converts a Unicode code point to a character. |\n| [CODE_POINTS_TO_BYTES](#code_points_to_bytes) | Converts an array of extended ASCII code points to a`BYTES`value. |\n| [CODE_POINTS_TO_STRING](#code_points_to_string) | Converts an array of extended ASCII code points to a`STRING`value. |\n| [COLLATE](#collate) | Combines a`STRING`value and a collation specification into a    collation specification-supported`STRING`value. |\n| [CONCAT](#concat) | Concatenates one or more`STRING`or`BYTES`values into a single result. |\n| [CONTAINS_SUBSTR](#contains_substr) | Performs a normalized, case-insensitive search to see if a value exists    as a substring in an expression. |\n| [EDIT_DISTANCE](#edit_distance) | Computes the Levenshtein distance between two`STRING`or`BYTES`values. |\n| [ENDS_WITH](#ends_with) | Checks if a`STRING`or`BYTES`value is the suffix    of another value. |\n| [FORMAT](#format_string) | Formats data and produces the results as a`STRING`value. |\n| [FROM_BASE32](#from_base32) | Converts a base32-encoded`STRING`value into a`BYTES`value. |\n| [FROM_BASE64](#from_base64) | Converts a base64-encoded`STRING`value into a`BYTES`value. |\n| [FROM_HEX](#from_hex) | Converts a hexadecimal-encoded`STRING`value into a`BYTES`value. |\n| [INITCAP](#initcap) | Formats a`STRING`as proper case, which means that the first    character in each word is uppercase and all other characters are lowercase. |\n| [INSTR](#instr) | Finds the position of a subvalue inside another value, optionally starting    the search at a given offset or occurrence. |\n| [LEFT](#left) | Gets the specified leftmost portion from a`STRING`or`BYTES`value. |\n| [LENGTH](#length) | Gets the length of a`STRING`or`BYTES`value. |\n| [LOWER](#lower) | Formats alphabetic characters in a`STRING`value as    lowercase.    \n    \nFormats ASCII characters in a`BYTES`value as    lowercase. |\n| [LPAD](#lpad) | Prepends a`STRING`or`BYTES`value with a pattern. |\n| [LTRIM](#ltrim) | Identical to the`TRIM`function, but only removes leading    characters. |\n| [NORMALIZE](#normalize) | Case-sensitively normalizes the characters in a`STRING`value. |\n| [NORMALIZE_AND_CASEFOLD](#normalize_and_casefold) | Case-insensitively normalizes the characters in a`STRING`value. |\n| [OCTET_LENGTH](#octet_length) | Alias for`BYTE_LENGTH`. |\n| [REGEXP_CONTAINS](#regexp_contains) | Checks if a value is a partial match for a regular expression. |\n| [REGEXP_EXTRACT](#regexp_extract) | Produces a substring that matches a regular expression. |\n| [REGEXP_EXTRACT_ALL](#regexp_extract_all) | Produces an array of all substrings that match a    regular expression. |\n| [REGEXP_INSTR](#regexp_instr) | Finds the position of a regular expression match in a value, optionally    starting the search at a given offset or occurrence. |\n| [REGEXP_REPLACE](#regexp_replace) | Produces a`STRING`value where all substrings that match a    regular expression are replaced with a specified value. |\n| [REGEXP_SUBSTR](#regexp_substr) | Synonym for`REGEXP_EXTRACT`. |\n| [REPEAT](#repeat) | Produces a`STRING`or`BYTES`value that consists of    an original value, repeated. |\n| [REPLACE](#replace) | Replaces all occurrences of a pattern with another pattern in a`STRING`or`BYTES`value. |\n| [REVERSE](#reverse) | Reverses a`STRING`or`BYTES`value. |\n| [RIGHT](#right) | Gets the specified rightmost portion from a`STRING`or`BYTES`value. |\n| [RPAD](#rpad) | Appends a`STRING`or`BYTES`value with a pattern. |\n| [RTRIM](#rtrim) | Identical to the`TRIM`function, but only removes trailing    characters. |\n| [SAFE_CONVERT_BYTES_TO_STRING](#safe_convert_bytes_to_string) | Converts a`BYTES`value to a`STRING`value and    replace any invalid UTF-8 characters with the Unicode replacement character,`U+FFFD`. |\n| [SOUNDEX](#soundex) | Gets the Soundex codes for words in a`STRING`value. |\n| [SPLIT](#split) | Splits a`STRING`or`BYTES`value, using a delimiter. |\n| [STARTS_WITH](#starts_with) | Checks if a`STRING`or`BYTES`value is a    prefix of another value. |\n| [STRPOS](#strpos) | Finds the position of the first occurrence of a subvalue inside another    value. |\n| [SUBSTR](#substr) | Gets a portion of a`STRING`or`BYTES`value. |\n| [SUBSTRING](#substring) | Alias for`SUBSTR` |\n| [TO_BASE32](#to_base32) | Converts a`BYTES`value to a    base32-encoded`STRING`value. |\n| [TO_BASE64](#to_base64) | Converts a`BYTES`value to a    base64-encoded`STRING`value. |\n| [TO_CODE_POINTS](#to_code_points) | Converts a`STRING`or`BYTES`value into an array of    extended ASCII code points. |\n| [TO_HEX](#to_hex) | Converts a`BYTES`value to a    hexadecimal`STRING`value. |\n| [TRANSLATE](#translate) | Within a value, replaces each source character with the corresponding    target character. |\n| [TRIM](#trim) | Removes the specified leading and trailing Unicode code points or bytes    from a`STRING`or`BYTES`value. |\n| [UNICODE](#unicode) | Gets the Unicode code point for the first character in a value. |\n| [UPPER](#upper) | Formats alphabetic characters in a`STRING`value as    uppercase.    \n    \nFormats ASCII characters in a`BYTES`value as    uppercase. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Table functions (built in)",
    "description": "| Name | Summary |\n| --- | --- |\n| [APPENDS](#appends) | Gets all rows that are appended to a table for a given time range. |\n| [EXTERNAL_OBJECT_TRANSFORM](#external_object_transform) | Produces an object table with the original columns plus    one or more additional columns. |\n| [GAP_FILL](#gap_fill_table_functions) | Finds and fills gaps in a time series. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Time functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [CURRENT_TIME](#current_time) | Returns the current time as a`TIME`value. |\n| [EXTRACT](#extract) | Extracts part of a`TIME`value. |\n| [FORMAT_TIME](#format_time) | Formats a`TIME`value according to the specified format string. |\n| [PARSE_TIME](#parse_time) | Converts a`STRING`value to a`TIME`value. |\n| [TIME](#time) | Constructs a`TIME`value. |\n| [TIME_ADD](#time_add) | Adds a specified time interval to a`TIME`value. |\n| [TIME_DIFF](#time_diff) | Gets the number of intervals between two`TIME`values. |\n| [TIME_SUB](#time_sub) | Subtracts a specified time interval from a`TIME`value. |\n| [TIME_TRUNC](#time_trunc) | Truncates a`TIME`value. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Time series functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [DATE_BUCKET](#date_bucket) | Gets the lower bound of the date bucket that contains a date. |\n| [DATETIME_BUCKET](#datetime_bucket) | Gets the lower bound of the datetime bucket that contains a datetime. |\n| [GAP_FILL](#gap_fill) | Finds and fills gaps in a time series. |\n| [TIMESTAMP_BUCKET](#timestamp_bucket) | Gets the lower bound of the timestamp bucket that contains a timestamp. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [CURRENT_TIMESTAMP](#current_timestamp) | Returns the current date and time as a`TIMESTAMP`object. |\n| [EXTRACT](#extract) | Extracts part of a`TIMESTAMP`value. |\n| [FORMAT_TIMESTAMP](#format_timestamp) | Formats a`TIMESTAMP`value according to the specified    format string. |\n| [PARSE_TIMESTAMP](#parse_timestamp) | Converts a`STRING`value to a`TIMESTAMP`value. |\n| [STRING](#string) | Converts a`TIMESTAMP`value to a`STRING`value. |\n| [TIMESTAMP](#timestamp) | Constructs a`TIMESTAMP`value. |\n| [TIMESTAMP_ADD](#timestamp_add) | Adds a specified time interval to a`TIMESTAMP`value. |\n| [TIMESTAMP_DIFF](#timestamp_diff) | Gets the number of intervals between two`TIMESTAMP`values. |\n| [TIMESTAMP_MICROS](#timestamp_micros) | Converts the number of microseconds since    1970-01-01 00:00:00 UTC to a`TIMESTAMP.` |\n| [TIMESTAMP_MILLIS](#timestamp_millis) | Converts the number of milliseconds since    1970-01-01 00:00:00 UTC to a`TIMESTAMP.` |\n| [TIMESTAMP_SECONDS](#timestamp_seconds) | Converts the number of seconds since    1970-01-01 00:00:00 UTC to a`TIMESTAMP.` |\n| [TIMESTAMP_SUB](#timestamp_sub) | Subtracts a specified time interval from a`TIMESTAMP`value. |\n| [TIMESTAMP_TRUNC](#timestamp_trunc) | Truncates a`TIMESTAMP`value. |\n| [UNIX_MICROS](#unix_micros) | Converts a`TIMESTAMP`value to the number of microseconds since    1970-01-01 00:00:00 UTC. |\n| [UNIX_MILLIS](#unix_millis) | Converts a`TIMESTAMP`value to the number of milliseconds    since 1970-01-01 00:00:00 UTC. |\n| [UNIX_SECONDS](#unix_seconds) | Converts a`TIMESTAMP`value to the number of seconds since    1970-01-01 00:00:00 UTC. |\n\n"
  },
  {
    "name": "FUNCTION LIST",
    "arguments": [],
    "category": "Utility functions",
    "description": "| Name | Summary |\n| --- | --- |\n| [GENERATE_UUID](#generate_uuid) | Produces a random universally unique identifier (UUID) as a`STRING`value. |\n\n"
  },
  {
    "name": "GAP_FILL",
    "arguments": [],
    "category": "Table functions (built in)",
    "description": "Finds and fills gaps in a time series.For more information, see[GAP_FILL](#gap_fill)inTime series functions.\n\n\n<span id=\"time_functions\">\n## Time functions\n\n</span>\nGoogleSQL for BigQuery supports the following time functions.\n\n"
  },
  {
    "name": "GAP_FILL",
    "arguments": [],
    "category": "Time series functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nGAP_FILL (  TABLE time_series_table,  time_series_column,  bucket_width,  [, partitioning_columns=&gt;value]  [, value_columns=&gt;value ]  [, origin=&gt;value]  [, ignore_null_values=&gt;value])\n```\n\n```\nGAP_FILL (  (time_series_subquery),  time_series_column,  bucket_width,  [, partitioning_columns=&gt;values]  [, value_columns=&gt;value ]  [, origin=&gt;value]  [, ignore_null_values=&gt;value])\n```\n\n **Description** \n\nFinds and fills gaps in a time series.\n\n **Definitions** \n\n- `    time_series_table`: The name of the table that contains thetime series data.\n- `    time_series_subquery`: The subquery that contains the time series data.\n- `    time_series_column`: The name of the column in`    time_series_table`or`    time_series_subquery`that contains the time points of thetime series data. This column must represent a`    DATE`,`    DATETIME`,or`    TIMESTAMP`type.\n- `    bucket_width`: The`    INTERVAL`value that represents the selected widthof the time buckets. The interval can represent a`    DATE`,`    DATETIME`, or`    TIMESTAMP`type.\n- `    partitioning_columns`: An`    ARRAY&lt;STRING&gt;`optional named argument.Represents an array of zero or more column names used to partition datainto individual time series (time series identity). This has the same columntype requirements as the`    PARTITION BY`clause.\n- `    value_columns`: An`    ARRAY&lt;STRUCT&lt;STRING, STRING&gt;&gt;`optional named argument.Represents an array of column name and gap-filling method pairs inthis format:\n    \n    \n    ```\n    [(column_name, gap_filling_method), ...]\n    ```\n    \n    \n    - `        column_name`: A`        STRING`value that represents a valid column from`        time_series_table`. A column name can only be used once in`        value_columns`.\n        \n        \n    - `        gap_filling_method`: A`        STRING`value that can be one of the followinggap-filling methods:\n        \n        \n        - `            null`(default): Fill in missing values with`            NULL`values.\n            \n            \n        - `            linear`: Fill in missing values usinglinear interpolation. So, when a new value is added, it's based ona linear slope for a specific time bucket. When this method isused,`            column_name`must be a numeric data type.\n            \n            \n        - `            locf`: Fill in missing values by carrying the last observed valueforward. So, when a new value is added, it's based onthe previous value.\n            \n            \n- `    origin`: A`    DATE`,`    DATETIME`or`    TIMESTAMP`optional named argument.Represents a point in time from which all time buckets expand ineach direction.\n    \n    If`    origin`is not provided, the data type for`    time_series_column`isassumed, and the corresponding default value is used:\n    \n    \n    - `        DATE '1950-01-01'`\n    - `        DATETIME '1950-01-01 00:00:00'`\n    - `        TIMESTAMP '1950-01-01 00:00:00'`\n- `    ignore_null_values`: A`    BOOL`optional named argument. Indicateswhether the function ignores`    NULL`values in the input data when performinggap filling. By default, this value is`    TRUE`.\n    \n    \n    - If`        TRUE`(default),`        NULL`values are skipped during gap filling.\n        \n        \n        - `            null`is the gap-filling method for a column: If a value in acolumn is`            NULL`, the output is`            NULL`for that column.\n            \n            \n        - `            locf`or`            linear`is the gap-filling method for a column: Theprevious or next non-`            NULL`value is used. The side effect of thisis that output value columns are never`            NULL`, except for the edges.\n            \n            \n    - If`        FALSE`,`        NULL`values are included during gap filling.\n        \n        \n        - `            null`is the gap-filling method for a column: If a value in acolumn is`            NULL`, the output is`            NULL`for that column.\n            \n            \n        - `            locf`is the gap-filling method for a column: If the previousvalue in that column is`            NULL`, the output is`            NULL`for thatcolumn.\n            \n            \n        - `            linear`is the gap-filling method for a column: If either ofthe endpoints in that column is`            NULL`, the output is`            NULL`forthat column.\n            \n            \n\n **Details** \n\nSometimes the fixed time intervals produced by time bucket functions have gaps,either due to irregular sampling intervals or an event that caused data lossfor some time period. This can cause irregularities in reporting. For example,a plot with irregular intervals might have visible discontinuity. You can usethe`GAP_FILL`function to employ various gap-filling methods to fill inthose missing data points.\n\n`time_series_column`and`origin`must be of the same data type.\n\n **Return type** \n\n`TABLE`\n\n **Examples** \n\nIn the following query, the`locf`gap-filling method is applied to gaps:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:37:00', 78, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:38:01', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'locf')  ])ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:35:00 | 74     | | 2023-11-01T09:36:00 | 77     | | 2023-11-01T09:37:00 | 78     | | 2023-11-01T09:38:00 | 78     | +---------------------+--------*/\n```\n\nIn the following query, the`linear`gap-filling method is applied to gaps:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:37:00', 78, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:38:01', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'linear')  ])ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:35:00 | 75     | | 2023-11-01T09:36:00 | 77     | | 2023-11-01T09:37:00 | 78     | | 2023-11-01T09:38:00 | 80     | +---------------------+--------*/\n```\n\nIn the following query, the`null`gap-filling method is applied to gaps:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:37:00', 78, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:38:01', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'null')  ])ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:35:00 | NULL   | | 2023-11-01T09:36:00 | 77     | | 2023-11-01T09:37:00 | 78     | | 2023-11-01T09:38:00 | NULL   | +---------------------+--------*/\n```\n\nIn the following query,`NULL`values in the input data are ignored by default:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:37:00', NULL, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:38:01', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'linear')  ])ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:35:00 | 75     | | 2023-11-01T09:36:00 | 77     | | 2023-11-01T09:37:00 | 78     | | 2023-11-01T09:38:00 | 80     | +---------------------+--------*/\n```\n\nIn the following query,`NULL`values in the input data are not ignored, usingthe`ignore_null_values`argument:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:37:00', NULL, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:38:01', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'linear')  ],  ignore_null_values =&gt; FALSE)ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:35:00 | 75     | | 2023-11-01T09:36:00 | 77     | | 2023-11-01T09:37:00 | NULL   | | 2023-11-01T09:38:00 | NULL   | +---------------------+--------*/\n```\n\nIn the following query, when the`value_columns`argument is not passed in,the`null`gap-filling method is used on all columns:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:37:00', 79, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:38:01', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE)ORDER BY time;/*---------------------+-----------+--------+----------+ | time                | device_id | signal | state    | +---------------------+-----------+--------+----------+ | 2023-11-01T09:35:00 | NULL      | NULL   | NULL     | | 2023-11-01T09:36:00 | 2         | 77     | ACTIVE   | | 2023-11-01T09:37:00 | 3         | 79     | ACTIVE   | | 2023-11-01T09:38:00 | NULL      | NULL   | NULL     | +---------------------+-----------+--------+----------*/\n```\n\nIn the following query, rows (buckets) are added for gaps that are found:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:35:39', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:37:39', 77, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:38:00', 77, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:40:00', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'locf')  ])ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:36:00 | 74     | | 2023-11-01T09:37:00 | 74     | | 2023-11-01T09:38:00 | 74     | | 2023-11-01T09:39:00 | 77     | | 2023-11-01T09:40:00 | 77     | +---------------------+--------*/\n```\n\nIn the following query, data is condensed when it fits in the same bucket andhas the same values:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:35:39', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:60', 77, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:37:00', 77, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:37:20', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'locf')  ])ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:36:00 | 74     | | 2023-11-01T09:37:00 | 77     | +---------------------+--------*/\n```\n\nIn the following query, gap filling is applied to partitions:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(2, DATETIME '2023-11-01 09:35:07', 87, 'ACTIVE'),    STRUCT(1, DATETIME '2023-11-01 09:35:26', 82, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:35:39', 74, 'INACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:07', 88, 'ACTIVE'),    STRUCT(1, DATETIME '2023-11-01 09:36:26', 82, 'ACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:37:07', 88, 'ACTIVE'),    STRUCT(1, DATETIME '2023-11-01 09:37:28', 80, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:37:39', 77, 'ACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:38:07', 86, 'ACTIVE'),    STRUCT(1, DATETIME '2023-11-01 09:38:26', 81, 'ACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:38:39', 77, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  partitioning_columns =&gt; ['device_id'],  value_columns =&gt; [    ('signal', 'locf')  ])ORDER BY device_id;/*---------------------+-----------+--------+ | time                | device_id | signal | +---------------------+-----------+--------+ | 2023-11-01T09:36:00 | 1         | 82     | | 2023-11-01T09:37:00 | 1         | 82     | | 2023-11-01T09:38:00 | 1         | 80     | | 2023-11-01T09:36:00 | 2         | 87     | | 2023-11-01T09:37:00 | 2         | 88     | | 2023-11-01T09:38:00 | 2         | 88     | | 2023-11-01T09:36:00 | 3         | 74     | | 2023-11-01T09:37:00 | 3         | 74     | | 2023-11-01T09:38:00 | 3         | 77     | +---------------------+-----------+--------*/\n```\n\nIn the following query, gap filling is applied to multiple columns, and eachcolumn uses a different gap-filling method:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'ACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'INACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:38:00', 78, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:39:01', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'linear'),    ('state', 'locf')  ])ORDER BY time;/*---------------------+--------+----------+ | time                | signal | state    | +---------------------+--------+----------+ | 2023-11-01T09:35:00 | 75     | ACTIVE   | | 2023-11-01T09:36:00 | 77     | INACTIVE | | 2023-11-01T09:37:00 | 78     | INACTIVE | | 2023-11-01T09:38:00 | 78     | ACTIVE   | | 2023-11-01T09:39:00 | 80     | ACTIVE   | +---------------------+--------+----------*/\n```\n\nIn the following query, the point of origin is changed in the gap-fillingresults to a custom origin, using the`origin`argument:\n\n```\nCREATE TEMP TABLE device_data ASSELECT * FROM UNNEST(  ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[    STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'ACTIVE'),    STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'INACTIVE'),    STRUCT(3, DATETIME '2023-11-01 09:38:00', 78, 'ACTIVE'),    STRUCT(4, DATETIME '2023-11-01 09:39:01', 80, 'ACTIVE')]);SELECT *FROM GAP_FILL(  TABLE device_data,  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'null')  ],  origin =&gt; DATETIME '2023-11-01 09:30:01')ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:34:01 | 74     | | 2023-11-01T09:35:01 | NULL   | | 2023-11-01T09:36:01 | NULL   | | 2023-11-01T09:37:01 | NULL   | | 2023-11-01T09:38:01 | NULL   | | 2023-11-01T09:39:01 | 80     | +---------------------+--------*/\n```\n\nIn the following query, a subquery is passed into the function instead of atable:\n\n```\nSELECT *FROM GAP_FILL(  (    SELECT * FROM UNNEST(    ARRAY&lt;STRUCT&lt;device_id INT64, time DATETIME, signal INT64, state STRING&gt;&gt;[      STRUCT(1, DATETIME '2023-11-01 09:34:01', 74, 'INACTIVE'),      STRUCT(2, DATETIME '2023-11-01 09:36:00', 77, 'ACTIVE'),      STRUCT(3, DATETIME '2023-11-01 09:37:00', 78, 'ACTIVE'),      STRUCT(4, DATETIME '2023-11-01 09:38:01', 80, 'ACTIVE')    ])  ),  ts_column =&gt; 'time',  bucket_width =&gt; INTERVAL 1 MINUTE,  value_columns =&gt; [    ('signal', 'linear')  ])ORDER BY time;/*---------------------+--------+ | time                | signal | +---------------------+--------+ | 2023-11-01T09:35:00 | 75     | | 2023-11-01T09:36:00 | 77     | | 2023-11-01T09:37:00 | 78     | | 2023-11-01T09:38:00 | 80     | +---------------------+--------*/\n```\n\n"
  },
  {
    "name": "GENERATE_ARRAY",
    "arguments": [],
    "category": "Array functions",
    "description": "```\nGENERATE_ARRAY(start_expression, end_expression[, step_expression])\n```\n\n **Description** \n\nReturns an array of values. The`start_expression`and`end_expression`parameters determine the inclusive start and end of the array.\n\nThe`GENERATE_ARRAY`function accepts the following data types as inputs:\n\n- `    INT64`\n- `    NUMERIC`\n- `    BIGNUMERIC`\n- `    FLOAT64`\n\nThe`step_expression`parameter determines the increment used togenerate array values. The default value for this parameter is`1`.\n\nThis function returns an error if`step_expression`is set to 0, or if anyinput is`NaN`.\n\nIf any argument is`NULL`, the function will return a`NULL`array.\n\n **Return Data Type** \n\n`ARRAY`\n\n **Examples** \n\nThe following returns an array of integers, with a default step of 1.\n\n```\nSELECT GENERATE_ARRAY(1, 5) AS example_array;/*-----------------* | example_array   | +-----------------+ | [1, 2, 3, 4, 5] | *-----------------*/\n```\n\nThe following returns an array using a user-specified step size.\n\n```\nSELECT GENERATE_ARRAY(0, 10, 3) AS example_array;/*---------------* | example_array | +---------------+ | [0, 3, 6, 9]  | *---------------*/\n```\n\nThe following returns an array using a negative value,`-3`for its step size.\n\n```\nSELECT GENERATE_ARRAY(10, 0, -3) AS example_array;/*---------------* | example_array | +---------------+ | [10, 7, 4, 1] | *---------------*/\n```\n\nThe following returns an array using the same value for the`start_expression`and`end_expression`.\n\n```\nSELECT GENERATE_ARRAY(4, 4, 10) AS example_array;/*---------------* | example_array | +---------------+ | [4]           | *---------------*/\n```\n\nThe following returns an empty array, because the`start_expression`is greaterthan the`end_expression`, and the`step_expression`value is positive.\n\n```\nSELECT GENERATE_ARRAY(10, 0, 3) AS example_array;/*---------------* | example_array | +---------------+ | []            | *---------------*/\n```\n\nThe following returns a`NULL`array because`end_expression`is`NULL`.\n\n```\nSELECT GENERATE_ARRAY(5, NULL, 1) AS example_array;/*---------------* | example_array | +---------------+ | NULL          | *---------------*/\n```\n\nThe following returns multiple arrays.\n\n```\nSELECT GENERATE_ARRAY(start, 5) AS example_arrayFROM UNNEST([3, 4, 5]) AS start;/*---------------* | example_array | +---------------+ | [3, 4, 5]     | | [4, 5]        | | [5]           | +---------------*/\n```\n\n"
  },
  {
    "name": "GENERATE_DATE_ARRAY",
    "arguments": [],
    "category": "Array functions",
    "description": "```\nGENERATE_DATE_ARRAY(start_date, end_date[, INTERVAL INT64_expr date_part])\n```\n\n **Description** \n\nReturns an array of dates. The`start_date`and`end_date`parameters determine the inclusive start and end of the array.\n\nThe`GENERATE_DATE_ARRAY`function accepts the following data types as inputs:\n\n- `    start_date`must be a`    DATE`.\n- `    end_date`must be a`    DATE`.\n- `    INT64_expr`must be an`    INT64`.\n- `    date_part`must be either DAY, WEEK, MONTH, QUARTER, or YEAR.\n\nThe`INT64_expr`parameter determines the increment used to generate dates. Thedefault value for this parameter is 1 day.\n\nThis function returns an error if`INT64_expr`is set to 0.\n\n **Return Data Type** \n\n`ARRAY`containing 0 or more`DATE`values.\n\n **Examples** \n\nThe following returns an array of dates, with a default step of 1.\n\n```\nSELECT GENERATE_DATE_ARRAY('2016-10-05', '2016-10-08') AS example;/*--------------------------------------------------* | example                                          | +--------------------------------------------------+ | [2016-10-05, 2016-10-06, 2016-10-07, 2016-10-08] | *--------------------------------------------------*/\n```\n\nThe following returns an array using a user-specified step size.\n\n```\nSELECT GENERATE_DATE_ARRAY( '2016-10-05', '2016-10-09', INTERVAL 2 DAY) AS example;/*--------------------------------------* | example                              | +--------------------------------------+ | [2016-10-05, 2016-10-07, 2016-10-09] | *--------------------------------------*/\n```\n\nThe following returns an array using a negative value,`-3`for its step size.\n\n```\nSELECT GENERATE_DATE_ARRAY('2016-10-05',  '2016-10-01', INTERVAL -3 DAY) AS example;/*--------------------------* | example                  | +--------------------------+ | [2016-10-05, 2016-10-02] | *--------------------------*/\n```\n\nThe following returns an array using the same value for the`start_date`and`end_date`.\n\n```\nSELECT GENERATE_DATE_ARRAY('2016-10-05',  '2016-10-05', INTERVAL 8 DAY) AS example;/*--------------* | example      | +--------------+ | [2016-10-05] | *--------------*/\n```\n\nThe following returns an empty array, because the`start_date`is greaterthan the`end_date`, and the`step`value is positive.\n\n```\nSELECT GENERATE_DATE_ARRAY('2016-10-05',  '2016-10-01', INTERVAL 1 DAY) AS example;/*---------* | example | +---------+ | []      | *---------*/\n```\n\nThe following returns a`NULL`array, because one of its inputs is`NULL`.\n\n```\nSELECT GENERATE_DATE_ARRAY('2016-10-05', NULL) AS example;/*---------* | example | +---------+ | NULL    | *---------*/\n```\n\nThe following returns an array of dates, using MONTH as the`date_part`interval:\n\n```\nSELECT GENERATE_DATE_ARRAY('2016-01-01',  '2016-12-31', INTERVAL 2 MONTH) AS example;/*--------------------------------------------------------------------------* | example                                                                  | +--------------------------------------------------------------------------+ | [2016-01-01, 2016-03-01, 2016-05-01, 2016-07-01, 2016-09-01, 2016-11-01] | *--------------------------------------------------------------------------*/\n```\n\nThe following uses non-constant dates to generate an array.\n\n```\nSELECT GENERATE_DATE_ARRAY(date_start, date_end, INTERVAL 1 WEEK) AS date_rangeFROM (  SELECT DATE '2016-01-01' AS date_start, DATE '2016-01-31' AS date_end  UNION ALL SELECT DATE \"2016-04-01\", DATE \"2016-04-30\"  UNION ALL SELECT DATE \"2016-07-01\", DATE \"2016-07-31\"  UNION ALL SELECT DATE \"2016-10-01\", DATE \"2016-10-31\") AS items;/*--------------------------------------------------------------* | date_range                                                   | +--------------------------------------------------------------+ | [2016-01-01, 2016-01-08, 2016-01-15, 2016-01-22, 2016-01-29] | | [2016-04-01, 2016-04-08, 2016-04-15, 2016-04-22, 2016-04-29] | | [2016-07-01, 2016-07-08, 2016-07-15, 2016-07-22, 2016-07-29] | | [2016-10-01, 2016-10-08, 2016-10-15, 2016-10-22, 2016-10-29] | *--------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "GENERATE_RANGE_ARRAY",
    "arguments": [],
    "category": "Range functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nGENERATE_RANGE_ARRAY(range_to_split, step_interval)\n```\n\n```\nGENERATE_RANGE_ARRAY(range_to_split, step_interval, include_last_partial_range)\n```\n\n **Description** \n\nSplits a range into an array of subranges.\n\n **Definitions** \n\n- `    range_to_split`: The`    RANGE&lt;T&gt;`value to split.\n- `    step_interval`: The`    INTERVAL`value, which determines the maximum size ofeach subrange in the resulting array. An[interval single date and time part](/bigquery/docs/reference/standard-sql/data-types#single_datetime_part_interval)is supported, but an interval range of date and time parts is not.\n    \n    \n    - If`        range_to_split`is`        RANGE&lt;DATE&gt;`, these intervaldate parts are supported:`        YEAR`to`        DAY`.\n        \n        \n    - If`        range_to_split`is`        RANGE&lt;DATETIME&gt;`, these intervaldate and time parts are supported:`        YEAR`to`        SECOND`.\n        \n        \n    - If`        range_to_split`is`        RANGE&lt;TIMESTAMP&gt;`, these intervaldate and time parts are supported:`        DAY`to`        SECOND`.\n        \n        \n- `    include_last_partial_range`: A`    BOOL`value, which determines whether ornot to include the last subrange if it's a partial subrange.If this argument is not specified, the default value is`    TRUE`.\n    \n    \n    - `        TRUE`(default): The last subrange is included, even if it'ssmaller than`        step_interval`.\n        \n        \n    - `        FALSE`: Exclude the last subrange if it's smaller than`        step_interval`.\n        \n        \n\n **Details** \n\nReturns`NULL`if any input is`NULL`.\n\n **Return type** \n\n`ARRAY&lt;RANGE&lt;T&gt;&gt;`\n\n **Examples** \n\nIn the following example, a date range between`2020-01-01`and`2020-01-06`is split into an array of subranges that are one day long. There areno partial ranges.\n\n```\nSELECT GENERATE_RANGE_ARRAY(  RANGE(DATE '2020-01-01', DATE '2020-01-06'),  INTERVAL 1 DAY) AS results;/*----------------------------+ | results                    | +----------------------------+ | [                          | |  [2020-01-01, 2020-01-02), | |  [2020-01-02, 2020-01-03), | |  [2020-01-03, 2020-01-04), | |  [2020-01-04, 2020-01-05), | |  [2020-01-05, 2020-01-06), | | ]                          | +----------------------------*/\n```\n\nIn the following examples, a date range between`2020-01-01`and`2020-01-06`is split into an array of subranges that are two days long. The final subrangeis smaller than two days:\n\n```\nSELECT GENERATE_RANGE_ARRAY(  RANGE(DATE '2020-01-01', DATE '2020-01-06'),  INTERVAL 2 DAY) AS results;/*----------------------------+ | results                    | +----------------------------+ | [                          | |  [2020-01-01, 2020-01-03), | |  [2020-01-03, 2020-01-05), | |  [2020-01-05, 2020-01-06)  | | ]                          | +----------------------------*/\n```\n\n```\nSELECT GENERATE_RANGE_ARRAY(  RANGE(DATE '2020-01-01', DATE '2020-01-06'),  INTERVAL 2 DAY,  TRUE) AS results;/*----------------------------+ | results                    | +----------------------------+ | [                          | |  [2020-01-01, 2020-01-03), | |  [2020-01-03, 2020-01-05), | |  [2020-01-05, 2020-01-06)  | | ]                          | +----------------------------*/\n```\n\nIn the following example, a date range between`2020-01-01`and`2020-01-06`is split into an array of subranges that are two days long, but the finalsubrange is excluded because it's smaller than two days:\n\n```\nSELECT GENERATE_RANGE_ARRAY(  RANGE(DATE '2020-01-01', DATE '2020-01-06'),  INTERVAL 2 DAY,  FALSE) AS results;/*----------------------------+ | results                    | +----------------------------+ | [                          | |  [2020-01-01, 2020-01-03), | |  [2020-01-03, 2020-01-05)  | | ]                          | +----------------------------*/\n```\n\n"
  },
  {
    "name": "GENERATE_TIMESTAMP_ARRAY",
    "arguments": [],
    "category": "Array functions",
    "description": "```\nGENERATE_TIMESTAMP_ARRAY(start_timestamp, end_timestamp,                         INTERVAL step_expression date_part)\n```\n\n **Description** \n\nReturns an`ARRAY`of`TIMESTAMPS`separated by a given interval. The`start_timestamp`and`end_timestamp`parameters determine the inclusivelower and upper bounds of the`ARRAY`.\n\nThe`GENERATE_TIMESTAMP_ARRAY`function accepts the following data types asinputs:\n\n- `    start_timestamp`:`    TIMESTAMP`\n- `    end_timestamp`:`    TIMESTAMP`\n- `    step_expression`:`    INT64`\n- Allowed`    date_part`values are:`    MICROSECOND`,`    MILLISECOND`,`    SECOND`,`    MINUTE`,`    HOUR`, or`    DAY`.\n\nThe`step_expression`parameter determines the increment used to generatetimestamps.\n\n **Return Data Type** \n\nAn`ARRAY`containing 0 or more`TIMESTAMP`values.\n\n **Examples** \n\nThe following example returns an`ARRAY`of`TIMESTAMP`s at intervals of 1 day.\n\n```\nSELECT GENERATE_TIMESTAMP_ARRAY('2016-10-05 00:00:00', '2016-10-07 00:00:00',                                INTERVAL 1 DAY) AS timestamp_array;/*--------------------------------------------------------------------------* | timestamp_array                                                          | +--------------------------------------------------------------------------+ | [2016-10-05 00:00:00+00, 2016-10-06 00:00:00+00, 2016-10-07 00:00:00+00] | *--------------------------------------------------------------------------*/\n```\n\nThe following example returns an`ARRAY`of`TIMESTAMP`s at intervals of 1second.\n\n```\nSELECT GENERATE_TIMESTAMP_ARRAY('2016-10-05 00:00:00', '2016-10-05 00:00:02',                                INTERVAL 1 SECOND) AS timestamp_array;/*--------------------------------------------------------------------------* | timestamp_array                                                          | +--------------------------------------------------------------------------+ | [2016-10-05 00:00:00+00, 2016-10-05 00:00:01+00, 2016-10-05 00:00:02+00] | *--------------------------------------------------------------------------*/\n```\n\nThe following example returns an`ARRAY`of`TIMESTAMPS`with a negativeinterval.\n\n```\nSELECT GENERATE_TIMESTAMP_ARRAY('2016-10-06 00:00:00', '2016-10-01 00:00:00',                                INTERVAL -2 DAY) AS timestamp_array;/*--------------------------------------------------------------------------* | timestamp_array                                                          | +--------------------------------------------------------------------------+ | [2016-10-06 00:00:00+00, 2016-10-04 00:00:00+00, 2016-10-02 00:00:00+00] | *--------------------------------------------------------------------------*/\n```\n\nThe following example returns an`ARRAY`with a single element, because`start_timestamp`and`end_timestamp`have the same value.\n\n```\nSELECT GENERATE_TIMESTAMP_ARRAY('2016-10-05 00:00:00', '2016-10-05 00:00:00',                                INTERVAL 1 HOUR) AS timestamp_array;/*--------------------------* | timestamp_array          | +--------------------------+ | [2016-10-05 00:00:00+00] | *--------------------------*/\n```\n\nThe following example returns an empty`ARRAY`, because`start_timestamp`islater than`end_timestamp`.\n\n```\nSELECT GENERATE_TIMESTAMP_ARRAY('2016-10-06 00:00:00', '2016-10-05 00:00:00',                                INTERVAL 1 HOUR) AS timestamp_array;/*-----------------* | timestamp_array | +-----------------+ | []              | *-----------------*/\n```\n\nThe following example returns a null`ARRAY`, because one of the inputs is`NULL`.\n\n```\nSELECT GENERATE_TIMESTAMP_ARRAY('2016-10-05 00:00:00', NULL, INTERVAL 1 HOUR)  AS timestamp_array;/*-----------------* | timestamp_array | +-----------------+ | NULL            | *-----------------*/\n```\n\nThe following example generates`ARRAY`s of`TIMESTAMP`s from columns containingvalues for`start_timestamp`and`end_timestamp`.\n\n```\nSELECT GENERATE_TIMESTAMP_ARRAY(start_timestamp, end_timestamp, INTERVAL 1 HOUR)  AS timestamp_arrayFROM  (SELECT    TIMESTAMP '2016-10-05 00:00:00' AS start_timestamp,    TIMESTAMP '2016-10-05 02:00:00' AS end_timestamp   UNION ALL   SELECT    TIMESTAMP '2016-10-05 12:00:00' AS start_timestamp,    TIMESTAMP '2016-10-05 14:00:00' AS end_timestamp   UNION ALL   SELECT    TIMESTAMP '2016-10-05 23:59:00' AS start_timestamp,    TIMESTAMP '2016-10-06 01:59:00' AS end_timestamp);/*--------------------------------------------------------------------------* | timestamp_array                                                          | +--------------------------------------------------------------------------+ | [2016-10-05 00:00:00+00, 2016-10-05 01:00:00+00, 2016-10-05 02:00:00+00] | | [2016-10-05 12:00:00+00, 2016-10-05 13:00:00+00, 2016-10-05 14:00:00+00] | | [2016-10-05 23:59:00+00, 2016-10-06 00:59:00+00, 2016-10-06 01:59:00+00] | *--------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "GENERATE_UUID",
    "arguments": [],
    "category": "Utility functions",
    "description": "```\nGENERATE_UUID()\n```\n\n **Description** \n\nReturns a random universally unique identifier (UUID) as a`STRING`.The returned`STRING`consists of 32 hexadecimaldigits in five groups separated by hyphens in the form 8-4-4-4-12. Thehexadecimal digits represent 122 random bits and 6 fixed bits, in compliancewith[RFC 4122 section 4.4](https://tools.ietf.org/html/rfc4122#section-4.4).The returned`STRING`is lowercase.\n\n **Return Data Type** \n\nSTRING\n\n **Example** \n\nThe following query generates a random UUID.\n\n```\nSELECT GENERATE_UUID() AS uuid;/*--------------------------------------* | uuid                                 | +--------------------------------------+ | 4192bff0-e1e0-43ce-a4db-912808c32493 | *--------------------------------------*/\n```\n\n"
  },
  {
    "name": "GREATEST",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nGREATEST(X1,...,XN)\n```\n\n **Description** \n\nReturns the greatest value among`X1,...,XN`. If any argument is`NULL`, returns`NULL`. Otherwise, in the case of floating-point arguments, if any argument is`NaN`, returns`NaN`. In all other cases, returns the value among`X1,...,XN`that has the greatest value according to the ordering used by the`ORDER BY`clause. The arguments`X1, ..., XN`must be coercible to a common supertype, andthe supertype must support ordering.\n\n| X1,...,XN | GREATEST(X1,...,XN) |\n| --- | --- |\n| 3,5,1 | 5 |\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Return Data Types** \n\nData type of the input values.\n\n"
  },
  {
    "name": "GROUPING",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nGROUPING(groupable_value)\n```\n\n **Description** \n\nIf a groupable item in the[GROUP BY clause](/bigquery/docs/reference/standard-sql/query-syntax#group_by_clause)is aggregated(and thus not grouped), this function returns`1`. Otherwise,this function returns`0`.\n\nDefinitions:\n\n- `    groupable_value`: An expression that represents a value that can be groupedin the`    GROUP BY`clause.\n\nDetails:\n\nThe`GROUPING`function is helpful if you need to determine which rows areproduced by which grouping sets. A grouping set is a group of columns by whichrows can be grouped together. So, if you need to filter rows bya few specific grouping sets, you can use the`GROUPING`function to identifywhich grouping sets grouped which rows by creating a matrix of the results.\n\nIn addition, you can use the`GROUPING`function to determine the type of`NULL`produced by the`GROUP BY`clause. In some cases, the`GROUP BY`clauseproduces a`NULL`placeholder. This placeholder represents all groupable itemsthat are aggregated (not grouped) in the current grouping set. This is differentfrom a standard`NULL`, which can also be produced by a query.\n\nFor more information, see the following examples.\n\n **Returned Data Type** \n\n`INT64`\n\n **Examples** \n\nIn the following example, it's difficult to determine which rows are grouped bythe grouping value`product_type`or`product_name`. The`GROUPING`functionmakes this easier to determine.\n\nPay close attention to what's in the`product_type_agg`and`product_name_agg`column matrix. This determines how the rows are grouped.\n\n| `product_type_agg` | `product_name_agg` | Notes |\n| --- | --- | --- |\n| 1 | 0 | Rows are grouped by`product_name`. |\n| 0 | 1 | Rows are grouped by`product_type`. |\n| 0 | 0 | Rows are grouped by`product_type`and`product_name`. |\n| 1 | 1 | Grand total row. |\n\n```\nWITH  Products AS (    SELECT 'shirt' AS product_type, 't-shirt' AS product_name, 3 AS product_count UNION ALL    SELECT 'shirt', 't-shirt', 8 UNION ALL    SELECT 'shirt', 'polo', 25 UNION ALL    SELECT 'pants', 'jeans', 6  )SELECT  product_type,  product_name,  SUM(product_count) AS product_sum,  GROUPING(product_type) AS product_type_agg,  GROUPING(product_name) AS product_name_agg,FROM ProductsGROUP BY GROUPING SETS(product_type, product_name, ())ORDER BY product_name;/*--------------+--------------+-------------+------------------+------------------+ | product_type | product_name | product_sum | product_type_agg | product_name_agg | +--------------+--------------+-------------+------------------+------------------+ | NULL         | NULL         | 36          | 1                | 1                | | shirt        | NULL         | 36          | 0                | 1                | | pants        | NULL         | 6           | 0                | 1                | | NULL         | jeans        | 6           | 1                | 0                | | NULL         | polo         | 25          | 1                | 0                | | NULL         | t-shirt      | 11          | 1                | 0                | +--------------+--------------+-------------+------------------+------------------*/\n```\n\nIn the following example, it's difficult to determineif`NULL`represents a`NULL`placeholder or a standard`NULL`value in the`product_type`column. The`GROUPING`function makes it easier todetermine what type of`NULL`is being produced. If`product_type_is_aggregated`is`1`, the`NULL`value forthe`product_type`column is a`NULL`placeholder.\n\n```\nWITH  Products AS (    SELECT 'shirt' AS product_type, 't-shirt' AS product_name, 3 AS product_count UNION ALL    SELECT 'shirt', 't-shirt', 8 UNION ALL    SELECT NULL, 'polo', 25 UNION ALL    SELECT 'pants', 'jeans', 6  )SELECT  product_type,  product_name,  SUM(product_count) AS product_sum,  GROUPING(product_type) AS product_type_is_aggregatedFROM ProductsGROUP BY GROUPING SETS(product_type, product_name)ORDER BY product_name;/*--------------+--------------+-------------+----------------------------+ | product_type | product_name | product_sum | product_type_is_aggregated | +--------------+--------------+-------------+----------------------------+ | shirt        | NULL         | 36          | 0                          | | NULL         | NULL         | 25          | 0                          | | pants        | NULL         | 6           | 0                          | | NULL         | jeans        | 6           | 1                          | | NULL         | polo         | 25          | 1                          | | NULL         | t-shirt      | 11          | 1                          | +--------------+--------------+-------------+----------------------------*/\n```\n\n"
  },
  {
    "name": "HLL_COUNT.EXTRACT",
    "arguments": [],
    "category": "HyperLogLog++ functions",
    "description": "```\nHLL_COUNT.EXTRACT(sketch)\n```\n\n **Description** \n\nA scalar function that extracts a cardinality estimate of a single[HLL++](https://research.google.com/pubs/pub40671.html)sketch.\n\nIf`sketch`is`NULL`, this function returns a cardinality estimate of`0`.\n\n **Supported input types** \n\n`BYTES`\n\n **Return type** \n\n`INT64`\n\n **Example** \n\nThe following query returns the number of distinct users for each country whohave at least one invoice.\n\n```\nSELECT  country,  HLL_COUNT.EXTRACT(HLL_sketch) AS distinct_customers_with_open_invoiceFROM  (    SELECT      country,      HLL_COUNT.INIT(customer_id) AS hll_sketch    FROM      UNNEST(        ARRAY&lt;STRUCT&lt;country STRING, customer_id STRING, invoice_id STRING&gt;&gt;[          ('UA', 'customer_id_1', 'invoice_id_11'),          ('BR', 'customer_id_3', 'invoice_id_31'),          ('CZ', 'customer_id_2', 'invoice_id_22'),          ('CZ', 'customer_id_2', 'invoice_id_23'),          ('BR', 'customer_id_3', 'invoice_id_31'),          ('UA', 'customer_id_2', 'invoice_id_24')])    GROUP BY country  );/*---------+--------------------------------------* | country | distinct_customers_with_open_invoice | +---------+--------------------------------------+ | UA      |                                    2 | | BR      |                                    1 | | CZ      |                                    1 | *---------+--------------------------------------*/\n```\n\n"
  },
  {
    "name": "HLL_COUNT.INIT",
    "arguments": [],
    "category": "HyperLogLog++ functions",
    "description": "```\nHLL_COUNT.INIT(input [, precision])\n```\n\n **Description** \n\nAn aggregate function that takes one or more`input`values and aggregates theminto a[HLL++](https://research.google.com/pubs/pub40671.html)sketch. Each sketchis represented using the`BYTES`data type. You can then merge sketches using`HLL_COUNT.MERGE`or`HLL_COUNT.MERGE_PARTIAL`. If no merging is needed,you can extract the final count of distinct values from the sketch using`HLL_COUNT.EXTRACT`.\n\nThis function supports an optional parameter,`precision`. This parameterdefines the accuracy of the estimate at the cost of additional memory requiredto process the sketches or store them on disk. The range for this value is`10`to`24`. The default value is`15`. For more information about precision,see[Precision for sketches](/bigquery/docs/sketches#precision_hll).\n\nIf the input is`NULL`, this function returns`NULL`.\n\nFor more information, see[HyperLogLog in Practice: Algorithmic Engineering ofa State of The Art Cardinality Estimation Algorithm](https://research.google.com/pubs/pub40671.html).\n\n **Supported input types** \n\n- `    INT64`\n- `    NUMERIC`\n- `    BIGNUMERIC`\n- `    STRING`\n- `    BYTES`\n\n **Return type** \n\n`BYTES`\n\n **Example** \n\nThe following query creates HLL++ sketches that count the number of distinctusers with at least one invoice per country.\n\n```\nSELECT  country,  HLL_COUNT.INIT(customer_id, 10)    AS hll_sketchFROM  UNNEST(    ARRAY&lt;STRUCT&lt;country STRING, customer_id STRING, invoice_id STRING&gt;&gt;[      ('UA', 'customer_id_1', 'invoice_id_11'),      ('CZ', 'customer_id_2', 'invoice_id_22'),      ('CZ', 'customer_id_2', 'invoice_id_23'),      ('BR', 'customer_id_3', 'invoice_id_31'),      ('UA', 'customer_id_2', 'invoice_id_24')])GROUP BY country;/*---------+------------------------------------------------------------------------------------* | country | hll_sketch                                                                         | +---------+------------------------------------------------------------------------------------+ | UA      | \"\\010p\\020\\002\\030\\002 \\013\\202\\007\\r\\020\\002\\030\\n \\0172\\005\\371\\344\\001\\315\\010\" | | CZ      | \"\\010p\\020\\002\\030\\002 \\013\\202\\007\\013\\020\\001\\030\\n \\0172\\003\\371\\344\\001\"       | | BR      | \"\\010p\\020\\001\\030\\002 \\013\\202\\007\\013\\020\\001\\030\\n \\0172\\003\\202\\341\\001\"       | *---------+------------------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "HLL_COUNT.MERGE",
    "arguments": [],
    "category": "HyperLogLog++ functions",
    "description": "```\nHLL_COUNT.MERGE(sketch)\n```\n\n **Description** \n\nAn aggregate function that returns the cardinality of several[HLL++](https://research.google.com/pubs/pub40671.html)sketches by computing their union.\n\nEach`sketch`must be initialized on the same type. Attempts to merge sketchesfor different types results in an error. For example, you cannot merge a sketchinitialized from`INT64`data with one initialized from`STRING`data.\n\nIf the merged sketches were initialized with different precisions, the precisionwill be downgraded to the lowest precision involved in the merge.\n\nThis function ignores`NULL`values when merging sketches. If the merge happensover zero rows or only over`NULL`values, the function returns`0`.\n\n **Supported input types** \n\n`BYTES`\n\n **Return type** \n\n`INT64`\n\n **Example** \n\nThe following query counts the number of distinct users across all countries who have at least one invoice.\n\n```\nSELECT HLL_COUNT.MERGE(hll_sketch) AS distinct_customers_with_open_invoiceFROM  (    SELECT      country,      HLL_COUNT.INIT(customer_id) AS hll_sketch    FROM      UNNEST(        ARRAY&lt;STRUCT&lt;country STRING, customer_id STRING, invoice_id STRING&gt;&gt;[          ('UA', 'customer_id_1', 'invoice_id_11'),          ('BR', 'customer_id_3', 'invoice_id_31'),          ('CZ', 'customer_id_2', 'invoice_id_22'),          ('CZ', 'customer_id_2', 'invoice_id_23'),          ('BR', 'customer_id_3', 'invoice_id_31'),          ('UA', 'customer_id_2', 'invoice_id_24')])    GROUP BY country  );/*--------------------------------------* | distinct_customers_with_open_invoice | +--------------------------------------+ |                                    3 | *--------------------------------------*/\n```\n\n"
  },
  {
    "name": "HLL_COUNT.MERGE_PARTIAL",
    "arguments": [],
    "category": "HyperLogLog++ functions",
    "description": "```\nHLL_COUNT.MERGE_PARTIAL(sketch)\n```\n\n **Description** \n\nAn aggregate function that takes one or more[HLL++](https://research.google.com/pubs/pub40671.html)`sketch`inputs and merges them into a new sketch.\n\nEach`sketch`must be initialized on the same type. Attempts to merge sketchesfor different types results in an error. For example, you cannot merge a sketchinitialized from`INT64`data with one initialized from`STRING`data.\n\nIf the merged sketches were initialized with different precisions, the precisionwill be downgraded to the lowest precision involved in the merge. For example,if`MERGE_PARTIAL`encounters sketches of precision 14 and 15, the returned newsketch will have precision 14.\n\nThis function returns`NULL`if there is no input or all inputs are`NULL`.\n\n **Supported input types** \n\n`BYTES`\n\n **Return type** \n\n`BYTES`\n\n **Example** \n\nThe following query returns an HLL++ sketch that counts the number of distinctusers who have at least one invoice across all countries.\n\n```\nSELECT HLL_COUNT.MERGE_PARTIAL(HLL_sketch) AS distinct_customers_with_open_invoiceFROM  (    SELECT      country,      HLL_COUNT.INIT(customer_id) AS hll_sketch    FROM      UNNEST(        ARRAY&lt;STRUCT&lt;country STRING, customer_id STRING, invoice_id STRING&gt;&gt;[          ('UA', 'customer_id_1', 'invoice_id_11'),          ('BR', 'customer_id_3', 'invoice_id_31'),          ('CZ', 'customer_id_2', 'invoice_id_22'),          ('CZ', 'customer_id_2', 'invoice_id_23'),          ('BR', 'customer_id_3', 'invoice_id_31'),          ('UA', 'customer_id_2', 'invoice_id_24')])    GROUP BY country  );/*----------------------------------------------------------------------------------------------* | distinct_customers_with_open_invoice                                                         | +----------------------------------------------------------------------------------------------+ | \"\\010p\\020\\006\\030\\002 \\013\\202\\007\\020\\020\\003\\030\\017 \\0242\\010\\320\\2408\\352}\\244\\223\\002\" | *----------------------------------------------------------------------------------------------*/\n```\n\n\n<span id=\"interval_functions\">\n## Interval functions\n\n</span>\nGoogleSQL for BigQuery supports the following interval functions.\n\n"
  },
  {
    "name": "HOW TIME ZONES WORK WITH TIMESTAMP FUNCTIONS",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "A timestamp represents an absolute point in time, independent of any timezone. However, when a timestamp value is displayed, it is usually converted toa human-readable format consisting of a civil date and time(YYYY-MM-DD HH:MM:SS)and a time zone. This is not the internal representation of the`TIMESTAMP`; it is only a human-understandable way to describe the point in timethat the timestamp represents.\n\nSome timestamp functions have a time zone argument. A time zone is needed toconvert between civil time (YYYY-MM-DD HH:MM:SS) and the absolute timerepresented by a timestamp.A function like`PARSE_TIMESTAMP`takes an input string that represents acivil time and returns a timestamp that represents an absolute time. Atime zone is needed for this conversion. A function like`EXTRACT`takes aninput timestamp (absolute time) and converts it to civil time in order toextract a part of that civil time. This conversion requires a time zone.If no time zone is specified, the default time zone, UTC,is used.\n\nCertain date and timestamp functions allow you to override the default time zoneand specify a different one. You can specify a time zone by either supplyingthe time zone name (for example,`America/Los_Angeles`)or time zone offset from UTC (for example, -08).\n\nTo learn more about how time zones work with the`TIMESTAMP`type, see[Time zones](/bigquery/docs/reference/standard-sql/data-types#time_zones).\n\n\n<span id=\"utility_functions\">\n## Utility functions\n\n</span>\nGoogleSQL for BigQuery supports the following utility functions.\n\n"
  },
  {
    "name": "IEEE_DIVIDE",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nIEEE_DIVIDE(X, Y)\n```\n\n **Description** \n\nDivides X by Y; this function never fails. Returns`FLOAT64`. Unlike the division operator (/),this function does not generate errors for division by zero or overflow.\n\n| X | Y | IEEE_DIVIDE(X, Y) |\n| --- | --- | --- |\n| 20.0 | 4.0 | 5.0 |\n| 0.0 | 25.0 | 0.0 |\n| 25.0 | 0.0 | `+inf` |\n| -25.0 | 0.0 | `-inf` |\n| 0.0 | 0.0 | `NaN` |\n| 0.0 | `NaN` | `NaN` |\n| `NaN` | 0.0 | `NaN` |\n| `+inf` | `+inf` | `NaN` |\n| `-inf` | `-inf` | `NaN` |\n\n"
  },
  {
    "name": "INITCAP",
    "arguments": [],
    "category": "String functions",
    "description": "```\nINITCAP(value[, delimiters])\n```\n\n **Description** \n\nTakes a`STRING`and returns it with the first character in each word inuppercase and all other characters in lowercase. Non-alphabetic charactersremain the same.\n\n`delimiters`is an optional string argument that is used to override the defaultset of characters used to separate words. If`delimiters`is not specified, itdefaults to the following characters:    \n`&lt;whitespace&gt; [ ] ( ) { } / | \\ &lt; &gt; ! ? @ \" ^ # $ &amp; ~ _ , . : ; * % + -`\n\nIf`value`or`delimiters`is`NULL`, the function returns`NULL`.\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n```\nWITH example AS(  SELECT 'Hello World-everyone!' AS value UNION ALL  SELECT 'tHe dog BARKS loudly+friendly' AS value UNION ALL  SELECT 'apples&amp;oranges;&amp;pears' AS value UNION ALL  SELECT 'καθίσματα ταινιών' AS value)SELECT value, INITCAP(value) AS initcap_value FROM example/*-------------------------------+-------------------------------* | value                         | initcap_value                 | +-------------------------------+-------------------------------+ | Hello World-everyone!         | Hello World-Everyone!         | | tHe dog BARKS loudly+friendly | The Dog Barks Loudly+Friendly | | apples&amp;oranges;&amp;pears         | Apples&amp;Oranges;&amp;Pears         | | καθίσματα ταινιών             | Καθίσματα Ταινιών             | *-------------------------------+-------------------------------*/WITH example AS(  SELECT 'hello WORLD!' AS value, '' AS delimiters UNION ALL  SELECT 'καθίσματα ταιντιώ@ν' AS value, 'τ@' AS delimiters UNION ALL  SELECT 'Apples1oranges2pears' AS value, '12' AS delimiters UNION ALL  SELECT 'tHisEisEaESentence' AS value, 'E' AS delimiters)SELECT value, delimiters, INITCAP(value, delimiters) AS initcap_value FROM example;/*----------------------+------------+----------------------* | value                | delimiters | initcap_value        | +----------------------+------------+----------------------+ | hello WORLD!         |            | Hello world!         | | καθίσματα ταιντιώ@ν  | τ@         | ΚαθίσματΑ τΑιντΙώ@Ν  | | Apples1oranges2pears | 12         | Apples1Oranges2Pears | | tHisEisEaESentence   | E          | ThisEIsEAESentence   | *----------------------+------------+----------------------*/\n```\n\n"
  },
  {
    "name": "INSTR",
    "arguments": [],
    "category": "String functions",
    "description": "```\nINSTR(value, subvalue[, position[, occurrence]])\n```\n\n **Description** \n\nReturns the lowest 1-based position of`subvalue`in`value`.`value`and`subvalue`must be the same type, either`STRING`or`BYTES`.\n\nIf`position`is specified, the search starts at this position in`value`, otherwise it starts at`1`, which is the beginning of`value`. If`position`is negative, the function searches backwardsfrom the end of`value`, with`-1`indicating the last character.`position`is of type`INT64`and cannot be`0`.\n\nIf`occurrence`is specified, the search returns the position of a specificinstance of`subvalue`in`value`. If not specified,`occurrence`defaults to`1`and returns the position of the first occurrence.For`occurrence`>`1`, the function includes overlapping occurrences.`occurrence`is of type`INT64`and must be positive.\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\nReturns`0`if:\n\n- No match is found.\n- If`    occurrence`is greater than the number of matches found.\n- If`    position`is greater than the length of`    value`.\n\nReturns`NULL`if:\n\n- Any input argument is`    NULL`.\n\nReturns an error if:\n\n- `    position`is`    0`.\n- `    occurrence`is`    0`or negative.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH example AS(SELECT 'banana' as value, 'an' as subvalue, 1 as position, 1 asoccurrence UNION ALLSELECT 'banana' as value, 'an' as subvalue, 1 as position, 2 asoccurrence UNION ALLSELECT 'banana' as value, 'an' as subvalue, 1 as position, 3 asoccurrence UNION ALLSELECT 'banana' as value, 'an' as subvalue, 3 as position, 1 asoccurrence UNION ALLSELECT 'banana' as value, 'an' as subvalue, -1 as position, 1 asoccurrence UNION ALLSELECT 'banana' as value, 'an' as subvalue, -3 as position, 1 asoccurrence UNION ALLSELECT 'banana' as value, 'ann' as subvalue, 1 as position, 1 asoccurrence UNION ALLSELECT 'helloooo' as value, 'oo' as subvalue, 1 as position, 1 asoccurrence UNION ALLSELECT 'helloooo' as value, 'oo' as subvalue, 1 as position, 2 asoccurrence)SELECT value, subvalue, position, occurrence, INSTR(value,subvalue, position, occurrence) AS instrFROM example;/*--------------+--------------+----------+------------+-------* | value        | subvalue     | position | occurrence | instr | +--------------+--------------+----------+------------+-------+ | banana       | an           | 1        | 1          | 2     | | banana       | an           | 1        | 2          | 4     | | banana       | an           | 1        | 3          | 0     | | banana       | an           | 3        | 1          | 4     | | banana       | an           | -1       | 1          | 4     | | banana       | an           | -3       | 1          | 4     | | banana       | ann          | 1        | 1          | 0     | | helloooo     | oo           | 1        | 1          | 5     | | helloooo     | oo           | 1        | 2          | 6     | *--------------+--------------+----------+------------+-------*/\n```\n\n"
  },
  {
    "name": "INT64",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nINT64(json_expr)\n```\n\n **Description** \n\nConverts a JSON number to a SQL`INT64`value.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '999'\n    ```\n    \n    If the JSON value is not a number, or the JSON number is not in the SQL`    INT64`domain, an error is produced. If the expression is SQL`    NULL`, thefunction returns SQL`    NULL`.\n    \n    \n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nSELECT INT64(JSON '2005') AS flight_number;/*---------------* | flight_number | +---------------+ | 2005          | *---------------*/\n```\n\n```\nSELECT INT64(JSON_QUERY(JSON '{\"gate\": \"A4\", \"flight_number\": 2005}', \"$.flight_number\")) AS flight_number;/*---------------* | flight_number | +---------------+ | 2005          | *---------------*/\n```\n\n```\nSELECT INT64(JSON '10.0') AS score;/*-------* | score | +-------+ | 10    | *-------*/\n```\n\nThe following examples show how invalid requests are handled:\n\n```\n-- An error is thrown if JSON is not a number or cannot be converted to a 64-bit integer.SELECT INT64(JSON '10.1') AS result;  -- Throws an errorSELECT INT64(JSON '\"strawberry\"') AS result; -- Throws an errorSELECT INT64(JSON 'null') AS result; -- Throws an errorSELECT SAFE.INT64(JSON '\"strawberry\"') AS result;  -- Returns a SQL NULL\n```\n\n"
  },
  {
    "name": "IS_INF",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nIS_INF(X)\n```\n\n **Description** \n\nReturns`TRUE`if the value is positive or negative infinity.\n\n| X | IS_INF(X) |\n| --- | --- |\n| `+inf` | `TRUE` |\n| `-inf` | `TRUE` |\n| 25 | `FALSE` |\n\n"
  },
  {
    "name": "IS_NAN",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nIS_NAN(X)\n```\n\n **Description** \n\nReturns`TRUE`if the value is a`NaN`value.\n\n| X | IS_NAN(X) |\n| --- | --- |\n| `NaN` | `TRUE` |\n| 25 | `FALSE` |\n\n"
  },
  {
    "name": "JSON ENCODINGS",
    "arguments": [],
    "category": "JSON functions",
    "description": "You can encode a SQL value as a JSON value with the following functions:\n\n- `    TO_JSON_STRING`\n- `    TO_JSON`\n- `    JSON_SET`(uses`    TO_JSON`encoding)\n- `    JSON_ARRAY`(uses`    TO_JSON`encoding)\n- `    JSON_ARRAY_APPEND`(uses`    TO_JSON`encoding)\n- `    JSON_ARRAY_INSERT`(uses`    TO_JSON`encoding)\n- `    JSON_OBJECT`(uses`    TO_JSON`encoding)\n\nThe following SQL to JSON encodings are supported:\n\n| From SQL | To JSON | Examples |\n| --- | --- | --- |\n| NULL | null\n\n | SQL input:`NULL`    \nJSON output:`null` |\n| BOOL | boolean | SQL input:`TRUE`    \nJSON output:`true`    \n\n---\nSQL input:`FALSE`    \nJSON output:`false`    \n |\n| INT64 | (TO_JSON_STRING only)\n\nnumber or string\n\nEncoded as a number when the value is in the range of          [-2, 2], which is the range of          integers that can be represented losslessly as IEEE 754          double-precision floating point numbers. A value outside of this range          is encoded as a string.\n\n | SQL input:`9007199254740992`    \nJSON output:`9007199254740992`    \n\n---\nSQL input:`9007199254740993`    \nJSON output:`\"9007199254740993\"`    \n |\n| INT64 | (TO_JSON only)\n\nnumber or string\n\nIf the`stringify_wide_numbers`argument          is`TRUE`and the value is outside of the          FLOAT64 type domain, the value is          encoded as a string. If the value cannot be stored in          JSON without loss of precision, the function fails.          Otherwise, the value is encoded as a number.\n\nIf the`stringify_wide_numbers`is not used or is`FALSE`, numeric values outside of the          `FLOAT64` type domain are not          encoded as strings, but are stored as JSON numbers. If a          numerical value cannot be stored in JSON without loss of precision,          an error is thrown.\n\n | SQL input:`9007199254740992`    \nJSON output:`9007199254740992`    \n\n---\nSQL input:`9007199254740993`    \nJSON output:`9007199254740993`    \n\n---\nSQL input with stringify_wide_numbers=>TRUE:`9007199254740992`    \nJSON output:`9007199254740992`    \n\n---\nSQL input with stringify_wide_numbers=>TRUE:`9007199254740993`    \nJSON output:`\"9007199254740993\"`    \n |\n| NUMERIC    \nBIGNUMERIC | (TO_JSON_STRING only)\n\nnumber or string\n\nEncoded as a number when the value is in the range of          [-2, 2] and has no fractional          part. A value outside of this range is encoded as a string.\n\n | SQL input:`-1`    \nJSON output:`-1`    \n\n---\nSQL input:`0`    \nJSON output:`0`    \n\n---\nSQL input:`9007199254740993`    \nJSON output:`\"9007199254740993\"`    \n\n---\nSQL input:`123.56`    \nJSON output:`\"123.56\"`    \n |\n| NUMERIC    \nBIGNUMERIC | (TO_JSON only)\n\nnumber or string\n\nIf the`stringify_wide_numbers`argument          is`TRUE`and the value is outside of the          FLOAT64 type domain, it is          encoded as a string. Otherwise, it's encoded as a number.\n\n | SQL input:`-1`    \nJSON output:`-1`    \n\n---\nSQL input:`0`    \nJSON output:`0`    \n\n---\nSQL input:`9007199254740993`    \nJSON output:`9007199254740993`    \n\n---\nSQL input:`123.56`    \nJSON output:`123.56`    \n\n---\nSQL input with stringify_wide_numbers=>TRUE:`9007199254740993`    \nJSON output:`\"9007199254740993\"`    \n\n---\nSQL input with stringify_wide_numbers=>TRUE:`123.56`    \nJSON output:`123.56`    \n |\n| FLOAT64 | number or string\n\n`+/-inf`and`NaN`are encoded as`Infinity`,`-Infinity`, and`NaN`.          Otherwise, this value is encoded as a number.\n\n | SQL input:`1.0`    \nJSON output:`1`    \n\n---\nSQL input:`9007199254740993`    \nJSON output:`9007199254740993`    \n\n---\nSQL input:`\"+inf\"`    \nJSON output:`\"Infinity\"`    \n\n---\nSQL input:`\"-inf\"`    \nJSON output:`\"-Infinity\"`    \n\n---\nSQL input:`\"NaN\"`    \nJSON output:`\"NaN\"`    \n |\n| STRING | string\n\nEncoded as a string, escaped according to the JSON standard.          Specifically,`\"`,`\\`, and the control          characters from`U+0000`to`U+001F`are          escaped.\n\n | SQL input:`\"abc\"`    \nJSON output:`\"abc\"`    \n\n---\nSQL input:`\"\\\"abc\\\"\"`    \nJSON output:`\"\\\"abc\\\"\"`    \n |\n| BYTES | string\n\nUses RFC 4648 Base64 data encoding.\n\n | SQL input:`b\"Google\"`    \nJSON output:`\"R29vZ2xl\"`    \n |\n| DATE | string | SQL input:`DATE '2017-03-06'`    \nJSON output:`\"2017-03-06\"`    \n |\n| TIMESTAMP | string\n\nEncoded as ISO 8601 date and time, where T separates the date and          time and Z (Zulu/UTC) represents the time zone.\n\n | SQL input:`TIMESTAMP '2017-03-06 12:34:56.789012'`    \nJSON output:`\"2017-03-06T12:34:56.789012Z\"`    \n |\n| DATETIME | string\n\nEncoded as ISO 8601 date and time, where T separates the date and          time.\n\n | SQL input:`DATETIME '2017-03-06 12:34:56.789012'`    \nJSON output:`\"2017-03-06T12:34:56.789012\"`    \n |\n| TIME | string\n\nEncoded as ISO 8601 time.\n\n | SQL input:`TIME '12:34:56.789012'`    \nJSON output:`\"12:34:56.789012\"`    \n |\n| JSON | data of the input JSON\n\n | SQL input:`JSON '{\"item\": \"pen\", \"price\": 10}'`    \nJSON output:`{\"item\":\"pen\", \"price\":10}`    \n\n---\nSQL input:`[1, 2, 3]`    \nJSON output:`[1, 2, 3]`    \n |\n| ARRAY | array\n\nCan contain zero or more elements.\n\n | SQL input:`[\"red\", \"blue\", \"green\"]`    \nJSON output:`[\"red\",\"blue\",\"green\"]`    \n\n---\nSQL input:`[1, 2, 3]`    \nJSON output:`[1,2,3]`    \n |\n| STRUCT | object\n\nThe object can contain zero or more key/value pairs.          Each value is formatted according to its type.\n\nFor`TO_JSON`, a field is          included in the output string and any duplicates of this field are          omitted.          For`TO_JSON_STRING`,          a field and any duplicates of this field are included in the          output string.\n\nAnonymous fields are represented with`\"\"`.\n\nInvalid UTF-8 field names might result in unparseable JSON. String          values are escaped according to the JSON standard. Specifically,`\"`,`\\`, and the control characters from`U+0000`to`U+001F`are escaped.\n\n | SQL input:`STRUCT(12 AS purchases, TRUE AS inStock)`    \nJSON output:`{\"inStock\": true,\"purchases\":12}`    \n |\n\n"
  },
  {
    "name": "JSONPATH FORMAT",
    "arguments": [],
    "category": "JSON functions",
    "description": "With the JSONPath format, you can identify the values you want toobtain from a JSON-formatted string. The JSONPath format supports theseoperators:\n\n| Operator | Description | Examples |\n| --- | --- | --- |\n| `$` | Root object or element. The JSONPath format must start with this        operator, which refers to the outermost level of the        JSON-formatted string. | JSON-formatted string:    \n`'{\"class\" : {\"students\" : [{\"name\" : \"Jane\"}]}}'`\n\nJSON path:    \n`\"$\"`\n\nJSON result:    \n`{\"class\":{\"students\":[{\"name\":\"Jane\"}]}}`    \n\n\n |\n| `.` | Child operator. You can identify child values using dot-notation. | JSON-formatted string:    \n`'{\"class\" : {\"students\" : [{\"name\" : \"Jane\"}]}}'`\n\nJSON path:    \n`\"$.class.students\"`\n\nJSON result:    \n`[{\"name\":\"Jane\"}]`\n\n |\n| `[]` | Subscript operator. If the object is a JSON array, you can use        brackets to specify the array index. | JSON-formatted string:    \n`'{\"class\" : {\"students\" : [{\"name\" : \"Jane\"}]}}'`\n\nJSON path:    \n`\"$.class.students[0]\"`\n\nJSON result:    \n`{\"name\":\"Jane\"}`\n\n |\n| `[][]`    \n`[][][]...` | Child subscript operator. If the object is a JSON array within        an array, you can use as many additional brackets as you need        to specify the child array index. | JSON-formatted string:    \n`'{\"a\": [[\"b\", \"c\"], \"d\"], \"e\":\"f\"}'`\n\nJSON path:    \n`\"$.a[0][1]\"`\n\nJSON result:    \n`\"c\"`\n\n |\n\nIf a key in a JSON functions contains a JSON format operator, refer to eachJSON function for how to escape them.\n\nA JSON function returns`NULL`if the JSONPath format does not match a value ina JSON-formatted string. If the selected value for a scalar function is notscalar, such as an object or an array, the function returns`NULL`. If theJSONPath format is invalid, an error is produced.\n\n"
  },
  {
    "name": "JSON_ARRAY",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_ARRAY([value][, ...])\n```\n\n **Description** \n\nCreates a JSON array from zero or more SQL values.\n\nArguments:\n\n- `    value`: A[JSON encoding-supported](#json_encodings)value to addto a JSON array.\n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nYou can create an empty JSON array. For example:\n\n```\nSELECT JSON_ARRAY() AS json_data/*-----------* | json_data | +-----------+ | []        | *-----------*/\n```\n\nThe following query creates a JSON array with one value in it:\n\n```\nSELECT JSON_ARRAY(10) AS json_data/*-----------* | json_data | +-----------+ | [10]      | *-----------*/\n```\n\nYou can create a JSON array with an empty JSON array in it. For example:\n\n```\nSELECT JSON_ARRAY([]) AS json_data/*-----------* | json_data | +-----------+ | [[]]      | *-----------*/\n```\n\n```\nSELECT JSON_ARRAY(10, 'foo', NULL) AS json_data/*-----------------* | json_data       | +-----------------+ | [10,\"foo\",null] | *-----------------*/\n```\n\n```\nSELECT JSON_ARRAY(STRUCT(10 AS a, 'foo' AS b)) AS json_data/*----------------------* | json_data            | +----------------------+ | [{\"a\":10,\"b\":\"foo\"}] | *----------------------*/\n```\n\n```\nSELECT JSON_ARRAY(10, ['foo', 'bar'], [20, 30]) AS json_data/*----------------------------* | json_data                  | +----------------------------+ | [10,[\"foo\",\"bar\"],[20,30]] | *----------------------------*/\n```\n\n```\nSELECT JSON_ARRAY(10, [JSON '20', JSON '\"foo\"']) AS json_data/*-----------------* | json_data       | +-----------------+ | [10,[20,\"foo\"]] | *-----------------*/\n```\n\n"
  },
  {
    "name": "JSON_ARRAY_APPEND",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_ARRAY_APPEND(  json_expr,  json_path_value_pair[, ...]  [, append_each_element=&gt;{ TRUE | FALSE }])json_path_value_pair:  json_path, value\n```\n\nAppends JSON data to the end of a JSON array.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '[\"a\", \"b\", \"c\"]'\n    ```\n    \n    \n- `    json_path_value_pair`: A value and the[JSONPath](#JSONPath_format)forthat value. This includes:\n    \n    \n    - `        json_path`: Append`        value`at this[JSONPath](#JSONPath_format)in`        json_expr`.\n        \n        \n    - `        value`: A[JSON encoding-supported](#json_encodings)value toappend.\n        \n        \n- `    append_each_element`: An optional, mandatory named argument.\n    \n    \n    - If`        TRUE`(default), and`        value`is a SQL array,appends each element individually.\n        \n        \n    - If`        FALSE,`and`        value`is a SQL array, appendsthe array as one element.\n        \n        \n\nDetails:\n\n- Path value pairs are evaluated left to right. The JSON produced byevaluating one pair becomes the JSON against which the next pairis evaluated.\n- The operation is ignored if the path points to a JSON non-array value thatis not a JSON null.\n- If`    json_path`points to a JSON null, the JSON null is replaced by aJSON array that contains`    value`.\n- If the path exists but has an incompatible type at any given path token,the path value pair operation is ignored.\n- The function applies all path value pair append operations even if anindividual path value pair operation is invalid. For invalid operations,the operation is ignored and the function continues to process the rest ofthe path value pairs.\n- If any`    json_path`is an invalid[JSONPath](#JSONPath_format), an error isproduced.\n- If`    json_expr`is SQL`    NULL`, the function returns SQL`    NULL`.\n- If`    append_each_element`is SQL`    NULL`, the function returns`    json_expr`.\n- If`    json_path`is SQL`    NULL`, the`    json_path_value_pair`operation isignored.\n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nIn the following example, path`$`is matched and appends`1`.\n\n```\nSELECT JSON_ARRAY_APPEND(JSON '[\"a\", \"b\", \"c\"]', '$', 1) AS json_data/*-----------------* | json_data       | +-----------------+ | [\"a\",\"b\",\"c\",1] | *-----------------*/\n```\n\nIn the following example,`append_each_element`defaults to`TRUE`, so`[1, 2]`is appended as individual elements.\n\n```\nSELECT JSON_ARRAY_APPEND(JSON '[\"a\", \"b\", \"c\"]', '$', [1, 2]) AS json_data/*-------------------* | json_data         | +-------------------+ | [\"a\",\"b\",\"c\",1,2] | *-------------------*/\n```\n\nIn the following example,`append_each_element`is`FALSE`, so`[1, 2]`is appended as one element.\n\n```\nSELECT JSON_ARRAY_APPEND(  JSON '[\"a\", \"b\", \"c\"]',  '$', [1, 2],  append_each_element=&gt;FALSE) AS json_data/*---------------------* | json_data           | +---------------------+ | [\"a\",\"b\",\"c\",[1,2]] | *---------------------*/\n```\n\nIn the following example,`append_each_element`is`FALSE`, so`[1, 2]`and`[3, 4]`are each appended as one element.\n\n```\nSELECT JSON_ARRAY_APPEND(  JSON '[\"a\", [\"b\"], \"c\"]',  '$[1]', [1, 2],  '$[1][1]', [3, 4],  append_each_element=&gt;FALSE) AS json_data/*-----------------------------* | json_data                   | +-----------------------------+ | [\"a\",[\"b\",[1,2,[3,4]]],\"c\"] | *-----------------------------*/\n```\n\nIn the following example, the first path`$[1]`appends`[1, 2]`as singleelements, and then the second path`$[1][1]`is not a valid path to an array,so the second operation is ignored.\n\n```\nSELECT JSON_ARRAY_APPEND(  JSON '[\"a\", [\"b\"], \"c\"]',  '$[1]', [1, 2],  '$[1][1]', [3, 4]) AS json_data/*---------------------* | json_data           | +---------------------+ | [\"a\",[\"b\",1,2],\"c\"] | *---------------------*/\n```\n\nIn the following example, path`$.a`is matched and appends`2`.\n\n```\nSELECT JSON_ARRAY_APPEND(JSON '{\"a\": [1]}', '$.a', 2) AS json_data/*-------------* | json_data   | +-------------+ | {\"a\":[1,2]} | *-------------*/\n```\n\nIn the following example, a value is appended into a JSON null.\n\n```\nSELECT JSON_ARRAY_APPEND(JSON '{\"a\": null}', '$.a', 10)/*------------* | json_data  | +------------+ | {\"a\":[10]} | *------------*/\n```\n\nIn the following example, path`$.a`is not an array, so the operation isignored.\n\n```\nSELECT JSON_ARRAY_APPEND(JSON '{\"a\": 1}', '$.a', 2) AS json_data/*-----------* | json_data | +-----------+ | {\"a\":1}   | *-----------*/\n```\n\nIn the following example, path`$.b`does not exist, so the operation isignored.\n\n```\nSELECT JSON_ARRAY_APPEND(JSON '{\"a\": 1}', '$.b', 2) AS json_data/*-----------* | json_data | +-----------+ | {\"a\":1}   | *-----------*/\n```\n\n"
  },
  {
    "name": "JSON_ARRAY_INSERT",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_ARRAY_INSERT(  json_expr,  json_path_value_pair[, ...]  [, insert_each_element=&gt;{ TRUE | FALSE }])json_path_value_pair:  json_path, value\n```\n\nProduces a new JSON value that is created by inserting JSON data intoa JSON array.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '[\"a\", \"b\", \"c\"]'\n    ```\n    \n    \n- `    json_path_value_pair`: A value and the[JSONPath](#JSONPath_format)forthat value. This includes:\n    \n    \n    - `        json_path`: Insert`        value`at this[JSONPath](#JSONPath_format)in`        json_expr`.\n        \n        \n    - `        value`: A[JSON encoding-supported](#json_encodings)value toinsert.\n        \n        \n- `    insert_each_element`: An optional, mandatory named argument.\n    \n    \n    - If`        TRUE`(default), and`        value`is a SQL array,inserts each element individually.\n        \n        \n    - If`        FALSE,`and`        value`is a SQL array, insertsthe array as one element.\n        \n        \n\nDetails:\n\n- Path value pairs are evaluated left to right. The JSON produced byevaluating one pair becomes the JSON against which the next pairis evaluated.\n- The operation is ignored if the path points to a JSON non-array value thatis not a JSON null.\n- If`    json_path`points to a JSON null, the JSON null is replaced by aJSON array of the appropriate size and padded on the left with JSON nulls.\n- If the path exists but has an incompatible type at any given path token,the path value pair operator is ignored.\n- The function applies all path value pair append operations even if anindividual path value pair operation is invalid. For invalid operations,the operation is ignored and the function continues to process the rest ofthe path value pairs.\n- If the array index in`    json_path`is larger than the size of the array, thefunction extends the length of the array to the index, fills inthe array with JSON nulls, then adds`    value`at the index.\n- If any`    json_path`is an invalid[JSONPath](#JSONPath_format), an error isproduced.\n- If`    json_expr`is SQL`    NULL`, the function returns SQL`    NULL`.\n- If`    insert_each_element`is SQL`    NULL`, the function returns`    json_expr`.\n- If`    json_path`is SQL`    NULL`, the`    json_path_value_pair`operation isignored.\n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nIn the following example, path`$[1]`is matched and inserts`1`.\n\n```\nSELECT JSON_ARRAY_INSERT(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1]', 1) AS json_data/*-----------------------* | json_data             | +-----------------------+ | [\"a\",1,[\"b\",\"c\"],\"d\"] | *-----------------------*/\n```\n\nIn the following example, path`$[1][0]`is matched and inserts`1`.\n\n```\nSELECT JSON_ARRAY_INSERT(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1][0]', 1) AS json_data/*-----------------------* | json_data             | +-----------------------+ | [\"a\",[1,\"b\",\"c\"],\"d\"] | *-----------------------*/\n```\n\nIn the following example,`insert_each_element`defaults to`TRUE`, so`[1, 2]`is inserted as individual elements.\n\n```\nSELECT JSON_ARRAY_INSERT(JSON '[\"a\", \"b\", \"c\"]', '$[1]', [1, 2]) AS json_data/*-------------------* | json_data         | +-------------------+ | [\"a\",1,2,\"b\",\"c\"] | *-------------------*/\n```\n\nIn the following example,`insert_each_element`is`FALSE`, so`[1, 2]`isinserted as one element.\n\n```\nSELECT JSON_ARRAY_INSERT(  JSON '[\"a\", \"b\", \"c\"]',  '$[1]', [1, 2],  insert_each_element=&gt;FALSE) AS json_data/*---------------------* | json_data           | +---------------------+ | [\"a\",[1,2],\"b\",\"c\"] | *---------------------*/\n```\n\nIn the following example, path`$[7]`is larger than the length of thematched array, so the array is extended with JSON nulls and`\"e\"`is inserted atthe end of the array.\n\n```\nSELECT JSON_ARRAY_INSERT(JSON '[\"a\", \"b\", \"c\", \"d\"]', '$[7]', \"e\") AS json_data/*--------------------------------------* | json_data                            | +--------------------------------------+ | [\"a\",\"b\",\"c\",\"d\",null,null,null,\"e\"] | *--------------------------------------*/\n```\n\nIn the following example, path`$.a`is an object, so the operation is ignored.\n\n```\nSELECT JSON_ARRAY_INSERT(JSON '{\"a\": {}}', '$.a[0]', 2) AS json_data/*-----------* | json_data | +-----------+ | {\"a\":{}}  | *-----------*/\n```\n\nIn the following example, path`$`does not specify a valid array position,so the operation is ignored.\n\n```\nSELECT JSON_ARRAY_INSERT(JSON '[1, 2]', '$', 3) AS json_data/*-----------* | json_data | +-----------+ | [1,2]     | *-----------*/\n```\n\nIn the following example, a value is inserted into a JSON null.\n\n```\nSELECT JSON_ARRAY_INSERT(JSON '{\"a\": null}', '$.a[2]', 10) AS json_data/*----------------------* | json_data            | +----------------------+ | {\"a\":[null,null,10]} | *----------------------*/\n```\n\nIn the following example, the operation is ignored because you can't insertdata into a JSON number.\n\n```\nSELECT JSON_ARRAY_INSERT(JSON '1', '$[0]', 'r1') AS json_data/*-----------* | json_data | +-----------+ | 1         | *-----------*/\n```\n\n"
  },
  {
    "name": "JSON_EXTRACT",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_EXTRACT(json_string_expr, json_path)\n```\n\n```\nJSON_EXTRACT(json_expr, json_path)\n```\n\n **Description** \n\nExtracts a JSON value and converts it to aSQL JSON-formatted`STRING`or`JSON`value.This function uses single quotes and brackets to escape invalid[JSONPath](#JSONPath_format)characters in JSON keys. For example:`['a.b']`.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}'\n    ```\n    \n    Extracts a SQL`    NULL`when a JSON-formatted string`    null`is encountered.For example:\n    \n    \n    ```\n    SELECT JSON_EXTRACT(\"null\", \"$\") -- Returns a SQL NULL\n    ```\n    \n    \n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}'\n    ```\n    \n    Extracts a JSON`    null`when a JSON`    null`is encountered.\n    \n    \n    ```\n    SELECT JSON_EXTRACT(JSON 'null', \"$\") -- Returns a JSON 'null'\n    ```\n    \n    \n- `    json_path`: The[JSONPath](#JSONPath_format). This identifies the data thatyou want to obtain from the input.\n    \n    \n\nThere are differences between the JSON-formatted string and JSON input types.For details, see[Differences between the JSON and JSON-formatted STRING types](#differences_json_and_string).\n\n **Return type** \n\n- `    json_string_expr`: A JSON-formatted`    STRING`\n- `    json_expr`:`    JSON`\n\n **Examples** \n\nIn the following example, JSON data is extracted and returned as JSON.\n\n```\nSELECT  JSON_EXTRACT(JSON '{\"class\": {\"students\": [{\"id\": 5}, {\"id\": 12}]}}', '$.class')  AS json_data;/*-----------------------------------* | json_data                         | +-----------------------------------+ | {\"students\":[{\"id\":5},{\"id\":12}]} | *-----------------------------------*/\n```\n\nIn the following examples, JSON data is extracted and returned asJSON-formatted strings.\n\n```\nSELECT JSON_EXTRACT(json_text, '$') AS json_text_stringFROM UNNEST([  '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}',  '{\"class\": {\"students\": []}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": \"Jamie\"}]}}'  ]) AS json_text;/*-----------------------------------------------------------* | json_text_string                                          | +-----------------------------------------------------------+ | {\"class\":{\"students\":[{\"name\":\"Jane\"}]}}                  | | {\"class\":{\"students\":[]}}                                 | | {\"class\":{\"students\":[{\"name\":\"John\"},{\"name\":\"Jamie\"}]}} | *-----------------------------------------------------------*/\n```\n\n```\nSELECT JSON_EXTRACT(json_text, '$.class.students[0]') AS first_studentFROM UNNEST([  '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}',  '{\"class\": {\"students\": []}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": \"Jamie\"}]}}'  ]) AS json_text;/*-----------------* | first_student   | +-----------------+ | {\"name\":\"Jane\"} | | NULL            | | {\"name\":\"John\"} | *-----------------*/\n```\n\n```\nSELECT JSON_EXTRACT(json_text, '$.class.students[1].name') AS second_student_nameFROM UNNEST([  '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}',  '{\"class\": {\"students\": []}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": null}]}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": \"Jamie\"}]}}'  ]) AS json_text;/*----------------* | second_student | +----------------+ | NULL           | | NULL           | | NULL           | | \"Jamie\"        | *----------------*/\n```\n\n```\nSELECT JSON_EXTRACT(json_text, \"$.class['students']\") AS student_namesFROM UNNEST([  '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}',  '{\"class\": {\"students\": []}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": \"Jamie\"}]}}'  ]) AS json_text;/*------------------------------------* | student_names                      | +------------------------------------+ | [{\"name\":\"Jane\"}]                  | | []                                 | | [{\"name\":\"John\"},{\"name\":\"Jamie\"}] | *------------------------------------*/\n```\n\n```\nSELECT JSON_EXTRACT('{\"a\": null}', \"$.a\"); -- Returns a SQL NULLSELECT JSON_EXTRACT('{\"a\": null}', \"$.b\"); -- Returns a SQL NULL\n```\n\n```\nSELECT JSON_EXTRACT(JSON '{\"a\": null}', \"$.a\"); -- Returns a JSON 'null'SELECT JSON_EXTRACT(JSON '{\"a\": null}', \"$.b\"); -- Returns a SQL NULL\n```\n\n"
  },
  {
    "name": "JSON_EXTRACT_ARRAY",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_EXTRACT_ARRAY(json_string_expr[, json_path])\n```\n\n```\nJSON_EXTRACT_ARRAY(json_expr[, json_path])\n```\n\n **Description** \n\nExtracts a JSON array and converts it toa SQL`ARRAY&lt;JSON-formatted STRING&gt;`or`ARRAY&lt;JSON&gt;`value.This function uses single quotes and brackets to escape invalid[JSONPath](#JSONPath_format)characters in JSON keys. For example:`['a.b']`.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '[\"a\", \"b\", {\"key\": \"c\"}]'\n    ```\n    \n    \n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '[\"a\", \"b\", {\"key\": \"c\"}]'\n    ```\n    \n    \n- `    json_path`: The[JSONPath](#JSONPath_format). This identifies the data thatyou want to obtain from the input. If this optional parameter is notprovided, then the JSONPath`    $`symbol is applied, which means that all ofthe data is analyzed.\n    \n    \n\nThere are differences between the JSON-formatted string and JSON input types.For details, see[Differences between the JSON and JSON-formatted STRING types](#differences_json_and_string).\n\n **Return type** \n\n- `    json_string_expr`:`    ARRAY&lt;JSON-formatted STRING&gt;`\n- `    json_expr`:`    ARRAY&lt;JSON&gt;`\n\n **Examples** \n\nThis extracts items in JSON to an array of`JSON`values:\n\n```\nSELECT JSON_EXTRACT_ARRAY(  JSON '{\"fruits\":[\"apples\",\"oranges\",\"grapes\"]}','$.fruits'  ) AS json_array;/*---------------------------------* | json_array                      | +---------------------------------+ | [\"apples\", \"oranges\", \"grapes\"] | *---------------------------------*/\n```\n\nThis extracts the items in a JSON-formatted string to a string array:\n\n```\nSELECT JSON_EXTRACT_ARRAY('[1,2,3]') AS string_array;/*--------------* | string_array | +--------------+ | [1, 2, 3]    | *--------------*/\n```\n\nThis extracts a string array and converts it to an integer array:\n\n```\nSELECT ARRAY(  SELECT CAST(integer_element AS INT64)  FROM UNNEST(    JSON_EXTRACT_ARRAY('[1,2,3]','$')  ) AS integer_element) AS integer_array;/*---------------* | integer_array | +---------------+ | [1, 2, 3]     | *---------------*/\n```\n\nThis extracts string values in a JSON-formatted string to an array:\n\n```\n-- Doesn't strip the double quotesSELECT JSON_EXTRACT_ARRAY('[\"apples\", \"oranges\", \"grapes\"]', '$') AS string_array;/*---------------------------------* | string_array                    | +---------------------------------+ | [\"apples\", \"oranges\", \"grapes\"] | *---------------------------------*/-- Strips the double quotesSELECT ARRAY(  SELECT JSON_EXTRACT_SCALAR(string_element, '$')  FROM UNNEST(JSON_EXTRACT_ARRAY('[\"apples\",\"oranges\",\"grapes\"]','$')) AS string_element) AS string_array;/*---------------------------* | string_array              | +---------------------------+ | [apples, oranges, grapes] | *---------------------------*/\n```\n\nThis extracts only the items in the`fruit`property to an array:\n\n```\nSELECT JSON_EXTRACT_ARRAY(  '{\"fruit\": [{\"apples\": 5, \"oranges\": 10}, {\"apples\": 2, \"oranges\": 4}], \"vegetables\": [{\"lettuce\": 7, \"kale\": 8}]}',  '$.fruit') AS string_array;/*-------------------------------------------------------* | string_array                                          | +-------------------------------------------------------+ | [{\"apples\":5,\"oranges\":10}, {\"apples\":2,\"oranges\":4}] | *-------------------------------------------------------*/\n```\n\nThese are equivalent:\n\n```\nSELECT JSON_EXTRACT_ARRAY('{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$[fruits]') AS string_array;SELECT JSON_EXTRACT_ARRAY('{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.fruits') AS string_array;-- The queries above produce the following result:/*---------------------------------* | string_array                    | +---------------------------------+ | [\"apples\", \"oranges\", \"grapes\"] | *---------------------------------*/\n```\n\nIn cases where a JSON key uses invalid JSONPath characters, you can escape thosecharacters using single quotes and brackets,`[' ']`. For example:\n\n```\nSELECT JSON_EXTRACT_ARRAY('{\"a.b\": {\"c\": [\"world\"]}}', \"$['a.b'].c\") AS hello;/*-----------* | hello     | +-----------+ | [\"world\"] | *-----------*/\n```\n\nThe following examples explore how invalid requests and empty arrays arehandled:\n\n- If a JSONPath is invalid, an error is thrown.\n- If a JSON-formatted string is invalid, the output is NULL.\n- It is okay to have empty arrays in the JSON-formatted string.\n\n```\n-- An error is thrown if you provide an invalid JSONPath.SELECT JSON_EXTRACT_ARRAY('[\"foo\", \"bar\", \"baz\"]', 'INVALID_JSONPath') AS result;-- If the JSONPath does not refer to an array, then NULL is returned.SELECT JSON_EXTRACT_ARRAY('{\"a\": \"foo\"}', '$.a') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a key that does not exist is specified, then the result is NULL.SELECT JSON_EXTRACT_ARRAY('{\"a\": \"foo\"}', '$.b') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- Empty arrays in JSON-formatted strings are supported.SELECT JSON_EXTRACT_ARRAY('{\"a\": \"foo\", \"b\": []}', '$.b') AS result;/*--------* | result | +--------+ | []     | *--------*/\n```\n\n"
  },
  {
    "name": "JSON_EXTRACT_SCALAR",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_EXTRACT_SCALAR(json_string_expr[, json_path])\n```\n\n```\nJSON_EXTRACT_SCALAR(json_expr[, json_path])\n```\n\n **Description** \n\nExtracts a JSON scalar value and converts it to a SQL`STRING`value.In addition, this function:\n\n- Removes the outermost quotes and unescapes the return values.\n- Returns a SQL`    NULL`if a non-scalar value is selected.\n- Uses single quotes and brackets to escape invalid[JSONPath](#JSONPath_format)characters in JSON keys. For example:`    ['a.b']`.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '{\"name\": \"Jane\", \"age\": \"6\"}'\n    ```\n    \n    \n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '{\"name\": \"Jane\", \"age\": \"6\"}'\n    ```\n    \n    \n- `    json_path`: The[JSONPath](#JSONPath_format). This identifies the data thatyou want to obtain from the input. If this optional parameter is notprovided, then the JSONPath`    $`symbol is applied, which means that all ofthe data is analyzed.\n    \n    If`    json_path`returns a JSON`    null`or a non-scalar value (in other words,if`    json_path`refers to an object or an array), then a SQL`    NULL`isreturned.\n    \n    \n\nThere are differences between the JSON-formatted string and JSON input types.For details, see[Differences between the JSON and JSON-formatted STRING types](#differences_json_and_string).\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\nIn the following example,`age`is extracted.\n\n```\nSELECT JSON_EXTRACT_SCALAR(JSON '{\"name\": \"Jakob\", \"age\": \"6\" }', '$.age') AS scalar_age;/*------------* | scalar_age | +------------+ | 6          | *------------*/\n```\n\nThe following example compares how results are returned for the`JSON_EXTRACT`and`JSON_EXTRACT_SCALAR`functions.\n\n```\nSELECT JSON_EXTRACT('{\"name\": \"Jakob\", \"age\": \"6\" }', '$.name') AS json_name,  JSON_EXTRACT_SCALAR('{\"name\": \"Jakob\", \"age\": \"6\" }', '$.name') AS scalar_name,  JSON_EXTRACT('{\"name\": \"Jakob\", \"age\": \"6\" }', '$.age') AS json_age,  JSON_EXTRACT_SCALAR('{\"name\": \"Jakob\", \"age\": \"6\" }', '$.age') AS scalar_age;/*-----------+-------------+----------+------------* | json_name | scalar_name | json_age | scalar_age | +-----------+-------------+----------+------------+ | \"Jakob\"   | Jakob       | \"6\"      | 6          | *-----------+-------------+----------+------------*/\n```\n\n```\nSELECT JSON_EXTRACT('{\"fruits\": [\"apple\", \"banana\"]}', '$.fruits') AS json_extract,  JSON_EXTRACT_SCALAR('{\"fruits\": [\"apple\", \"banana\"]}', '$.fruits') AS json_extract_scalar;/*--------------------+---------------------* | json_extract       | json_extract_scalar | +--------------------+---------------------+ | [\"apple\",\"banana\"] | NULL                | *--------------------+---------------------*/\n```\n\nIn cases where a JSON key uses invalid JSONPath characters, you can escape thosecharacters using single quotes and brackets,`[' ']`. For example:\n\n```\nSELECT JSON_EXTRACT_SCALAR('{\"a.b\": {\"c\": \"world\"}}', \"$['a.b'].c\") AS hello;/*-------* | hello | +-------+ | world | *-------*/\n```\n\n"
  },
  {
    "name": "JSON_EXTRACT_STRING_ARRAY",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_EXTRACT_STRING_ARRAY(json_string_expr[, json_path])\n```\n\n```\nJSON_EXTRACT_STRING_ARRAY(json_expr[, json_path])\n```\n\n **Description** \n\nExtracts a JSON array of scalar values and converts it to a SQL`ARRAY&lt;STRING&gt;`value. In addition, this function:\n\n- Removes the outermost quotes and unescapes the values.\n- Returns a SQL`    NULL`if the selected value is not an array ornot an array containing only scalar values.\n- Uses single quotes and brackets to escape invalid[JSONPath](#JSONPath_format)characters in JSON keys. For example:`    ['a.b']`.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '[\"apples\", \"oranges\", \"grapes\"]'\n    ```\n    \n    \n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '[\"apples\", \"oranges\", \"grapes\"]'\n    ```\n    \n    \n- `    json_path`: The[JSONPath](#JSONPath_format). This identifies the data thatyou want to obtain from the input. If this optional parameter is notprovided, then the JSONPath`    $`symbol is applied, which means that all ofthe data is analyzed.\n    \n    \n\nThere are differences between the JSON-formatted string and JSON input types.For details, see[Differences between the JSON and JSON-formatted STRING types](#differences_json_and_string).\n\nCaveats:\n\n- A JSON`    null`in the input array produces a SQL`    NULL`as the output for thatJSON`    null`. If the output contains a`    NULL`array element, an error isproduced because the final output cannot be an array with`    NULL`values.\n- If a JSONPath matches an array that contains scalar objects and a JSON`    null`,then the output of the function must be transformed because the final outputcannot be an array with`    NULL`values.\n\n **Return type** \n\n`ARRAY&lt;STRING&gt;`\n\n **Examples** \n\nThis extracts items in JSON to a string array:\n\n```\nSELECT JSON_EXTRACT_STRING_ARRAY(  JSON '{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.fruits'  ) AS string_array;/*---------------------------* | string_array              | +---------------------------+ | [apples, oranges, grapes] | *---------------------------*/\n```\n\nThe following example compares how results are returned for the`JSON_EXTRACT_ARRAY`and`JSON_EXTRACT_STRING_ARRAY`functions.\n\n```\nSELECT JSON_EXTRACT_ARRAY('[\"apples\", \"oranges\"]') AS json_array,JSON_EXTRACT_STRING_ARRAY('[\"apples\", \"oranges\"]') AS string_array;/*-----------------------+-------------------* | json_array            | string_array      | +-----------------------+-------------------+ | [\"apples\", \"oranges\"] | [apples, oranges] | *-----------------------+-------------------*/\n```\n\nThis extracts the items in a JSON-formatted string to a string array:\n\n```\n-- Strips the double quotesSELECT JSON_EXTRACT_STRING_ARRAY('[\"foo\", \"bar\", \"baz\"]', '$') AS string_array;/*-----------------* | string_array    | +-----------------+ | [foo, bar, baz] | *-----------------*/\n```\n\nThis extracts a string array and converts it to an integer array:\n\n```\nSELECT ARRAY(  SELECT CAST(integer_element AS INT64)  FROM UNNEST(    JSON_EXTRACT_STRING_ARRAY('[1, 2, 3]', '$')  ) AS integer_element) AS integer_array;/*---------------* | integer_array | +---------------+ | [1, 2, 3]     | *---------------*/\n```\n\nThese are equivalent:\n\n```\nSELECT JSON_EXTRACT_STRING_ARRAY('{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$[fruits]') AS string_array;SELECT JSON_EXTRACT_STRING_ARRAY('{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.fruits') AS string_array;-- The queries above produce the following result:/*---------------------------* | string_array              | +---------------------------+ | [apples, oranges, grapes] | *---------------------------*/\n```\n\nIn cases where a JSON key uses invalid JSONPath characters, you can escape thosecharacters using single quotes and brackets:`[' ']`. For example:\n\n```\nSELECT JSON_EXTRACT_STRING_ARRAY('{\"a.b\": {\"c\": [\"world\"]}}', \"$['a.b'].c\") AS hello;/*---------* | hello   | +---------+ | [world] | *---------*/\n```\n\nThe following examples explore how invalid requests and empty arrays arehandled:\n\n```\n-- An error is thrown if you provide an invalid JSONPath.SELECT JSON_EXTRACT_STRING_ARRAY('[\"foo\", \"bar\", \"baz\"]', 'INVALID_JSONPath') AS result;-- If the JSON formatted string is invalid, then NULL is returned.SELECT JSON_EXTRACT_STRING_ARRAY('}}', '$') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If the JSON document is NULL, then NULL is returned.SELECT JSON_EXTRACT_STRING_ARRAY(NULL, '$') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath does not match anything, then the output is NULL.SELECT JSON_EXTRACT_STRING_ARRAY('{\"a\": [\"foo\", \"bar\", \"baz\"]}', '$.b') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath matches an object that is not an array, then the output is NULL.SELECT JSON_EXTRACT_STRING_ARRAY('{\"a\": \"foo\"}', '$') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath matches an array of non-scalar objects, then the output is NULL.SELECT JSON_EXTRACT_STRING_ARRAY('{\"a\": [{\"b\": \"foo\", \"c\": 1}, {\"b\": \"bar\", \"c\":2}], \"d\": \"baz\"}', '$.a') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath matches an array of mixed scalar and non-scalar objects, then the output is NULL.SELECT JSON_EXTRACT_STRING_ARRAY('{\"a\": [10, {\"b\": 20}]', '$.a') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath matches an empty JSON array, then the output is an empty array instead of NULL.SELECT JSON_EXTRACT_STRING_ARRAY('{\"a\": \"foo\", \"b\": []}', '$.b') AS result;/*--------* | result | +--------+ | []     | *--------*/-- The following query produces and error because the final output cannot be an-- array with NULLs.SELECT JSON_EXTRACT_STRING_ARRAY('[\"world\", 1, null]') AS result;\n```\n\n"
  },
  {
    "name": "JSON_OBJECT",
    "arguments": [],
    "category": "JSON functions",
    "description": "- [Signature 1](#json_object_signature1):`    JSON_OBJECT([json_key, json_value][, ...])`\n- [Signature 2](#json_object_signature2):`    JSON_OBJECT(json_key_array, json_value_array)`\n\n\n<span id=\"json_object_signature1\">\n#### Signature 1\n\n</span>\n```\nJSON_OBJECT([json_key, json_value][, ...])\n```\n\n **Description** \n\nCreates a JSON object, using key-value pairs.\n\nArguments:\n\n- `    json_key`: A`    STRING`value that represents a key.\n- `    json_value`: A[JSON encoding-supported](#json_encodings)value.\n\nDetails:\n\n- If two keys are passed in with the same name, only the first key-value pairis preserved.\n- The order of key-value pairs is not preserved.\n- If`    json_key`is`    NULL`, an error is produced.\n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nYou can create an empty JSON object by passing in no JSON keys and values.For example:\n\n```\nSELECT JSON_OBJECT() AS json_data/*-----------* | json_data | +-----------+ | {}        | *-----------*/\n```\n\nYou can create a JSON object by passing in key-value pairs. For example:\n\n```\nSELECT JSON_OBJECT('foo', 10, 'bar', TRUE) AS json_data/*-----------------------* | json_data             | +-----------------------+ | {\"bar\":true,\"foo\":10} | *-----------------------*/\n```\n\n```\nSELECT JSON_OBJECT('foo', 10, 'bar', ['a', 'b']) AS json_data/*----------------------------* | json_data                  | +----------------------------+ | {\"bar\":[\"a\",\"b\"],\"foo\":10} | *----------------------------*/\n```\n\n```\nSELECT JSON_OBJECT('a', NULL, 'b', JSON 'null') AS json_data/*---------------------* | json_data           | +---------------------+ | {\"a\":null,\"b\":null} | *---------------------*/\n```\n\n```\nSELECT JSON_OBJECT('a', 10, 'a', 'foo') AS json_data/*-----------* | json_data | +-----------+ | {\"a\":10}  | *-----------*/\n```\n\n```\nWITH Items AS (SELECT 'hello' AS key, 'world' AS value)SELECT JSON_OBJECT(key, value) AS json_data FROM Items/*-------------------* | json_data         | +-------------------+ | {\"hello\":\"world\"} | *-------------------*/\n```\n\nAn error is produced if a SQL`NULL`is passed in for a JSON key.\n\n```\n-- Error: A key cannot be NULL.SELECT JSON_OBJECT(NULL, 1) AS json_data\n```\n\nAn error is produced if the number of JSON keys and JSON values don't match:\n\n```\n-- Error: No matching signature for function JSON_OBJECT for argument types:-- STRING, INT64, STRINGSELECT JSON_OBJECT('a', 1, 'b') AS json_data\n```\n\n\n<span id=\"json_object_signature2\">\n#### Signature 2\n\n</span>\n```\nJSON_OBJECT(json_key_array, json_value_array)\n```\n\nCreates a JSON object, using an array of keys and values.\n\nArguments:\n\n- `    json_key_array`: An array of zero or more`    STRING`keys.\n- `    json_value_array`: An array of zero or more[JSON encoding-supported](#json_encodings)values.\n\nDetails:\n\n- If two keys are passed in with the same name, only the first key-value pairis preserved.\n- The order of key-value pairs is not preserved.\n- The number of keys must match the number of values, otherwise an error isproduced.\n- If any argument is`    NULL`, an error is produced.\n- If a key in`    json_key_array`is`    NULL`, an error is produced.\n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nYou can create an empty JSON object by passing in an empty array ofkeys and values. For example:\n\n```\nSELECT JSON_OBJECT(CAST([] AS ARRAY&lt;STRING&gt;), []) AS json_data/*-----------* | json_data | +-----------+ | {}        | *-----------*/\n```\n\nYou can create a JSON object by passing in an array of keys and an array ofvalues. For example:\n\n```\nSELECT JSON_OBJECT(['a', 'b'], [10, NULL]) AS json_data/*-------------------* | json_data         | +-------------------+ | {\"a\":10,\"b\":null} | *-------------------*/\n```\n\n```\nSELECT JSON_OBJECT(['a', 'b'], [JSON '10', JSON '\"foo\"']) AS json_data/*--------------------* | json_data          | +--------------------+ | {\"a\":10,\"b\":\"foo\"} | *--------------------*/\n```\n\n```\nSELECT  JSON_OBJECT(    ['a', 'b'],    [STRUCT(10 AS id, 'Red' AS color), STRUCT(20 AS id, 'Blue' AS color)])    AS json_data/*------------------------------------------------------------* | json_data                                                  | +------------------------------------------------------------+ | {\"a\":{\"color\":\"Red\",\"id\":10},\"b\":{\"color\":\"Blue\",\"id\":20}} | *------------------------------------------------------------*/\n```\n\n```\nSELECT  JSON_OBJECT(    ['a', 'b'],    [TO_JSON(10), TO_JSON(['foo', 'bar'])])    AS json_data/*----------------------------* | json_data                  | +----------------------------+ | {\"a\":10,\"b\":[\"foo\",\"bar\"]} | *----------------------------*/\n```\n\nThe following query groups by`id`and then creates an array of keys andvalues from the rows with the same`id`:\n\n```\nWITH  Fruits AS (    SELECT 0 AS id, 'color' AS json_key, 'red' AS json_value UNION ALL    SELECT 0, 'fruit', 'apple' UNION ALL    SELECT 1, 'fruit', 'banana' UNION ALL    SELECT 1, 'ripe', 'true'  )SELECT JSON_OBJECT(ARRAY_AGG(json_key), ARRAY_AGG(json_value)) AS json_dataFROM FruitsGROUP BY id/*----------------------------------* | json_data                        | +----------------------------------+ | {\"color\":\"red\",\"fruit\":\"apple\"}  | | {\"fruit\":\"banana\",\"ripe\":\"true\"} | *----------------------------------*/\n```\n\nAn error is produced if the size of the JSON keys and values arrays don'tmatch:\n\n```\n-- Error: The number of keys and values must match.SELECT JSON_OBJECT(['a', 'b'], [10]) AS json_data\n```\n\nAn error is produced if the array of JSON keys or JSON values is a SQL`NULL`.\n\n```\n-- Error: The keys array cannot be NULL.SELECT JSON_OBJECT(CAST(NULL AS ARRAY&lt;STRING&gt;), [10, 20]) AS json_data\n```\n\n```\n-- Error: The values array cannot be NULL.SELECT JSON_OBJECT(['a', 'b'], CAST(NULL AS ARRAY&lt;INT64&gt;)) AS json_data\n```\n\n"
  },
  {
    "name": "JSON_QUERY",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_QUERY(json_string_expr, json_path)\n```\n\n```\nJSON_QUERY(json_expr, json_path)\n```\n\n **Description** \n\nExtracts a JSON value and converts it to a SQLJSON-formatted`STRING`or`JSON`value.This function uses double quotes to escape invalid[JSONPath](#JSONPath_format)characters in JSON keys. For example:`\"a.b\"`.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}'\n    ```\n    \n    Extracts a SQL`    NULL`when a JSON-formatted string`    null`is encountered.For example:\n    \n    \n    ```\n    SELECT JSON_QUERY(\"null\", \"$\") -- Returns a SQL NULL\n    ```\n    \n    \n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}'\n    ```\n    \n    Extracts a JSON`    null`when a JSON`    null`is encountered.\n    \n    \n    ```\n    SELECT JSON_QUERY(JSON 'null', \"$\") -- Returns a JSON 'null'\n    ```\n    \n    \n- `    json_path`: The[JSONPath](#JSONPath_format). This identifies the data thatyou want to obtain from the input.\n    \n    \n\nThere are differences between the JSON-formatted string and JSON input types.For details, see[Differences between the JSON and JSON-formatted STRING types](#differences_json_and_string).\n\n **Return type** \n\n- `    json_string_expr`: A JSON-formatted`    STRING`\n- `    json_expr`:`    JSON`\n\n **Examples** \n\nIn the following example, JSON data is extracted and returned as JSON.\n\n```\nSELECT  JSON_QUERY(JSON '{\"class\": {\"students\": [{\"id\": 5}, {\"id\": 12}]}}', '$.class')  AS json_data;/*-----------------------------------* | json_data                         | +-----------------------------------+ | {\"students\":[{\"id\":5},{\"id\":12}]} | *-----------------------------------*/\n```\n\nIn the following examples, JSON data is extracted and returned asJSON-formatted strings.\n\n```\nSELECT JSON_QUERY(json_text, '$') AS json_text_stringFROM UNNEST([  '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}',  '{\"class\": {\"students\": []}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": \"Jamie\"}]}}'  ]) AS json_text;/*-----------------------------------------------------------* | json_text_string                                          | +-----------------------------------------------------------+ | {\"class\":{\"students\":[{\"name\":\"Jane\"}]}}                  | | {\"class\":{\"students\":[]}}                                 | | {\"class\":{\"students\":[{\"name\":\"John\"},{\"name\":\"Jamie\"}]}} | *-----------------------------------------------------------*/\n```\n\n```\nSELECT JSON_QUERY(json_text, '$.class.students[0]') AS first_studentFROM UNNEST([  '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}',  '{\"class\": {\"students\": []}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": \"Jamie\"}]}}'  ]) AS json_text;/*-----------------* | first_student   | +-----------------+ | {\"name\":\"Jane\"} | | NULL            | | {\"name\":\"John\"} | *-----------------*/\n```\n\n```\nSELECT JSON_QUERY(json_text, '$.class.students[1].name') AS second_student_nameFROM UNNEST([  '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}',  '{\"class\": {\"students\": []}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": null}]}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": \"Jamie\"}]}}'  ]) AS json_text;/*----------------* | second_student | +----------------+ | NULL           | | NULL           | | NULL           | | \"Jamie\"        | *----------------*/\n```\n\n```\nSELECT JSON_QUERY(json_text, '$.class.\"students\"') AS student_namesFROM UNNEST([  '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}',  '{\"class\": {\"students\": []}}',  '{\"class\": {\"students\": [{\"name\": \"John\"}, {\"name\": \"Jamie\"}]}}'  ]) AS json_text;/*------------------------------------* | student_names                      | +------------------------------------+ | [{\"name\":\"Jane\"}]                  | | []                                 | | [{\"name\":\"John\"},{\"name\":\"Jamie\"}] | *------------------------------------*/\n```\n\n```\nSELECT JSON_QUERY('{\"a\": null}', \"$.a\"); -- Returns a SQL NULLSELECT JSON_QUERY('{\"a\": null}', \"$.b\"); -- Returns a SQL NULL\n```\n\n```\nSELECT JSON_QUERY(JSON '{\"a\": null}', \"$.a\"); -- Returns a JSON 'null'SELECT JSON_QUERY(JSON '{\"a\": null}', \"$.b\"); -- Returns a SQL NULL\n```\n\n"
  },
  {
    "name": "JSON_QUERY_ARRAY",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_QUERY_ARRAY(json_string_expr[, json_path])\n```\n\n```\nJSON_QUERY_ARRAY(json_expr[, json_path])\n```\n\n **Description** \n\nExtracts a JSON array and converts it toa SQL`ARRAY&lt;JSON-formatted STRING&gt;`or`ARRAY&lt;JSON&gt;`value.In addition, this function uses double quotes to escape invalid[JSONPath](#JSONPath_format)characters in JSON keys. For example:`\"a.b\"`.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '[\"a\", \"b\", {\"key\": \"c\"}]'\n    ```\n    \n    \n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '[\"a\", \"b\", {\"key\": \"c\"}]'\n    ```\n    \n    \n- `    json_path`: The[JSONPath](#JSONPath_format). This identifies the data thatyou want to obtain from the input. If this optional parameter is notprovided, then the JSONPath`    $`symbol is applied, which means that all ofthe data is analyzed.\n    \n    \n\nThere are differences between the JSON-formatted string and JSON input types.For details, see[Differences between the JSON and JSON-formatted STRING types](#differences_json_and_string).\n\n **Return type** \n\n- `    json_string_expr`:`    ARRAY&lt;JSON-formatted STRING&gt;`\n- `    json_expr`:`    ARRAY&lt;JSON&gt;`\n\n **Examples** \n\nThis extracts items in JSON to an array of`JSON`values:\n\n```\nSELECT JSON_QUERY_ARRAY(  JSON '{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.fruits'  ) AS json_array;/*---------------------------------* | json_array                      | +---------------------------------+ | [\"apples\", \"oranges\", \"grapes\"] | *---------------------------------*/\n```\n\nThis extracts the items in a JSON-formatted string to a string array:\n\n```\nSELECT JSON_QUERY_ARRAY('[1, 2, 3]') AS string_array;/*--------------* | string_array | +--------------+ | [1, 2, 3]    | *--------------*/\n```\n\nThis extracts a string array and converts it to an integer array:\n\n```\nSELECT ARRAY(  SELECT CAST(integer_element AS INT64)  FROM UNNEST(    JSON_QUERY_ARRAY('[1, 2, 3]','$')  ) AS integer_element) AS integer_array;/*---------------* | integer_array | +---------------+ | [1, 2, 3]     | *---------------*/\n```\n\nThis extracts string values in a JSON-formatted string to an array:\n\n```\n-- Doesn't strip the double quotesSELECT JSON_QUERY_ARRAY('[\"apples\", \"oranges\", \"grapes\"]', '$') AS string_array;/*---------------------------------* | string_array                    | +---------------------------------+ | [\"apples\", \"oranges\", \"grapes\"] | *---------------------------------*/-- Strips the double quotesSELECT ARRAY(  SELECT JSON_VALUE(string_element, '$')  FROM UNNEST(JSON_QUERY_ARRAY('[\"apples\", \"oranges\", \"grapes\"]', '$')) AS string_element) AS string_array;/*---------------------------* | string_array              | +---------------------------+ | [apples, oranges, grapes] | *---------------------------*/\n```\n\nThis extracts only the items in the`fruit`property to an array:\n\n```\nSELECT JSON_QUERY_ARRAY(  '{\"fruit\": [{\"apples\": 5, \"oranges\": 10}, {\"apples\": 2, \"oranges\": 4}], \"vegetables\": [{\"lettuce\": 7, \"kale\": 8}]}',  '$.fruit') AS string_array;/*-------------------------------------------------------* | string_array                                          | +-------------------------------------------------------+ | [{\"apples\":5,\"oranges\":10}, {\"apples\":2,\"oranges\":4}] | *-------------------------------------------------------*/\n```\n\nThese are equivalent:\n\n```\nSELECT JSON_QUERY_ARRAY('{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.fruits') AS string_array;SELECT JSON_QUERY_ARRAY('{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.\"fruits\"') AS string_array;-- The queries above produce the following result:/*---------------------------------* | string_array                    | +---------------------------------+ | [\"apples\", \"oranges\", \"grapes\"] | *---------------------------------*/\n```\n\nIn cases where a JSON key uses invalid JSONPath characters, you can escape thosecharacters using double quotes:`\" \"`. For example:\n\n```\nSELECT JSON_QUERY_ARRAY('{\"a.b\": {\"c\": [\"world\"]}}', '$.\"a.b\".c') AS hello;/*-----------* | hello     | +-----------+ | [\"world\"] | *-----------*/\n```\n\nThe following examples show how invalid requests and empty arrays are handled:\n\n```\n-- An error is returned if you provide an invalid JSONPath.SELECT JSON_QUERY_ARRAY('[\"foo\", \"bar\", \"baz\"]', 'INVALID_JSONPath') AS result;-- If the JSONPath does not refer to an array, then NULL is returned.SELECT JSON_QUERY_ARRAY('{\"a\": \"foo\"}', '$.a') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a key that does not exist is specified, then the result is NULL.SELECT JSON_QUERY_ARRAY('{\"a\": \"foo\"}', '$.b') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- Empty arrays in JSON-formatted strings are supported.SELECT JSON_QUERY_ARRAY('{\"a\": \"foo\", \"b\": []}', '$.b') AS result;/*--------* | result | +--------+ | []     | *--------*/\n```\n\n"
  },
  {
    "name": "JSON_REMOVE",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_REMOVE(json_expr, json_path[, ...])\n```\n\nProduces a new SQL`JSON`value with the specified JSON data removed.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}'\n    ```\n    \n    \n- `    json_path`: Remove data at this[JSONPath](#JSONPath_format)in`    json_expr`.\n    \n    \n\nDetails:\n\n- Paths are evaluated left to right. The JSON produced by evaluating thefirst path is the JSON for the next path.\n- The operation ignores non-existent paths and continue processing the restof the paths.\n- For each path, the entire matched JSON subtree is deleted.\n- If the path matches a JSON object key, this function deletes thekey-value pair.\n- If the path matches an array element, this function deletes the specificelement from the matched array.\n- If removing the path results in an empty JSON object or empty JSON array,the empty structure is preserved.\n- If`    json_path`is`    $`or an invalid[JSONPath](#JSONPath_format), an error isproduced.\n- If`    json_path`is SQL`    NULL`, the path operation is ignored.\n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nIn the following example, the path`$[1]`is matched and removes`[\"b\", \"c\"]`.\n\n```\nSELECT JSON_REMOVE(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1]') AS json_data/*-----------* | json_data | +-----------+ | [\"a\",\"d\"] | *-----------*/\n```\n\nYou can use the field access operator to pass JSON data into this function.For example:\n\n```\nWITH T AS (SELECT JSON '{\"a\": {\"b\": 10, \"c\": 20}}' AS data)SELECT JSON_REMOVE(data.a, '$.b') AS json_data FROM T/*-----------* | json_data | +-----------+ | {\"c\":20}  | *-----------*/\n```\n\nIn the following example, the first path`$[1]`is matched and removes`[\"b\", \"c\"]`. Then, the second path`$[1]`is matched and removes`\"d\"`.\n\n```\nSELECT JSON_REMOVE(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1]', '$[1]') AS json_data/*-----------* | json_data | +-----------+ | [\"a\"]     | *-----------*/\n```\n\nThe structure of an empty array is preserved when all elements are deletedfrom it. For example:\n\n```\nSELECT JSON_REMOVE(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1]', '$[1]', '$[0]') AS json_data/*-----------* | json_data | +-----------+ | []        | *-----------*/\n```\n\nIn the following example, the path`$.a.b.c`is matched and removes the`\"c\":\"d\"`key-value pair from the JSON object.\n\n```\nSELECT JSON_REMOVE(JSON '{\"a\": {\"b\": {\"c\": \"d\"}}}', '$.a.b.c') AS json_data/*----------------* | json_data      | +----------------+ | {\"a\":{\"b\":{}}} | *----------------*/\n```\n\nIn the following example, the path`$.a.b`is matched and removes the`\"b\": {\"c\":\"d\"}`key-value pair from the JSON object.\n\n```\nSELECT JSON_REMOVE(JSON '{\"a\": {\"b\": {\"c\": \"d\"}}}', '$.a.b') AS json_data/*-----------* | json_data | +-----------+ | {\"a\":{}}  | *-----------*/\n```\n\nIn the following example, the path`$.b`is not valid, so the operation makesno changes.\n\n```\nSELECT JSON_REMOVE(JSON '{\"a\": 1}', '$.b') AS json_data/*-----------* | json_data | +-----------+ | {\"a\":1}   | *-----------*/\n```\n\nIn the following example, path`$.a.b`and`$.b`don't exist, so thoseoperations are ignored, but the others are processed.\n\n```\nSELECT JSON_REMOVE(JSON '{\"a\": [1, 2, 3]}', '$.a[0]', '$.a.b', '$.b', '$.a[0]') AS json_data/*-----------* | json_data | +-----------+ | {\"a\":[3]} | *-----------*/\n```\n\nIf you pass in`$`as the path, an error is produced. For example:\n\n```\n-- Error: The JSONPath cannot be '$'SELECT JSON_REMOVE(JSON '{}', '$') AS json_data\n```\n\nIn the following example, the operation is ignored because you can't removedata from a JSON null.\n\n```\nSELECT JSON_REMOVE(JSON 'null', '$.a.b') AS json_data/*-----------* | json_data | +-----------+ | null      | *-----------*/\n```\n\n"
  },
  {
    "name": "JSON_SET",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_SET(  json_expr,  json_path_value_pair[, ...]  [, create_if_missing=&gt; { TRUE | FALSE }])json_path_value_pair:  json_path, value\n```\n\nProduces a new SQL`JSON`value with the specified JSON data insertedor replaced.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}'\n    ```\n    \n    \n- `    json_path_value_pair`: A value and the[JSONPath](#JSONPath_format)forthat value. This includes:\n    \n    \n    - `        json_path`: Insert or replace`        value`at this[JSONPath](#JSONPath_format)in`        json_expr`.\n        \n        \n    - `        value`: A[JSON encoding-supported](#json_encodings)value toinsert.\n        \n        \n- `    create_if_missing`: An optional, mandatory named argument.\n    \n    \n    - If TRUE (default), replaces or inserts data if the path does not exist.\n        \n        \n    - If FALSE, only *existing* JSONPath values are replaced. If the pathdoesn't exist, the set operation is ignored.\n        \n        \n\nDetails:\n\n- Path value pairs are evaluated left to right. The JSON produced byevaluating one pair becomes the JSON against which the next pairis evaluated.\n- If a matched path has an existing value, it overwrites the existing datawith`    value`.\n- If`    create_if_missing`is`    TRUE`:\n    \n    \n    - If a path doesn't exist, the remainder of the path is recursively created.\n    - If the matched path prefix points to a JSON null, the remainder of the path is recursively created, and`        value`is inserted.\n    - If a path token points to a JSON array and the specified index is *larger* than the size of the array, pads the JSON array with JSON nulls, recursively creates the remainder of the path at the specified index, and inserts the path value pair.\n- This function applies all path value pair set operations even if anindividual path value pair operation is invalid. For invalid operations,the operation is ignored and the function continues to process the restof the path value pairs.\n    \n    \n- If the path exists but has an incompatible type at any given pathtoken, no update happens for that specific path value pair.\n    \n    \n- If any`    json_path`is an invalid[JSONPath](#JSONPath_format), an error isproduced.\n    \n    \n- If`    json_expr`is SQL`    NULL`, the function returns SQL`    NULL`.\n    \n    \n- If`    json_path`is SQL`    NULL`, the`    json_path_value_pair`operation isignored.\n    \n    \n- If`    create_if_missing`is SQL`    NULL`, the set operation is ignored.\n    \n    \n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nIn the following example, the path`$`matches the entire`JSON`valueand replaces it with`{\"b\": 2, \"c\": 3}`.\n\n```\nSELECT JSON_SET(JSON '{\"a\": 1}', '$', JSON '{\"b\": 2, \"c\": 3}') AS json_data/*---------------* | json_data     | +---------------+ | {\"b\":2,\"c\":3} | *---------------*/\n```\n\nIn the following example,`create_if_missing`is`FALSE`and the path`$.b`doesn't exist, so the set operation is ignored.\n\n```\nSELECT JSON_SET(  JSON '{\"a\": 1}',  \"$.b\", 999,  create_if_missing =&gt; false) AS json_data/*------------* | json_data  | +------------+ | '{\"a\": 1}' | *------------*/\n```\n\nIn the following example,`create_if_missing`is`TRUE`and the path`$.a`exists, so the value is replaced.\n\n```\nSELECT JSON_SET(  JSON '{\"a\": 1}',  \"$.a\", 999,  create_if_missing =&gt; false) AS json_data/*--------------* | json_data    | +--------------+ | '{\"a\": 999}' | *--------------*/\n```\n\nIn the following example, the path`$.a`is matched, but`$.a.b`does notexist, so the new path and the value are inserted.\n\n```\nSELECT JSON_SET(JSON '{\"a\": {}}', '$.a.b', 100) AS json_data/*-----------------* | json_data       | +-----------------+ | {\"a\":{\"b\":100}} | *-----------------*/\n```\n\nIn the following example, the path prefix`$`points to a JSON null, so theremainder of the path is created for the value`100`.\n\n```\nSELECT JSON_SET(JSON 'null', '$.a.b', 100) AS json_data/*-----------------* | json_data       | +-----------------+ | {\"a\":{\"b\":100}} | *-----------------*/\n```\n\nIn the following example, the path`$.a.c`implies that the value at`$.a`isa JSON object but it's not. This part of the operation is ignored, but the otherparts of the operation are completed successfully.\n\n```\nSELECT JSON_SET(  JSON '{\"a\": 1}',  '$.b', 2,  '$.a.c', 100,  '$.d', 3) AS json_data/*---------------------* | json_data           | +---------------------+ | {\"a\":1,\"b\":2,\"d\":3} | *---------------------*/\n```\n\nIn the following example, the path`$.a[2]`implies that the value for`$.a`isan array, but it's not, so the operation is ignored for that value.\n\n```\nSELECT JSON_SET(  JSON '{\"a\": 1}',  '$.a[2]', 100,  '$.b', 2) AS json_data/*---------------* | json_data     | +---------------+ | {\"a\":1,\"b\":2} | *---------------*/\n```\n\nIn the following example, the path`$[1]`is matched and replaces thearray element value with`foo`.\n\n```\nSELECT JSON_SET(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1]', \"foo\") AS json_data/*-----------------* | json_data       | +-----------------+ | [\"a\",\"foo\",\"d\"] | *-----------------*/\n```\n\nIn the following example, the path`$[1][0]`is matched and replaces thearray element value with`foo`.\n\n```\nSELECT JSON_SET(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1][0]', \"foo\") AS json_data/*-----------------------* | json_data             | +-----------------------+ | [\"a\",[\"foo\",\"c\"],\"d\"] | *-----------------------*/\n```\n\nIn the following example, the path prefix`$`points to a JSON null, so theremainder of the path is created. The resulting array is padded withJSON nulls and appended with`foo`.\n\n```\nSELECT JSON_SET(JSON 'null', '$[0][3]', \"foo\")/*--------------------------* | json_data                | +--------------------------+ | [[null,null,null,\"foo\"]] | *--------------------------*/\n```\n\nIn the following example, the path`$[1]`is matched, the matched array isextended since`$[1][4]`is larger than the existing array, and then`foo`isinserted in the array.\n\n```\nSELECT JSON_SET(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1][4]', \"foo\") AS json_data/*-------------------------------------* | json_data                           | +-------------------------------------+ | [\"a\",[\"b\",\"c\",null,null,\"foo\"],\"d\"] | *-------------------------------------*/\n```\n\nIn the following example, the path`$[1][0][0]`implies that the value of`$[1][0]`is an array, but it is not, so the operation is ignored.\n\n```\nSELECT JSON_SET(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1][0][0]', \"foo\") AS json_data/*---------------------* | json_data           | +---------------------+ | [\"a\",[\"b\",\"c\"],\"d\"] | *---------------------*/\n```\n\nIn the following example, the path`$[1][2]`is larger than the length ofthe matched array. The array length is extended and the remainder of the pathis recursively created. The operation continues to the path`$[1][2][1]`and inserts`foo`.\n\n```\nSELECT JSON_SET(JSON '[\"a\", [\"b\", \"c\"], \"d\"]', '$[1][2][1]', \"foo\") AS json_data/*----------------------------------* | json_data                        | +----------------------------------+ | [\"a\",[\"b\",\"c\",[null,\"foo\"]],\"d\"] | *----------------------------------*/\n```\n\nIn the following example, because the`JSON`object is empty, key`b`isinserted, and the remainder of the path is recursively created.\n\n```\nSELECT JSON_SET(JSON '{}', '$.b[2].d', 100) AS json_data/*-----------------------------* | json_data                   | +-----------------------------+ | {\"b\":[null,null,{\"d\":100}]} | *-----------------------------*/\n```\n\nIn the following example, multiple values are set.\n\n```\nSELECT JSON_SET(  JSON '{\"a\": 1, \"b\": {\"c\":3}, \"d\": [4]}',  '$.a', 'v1',  '$.b.e', 'v2',  '$.d[2]', 'v3') AS json_data/*---------------------------------------------------* | json_data                                         | +---------------------------------------------------+ | {\"a\":\"v1\",\"b\":{\"c\":3,\"e\":\"v2\"},\"d\":[4,null,\"v3\"]} | *---------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "JSON_STRIP_NULLS",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_STRIP_NULLS(  json_expr  [, json_path]  [, include_arrays =&gt; { TRUE | FALSE }]  [, remove_empty =&gt; { TRUE | FALSE }])\n```\n\nRecursively removes JSON nulls from JSON objects and JSON arrays.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '{\"a\": null, \"b\": \"c\"}'\n    ```\n    \n    \n- `    json_path`: Remove JSON nulls at this[JSONPath](#JSONPath_format)for`    json_expr`.\n    \n    \n- `    include_arrays`: An optional, mandatory named argument that is either`    TRUE`(default) or`    FALSE`. If`    TRUE`or omitted, the function removes JSON nulls from JSON arrays. If`    FALSE`, does not.\n    \n    \n- `    remove_empty`: An optional, mandatory named argument that is either`    TRUE`or`    FALSE`(default). If`    TRUE`, the function removes empty JSON objects after JSON nulls are removed. If`    FALSE`or omitted, does not.\n    \n    If`    remove_empty`is`    TRUE`and`    include_arrays`is`    TRUE`or omitted,the function additionally removes empty JSON arrays.\n    \n    \n\nDetails:\n\n- If a value is a JSON null, the associated key-value pair is removed.\n- If`    remove_empty`is set to`    TRUE`, the function recursively removes emptycontainers after JSON nulls are removed.\n- If the function generates JSON with nothing in it, the function returns aJSON null.\n- If`    json_path`is an invalid[JSONPath](#JSONPath_format), an error isproduced.\n- If`    json_expr`is SQL`    NULL`, the function returns SQL`    NULL`.\n- If`    json_path`,`    include_arrays`, or`    remove_empty`is SQL`    NULL`, thefunction returns`    json_expr`.\n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nIn the following example, all JSON nulls are removed.\n\n```\nSELECT JSON_STRIP_NULLS(JSON '{\"a\": null, \"b\": \"c\"}') AS json_data/*-----------* | json_data | +-----------+ | {\"b\":\"c\"} | *-----------*/\n```\n\nIn the following example, all JSON nulls are removed from a JSON array.\n\n```\nSELECT JSON_STRIP_NULLS(JSON '[1, null, 2, null]') AS json_data/*-----------* | json_data | +-----------+ | [1,2]     | *-----------*/\n```\n\nIn the following example,`include_arrays`is set as`FALSE`so that JSON nullsare not removed from JSON arrays.\n\n```\nSELECT JSON_STRIP_NULLS(JSON '[1, null, 2, null]', include_arrays=&gt;FALSE) AS json_data/*-----------------* | json_data       | +-----------------+ | [1,null,2,null] | *-----------------*/\n```\n\nIn the following example,`remove_empty`is omitted and defaults to`FALSE`, and the empty structures are retained.\n\n```\nSELECT JSON_STRIP_NULLS(JSON '[1, null, 2, null, [null]]') AS json_data/*-----------* | json_data | +-----------+ | [1,2,[]]  | *-----------*/\n```\n\nIn the following example,`remove_empty`is set as`TRUE`, and theempty structures are removed.\n\n```\nSELECT JSON_STRIP_NULLS(  JSON '[1, null, 2, null, [null]]',  remove_empty=&gt;TRUE) AS json_data/*-----------* | json_data | +-----------+ | [1,2]     | *-----------*/\n```\n\nIn the following examples,`remove_empty`is set as`TRUE`, and theempty structures are removed. Because no JSON data is left the functionreturns JSON null.\n\n```\nSELECT JSON_STRIP_NULLS(JSON '{\"a\": null}', remove_empty=&gt;TRUE) AS json_data/*-----------* | json_data | +-----------+ | null      | *-----------*/\n```\n\n```\nSELECT JSON_STRIP_NULLS(JSON '{\"a\": [null]}', remove_empty=&gt;TRUE) AS json_data/*-----------* | json_data | +-----------+ | null      | *-----------*/\n```\n\nIn the following example, empty structures are removed for JSON objects,but not JSON arrays.\n\n```\nSELECT JSON_STRIP_NULLS(  JSON '{\"a\": {\"b\": {\"c\": null}}, \"d\": [null], \"e\": [], \"f\": 1}',  include_arrays=&gt;FALSE,  remove_empty=&gt;TRUE) AS json_data/*---------------------------* | json_data                 | +---------------------------+ | {\"d\":[null],\"e\":[],\"f\":1} | *---------------------------*/\n```\n\nIn the following example, empty structures are removed for both JSON objects,and JSON arrays.\n\n```\nSELECT JSON_STRIP_NULLS(  JSON '{\"a\": {\"b\": {\"c\": null}}, \"d\": [null], \"e\": [], \"f\": 1}',  remove_empty=&gt;TRUE) AS json_data/*-----------* | json_data | +-----------+ | {\"f\":1}   | *-----------*/\n```\n\nIn the following example, because no JSON data is left, the function returns aJSON null.\n\n```\nSELECT JSON_STRIP_NULLS(JSON 'null') AS json_data/*-----------* | json_data | +-----------+ | null      | *-----------*/\n```\n\n"
  },
  {
    "name": "JSON_TYPE",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_TYPE(json_expr)\n```\n\n **Description** \n\nGets the JSON type of the outermost JSON value and converts the name ofthis type to a SQL`STRING`value. The names of these JSON types can bereturned:`object`,`array`,`string`,`number`,`boolean`,`null`\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '{\"name\": \"sky\", \"color\": \"blue\"}'\n    ```\n    \n    If this expression is SQL`    NULL`, the function returns SQL`    NULL`. If theextracted JSON value is not a valid JSON type, an error is produced.\n    \n    \n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n```\nSELECT json_val, JSON_TYPE(json_val) AS typeFROM  UNNEST(    [      JSON '\"apple\"',      JSON '10',      JSON '3.14',      JSON 'null',      JSON '{\"city\": \"New York\", \"State\": \"NY\"}',      JSON '[\"apple\", \"banana\"]',      JSON 'false'    ]  ) AS json_val;/*----------------------------------+---------* | json_val                         | type    | +----------------------------------+---------+ | \"apple\"                          | string  | | 10                               | number  | | 3.14                             | number  | | null                             | null    | | {\"State\":\"NY\",\"city\":\"New York\"} | object  | | [\"apple\",\"banana\"]               | array   | | false                            | boolean | *----------------------------------+---------*/\n```\n\n"
  },
  {
    "name": "JSON_VALUE",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_VALUE(json_string_expr[, json_path])\n```\n\n```\nJSON_VALUE(json_expr[, json_path])\n```\n\n **Description** \n\nExtracts a JSON scalar value and converts it to a SQL`STRING`value.In addition, this function:\n\n- Removes the outermost quotes and unescapes the values.\n- Returns a SQL`    NULL`if a non-scalar value is selected.\n- Uses double quotes to escape invalid[JSONPath](#JSONPath_format)charactersin JSON keys. For example:`    \"a.b\"`.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '{\"name\": \"Jakob\", \"age\": \"6\"}'\n    ```\n    \n    \n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '{\"name\": \"Jane\", \"age\": \"6\"}'\n    ```\n    \n    \n- `    json_path`: The[JSONPath](#JSONPath_format). This identifies the data thatyou want to obtain from the input. If this optional parameter is notprovided, then the JSONPath`    $`symbol is applied, which means that all ofthe data is analyzed.\n    \n    If`    json_path`returns a JSON`    null`or a non-scalar value (in other words,if`    json_path`refers to an object or an array), then a SQL`    NULL`isreturned.\n    \n    \n\nThere are differences between the JSON-formatted string and JSON input types.For details, see[Differences between the JSON and JSON-formatted STRING types](#differences_json_and_string).\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\nIn the following example, JSON data is extracted and returned as a scalar value.\n\n```\nSELECT JSON_VALUE(JSON '{\"name\": \"Jakob\", \"age\": \"6\" }', '$.age') AS scalar_age;/*------------* | scalar_age | +------------+ | 6          | *------------*/\n```\n\nThe following example compares how results are returned for the`JSON_QUERY`and`JSON_VALUE`functions.\n\n```\nSELECT JSON_QUERY('{\"name\": \"Jakob\", \"age\": \"6\"}', '$.name') AS json_name,  JSON_VALUE('{\"name\": \"Jakob\", \"age\": \"6\"}', '$.name') AS scalar_name,  JSON_QUERY('{\"name\": \"Jakob\", \"age\": \"6\"}', '$.age') AS json_age,  JSON_VALUE('{\"name\": \"Jakob\", \"age\": \"6\"}', '$.age') AS scalar_age;/*-----------+-------------+----------+------------* | json_name | scalar_name | json_age | scalar_age | +-----------+-------------+----------+------------+ | \"Jakob\"   | Jakob       | \"6\"      | 6          | *-----------+-------------+----------+------------*/\n```\n\n```\nSELECT JSON_QUERY('{\"fruits\": [\"apple\", \"banana\"]}', '$.fruits') AS json_query,  JSON_VALUE('{\"fruits\": [\"apple\", \"banana\"]}', '$.fruits') AS json_value;/*--------------------+------------* | json_query         | json_value | +--------------------+------------+ | [\"apple\",\"banana\"] | NULL       | *--------------------+------------*/\n```\n\nIn cases where a JSON key uses invalid JSONPath characters, you can escape thosecharacters using double quotes. For example:\n\n```\nSELECT JSON_VALUE('{\"a.b\": {\"c\": \"world\"}}', '$.\"a.b\".c') AS hello;/*-------* | hello | +-------+ | world | *-------*/\n```\n\n"
  },
  {
    "name": "JSON_VALUE_ARRAY",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nJSON_VALUE_ARRAY(json_string_expr[, json_path])\n```\n\n```\nJSON_VALUE_ARRAY(json_expr[, json_path])\n```\n\n **Description** \n\nExtracts a JSON array of scalar values and converts it to a SQL`ARRAY&lt;STRING&gt;`value.In addition, this function:\n\n- Removes the outermost quotes and unescapes the values.\n- Returns a SQL`    NULL`if the selected value is not an array ornot an array containing only scalar values.\n- Uses double quotes to escape invalid[JSONPath](#JSONPath_format)charactersin JSON keys. For example:`    \"a.b\"`.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '[\"apples\", \"oranges\", \"grapes\"]'\n    ```\n    \n    \n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '[\"apples\", \"oranges\", \"grapes\"]'\n    ```\n    \n    \n- `    json_path`: The[JSONPath](#JSONPath_format). This identifies the data thatyou want to obtain from the input. If this optional parameter is notprovided, then the JSONPath`    $`symbol is applied, which means that all ofthe data is analyzed.\n    \n    \n\nThere are differences between the JSON-formatted string and JSON input types.For details, see[Differences between the JSON and JSON-formatted STRING types](#differences_json_and_string).\n\nCaveats:\n\n- A JSON`    null`in the input array produces a SQL`    NULL`as the output forJSON`    null`. If the output contains a`    NULL`array element, an error isproduced because the final output cannot be an array with`    NULL`values.\n- If a JSONPath matches an array that contains scalar objects and a JSON`    null`,then the output of the function must be transformed because the final outputcannot be an array with`    NULL`values.\n\n **Return type** \n\n`ARRAY&lt;STRING&gt;`\n\n **Examples** \n\nThis extracts items in JSON to a string array:\n\n```\nSELECT JSON_VALUE_ARRAY(  JSON '{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.fruits'  ) AS string_array;/*---------------------------* | string_array              | +---------------------------+ | [apples, oranges, grapes] | *---------------------------*/\n```\n\nThe following example compares how results are returned for the`JSON_QUERY_ARRAY`and`JSON_VALUE_ARRAY`functions.\n\n```\nSELECT JSON_QUERY_ARRAY('[\"apples\", \"oranges\"]') AS json_array,       JSON_VALUE_ARRAY('[\"apples\", \"oranges\"]') AS string_array;/*-----------------------+-------------------* | json_array            | string_array      | +-----------------------+-------------------+ | [\"apples\", \"oranges\"] | [apples, oranges] | *-----------------------+-------------------*/\n```\n\nThis extracts the items in a JSON-formatted string to a string array:\n\n```\n-- Strips the double quotesSELECT JSON_VALUE_ARRAY('[\"foo\", \"bar\", \"baz\"]', '$') AS string_array;/*-----------------* | string_array    | +-----------------+ | [foo, bar, baz] | *-----------------*/\n```\n\nThis extracts a string array and converts it to an integer array:\n\n```\nSELECT ARRAY(  SELECT CAST(integer_element AS INT64)  FROM UNNEST(    JSON_VALUE_ARRAY('[1, 2, 3]', '$')  ) AS integer_element) AS integer_array;/*---------------* | integer_array | +---------------+ | [1, 2, 3]     | *---------------*/\n```\n\nThese are equivalent:\n\n```\nSELECT JSON_VALUE_ARRAY('{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.fruits') AS string_array;SELECT JSON_VALUE_ARRAY('{\"fruits\": [\"apples\", \"oranges\", \"grapes\"]}', '$.\"fruits\"') AS string_array;-- The queries above produce the following result:/*---------------------------* | string_array              | +---------------------------+ | [apples, oranges, grapes] | *---------------------------*/\n```\n\nIn cases where a JSON key uses invalid JSONPath characters, you can escape thosecharacters using double quotes:`\" \"`. For example:\n\n```\nSELECT JSON_VALUE_ARRAY('{\"a.b\": {\"c\": [\"world\"]}}', '$.\"a.b\".c') AS hello;/*---------* | hello   | +---------+ | [world] | *---------*/\n```\n\nThe following examples explore how invalid requests and empty arrays arehandled:\n\n```\n-- An error is thrown if you provide an invalid JSONPath.SELECT JSON_VALUE_ARRAY('[\"foo\", \"bar\", \"baz\"]', 'INVALID_JSONPath') AS result;-- If the JSON-formatted string is invalid, then NULL is returned.SELECT JSON_VALUE_ARRAY('}}', '$') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If the JSON document is NULL, then NULL is returned.SELECT JSON_VALUE_ARRAY(NULL, '$') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath does not match anything, then the output is NULL.SELECT JSON_VALUE_ARRAY('{\"a\": [\"foo\", \"bar\", \"baz\"]}', '$.b') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath matches an object that is not an array, then the output is NULL.SELECT JSON_VALUE_ARRAY('{\"a\": \"foo\"}', '$') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath matches an array of non-scalar objects, then the output is NULL.SELECT JSON_VALUE_ARRAY('{\"a\": [{\"b\": \"foo\", \"c\": 1}, {\"b\": \"bar\", \"c\": 2}], \"d\": \"baz\"}', '$.a') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath matches an array of mixed scalar and non-scalar objects,-- then the output is NULL.SELECT JSON_VALUE_ARRAY('{\"a\": [10, {\"b\": 20}]', '$.a') AS result;/*--------* | result | +--------+ | NULL   | *--------*/-- If a JSONPath matches an empty JSON array, then the output is an empty array instead of NULL.SELECT JSON_VALUE_ARRAY('{\"a\": \"foo\", \"b\": []}', '$.b') AS result;/*--------* | result | +--------+ | []     | *--------*/-- The following query produces and error because the final output cannot be an-- array with NULLs.SELECT JSON_VALUE_ARRAY('[\"world\", 1, null]') AS result;\n```\n\n"
  },
  {
    "name": "JUSTIFY_DAYS",
    "arguments": [],
    "category": "Interval functions",
    "description": "```\nJUSTIFY_DAYS(interval_expression)\n```\n\n **Description** \n\nNormalizes the day part of the interval to the range from -29 to 29 byincrementing/decrementing the month or year part of the interval.\n\n **Return Data Type** \n\n`INTERVAL`\n\n **Example** \n\n```\nSELECT  JUSTIFY_DAYS(INTERVAL 29 DAY) AS i1,  JUSTIFY_DAYS(INTERVAL -30 DAY) AS i2,  JUSTIFY_DAYS(INTERVAL 31 DAY) AS i3,  JUSTIFY_DAYS(INTERVAL -65 DAY) AS i4,  JUSTIFY_DAYS(INTERVAL 370 DAY) AS i5/*--------------+--------------+-------------+---------------+--------------* | i1           | i2           | i3          | i4            | i5           | +--------------+--------------+-------------+---------------+--------------+ | 0-0 29 0:0:0 | -0-1 0 0:0:0 | 0-1 1 0:0:0 | -0-2 -5 0:0:0 | 1-0 10 0:0:0 | *--------------+--------------+-------------+---------------+--------------*/\n```\n\n"
  },
  {
    "name": "JUSTIFY_HOURS",
    "arguments": [],
    "category": "Interval functions",
    "description": "```\nJUSTIFY_HOURS(interval_expression)\n```\n\n **Description** \n\nNormalizes the time part of the interval to the range from -23:59:59.999999 to23:59:59.999999 by incrementing/decrementing the day part of the interval.\n\n **Return Data Type** \n\n`INTERVAL`\n\n **Example** \n\n```\nSELECT  JUSTIFY_HOURS(INTERVAL 23 HOUR) AS i1,  JUSTIFY_HOURS(INTERVAL -24 HOUR) AS i2,  JUSTIFY_HOURS(INTERVAL 47 HOUR) AS i3,  JUSTIFY_HOURS(INTERVAL -12345 MINUTE) AS i4/*--------------+--------------+--------------+-----------------* | i1           | i2           | i3           | i4              | +--------------+--------------+--------------+-----------------+ | 0-0 0 23:0:0 | 0-0 -1 0:0:0 | 0-0 1 23:0:0 | 0-0 -8 -13:45:0 | *--------------+--------------+--------------+-----------------*/\n```\n\n"
  },
  {
    "name": "JUSTIFY_INTERVAL",
    "arguments": [],
    "category": "Interval functions",
    "description": "```\nJUSTIFY_INTERVAL(interval_expression)\n```\n\n **Description** \n\nNormalizes the days and time parts of the interval.\n\n **Return Data Type** \n\n`INTERVAL`\n\n **Example** \n\n```\nSELECT JUSTIFY_INTERVAL(INTERVAL '29 49:00:00' DAY TO SECOND) AS i/*-------------* | i           | +-------------+ | 0-1 1 1:0:0 | *-------------*/\n```\n\n"
  },
  {
    "name": "KEYS.ADD_KEY_FROM_RAW_BYTES",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.ADD_KEY_FROM_RAW_BYTES(keyset, key_type, raw_key_bytes)\n```\n\n **Description** \n\nReturns a serialized keyset as`BYTES`with theaddition of a key to`keyset`based on`key_type`and`raw_key_bytes`.\n\nThe primary cryptographic key remains the same as in`keyset`. The expectedlength of`raw_key_bytes`depends on the value of`key_type`. The following aresupported`key_types`:\n\n- `    'AES_CBC_PKCS'`: Creates a key for AES decryption using cipher block chainingand PKCS padding.`    raw_key_bytes`is expected to be a raw key`    BYTES`value of length 16, 24, or 32; theselengths have sizes of 128, 192, and 256 bits, respectively. GoogleSQLAEAD functions do not support keys of these types for encryption; instead,prefer`    'AEAD_AES_GCM_256'`or`    'AES_GCM'`keys.\n- `    'AES_GCM'`: Creates a key for AES decryption or encryption using[Galois/Counter Mode](https://en.wikipedia.org/wiki/Galois/Counter_Mode).`    raw_key_bytes`must be a raw key`    BYTES`value of length 16 or 32; these lengths have sizes of 128 and 256 bits,respectively. When keys of this type are inputs to`    AEAD.ENCRYPT`, the outputciphertext does not have a Tink-specific prefix indicating which key wasused as input.\n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nThe following query creates a table of customer IDs along with raw key bytes,called`CustomerRawKeys`, and a table of unique IDs, called`CustomerIds`. Itcreates a new`'AEAD_AES_GCM_256'`keyset for each`customer_id`; then it adds anew key to each keyset, using the`raw_key_bytes`value corresponding to that`customer_id`. The output is a table where each row contains a`customer_id`anda keyset in`BYTES`, which contains the raw key addedusing KEYS.ADD_KEY_FROM_RAW_BYTES.\n\n```\nWITH CustomerRawKeys AS (  SELECT 1 AS customer_id, b'0123456789012345' AS raw_key_bytes UNION ALL  SELECT 2, b'9876543210543210' UNION ALL  SELECT 3, b'0123012301230123'), CustomerIds AS (  SELECT 1 AS customer_id UNION ALL  SELECT 2 UNION ALL  SELECT 3)SELECT  ci.customer_id,  KEYS.ADD_KEY_FROM_RAW_BYTES(    KEYS.NEW_KEYSET('AEAD_AES_GCM_256'),    'AES_CBC_PKCS',    (SELECT raw_key_bytes FROM CustomerRawKeys AS crk     WHERE crk.customer_id = ci.customer_id)  ) AS keysetFROM CustomerIds AS ci;\n```\n\nThe output keysets each contain two things: the primary cryptographic keycreated using`KEYS.NEW_KEYSET('AEAD_AES_GCM_256')`, and the raw key added using`KEYS.ADD_KEY_FROM_RAW_BYTES`. If a keyset in the output is used with`AEAD.ENCRYPT`, GoogleSQL uses the primary cryptographic key createdusing`KEYS.NEW_KEYSET('AEAD_AES_GCM_256')`to encrypt the input plaintext. Ifthe keyset is used with`AEAD.DECRYPT_STRING`or`AEAD.DECRYPT_BYTES`,GoogleSQL returns the resulting plaintext if either key succeeds indecrypting the ciphertext.\n\n"
  },
  {
    "name": "KEYS.KEYSET_CHAIN",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.KEYSET_CHAIN(kms_resource_name, first_level_keyset)\n```\n\n **Description** \n\nCan be used in place of the`keyset`argument to the AEADand deterministicencryption functions to pass a[Tink](https://github.com/google/tink/blob/master/docs/KEY-MANAGEMENT.md)keyset that is encryptedwith a[Cloud KMS key](/bigquery/docs/aead-encryption-concepts#cloud_kms_protection). This function lets you useother AEAD functions without including plaintext keys in a query.\n\nThis function takes the following arguments:\n\n- `    kms_resource_name`: A`    STRING`literal that contains the resource path tothe Cloud KMS key that's used to decrypt`    first_level_keyset`.This key must reside in the same Cloud region where this function is executed.A Cloud KMS key looks like this:\n    \n    \n    ```\n    gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key\n    ```\n    \n    \n- `    first_level_keyset`: A`    BYTES`literal that represents a[keyset](/bigquery/docs/aead-encryption-concepts#keysets)or[wrapped keyset](/bigquery/docs/aead-encryption-concepts#wrapped_keysets).\n    \n    \n\n **Return Data Type** \n\n`STRUCT`\n\n **Example** \n\nThis example creates a table of example data, then shows how to encrypt thatdata using a wrapped (encrypted) keyset. Finally it shows how to query theencrypted version of the data.\n\nThe following statement creates a table`RawCustomerData`containing a column ofcustomer ids and a column of favorite animals.\n\n```\nCREATE TABLE aead.RawCustomerData ASSELECT  1 AS customer_id,  b'jaguar' AS favorite_animalUNION ALLSELECT  2 AS customer_id,  b'zebra' AS favorite_animalUNION ALLSELECT  3 AS customer_id,  b'zebra' AS favorite_animal;\n```\n\nThe following statement creates a table`EncryptedCustomerData`containing acolumn of unique IDs and a column of ciphertext. The statement encrypts theplaintext`favorite_animal`using the first_level_keyset provided.\n\n```\nDECLARE kms_resource_name STRING;DECLARE first_level_keyset BYTES;SET kms_resource_name = 'gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key';SET first_level_keyset = b'\\012\\044\\000\\107\\275\\360\\176\\264\\206\\332\\235\\215\\304...';CREATE TABLE aead.EncryptedCustomerData ASSELECT  customer_id,  AEAD.ENCRYPT(    KEYS.KEYSET_CHAIN(kms_resource_name, first_level_keyset),    favorite_animal,    CAST(CAST(customer_id AS STRING) AS BYTES)  ) AS encrypted_animalFROM  aead.RawCustomerData;\n```\n\nThe following query uses the first_level_keyset to decrypt data in the`EncryptedCustomerData`table.\n\n```\nDECLARE kms_resource_name STRING;DECLARE first_level_keyset BYTES;SET kms_resource_name = 'gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key';SET first_level_keyset = b'\\012\\044\\000\\107\\275\\360\\176\\264\\206\\332\\235\\215\\304...';SELECT  customer_id,  AEAD.DECRYPT_BYTES(    KEYS.KEYSET_CHAIN(kms_resource_name, first_level_keyset),    encrypted_animal,    CAST(CAST(customer_id AS STRING) AS BYTES)  ) AS favorite_animalFROM  aead.EncryptedCustomerData;\n```\n\nThe previous two steps also work with the`DETERMINISTIC_ENCRYPT`and`DETERMINISTIC_DECRYPT_BYTES`functions. The wrapped keyset must be createdusing the`DETERMINISTIC_AEAD_AES_SIV_CMAC_256`type.\n\nThe following statement creates a table`EncryptedCustomerData`containing acolumn of unique IDs and a column of ciphertext. The statement encrypts theplaintext`favorite_animal`using the first_level_keyset provided. You can seethat the ciphertext for`favorite_animal`is the same for customers 2 and 3since their plaintext`favorite_animal`is the same.\n\n```\nDECLARE kms_resource_name STRING;DECLARE first_level_keyset BYTES;SET kms_resource_name = 'gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key';SET first_level_keyset = b'\\012\\044\\000\\107\\275\\360\\176\\264\\206\\332\\235\\215\\304...';CREATE TABLE daead.EncryptedCustomerData ASSELECT  customer_id,  DETERMINISTC_ENCRYPT(    KEYS.KEYSET_CHAIN(kms_resource_name, first_level_keyset),    favorite_animal,    CAST(CAST(customer_id AS STRING) AS BYTES)  ) AS encrypted_animalFROM  daead.RawCustomerData;\n```\n\nThe following query uses the first_level_keyset to decrypt data in the`EncryptedCustomerData`table.\n\n```\nDECLARE kms_resource_name STRING;DECLARE first_level_keyset BYTES;SET kms_resource_name = 'gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key';SET first_level_keyset = b'\\012\\044\\000\\107\\275\\360\\176\\264\\206\\332\\235\\215\\304...';SELECT  customer_id,  DETERMINISTIC_DECRYPT_BYTES(    KEYS.KEYSET_CHAIN(kms_resource_name, first_level_keyset),    encrypted_animal,    CAST(CAST(customer_id AS STRING) AS BYTES)  ) AS favorite_animalFROM dead.EncryptedCustomerData;\n```\n\n"
  },
  {
    "name": "KEYS.KEYSET_FROM_JSON",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.KEYSET_FROM_JSON(json_keyset)\n```\n\n **Description** \n\nReturns the input`json_keyset``STRING`asserialized`BYTES`, which is a valid input for other`KEYS`and`AEAD`functions. The JSON`STRING`mustbe compatible with the definition of the[google.crypto.tink.Keyset](https://github.com/google/tink/blob/master/proto/tink.proto)protocol buffer message: the JSON keyset should be a JSON object containingobjects and name-value pairs corresponding to those in the \"keyset\" message inthe google.crypto.tink.Keyset definition. You can convert the output serialized`BYTES`representation back to a JSON`STRING`using`KEYS.KEYSET_TO_JSON`.\n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\n`KEYS.KEYSET_FROM_JSON`takes JSON-formatted`STRING`values like the following:\n\n```\n{  \"key\":[      {        \"keyData\":{          \"keyMaterialType\":\"SYMMETRIC\",          \"typeUrl\":\"type.googleapis.com/google.crypto.tink.AesGcmKey\",          \"value\":\"GiD80Z8kL6AP3iSNHhqseZGAIvq7TVQzClT7FQy8YwK3OQ==\"        },        \"keyId\":3101427138,        \"outputPrefixType\":\"TINK\",        \"status\":\"ENABLED\"      }    ],  \"primaryKeyId\":3101427138}\n```\n\nThe following query creates a new keyset from a JSON-formatted`STRING``json_keyset`:\n\n```\nSELECT KEYS.KEYSET_FROM_JSON(json_keyset);\n```\n\nThis returns the`json_keyset`serialized as`BYTES`, like the following:\n\n```\n\\x08\\x9d\\x8e\\x85\\x82\\x09\\x12d\\x0aX\\x0a0type.googleapis.com/google.crypto.tink.AesGcmKey\\x12\\\"\\x1a qX\\xe4IG\\x87\\x1f\\xde\\xe3)+e\\x98\\x0a\\x1c}\\xfe\\x88&lt;\\x12\\xeb\\xc1t\\xb8\\x83\\x1a\\xcd\\xa8\\x97\\x84g\\x18\\x01\\x10\\x01\\x18\\x9d\\x8e\\x85\\x82\\x09 \\x01\n```\n\n"
  },
  {
    "name": "KEYS.KEYSET_LENGTH",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.KEYSET_LENGTH(keyset)\n```\n\n **Description** \n\nReturns the number of keys in the provided keyset.\n\n **Return Data Type** \n\n`INT64`\n\n **Example** \n\nThis example references a JSON-formatted STRINGcalled`json_keyset`that contains two keys:\n\n```\n{   \"primaryKeyId\":1354994251,   \"key\":[      {         \"keyData\":{            \"keyMaterialType\":\"SYMMETRIC\",            \"typeUrl\":\"type.googleapis.com/google.crypto.tink.AesGcmKey\",            \"value\":\"GiD9sxQRgFj4aYN78vaIlxInjZkG/uvyWSY9a8GN+ELV2Q==\"         },         \"keyId\":1354994251,         \"outputPrefixType\":\"TINK\",         \"status\":\"ENABLED\"      }   ],   \"key\":[      {         \"keyData\":{            \"keyMaterialType\":\"SYMMETRIC\",            \"typeUrl\":\"type.googleapis.com/google.crypto.tink.AesGcmKey\",            \"value\":\"PRn76sxQRgFj4aYN00vaIlxInjZkG/uvyWSY9a2bLRm\"         },         \"keyId\":852264701,         \"outputPrefixType\":\"TINK\",         \"status\":\"DISABLED\"      }   ]}\n```\n\nThe following query converts`json_keyset`to a keyset and then returnsthe number of keys in the keyset:\n\n```\nSELECT KEYS.KEYSET_LENGTH(KEYS.KEYSET_FROM_JSON(json_keyset)) as key_count;/*-----------* | key_count | +-----------+ | 2         | *-----------*/\n```\n\n"
  },
  {
    "name": "KEYS.KEYSET_TO_JSON",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.KEYSET_TO_JSON(keyset)\n```\n\n **Description** \n\nReturns a JSON`STRING`representation of the input`keyset`. The returned JSON`STRING`is compatiblewith the definition of the[google.crypto.tink.Keyset](https://github.com/google/tink/blob/master/proto/tink.proto)protocol buffer message. You can convert the JSON`STRING`representation back to`BYTES`using`KEYS.KEYSET_FROM_JSON`.\n\n **Return Data Type** \n\n`STRING`\n\n **Example** \n\nThe following query returns a new`'AEAD_AES_GCM_256'`keyset as aJSON-formatted`STRING`.\n\n```\nSELECT KEYS.KEYSET_TO_JSON(KEYS.NEW_KEYSET('AEAD_AES_GCM_256'));\n```\n\nThe result is a`STRING`like the following.\n\n```\n{  \"key\":[      {        \"keyData\":{          \"keyMaterialType\":\"SYMMETRIC\",          \"typeUrl\":\"type.googleapis.com/google.crypto.tink.AesGcmKey\",          \"value\":\"GiD80Z8kL6AP3iSNHhqseZGAIvq7TVQzClT7FQy8YwK3OQ==\"        },        \"keyId\":3101427138,        \"outputPrefixType\":\"TINK\",        \"status\":\"ENABLED\"      }    ],  \"primaryKeyId\":3101427138}\n```\n\n"
  },
  {
    "name": "KEYS.NEW_KEYSET",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.NEW_KEYSET(key_type)\n```\n\n **Description** \n\nReturns a serialized keyset containing a new key based on`key_type`. Thereturned keyset is a serialized`BYTES`representation of[google.crypto.tink.Keyset](https://github.com/google/tink/blob/master/proto/tink.proto)that contains a primary cryptographic key and no additional keys. You can usethe keyset with the`AEAD.ENCRYPT`,`AEAD.DECRYPT_BYTES`, and`AEAD.DECRYPT_STRING`functions for encryption and decryption, as well as withthe`KEYS`group of key- and keyset-related functions.\n\n`key_type`is a`STRING`literal representation of the type of key to create.`key_type`cannot be`NULL`.`key_type`can be:\n\n- `    AEAD_AES_GCM_256`: Creates a 256-bit key with the pseudo-random numbergenerator provided by[boringSSL](https://boringssl.googlesource.com/boringssl/). The key uses AES-GCM forencryption and decryption operations.\n- `    DETERMINISTIC_AEAD_AES_SIV_CMAC_256`:Creates a 512-bit`    AES-SIV-CMAC`key, which contains a 256-bit`    AES-CTR`keyand 256-bit`    AES-CMAC`key. The`    AES-SIV-CMAC`key is created with thepseudo-random number generator provided by[boringSSL](https://boringssl.googlesource.com/boringssl/). The keyuses AES-SIV for encryption and decryption operations.\n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nThe following query creates a keyset for each row in`CustomerIds`, which cansubsequently be used to encrypt data. Each keyset contains a single encryptionkey with randomly-generated key data. Each row in the output contains a`customer_id`and an`'AEAD_AES_GCM_256'`key in`BYTES`.\n\n```\nSELECT customer_id, KEYS.NEW_KEYSET('AEAD_AES_GCM_256') AS keysetFROM (  SELECT 1 AS customer_id UNION ALL  SELECT 2 UNION ALL  SELECT 3) AS CustomerIds;\n```\n\n"
  },
  {
    "name": "KEYS.NEW_WRAPPED_KEYSET",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.NEW_WRAPPED_KEYSET(kms_resource_name, key_type)\n```\n\n **Description** \n\nCreates a new keyset and encrypts it with a[Cloud KMS key](/bigquery/docs/aead-encryption-concepts#cloud_kms_protection).Returns the[wrapped keyset](/bigquery/docs/aead-encryption-concepts#wrapped_keysets)as a`BYTES`representation of[google.crypto.tink.Keyset](https://github.com/google/tink/blob/master/proto/tink.proto)that contains a primary cryptographic key and no additional keys.\n\nThis function takes the following arguments:\n\n- `    kms_resource_name`: A`    STRING`literal representation of theCloud KMS key.`    kms_resource_name`cannot be`    NULL`. TheCloud KMS key must reside in the same Cloud region where thisfunction is executed. A Cloud KMS key looks like this:\n    \n    \n    ```\n    gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key\n    ```\n    \n    \n- `    key_type`: A`    STRING`literal representation of the keyset type.`    key_type`cannot be`    NULL`but can be one of the following values:\n    \n    \n    - `        AEAD_AES_GCM_256`: Creates a 256-bit key with the pseudo-random numbergenerator provided by[boringSSL](https://boringssl.googlesource.com/boringssl/). The key uses AES-GCM forencryption and decryption operations.\n        \n        \n    - `        DETERMINISTIC_AEAD_AES_SIV_CMAC_256`:Creates a 512-bit`        AES-SIV-CMAC`key, which contains a 256-bit`        AES-CTR`keyand 256-bit`        AES-CMAC`key. The`        AES-SIV-CMAC`key is created with thepseudo-random number generator provided by[boringSSL](https://boringssl.googlesource.com/boringssl/). The keyuses AES-SIV for encryption and decryption operations.\n        \n        \n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nPut the following variables above each example query that you run:\n\n```\nDECLARE kms_resource_name STRING;SET kms_resource_name = 'gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key';\n```\n\nThe following query creates a wrapped keyset, which contains the ciphertextproduced by encrypting a[Tink](https://github.com/google/tink/blob/master/proto/tink.proto)keysetwith the specified Cloud KMS key. If you run the query multiple times,it generates multiple wrapped keysets, and each wrapped keyset is unique toeach query that is run.\n\n```\nSELECT KEYS.NEW_WRAPPED_KEYSET(kms_resource_name, 'AEAD_AES_GCM_256');\n```\n\nMultiple calls to this function with the same arguments in one queryreturns the same value. For example, the following query only creates onewrapped keysest and returns it for each row in a table called`my_table`.\n\n```\nSELECT  *,  KEYS.NEW_WRAPPED_KEYSET(kms_resource_name, 'AEAD_AES_GCM_256')FROM my_table\n```\n\n"
  },
  {
    "name": "KEYS.REWRAP_KEYSET",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.REWRAP_KEYSET(source_kms_resource_name, target_kms_resource_name, wrapped_keyset)\n```\n\n **Description** \n\nRe-encrypts a[wrapped keyset](/bigquery/docs/aead-encryption-concepts#wrapped_keysets)with a new[Cloud KMS key](/bigquery/docs/aead-encryption-concepts#cloud_kms_protection). Returns the wrapped keyset as a`BYTES`representation of[google.crypto.tink.Keyset](https://github.com/google/tink/blob/master/proto/tink.proto)that contains a primary cryptographic key and no additional keys.\n\nWhen this function is used, a wrapped keyset is decrypted by`source_kms_resource_name`and then re-encrypted by`target_kms_resource_name`.During this process, the decrypted keyset is never visible to customers.\n\nThis function takes the following arguments:\n\n- `    source_kms_resource_name`: A`    STRING`literal representation of theCloud KMS key you want to replace. This key must reside in the sameCloud region where this function is executed. A Cloud KMS key lookslike this:\n    \n    \n    ```\n    gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key\n    ```\n    \n    \n- `    target_kms_resource_name`: A`    STRING`literal representation of thenew Cloud KMS key that you want to use.\n    \n    \n- `    wrapped_keyset`: A`    BYTES`literal representation of thekeyset that you want to re-encrypt.\n    \n    \n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nPut the following variables above each example query that you run:\n\n```\nDECLARE source_kms_resource_name STRING;DECLARE target_kms_resource_name STRING;DECLARE wrapped_keyset BYTES;SET source_kms_resource_name = 'gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key';SET target_kms_resource_name = 'gcp-kms://projects/my-project/locations/another-location/keyRings/my-key-ring/cryptoKeys/my-other-crypto-key';SET wrapped_keyset = b'\\012\\044\\000\\107\\275\\360\\176\\264\\206\\332\\235\\215\\304...';\n```\n\nThe following query rewraps a wrapped keyset. If you run the query multipletimes, it generates multiple wrapped keysets, and each wrapped keyset is uniqueto each query that is run.\n\n```\nSELECT KEYS.REWRAP_KEYSET(source_kms_resource_name, target_kms_resource_name, wrapped_keyset);\n```\n\nMultiple calls to this function with the same arguments in one queryreturns the same value. For example, the following query only creates onewrapped keysest and returns it for each row in a table called`my_table`.\n\n```\nSELECT  *,  KEYS.REWRAP_KEYSET(source_kms_resource_name, target_kms_resource_name, wrapped_keyset)FROM my_table\n```\n\n"
  },
  {
    "name": "KEYS.ROTATE_KEYSET",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.ROTATE_KEYSET(keyset, key_type)\n```\n\n **Description** \n\nAdds a new key to`keyset`based on`key_type`. This new key becomes the primarycryptographic key of the new keyset. Returns the new keyset serialized as`BYTES`.\n\nThe old primary cryptographic key from the input`keyset`remains an additionalkey in the returned keyset.\n\nThe new`key_type`must match the key type of existing keys in the`keyset`.\n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nThe following statement creates a table containing a column of unique`customer_id`values and`'AEAD_AES_GCM_256'`keysets. Then, it creates a newprimary cryptographic key within each keyset in the source table using`KEYS.ROTATE_KEYSET`. Each row in the output contains a`customer_id`and an`'AEAD_AES_GCM_256'`keyset in`BYTES`.\n\n```\nWITH ExistingKeysets AS (SELECT 1 AS customer_id, KEYS.NEW_KEYSET('AEAD_AES_GCM_256') AS keyset    UNION ALL  SELECT 2, KEYS.NEW_KEYSET('AEAD_AES_GCM_256') UNION ALL  SELECT 3, KEYS.NEW_KEYSET('AEAD_AES_GCM_256'))SELECT customer_id, KEYS.ROTATE_KEYSET(keyset, 'AEAD_AES_GCM_256') AS keysetFROM ExistingKeysets;\n```\n\n"
  },
  {
    "name": "KEYS.ROTATE_WRAPPED_KEYSET",
    "arguments": [],
    "category": "AEAD encryption functions",
    "description": "```\nKEYS.ROTATE_WRAPPED_KEYSET(kms_resource_name, wrapped_keyset, key_type)\n```\n\n **Description** \n\nTakes an existing[wrapped keyset](/bigquery/docs/aead-encryption-concepts#wrapped_keysets)and returns a rotated andrewrapped keyset. The returned wrapped keyset is a`BYTES`representation of[google.crypto.tink.Keyset](https://github.com/google/tink/blob/master/proto/tink.proto).\n\nWhen this function is used, the wrapped keyset is decrypted,the new key is added, and then the keyset is re-encrypted. The primarycryptographic key from the input`wrapped_keyset`remains as anadditional key in the returned keyset. During this rotation process,the decrypted keyset is never visible to customers.\n\nThis function takes the following arguments:\n\n- `    kms_resource_name`: A`    STRING`literal representation of the[Cloud KMS key](/bigquery/docs/aead-encryption-concepts#cloud_kms_protection)that was used to wrap thewrapped keyset. The Cloud KMS key must reside in the same Cloudregion where this function is executed. A Cloud KMS key looks likethis:\n    \n    \n    ```\n    gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key\n    ```\n    \n    \n- `    wrapped_keyset`: A`    BYTES`literal representation of theexisting keyset that you want to work with.\n    \n    \n- `    key_type`: A`    STRING`literal representation of the keyset type. This mustmatch the key type of existing keys in`    wrapped_keyset`.\n    \n    \n\n **Return Data Type** \n\n`BYTES`\n\n **Example** \n\nPut the following variables above each example query that you run:\n\n```\nDECLARE kms_resource_name STRING;DECLARE wrapped_keyset BYTES;SET kms_resource_name = 'gcp-kms://projects/my-project/locations/us/keyRings/my-key-ring/cryptoKeys/my-crypto-key';SET wrapped_keyset = b'\\012\\044\\000\\107\\275\\360\\176\\264\\206\\332\\235\\215\\304...';\n```\n\nThe following query rotates a wrapped keyset. If you run the query multipletimes, it generates multiple wrapped keysets, and each wrapped keyset is uniqueto each query that is run.\n\n```\nSELECT KEYS.ROTATE_WRAPPED_KEYSET(kms_resource_name, wrapped_keyset, 'AEAD_AES_GCM_256');\n```\n\nMultiple calls to this function with the same arguments in one queryreturns the same value. For example, the following query only creates onewrapped keysest and returns it for each row in a table called`my_table`.\n\n```\nSELECT  *,  KEYS.ROTATE_WRAPPED_KEYSET(kms_resource_name, wrapped_keyset, 'AEAD_AES_GCM_256')FROM my_table\n```\n\n\n<span id=\"aggregate_functions\">\n## Aggregate functions\n\n</span>\nGoogleSQL for BigQuery supports the following general aggregate functions.To learn about the syntax for aggregate function calls, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n"
  },
  {
    "name": "LAG",
    "arguments": [],
    "category": "Navigation functions",
    "description": "```\nLAG (value_expression[, offset [, default_expression]])OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]\n```\n\n **Description** \n\nReturns the value of the`value_expression`on a preceding row. Changing the`offset`value changes which preceding row is returned; the default value is`1`, indicating the previous row in the window frame. An error occurs if`offset`is NULL or a negative value.\n\nThe optional`default_expression`is used if there isn't a row in the windowframe at the specified offset. This expression must be a constant expression andits type must be implicitly coercible to the type of`value_expression`. If leftunspecified,`default_expression`defaults to NULL.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\n- `    value_expression`can be any data type that can be returned from anexpression.\n- `    offset`must be a non-negative integer literal or parameter.\n- `    default_expression`must be compatible with the value expression type.\n\n **Return Data Type** \n\nSame type as`value_expression`.\n\n **Examples** \n\nThe following example illustrates a basic use of the`LAG`function.\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  finish_time,  division,  LAG(name)    OVER (PARTITION BY division ORDER BY finish_time ASC) AS preceding_runnerFROM finishers;/*-----------------+-------------+----------+------------------* | name            | finish_time | division | preceding_runner | +-----------------+-------------+----------+------------------+ | Carly Forte     | 03:08:58    | F25-29   | NULL             | | Sophia Liu      | 02:51:45    | F30-34   | NULL             | | Nikki Leith     | 02:59:01    | F30-34   | Sophia Liu       | | Jen Edwards     | 03:06:36    | F30-34   | Nikki Leith      | | Meghan Lederer  | 03:07:41    | F30-34   | Jen Edwards      | | Lauren Reasoner | 03:10:14    | F30-34   | Meghan Lederer   | | Lisa Stelzner   | 02:54:11    | F35-39   | NULL             | | Lauren Matthews | 03:01:17    | F35-39   | Lisa Stelzner    | | Desiree Berry   | 03:05:42    | F35-39   | Lauren Matthews  | | Suzy Slane      | 03:06:24    | F35-39   | Desiree Berry    | *-----------------+-------------+----------+------------------*/\n```\n\nThis next example uses the optional`offset`parameter.\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  finish_time,  division,  LAG(name, 2)    OVER (PARTITION BY division ORDER BY finish_time ASC) AS two_runners_aheadFROM finishers;/*-----------------+-------------+----------+-------------------* | name            | finish_time | division | two_runners_ahead | +-----------------+-------------+----------+-------------------+ | Carly Forte     | 03:08:58    | F25-29   | NULL              | | Sophia Liu      | 02:51:45    | F30-34   | NULL              | | Nikki Leith     | 02:59:01    | F30-34   | NULL              | | Jen Edwards     | 03:06:36    | F30-34   | Sophia Liu        | | Meghan Lederer  | 03:07:41    | F30-34   | Nikki Leith       | | Lauren Reasoner | 03:10:14    | F30-34   | Jen Edwards       | | Lisa Stelzner   | 02:54:11    | F35-39   | NULL              | | Lauren Matthews | 03:01:17    | F35-39   | NULL              | | Desiree Berry   | 03:05:42    | F35-39   | Lisa Stelzner     | | Suzy Slane      | 03:06:24    | F35-39   | Lauren Matthews   | *-----------------+-------------+----------+-------------------*/\n```\n\nThe following example replaces NULL values with a default value.\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  finish_time,  division,  LAG(name, 2, 'Nobody')    OVER (PARTITION BY division ORDER BY finish_time ASC) AS two_runners_aheadFROM finishers;/*-----------------+-------------+----------+-------------------* | name            | finish_time | division | two_runners_ahead | +-----------------+-------------+----------+-------------------+ | Carly Forte     | 03:08:58    | F25-29   | Nobody            | | Sophia Liu      | 02:51:45    | F30-34   | Nobody            | | Nikki Leith     | 02:59:01    | F30-34   | Nobody            | | Jen Edwards     | 03:06:36    | F30-34   | Sophia Liu        | | Meghan Lederer  | 03:07:41    | F30-34   | Nikki Leith       | | Lauren Reasoner | 03:10:14    | F30-34   | Jen Edwards       | | Lisa Stelzner   | 02:54:11    | F35-39   | Nobody            | | Lauren Matthews | 03:01:17    | F35-39   | Nobody            | | Desiree Berry   | 03:05:42    | F35-39   | Lisa Stelzner     | | Suzy Slane      | 03:06:24    | F35-39   | Lauren Matthews   | *-----------------+-------------+----------+-------------------*/\n```\n\n"
  },
  {
    "name": "LAST_DAY",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nLAST_DAY(date_expression[, date_part])\n```\n\n **Description** \n\nReturns the last day from a date expression. This is commonly used to returnthe last day of the month.\n\nYou can optionally specify the date part for which the last day is returned.If this parameter is not used, the default value is`MONTH`.`LAST_DAY`supports the following values for`date_part`:\n\n- `    YEAR`\n- `    QUARTER`\n- `    MONTH`\n- `    WEEK`. Equivalent to 7`    DAY`s.\n- `    WEEK(&lt;WEEKDAY&gt;)`.`    &lt;WEEKDAY&gt;`represents the starting day of the week.Valid values are`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`, and`    SATURDAY`.\n- `    ISOWEEK`. Uses[ISO 8601](https://en.wikipedia.org/wiki/ISO_week_date)week boundaries. ISO weeks beginon Monday.\n- `    ISOYEAR`. Uses the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering year boundary.The ISO year boundary is the Monday of the first week whose Thursday belongsto the corresponding Gregorian calendar year.\n\n **Return Data Type** \n\n`DATE`\n\n **Example** \n\nThese both return the last day of the month:\n\n```\nSELECT LAST_DAY(DATE '2008-11-25', MONTH) AS last_day/*------------* | last_day   | +------------+ | 2008-11-30 | *------------*/\n```\n\n```\nSELECT LAST_DAY(DATE '2008-11-25') AS last_day/*------------* | last_day   | +------------+ | 2008-11-30 | *------------*/\n```\n\nThis returns the last day of the year:\n\n```\nSELECT LAST_DAY(DATE '2008-11-25', YEAR) AS last_day/*------------* | last_day   | +------------+ | 2008-12-31 | *------------*/\n```\n\nThis returns the last day of the week for a week that starts on a Sunday:\n\n```\nSELECT LAST_DAY(DATE '2008-11-10', WEEK(SUNDAY)) AS last_day/*------------* | last_day   | +------------+ | 2008-11-15 | *------------*/\n```\n\nThis returns the last day of the week for a week that starts on a Monday:\n\n```\nSELECT LAST_DAY(DATE '2008-11-10', WEEK(MONDAY)) AS last_day/*------------* | last_day   | +------------+ | 2008-11-16 | *------------*/\n```\n\n"
  },
  {
    "name": "LAST_DAY",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nLAST_DAY(datetime_expression[, date_part])\n```\n\n **Description** \n\nReturns the last day from a datetime expression that contains the date.This is commonly used to return the last day of the month.\n\nYou can optionally specify the date part for which the last day is returned.If this parameter is not used, the default value is`MONTH`.`LAST_DAY`supports the following values for`date_part`:\n\n- `    YEAR`\n- `    QUARTER`\n- `    MONTH`\n- `    WEEK`. Equivalent to 7`    DAY`s.\n- `    WEEK(&lt;WEEKDAY&gt;)`.`    &lt;WEEKDAY&gt;`represents the starting day of the week.Valid values are`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`, and`    SATURDAY`.\n- `    ISOWEEK`. Uses[ISO 8601](https://en.wikipedia.org/wiki/ISO_week_date)week boundaries. ISO weeks beginon Monday.\n- `    ISOYEAR`. Uses the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering year boundary.The ISO year boundary is the Monday of the first week whose Thursday belongsto the corresponding Gregorian calendar year.\n\n **Return Data Type** \n\n`DATE`\n\n **Example** \n\nThese both return the last day of the month:\n\n```\nSELECT LAST_DAY(DATETIME '2008-11-25', MONTH) AS last_day/*------------* | last_day   | +------------+ | 2008-11-30 | *------------*/\n```\n\n```\nSELECT LAST_DAY(DATETIME '2008-11-25') AS last_day/*------------* | last_day   | +------------+ | 2008-11-30 | *------------*/\n```\n\nThis returns the last day of the year:\n\n```\nSELECT LAST_DAY(DATETIME '2008-11-25 15:30:00', YEAR) AS last_day/*------------* | last_day   | +------------+ | 2008-12-31 | *------------*/\n```\n\nThis returns the last day of the week for a week that starts on a Sunday:\n\n```\nSELECT LAST_DAY(DATETIME '2008-11-10 15:30:00', WEEK(SUNDAY)) AS last_day/*------------* | last_day   | +------------+ | 2008-11-15 | *------------*/\n```\n\nThis returns the last day of the week for a week that starts on a Monday:\n\n```\nSELECT LAST_DAY(DATETIME '2008-11-10 15:30:00', WEEK(MONDAY)) AS last_day/*------------* | last_day   | +------------+ | 2008-11-16 | *------------*/\n```\n\n"
  },
  {
    "name": "LAST_VALUE",
    "arguments": [],
    "category": "Navigation functions",
    "description": "```\nLAST_VALUE (value_expression [{RESPECT | IGNORE} NULLS])OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the value of the`value_expression`for the last row in the currentwindow frame.\n\nThis function includes`NULL`values in the calculation unless`IGNORE NULLS`ispresent. If`IGNORE NULLS`is present, the function excludes`NULL`values fromthe calculation.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\n`value_expression`can be any data type that an expression can return.\n\n **Return Data Type** \n\nSame type as`value_expression`.\n\n **Examples** \n\nThe following example computes the slowest time for each division.\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  FORMAT_TIMESTAMP('%X', finish_time) AS finish_time,  division,  FORMAT_TIMESTAMP('%X', slowest_time) AS slowest_time,  TIMESTAMP_DIFF(slowest_time, finish_time, SECOND) AS delta_in_secondsFROM (  SELECT name,  finish_time,  division,  LAST_VALUE(finish_time)    OVER (PARTITION BY division ORDER BY finish_time ASC    ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS slowest_time  FROM finishers);/*-----------------+-------------+----------+--------------+------------------* | name            | finish_time | division | slowest_time | delta_in_seconds | +-----------------+-------------+----------+--------------+------------------+ | Carly Forte     | 03:08:58    | F25-29   | 03:08:58     | 0                | | Sophia Liu      | 02:51:45    | F30-34   | 03:10:14     | 1109             | | Nikki Leith     | 02:59:01    | F30-34   | 03:10:14     | 673              | | Jen Edwards     | 03:06:36    | F30-34   | 03:10:14     | 218              | | Meghan Lederer  | 03:07:41    | F30-34   | 03:10:14     | 153              | | Lauren Reasoner | 03:10:14    | F30-34   | 03:10:14     | 0                | | Lisa Stelzner   | 02:54:11    | F35-39   | 03:06:24     | 733              | | Lauren Matthews | 03:01:17    | F35-39   | 03:06:24     | 307              | | Desiree Berry   | 03:05:42    | F35-39   | 03:06:24     | 42               | | Suzy Slane      | 03:06:24    | F35-39   | 03:06:24     | 0                | *-----------------+-------------+----------+--------------+------------------*/\n```\n\n"
  },
  {
    "name": "LAX_BOOL",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nLAX_BOOL(json_expr)\n```\n\n **Description** \n\nAttempts to convert a JSON value to a SQL`BOOL`value.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON 'true'\n    ```\n    \n    \n\nDetails:\n\n- If`    json_expr`is SQL`    NULL`, the function returns SQL`    NULL`.\n- See the conversion rules in the next section for additional`    NULL`handling.\n\n **Conversion rules** \n\n| From JSON type | To SQL`BOOL` |\n| --- | --- |\n| boolean | If the JSON boolean is`true`, returns`TRUE`.      Otherwise, returns`FALSE`. |\n| string | If the JSON string is`'true'`, returns`TRUE`.      If the JSON string is`'false'`, returns`FALSE`.      If the JSON string is any other value or has whitespace in it,      returns`NULL`.      This conversion is case-insensitive. |\n| number | If the JSON number is a representation of`0`,      returns`FALSE`. Otherwise, returns`TRUE`. |\n| other type or null | `NULL` |\n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\nExample with input that is a JSON boolean:\n\n```\nSELECT LAX_BOOL(JSON 'true') AS result;/*--------* | result | +--------+ | true   | *--------*/\n```\n\nExamples with inputs that are JSON strings:\n\n```\nSELECT LAX_BOOL(JSON '\"true\"') AS result;/*--------* | result | +--------+ | TRUE   | *--------*/\n```\n\n```\nSELECT LAX_BOOL(JSON '\"true \"') AS result;/*--------* | result | +--------+ | NULL   | *--------*/\n```\n\n```\nSELECT LAX_BOOL(JSON '\"foo\"') AS result;/*--------* | result | +--------+ | NULL   | *--------*/\n```\n\nExamples with inputs that are JSON numbers:\n\n```\nSELECT LAX_BOOL(JSON '10') AS result;/*--------* | result | +--------+ | TRUE   | *--------*/\n```\n\n```\nSELECT LAX_BOOL(JSON '0') AS result;/*--------* | result | +--------+ | FALSE  | *--------*/\n```\n\n```\nSELECT LAX_BOOL(JSON '0.0') AS result;/*--------* | result | +--------+ | FALSE  | *--------*/\n```\n\n```\nSELECT LAX_BOOL(JSON '-1.1') AS result;/*--------* | result | +--------+ | TRUE   | *--------*/\n```\n\n"
  },
  {
    "name": "LAX_FLOAT64",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nLAX_FLOAT64(json_expr)\n```\n\n **Description** \n\nAttempts to convert a JSON value to aSQL`FLOAT64`value.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '9.8'\n    ```\n    \n    \n\nDetails:\n\n- If`    json_expr`is SQL`    NULL`, the function returns SQL`    NULL`.\n- See the conversion rules in the next section for additional`    NULL`handling.\n\n **Conversion rules** \n\n| From JSON type | To SQL`FLOAT64` |\n| --- | --- |\n| boolean | `NULL` |\n| string | If the JSON string represents a JSON number, parses it as      a`BIGNUMERIC`value, and then safe casts the result as a`FLOAT64`value.      If the JSON string can't be converted, returns`NULL`. |\n| number | Casts the JSON number as a`FLOAT64`value.      Large JSON numbers are rounded. |\n| other type or null | `NULL` |\n\n **Return type** \n\n`FLOAT64`\n\n **Examples** \n\nExamples with inputs that are JSON numbers:\n\n```\nSELECT LAX_FLOAT64(JSON '9.8') AS result;/*--------* | result | +--------+ | 9.8    | *--------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '9') AS result;/*--------* | result | +--------+ | 9.0    | *--------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '9007199254740993') AS result;/*--------------------* | result             | +--------------------+ | 9007199254740992.0 | *--------------------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '1e100') AS result;/*--------* | result | +--------+ | 1e+100 | *--------*/\n```\n\nExamples with inputs that are JSON booleans:\n\n```\nSELECT LAX_FLOAT64(JSON 'true') AS result;/*--------* | result | +--------+ | NULL   | *--------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON 'false') AS result;/*--------* | result | +--------+ | NULL   | *--------*/\n```\n\nExamples with inputs that are JSON strings:\n\n```\nSELECT LAX_FLOAT64(JSON '\"10\"') AS result;/*--------* | result | +--------+ | 10.0   | *--------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '\"1.1\"') AS result;/*--------* | result | +--------+ | 1.1    | *--------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '\"1.1e2\"') AS result;/*--------* | result | +--------+ | 110.0  | *--------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '\"9007199254740993\"') AS result;/*--------------------* | result             | +--------------------+ | 9007199254740992.0 | *--------------------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '\"+1.5\"') AS result;/*--------* | result | +--------+ | 1.5    | *--------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '\"NaN\"') AS result;/*--------* | result | +--------+ | NaN    | *--------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '\"Inf\"') AS result;/*----------* | result   | +----------+ | Infinity | *----------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '\"-InfiNiTY\"') AS result;/*-----------* | result    | +-----------+ | -Infinity | *-----------*/\n```\n\n```\nSELECT LAX_FLOAT64(JSON '\"foo\"') AS result;/*--------* | result | +--------+ | NULL   | *--------*/\n```\n\n"
  },
  {
    "name": "LAX_INT64",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nLAX_INT64(json_expr)\n```\n\n **Description** \n\nAttempts to convert a JSON value to a SQL`INT64`value.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '999'\n    ```\n    \n    \n\nDetails:\n\n- If`    json_expr`is SQL`    NULL`, the function returns SQL`    NULL`.\n- See the conversion rules in the next section for additional`    NULL`handling.\n\n **Conversion rules** \n\n| From JSON type | To SQL`INT64` |\n| --- | --- |\n| boolean | If the JSON boolean is`true`, returns`1`.      If`false`, returns`0`. |\n| string | If the JSON string represents a JSON number, parses it as      a`BIGNUMERIC`value, and then safe casts the results as an`INT64`value.      If the JSON string can't be converted, returns`NULL`. |\n| number | Casts the JSON number as an`INT64`value.      If the JSON number can't be converted, returns`NULL`. |\n| other type or null | `NULL` |\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\nExamples with inputs that are JSON numbers:\n\n```\nSELECT LAX_INT64(JSON '10') AS result;/*--------* | result | +--------+ | 10     | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '10.0') AS result;/*--------* | result | +--------+ | 10     | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '1.1') AS result;/*--------* | result | +--------+ | 1      | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '3.5') AS result;/*--------* | result | +--------+ | 4      | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '1.1e2') AS result;/*--------* | result | +--------+ | 110    | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '1e100') AS result;/*--------* | result | +--------+ | NULL   | *--------*/\n```\n\nExamples with inputs that are JSON booleans:\n\n```\nSELECT LAX_INT64(JSON 'true') AS result;/*--------* | result | +--------+ | 1      | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON 'false') AS result;/*--------* | result | +--------+ | 0      | *--------*/\n```\n\nExamples with inputs that are JSON strings:\n\n```\nSELECT LAX_INT64(JSON '\"10\"') AS result;/*--------* | result | +--------+ | 10     | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '\"1.1\"') AS result;/*--------* | result | +--------+ | 1      | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '\"1.1e2\"') AS result;/*--------* | result | +--------+ | 110    | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '\"+1.5\"') AS result;/*--------* | result | +--------+ | 2      | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '\"1e100\"') AS result;/*--------* | result | +--------+ | NULL   | *--------*/\n```\n\n```\nSELECT LAX_INT64(JSON '\"foo\"') AS result;/*--------* | result | +--------+ | NULL   | *--------*/\n```\n\n"
  },
  {
    "name": "LAX_STRING",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nLAX_STRING(json_expr)\n```\n\n **Description** \n\nAttempts to convert a JSON value to a SQL`STRING`value.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '\"name\"'\n    ```\n    \n    \n\nDetails:\n\n- If`    json_expr`is SQL`    NULL`, the function returns SQL`    NULL`.\n- See the conversion rules in the next section for additional`    NULL`handling.\n\n **Conversion rules** \n\n| From JSON type | To SQL`STRING` |\n| --- | --- |\n| boolean | If the JSON boolean is`true`, returns`'true'`.      If`false`, returns`'false'`. |\n| string | Returns the JSON string as a`STRING`value. |\n| number | Returns the JSON number as a`STRING`value. |\n| other type or null | `NULL` |\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\nExamples with inputs that are JSON strings:\n\n```\nSELECT LAX_STRING(JSON '\"purple\"') AS result;/*--------* | result | +--------+ | purple | *--------*/\n```\n\n```\nSELECT LAX_STRING(JSON '\"10\"') AS result;/*--------* | result | +--------+ | 10     | *--------*/\n```\n\nExamples with inputs that are JSON booleans:\n\n```\nSELECT LAX_STRING(JSON 'true') AS result;/*--------* | result | +--------+ | true   | *--------*/\n```\n\n```\nSELECT LAX_STRING(JSON 'false') AS result;/*--------* | result | +--------+ | false  | *--------*/\n```\n\nExamples with inputs that are JSON numbers:\n\n```\nSELECT LAX_STRING(JSON '10.0') AS result;/*--------* | result | +--------+ | 10     | *--------*/\n```\n\n```\nSELECT LAX_STRING(JSON '10') AS result;/*--------* | result | +--------+ | 10     | *--------*/\n```\n\n```\nSELECT LAX_STRING(JSON '1e100') AS result;/*--------* | result | +--------+ | 1e+100 | *--------*/\n```\n\n"
  },
  {
    "name": "LEAD",
    "arguments": [],
    "category": "Navigation functions",
    "description": "```\nLEAD (value_expression[, offset [, default_expression]])OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]\n```\n\n **Description** \n\nReturns the value of the`value_expression`on a subsequent row. Changing the`offset`value changes which subsequent row is returned; the default value is`1`, indicating the next row in the window frame. An error occurs if`offset`isNULL or a negative value.\n\nThe optional`default_expression`is used if there isn't a row in the windowframe at the specified offset. This expression must be a constant expression andits type must be implicitly coercible to the type of`value_expression`. If leftunspecified,`default_expression`defaults to NULL.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\n- `    value_expression`can be any data type that can be returned from anexpression.\n- `    offset`must be a non-negative integer literal or parameter.\n- `    default_expression`must be compatible with the value expression type.\n\n **Return Data Type** \n\nSame type as`value_expression`.\n\n **Examples** \n\nThe following example illustrates a basic use of the`LEAD`function.\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  finish_time,  division,  LEAD(name)    OVER (PARTITION BY division ORDER BY finish_time ASC) AS followed_byFROM finishers;/*-----------------+-------------+----------+-----------------* | name            | finish_time | division | followed_by     | +-----------------+-------------+----------+-----------------+ | Carly Forte     | 03:08:58    | F25-29   | NULL            | | Sophia Liu      | 02:51:45    | F30-34   | Nikki Leith     | | Nikki Leith     | 02:59:01    | F30-34   | Jen Edwards     | | Jen Edwards     | 03:06:36    | F30-34   | Meghan Lederer  | | Meghan Lederer  | 03:07:41    | F30-34   | Lauren Reasoner | | Lauren Reasoner | 03:10:14    | F30-34   | NULL            | | Lisa Stelzner   | 02:54:11    | F35-39   | Lauren Matthews | | Lauren Matthews | 03:01:17    | F35-39   | Desiree Berry   | | Desiree Berry   | 03:05:42    | F35-39   | Suzy Slane      | | Suzy Slane      | 03:06:24    | F35-39   | NULL            | *-----------------+-------------+----------+-----------------*/\n```\n\nThis next example uses the optional`offset`parameter.\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  finish_time,  division,  LEAD(name, 2)    OVER (PARTITION BY division ORDER BY finish_time ASC) AS two_runners_backFROM finishers;/*-----------------+-------------+----------+------------------* | name            | finish_time | division | two_runners_back | +-----------------+-------------+----------+------------------+ | Carly Forte     | 03:08:58    | F25-29   | NULL             | | Sophia Liu      | 02:51:45    | F30-34   | Jen Edwards      | | Nikki Leith     | 02:59:01    | F30-34   | Meghan Lederer   | | Jen Edwards     | 03:06:36    | F30-34   | Lauren Reasoner  | | Meghan Lederer  | 03:07:41    | F30-34   | NULL             | | Lauren Reasoner | 03:10:14    | F30-34   | NULL             | | Lisa Stelzner   | 02:54:11    | F35-39   | Desiree Berry    | | Lauren Matthews | 03:01:17    | F35-39   | Suzy Slane       | | Desiree Berry   | 03:05:42    | F35-39   | NULL             | | Suzy Slane      | 03:06:24    | F35-39   | NULL             | *-----------------+-------------+----------+------------------*/\n```\n\nThe following example replaces NULL values with a default value.\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  finish_time,  division,  LEAD(name, 2, 'Nobody')    OVER (PARTITION BY division ORDER BY finish_time ASC) AS two_runners_backFROM finishers;/*-----------------+-------------+----------+------------------* | name            | finish_time | division | two_runners_back | +-----------------+-------------+----------+------------------+ | Carly Forte     | 03:08:58    | F25-29   | Nobody           | | Sophia Liu      | 02:51:45    | F30-34   | Jen Edwards      | | Nikki Leith     | 02:59:01    | F30-34   | Meghan Lederer   | | Jen Edwards     | 03:06:36    | F30-34   | Lauren Reasoner  | | Meghan Lederer  | 03:07:41    | F30-34   | Nobody           | | Lauren Reasoner | 03:10:14    | F30-34   | Nobody           | | Lisa Stelzner   | 02:54:11    | F35-39   | Desiree Berry    | | Lauren Matthews | 03:01:17    | F35-39   | Suzy Slane       | | Desiree Berry   | 03:05:42    | F35-39   | Nobody           | | Suzy Slane      | 03:06:24    | F35-39   | Nobody           | *-----------------+-------------+----------+------------------*/\n```\n\n"
  },
  {
    "name": "LEAST",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nLEAST(X1,...,XN)\n```\n\n **Description** \n\nReturns the least value among`X1,...,XN`. If any argument is`NULL`, returns`NULL`. Otherwise, in the case of floating-point arguments, if any argument is`NaN`, returns`NaN`. In all other cases, returns the value among`X1,...,XN`that has the least value according to the ordering used by the`ORDER BY`clause. The arguments`X1, ..., XN`must be coercible to a common supertype, andthe supertype must support ordering.\n\n| X1,...,XN | LEAST(X1,...,XN) |\n| --- | --- |\n| 3,5,1 | 1 |\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Return Data Types** \n\nData type of the input values.\n\n"
  },
  {
    "name": "LEFT",
    "arguments": [],
    "category": "String functions",
    "description": "```\nLEFT(value, length)\n```\n\n **Description** \n\nReturns a`STRING`or`BYTES`value that consists of the specifiednumber of leftmost characters or bytes from`value`. The`length`is an`INT64`that specifies the length of the returnedvalue. If`value`is of type`BYTES`,`length`is the number of leftmost bytesto return. If`value`is`STRING`,`length`is the number of leftmost charactersto return.\n\nIf`length`is 0, an empty`STRING`or`BYTES`value will bereturned. If`length`is negative, an error will be returned. If`length`exceeds the number of characters or bytes from`value`, the original`value`will be returned.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH examples AS(SELECT 'apple' as exampleUNION ALLSELECT 'banana' as exampleUNION ALLSELECT 'абвгд' as example)SELECT example, LEFT(example, 3) AS left_exampleFROM examples;/*---------+--------------* | example | left_example | +---------+--------------+ | apple   | app          | | banana  | ban          | | абвгд   | абв          | *---------+--------------*/\n```\n\n```\nWITH examples AS(SELECT b'apple' as exampleUNION ALLSELECT b'banana' as exampleUNION ALLSELECT b'\\xab\\xcd\\xef\\xaa\\xbb' as example)SELECT example, LEFT(example, 3) AS left_exampleFROM examples;-- Note that the result of LEFT is of type BYTES, displayed as a base64-encoded string./*----------+--------------* | example  | left_example | +----------+--------------+ | YXBwbGU= | YXBw         | | YmFuYW5h | YmFu         | | q83vqrs= | q83v         | *----------+--------------*/\n```\n\n"
  },
  {
    "name": "LENGTH",
    "arguments": [],
    "category": "String functions",
    "description": "```\nLENGTH(value)\n```\n\n **Description** \n\nReturns the length of the`STRING`or`BYTES`value. The returnedvalue is in characters for`STRING`arguments and in bytes for the`BYTES`argument.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH example AS  (SELECT 'абвгд' AS characters)SELECT  characters,  LENGTH(characters) AS string_example,  LENGTH(CAST(characters AS BYTES)) AS bytes_exampleFROM example;/*------------+----------------+---------------* | characters | string_example | bytes_example | +------------+----------------+---------------+ | абвгд      |              5 |            10 | *------------+----------------+---------------*/\n```\n\n"
  },
  {
    "name": "LN",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nLN(X)\n```\n\n **Description** \n\nComputes the natural logarithm of X. Generates an error if X is less than orequal to zero.\n\n| X | LN(X) |\n| --- | --- |\n| 1.0 | 0.0 |\n| `+inf` | `+inf` |\n| `X &lt; 0` | Error |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "LOG",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nLOG(X [, Y])\n```\n\n **Description** \n\nIf only X is present,`LOG`is a synonym of`LN`. If Y is also present,`LOG`computes the logarithm of X to base Y.\n\n| X | Y | LOG(X, Y) |\n| --- | --- | --- |\n| 100.0 | 10.0 | 2.0 |\n| `-inf` | Any value | `NaN` |\n| Any value | `+inf` | `NaN` |\n| `+inf` | 0.0 < Y < 1.0 | `-inf` |\n| `+inf` | Y > 1.0 | `+inf` |\n| X <= 0 | Any value | Error |\n| Any value | Y <= 0 | Error |\n| Any value | 1.0 | Error |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| `INT64` | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `NUMERIC` | `NUMERIC` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` |\n\n"
  },
  {
    "name": "LOG10",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nLOG10(X)\n```\n\n **Description** \n\nSimilar to`LOG`, but computes logarithm to base 10.\n\n| X | LOG10(X) |\n| --- | --- |\n| 100.0 | 2.0 |\n| `-inf` | `NaN` |\n| `+inf` | `+inf` |\n| X <= 0 | Error |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "LOGICAL_AND",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nLOGICAL_AND(  expression)\n```\n\n **Description** \n\nReturns the logical AND of all non-`NULL`expressions. Returns`NULL`if thereare zero input rows or`expression`evaluates to`NULL`for all rows.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\n **Supported Argument Types** \n\n`BOOL`\n\n **Return Data Types** \n\n`BOOL`\n\n **Examples** \n\n`LOGICAL_AND`returns`FALSE`because not all of the values in the array areless than 3.\n\n```\nSELECT LOGICAL_AND(x &lt; 3) AS logical_and FROM UNNEST([1, 2, 4]) AS x;/*-------------* | logical_and | +-------------+ | FALSE       | *-------------*/\n```\n\n"
  },
  {
    "name": "LOGICAL_OR",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nLOGICAL_OR(  expression)\n```\n\n **Description** \n\nReturns the logical OR of all non-`NULL`expressions. Returns`NULL`if thereare zero input rows or`expression`evaluates to`NULL`for all rows.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\n **Supported Argument Types** \n\n`BOOL`\n\n **Return Data Types** \n\n`BOOL`\n\n **Examples** \n\n`LOGICAL_OR`returns`TRUE`because at least one of the values in the array isless than 3.\n\n```\nSELECT LOGICAL_OR(x &lt; 3) AS logical_or FROM UNNEST([1, 2, 4]) AS x;/*------------* | logical_or | +------------+ | TRUE       | *------------*/\n```\n\n"
  },
  {
    "name": "LOWER",
    "arguments": [],
    "category": "String functions",
    "description": "```\nLOWER(value)\n```\n\n **Description** \n\nFor`STRING`arguments, returns the original string with all alphabeticcharacters in lowercase. Mapping between lowercase and uppercase is doneaccording to the[Unicode Character Database](http://unicode.org/ucd/)without taking into account language-specific mappings.\n\nFor`BYTES`arguments, the argument is treated as ASCII text, with all bytesgreater than 127 left intact.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH items AS  (SELECT    'FOO' as item  UNION ALL  SELECT    'BAR' as item  UNION ALL  SELECT    'BAZ' as item)SELECT  LOWER(item) AS exampleFROM items;/*---------* | example | +---------+ | foo     | | bar     | | baz     | *---------*/\n```\n\n"
  },
  {
    "name": "LPAD",
    "arguments": [],
    "category": "String functions",
    "description": "```\nLPAD(original_value, return_length[, pattern])\n```\n\n **Description** \n\nReturns a`STRING`or`BYTES`value that consists of`original_value`prependedwith`pattern`. The`return_length`is an`INT64`thatspecifies the length of the returned value. If`original_value`is of type`BYTES`,`return_length`is the number of bytes. If`original_value`isof type`STRING`,`return_length`is the number of characters.\n\nThe default value of`pattern`is a blank space.\n\nBoth`original_value`and`pattern`must be the same data type.\n\nIf`return_length`is less than or equal to the`original_value`length, thisfunction returns the`original_value`value, truncated to the value of`return_length`. For example,`LPAD('hello world', 7);`returns`'hello w'`.\n\nIf`original_value`,`return_length`, or`pattern`is`NULL`, this functionreturns`NULL`.\n\nThis function returns an error if:\n\n- `    return_length`is negative\n- `    pattern`is empty\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nSELECT t, len, FORMAT('%T', LPAD(t, len)) AS LPAD FROM UNNEST([  STRUCT('abc' AS t, 5 AS len),  ('abc', 2),  ('例子', 4)]);/*------+-----+----------* | t    | len | LPAD     | |------|-----|----------| | abc  | 5   | \"  abc\"  | | abc  | 2   | \"ab\"     | | 例子  | 4   | \"  例子\" | *------+-----+----------*/\n```\n\n```\nSELECT t, len, pattern, FORMAT('%T', LPAD(t, len, pattern)) AS LPAD FROM UNNEST([  STRUCT('abc' AS t, 8 AS len, 'def' AS pattern),  ('abc', 5, '-'),  ('例子', 5, '中文')]);/*------+-----+---------+--------------* | t    | len | pattern | LPAD         | |------|-----|---------|--------------| | abc  | 8   | def     | \"defdeabc\"   | | abc  | 5   | -       | \"--abc\"      | | 例子  | 5   | 中文    | \"中文中例子\"   | *------+-----+---------+--------------*/\n```\n\n```\nSELECT FORMAT('%T', t) AS t, len, FORMAT('%T', LPAD(t, len)) AS LPAD FROM UNNEST([  STRUCT(b'abc' AS t, 5 AS len),  (b'abc', 2),  (b'\\xab\\xcd\\xef', 4)]);/*-----------------+-----+------------------* | t               | len | LPAD             | |-----------------|-----|------------------| | b\"abc\"          | 5   | b\"  abc\"         | | b\"abc\"          | 2   | b\"ab\"            | | b\"\\xab\\xcd\\xef\" | 4   | b\" \\xab\\xcd\\xef\" | *-----------------+-----+------------------*/\n```\n\n```\nSELECT  FORMAT('%T', t) AS t,  len,  FORMAT('%T', pattern) AS pattern,  FORMAT('%T', LPAD(t, len, pattern)) AS LPADFROM UNNEST([  STRUCT(b'abc' AS t, 8 AS len, b'def' AS pattern),  (b'abc', 5, b'-'),  (b'\\xab\\xcd\\xef', 5, b'\\x00')]);/*-----------------+-----+---------+-------------------------* | t               | len | pattern | LPAD                    | |-----------------|-----|---------|-------------------------| | b\"abc\"          | 8   | b\"def\"  | b\"defdeabc\"             | | b\"abc\"          | 5   | b\"-\"    | b\"--abc\"                | | b\"\\xab\\xcd\\xef\" | 5   | b\"\\x00\" | b\"\\x00\\x00\\xab\\xcd\\xef\" | *-----------------+-----+---------+-------------------------*/\n```\n\n"
  },
  {
    "name": "LTRIM",
    "arguments": [],
    "category": "String functions",
    "description": "```\nLTRIM(value1[, value2])\n```\n\n **Description** \n\nIdentical to[TRIM](#trim), but only removes leading characters.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH items AS  (SELECT '   apple   ' as item  UNION ALL  SELECT '   banana   ' as item  UNION ALL  SELECT '   orange   ' as item)SELECT  CONCAT('#', LTRIM(item), '#') as exampleFROM items;/*-------------* | example     | +-------------+ | #apple   #  | | #banana   # | | #orange   # | *-------------*/\n```\n\n```\nWITH items AS  (SELECT '***apple***' as item  UNION ALL  SELECT '***banana***' as item  UNION ALL  SELECT '***orange***' as item)SELECT  LTRIM(item, '*') as exampleFROM items;/*-----------* | example   | +-----------+ | apple***  | | banana*** | | orange*** | *-----------*/\n```\n\n```\nWITH items AS  (SELECT 'xxxapplexxx' as item  UNION ALL  SELECT 'yyybananayyy' as item  UNION ALL  SELECT 'zzzorangezzz' as item  UNION ALL  SELECT 'xyzpearxyz' as item)\n```\n\n```\nSELECT  LTRIM(item, 'xyz') as exampleFROM items;/*-----------* | example   | +-----------+ | applexxx  | | bananayyy | | orangezzz | | pearxyz   | *-----------*/\n```\n\n"
  },
  {
    "name": "MAKE_INTERVAL",
    "arguments": [],
    "category": "Interval functions",
    "description": "```\nMAKE_INTERVAL([year][, month][, day][, hour][, minute][, second])\n```\n\n **Description** \n\nConstructs an[INTERVAL](/bigquery/docs/reference/standard-sql/data-types#interval_type)object using`INT64`valuesrepresenting the year, month, day, hour, minute, and second. All arguments areoptional,`0`by default, and can be[named arguments](/bigquery/docs/reference/standard-sql/functions-reference#named_arguments).\n\n **Return Data Type** \n\n`INTERVAL`\n\n **Example** \n\n```\nSELECT  MAKE_INTERVAL(1, 6, 15) AS i1,  MAKE_INTERVAL(hour =&gt; 10, second =&gt; 20) AS i2,  MAKE_INTERVAL(1, minute =&gt; 5, day =&gt; 2) AS i3/*--------------+---------------+-------------* | i1           | i2            | i3          | +--------------+---------------+-------------+ | 1-6 15 0:0:0 | 0-0 0 10:0:20 | 1-0 2 0:5:0 | *--------------+---------------+-------------*/\n```\n\n\n<span id=\"json_functions\">\n## JSON functions\n\n</span>\nGoogleSQL for BigQuery supports the following functions, which can retrieve andtransform JSON data.\n\n"
  },
  {
    "name": "MAX",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nMAX(  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the maximum non-`NULL`value in an aggregated group.\n\nCaveats:\n\n- If the aggregated group is empty or the argument is`    NULL`for all rows inthe group, returns`    NULL`.\n- If the argument is`    NaN`for any row in the group, returns`    NaN`.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Supported Argument Types** \n\nAny[orderable data type](/bigquery/docs/reference/standard-sql/data-types#data_type_properties)except for`ARRAY`.\n\n **Return Data Types** \n\nThe data type of the input values.\n\n **Examples** \n\n```\nSELECT MAX(x) AS maxFROM UNNEST([8, 37, 55, 4]) AS x;/*-----* | max | +-----+ | 55  | *-----*/\n```\n\n```\nSELECT x, MAX(x) OVER (PARTITION BY MOD(x, 2)) AS maxFROM UNNEST([8, NULL, 37, 55, NULL, 4]) AS x;/*------+------* | x    | max  | +------+------+ | NULL | NULL | | NULL | NULL | | 8    | 8    | | 4    | 8    | | 37   | 55   | | 55   | 55   | *------+------*/\n```\n\n"
  },
  {
    "name": "MAX_BY",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nMAX_BY(  x, y)\n```\n\n **Description** \n\nSynonym for[ANY_VALUE(x HAVING MAX y)](#any_value).\n\n **Return Data Types** \n\nMatches the input`x`data type.\n\n **Examples** \n\n```\nWITH fruits AS (  SELECT \"apple\"  fruit, 3.55 price UNION ALL  SELECT \"banana\"  fruit, 2.10 price UNION ALL  SELECT \"pear\"  fruit, 4.30 price)SELECT MAX_BY(fruit, price) as fruitFROM fruits;/*-------* | fruit | +-------+ | pear  | *-------*/\n```\n\n"
  },
  {
    "name": "MD5",
    "arguments": [],
    "category": "Hash functions",
    "description": "```\nMD5(input)\n```\n\n **Description** \n\nComputes the hash of the input using the[MD5 algorithm](https://en.wikipedia.org/wiki/MD5). The input can either be`STRING`or`BYTES`. The string version treats the input as an array of bytes.\n\nThis function returns 16 bytes.\n\n **Warning:** MD5 is no longer considered secure.For increased security use another hashing function. **Return type** \n\n`BYTES`\n\n **Example** \n\n```\nSELECT MD5(\"Hello World\") as md5;-- Note that the result of MD5 is of type BYTES, displayed as a base64-encoded string./*--------------------------* | md5                      | +--------------------------+ | sQqNsWTgdUEFt6mb5y4/5Q== | *--------------------------*/\n```\n\n"
  },
  {
    "name": "MIN",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nMIN(  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the minimum non-`NULL`value in an aggregated group.\n\nCaveats:\n\n- If the aggregated group is empty or the argument is`    NULL`for all rows inthe group, returns`    NULL`.\n- If the argument is`    NaN`for any row in the group, returns`    NaN`.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Supported Argument Types** \n\nAny[orderable data type](/bigquery/docs/reference/standard-sql/data-types#data_type_properties)except for`ARRAY`.\n\n **Return Data Types** \n\nThe data type of the input values.\n\n **Examples** \n\n```\nSELECT MIN(x) AS minFROM UNNEST([8, 37, 4, 55]) AS x;/*-----* | min | +-----+ | 4   | *-----*/\n```\n\n```\nSELECT x, MIN(x) OVER (PARTITION BY MOD(x, 2)) AS minFROM UNNEST([8, NULL, 37, 4, NULL, 55]) AS x;/*------+------* | x    | min  | +------+------+ | NULL | NULL | | NULL | NULL | | 8    | 4    | | 4    | 4    | | 37   | 37   | | 55   | 37   | *------+------*/\n```\n\n"
  },
  {
    "name": "MIN_BY",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nMIN_BY(  x, y)\n```\n\n **Description** \n\nSynonym for[ANY_VALUE(x HAVING MIN y)](#any_value).\n\n **Return Data Types** \n\nMatches the input`x`data type.\n\n **Examples** \n\n```\nWITH fruits AS (  SELECT \"apple\"  fruit, 3.55 price UNION ALL  SELECT \"banana\"  fruit, 2.10 price UNION ALL  SELECT \"pear\"  fruit, 4.30 price)SELECT MIN_BY(fruit, price) as fruitFROM fruits;/*--------* | fruit  | +--------+ | banana | *--------*/\n```\n\n"
  },
  {
    "name": "MOD",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nMOD(X, Y)\n```\n\n **Description** \n\nModulo function: returns the remainder of the division of X by Y. Returnedvalue has the same sign as X. An error is generated if Y is 0.\n\n| X | Y | MOD(X, Y) |\n| --- | --- | --- |\n| 25 | 12 | 1 |\n| 25 | 0 | Error |\n\n **Return Data Type** \n\nThe return data type is determined by the argument types with the followingtable.\n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` |\n| --- | --- | --- | --- |\n| `INT64` | `INT64` | `NUMERIC` | `BIGNUMERIC` |\n| `NUMERIC` | `NUMERIC` | `NUMERIC` | `BIGNUMERIC` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` |\n\n"
  },
  {
    "name": "NET.HOST",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.HOST(url)\n```\n\n **Description** \n\nTakes a URL as a`STRING`value and returns the host. For best results, URLvalues should comply with the format as defined by[RFC 3986](https://tools.ietf.org/html/rfc3986#appendix-A). If the URL value does not complywith RFC 3986 formatting, this function makes a best effort to parse the inputand return a relevant result. If the function cannot parse the input, itreturns`NULL`.\n\n **Note:** The function does not perform any normalization. **Return Data Type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT  FORMAT(\"%T\", input) AS input,  description,  FORMAT(\"%T\", NET.HOST(input)) AS host,  FORMAT(\"%T\", NET.PUBLIC_SUFFIX(input)) AS suffix,  FORMAT(\"%T\", NET.REG_DOMAIN(input)) AS domainFROM (  SELECT \"\" AS input, \"invalid input\" AS description  UNION ALL SELECT \"http://abc.xyz\", \"standard URL\"  UNION ALL SELECT \"//user:password@a.b:80/path?query\",                   \"standard URL with relative scheme, port, path and query, but no public suffix\"  UNION ALL SELECT \"https://[::1]:80\", \"standard URL with IPv6 host\"  UNION ALL SELECT \"http://例子.卷筒纸.中国\", \"standard URL with internationalized domain name\"  UNION ALL SELECT \"    www.Example.Co.UK    \",                   \"non-standard URL with spaces, upper case letters, and without scheme\"  UNION ALL SELECT \"mailto:?to=&amp;subject=&amp;body=\", \"URI rather than URL--unsupported\");\n```\n\n| input | description | host | suffix | domain |\n| --- | --- | --- | --- | --- |\n| \"\" | invalid input | NULL | NULL | NULL |\n| \"http://abc.xyz\" | standard URL | \"abc.xyz\" | \"xyz\" | \"abc.xyz\" |\n| \"//user:password@a.b:80/path?query\" | standard URL with relative scheme, port, path and query, but no public suffix | \"a.b\" | NULL | NULL |\n| \"https://[::1]:80\" | standard URL with IPv6 host | \"[::1]\" | NULL | NULL |\n| \"http://例子.卷筒纸.中国\" | standard URL with internationalized domain name | \"例子.卷筒纸.中国\" | \"中国\" | \"卷筒纸.中国\" |\n| \"    www.Example.Co.UK    \" | non-standard URL with spaces, upper case letters, and without scheme | \"www.Example.Co.UK\" | \"Co.UK\" | \"Example.Co.UK\" |\n| \"mailto:?to=&subject=&body=\" | URI rather than URL--unsupported | \"mailto\" | NULL | NULL |\n\n"
  },
  {
    "name": "NET.IPV4_FROM_INT64",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.IPV4_FROM_INT64(integer_value)\n```\n\n **Description** \n\nConverts an IPv4 address from integer format to binary (BYTES) format in networkbyte order. In the integer input, the least significant bit of the IP address isstored in the least significant bit of the integer, regardless of host or clientarchitecture. For example,`1`means`0.0.0.1`, and`0x1FF`means`0.0.1.255`.\n\nThis function checks that either all the most significant 32 bits are 0, or allthe most significant 33 bits are 1 (sign-extended from a 32-bit integer).In other words, the input should be in the range`[-0x80000000, 0xFFFFFFFF]`;otherwise, this function throws an error.\n\nThis function does not support IPv6.\n\n **Return Data Type** \n\nBYTES\n\n **Example** \n\n```\nSELECT x, x_hex, FORMAT(\"%T\", NET.IPV4_FROM_INT64(x)) AS ipv4_from_int64FROM (  SELECT CAST(x_hex AS INT64) x, x_hex  FROM UNNEST([\"0x0\", \"0xABCDEF\", \"0xFFFFFFFF\", \"-0x1\", \"-0x2\"]) AS x_hex);/*-----------------------------------------------* | x          | x_hex      | ipv4_from_int64     | +-----------------------------------------------+ | 0          | 0x0        | b\"\\x00\\x00\\x00\\x00\" | | 11259375   | 0xABCDEF   | b\"\\x00\\xab\\xcd\\xef\" | | 4294967295 | 0xFFFFFFFF | b\"\\xff\\xff\\xff\\xff\" | | -1         | -0x1       | b\"\\xff\\xff\\xff\\xff\" | | -2         | -0x2       | b\"\\xff\\xff\\xff\\xfe\" | *-----------------------------------------------*/\n```\n\n"
  },
  {
    "name": "NET.IPV4_TO_INT64",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.IPV4_TO_INT64(addr_bin)\n```\n\n **Description** \n\nConverts an IPv4 address from binary (BYTES) format in network byte order tointeger format. In the integer output, the least significant bit of the IPaddress is stored in the least significant bit of the integer, regardless ofhost or client architecture. For example,`1`means`0.0.0.1`, and`0x1FF`means`0.0.1.255`. The output is in the range`[0, 0xFFFFFFFF]`.\n\nIf the input length is not 4, this function throws an error.\n\nThis function does not support IPv6.\n\n **Return Data Type** \n\nINT64\n\n **Example** \n\n```\nSELECT  FORMAT(\"%T\", x) AS addr_bin,  FORMAT(\"0x%X\", NET.IPV4_TO_INT64(x)) AS ipv4_to_int64FROMUNNEST([b\"\\x00\\x00\\x00\\x00\", b\"\\x00\\xab\\xcd\\xef\", b\"\\xff\\xff\\xff\\xff\"]) AS x;/*-------------------------------------* | addr_bin            | ipv4_to_int64 | +-------------------------------------+ | b\"\\x00\\x00\\x00\\x00\" | 0x0           | | b\"\\x00\\xab\\xcd\\xef\" | 0xABCDEF      | | b\"\\xff\\xff\\xff\\xff\" | 0xFFFFFFFF    | *-------------------------------------*/\n```\n\n"
  },
  {
    "name": "NET.IP_FROM_STRING",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.IP_FROM_STRING(addr_str)\n```\n\n **Description** \n\nConverts an IPv4 or IPv6 address from text (STRING) format to binary (BYTES)format in network byte order.\n\nThis function supports the following formats for`addr_str`:\n\n- IPv4: Dotted-quad format. For example,`    10.1.2.3`.\n- IPv6: Colon-separated format. For example,`    1234:5678:90ab:cdef:1234:5678:90ab:cdef`. For more examples, see the[IP Version 6 Addressing Architecture](http://www.ietf.org/rfc/rfc2373.txt).\n\nThis function does not support[CIDR notation](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing), such as`10.1.2.3/32`.\n\nIf this function receives a`NULL`input, it returns`NULL`. If the input isconsidered invalid, an`OUT_OF_RANGE`error occurs.\n\n **Return Data Type** \n\nBYTES\n\n **Example** \n\n```\nSELECT  addr_str, FORMAT(\"%T\", NET.IP_FROM_STRING(addr_str)) AS ip_from_stringFROM UNNEST([  '48.49.50.51',  '::1',  '3031:3233:3435:3637:3839:4041:4243:4445',  '::ffff:192.0.2.128']) AS addr_str;/*---------------------------------------------------------------------------------------------------------------* | addr_str                                | ip_from_string                                                      | +---------------------------------------------------------------------------------------------------------------+ | 48.49.50.51                             | b\"0123\"                                                             | | ::1                                     | b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\" | | 3031:3233:3435:3637:3839:4041:4243:4445 | b\"0123456789@ABCDE\"                                                 | | ::ffff:192.0.2.128                      | b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xff\\xc0\\x00\\x02\\x80\" | *---------------------------------------------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "NET.IP_NET_MASK",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.IP_NET_MASK(num_output_bytes, prefix_length)\n```\n\n **Description** \n\nReturns a network mask: a byte sequence with length equal to`num_output_bytes`,where the first`prefix_length`bits are set to 1 and the other bits are set to0.`num_output_bytes`and`prefix_length`are INT64.This function throws an error if`num_output_bytes`is not 4 (for IPv4) or 16(for IPv6). It also throws an error if`prefix_length`is negative or greaterthan`8 * num_output_bytes`.\n\n **Return Data Type** \n\nBYTES\n\n **Example** \n\n```\nSELECT x, y, FORMAT(\"%T\", NET.IP_NET_MASK(x, y)) AS ip_net_maskFROM UNNEST([  STRUCT(4 as x, 0 as y),  (4, 20),  (4, 32),  (16, 0),  (16, 1),  (16, 128)]);/*--------------------------------------------------------------------------------* | x  | y   | ip_net_mask                                                         | +--------------------------------------------------------------------------------+ | 4  | 0   | b\"\\x00\\x00\\x00\\x00\"                                                 | | 4  | 20  | b\"\\xff\\xff\\xf0\\x00\"                                                 | | 4  | 32  | b\"\\xff\\xff\\xff\\xff\"                                                 | | 16 | 0   | b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" | | 16 | 1   | b\"\\x80\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" | | 16 | 128 | b\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\" | *--------------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "NET.IP_TO_STRING",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.IP_TO_STRING(addr_bin)\n```\n\n **Description** Converts an IPv4 or IPv6 address from binary (BYTES) format in network byteorder to text (STRING) format.\n\nIf the input is 4 bytes, this function returns an IPv4 address as a STRING. Ifthe input is 16 bytes, it returns an IPv6 address as a STRING.\n\nIf this function receives a`NULL`input, it returns`NULL`. If the input hasa length different from 4 or 16, an`OUT_OF_RANGE`error occurs.\n\n **Return Data Type** \n\nSTRING\n\n **Example** \n\n```\nSELECT FORMAT(\"%T\", x) AS addr_bin, NET.IP_TO_STRING(x) AS ip_to_stringFROM UNNEST([  b\"0123\",  b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\",  b\"0123456789@ABCDE\",  b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xff\\xc0\\x00\\x02\\x80\"]) AS x;/*---------------------------------------------------------------------------------------------------------------* | addr_bin                                                            | ip_to_string                            | +---------------------------------------------------------------------------------------------------------------+ | b\"0123\"                                                             | 48.49.50.51                             | | b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\" | ::1                                     | | b\"0123456789@ABCDE\"                                                 | 3031:3233:3435:3637:3839:4041:4243:4445 | | b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xff\\xc0\\x00\\x02\\x80\" | ::ffff:192.0.2.128                      | *---------------------------------------------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "NET.IP_TRUNC",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.IP_TRUNC(addr_bin, prefix_length)\n```\n\n **Description** Takes`addr_bin`, an IPv4 or IPv6 address in binary (BYTES) format in networkbyte order, and returns a subnet address in the same format. The result has thesame length as`addr_bin`, where the first`prefix_length`bits are equal tothose in`addr_bin`and the remaining bits are 0.\n\nThis function throws an error if`LENGTH(addr_bin)`is not 4 or 16, or if`prefix_len`is negative or greater than`LENGTH(addr_bin) * 8`.\n\n **Return Data Type** \n\nBYTES\n\n **Example** \n\n```\nSELECT  FORMAT(\"%T\", x) as addr_bin, prefix_length,  FORMAT(\"%T\", NET.IP_TRUNC(x, prefix_length)) AS ip_truncFROM UNNEST([  STRUCT(b\"\\xAA\\xBB\\xCC\\xDD\" as x, 0 as prefix_length),  (b\"\\xAA\\xBB\\xCC\\xDD\", 11), (b\"\\xAA\\xBB\\xCC\\xDD\", 12),  (b\"\\xAA\\xBB\\xCC\\xDD\", 24), (b\"\\xAA\\xBB\\xCC\\xDD\", 32),  (b'0123456789@ABCDE', 80)]);/*-----------------------------------------------------------------------------* | addr_bin            | prefix_length | ip_trunc                              | +-----------------------------------------------------------------------------+ | b\"\\xaa\\xbb\\xcc\\xdd\" | 0             | b\"\\x00\\x00\\x00\\x00\"                   | | b\"\\xaa\\xbb\\xcc\\xdd\" | 11            | b\"\\xaa\\xa0\\x00\\x00\"                   | | b\"\\xaa\\xbb\\xcc\\xdd\" | 12            | b\"\\xaa\\xb0\\x00\\x00\"                   | | b\"\\xaa\\xbb\\xcc\\xdd\" | 24            | b\"\\xaa\\xbb\\xcc\\x00\"                   | | b\"\\xaa\\xbb\\xcc\\xdd\" | 32            | b\"\\xaa\\xbb\\xcc\\xdd\"                   | | b\"0123456789@ABCDE\" | 80            | b\"0123456789\\x00\\x00\\x00\\x00\\x00\\x00\" | *-----------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "NET.PUBLIC_SUFFIX",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.PUBLIC_SUFFIX(url)\n```\n\n **Description** \n\nTakes a URL as a`STRING`value and returns the public suffix (such as`com`,`org`, or`net`). A public suffix is an ICANN domain registered at[publicsuffix.org](https://publicsuffix.org/list/). For best results, URL valuesshould comply with the format as defined by[RFC 3986](https://tools.ietf.org/html/rfc3986#appendix-A). If the URL value does not complywith RFC 3986 formatting, this function makes a best effort to parse the inputand return a relevant result.\n\nThis function returns`NULL`if any of the following is true:\n\n- It cannot parse the host from the input;\n- The parsed host contains adjacent dots in the middle(not leading or trailing);\n- The parsed host does not contain any public suffix.\n\nBefore looking up the public suffix, this function temporarily normalizes thehost by converting uppercase English letters to lowercase and encoding allnon-ASCII characters with[Punycode](https://en.wikipedia.org/wiki/Punycode).The function then returns the public suffix as part of the original host insteadof the normalized host.\n\n **Note:** The function does not perform[Unicode normalization](https://en.wikipedia.org/wiki/Unicode_equivalence). **Note:** The public suffix data at[publicsuffix.org](https://publicsuffix.org/list/)also containsprivate domains. This function ignores the private domains. **Note:** The public suffix data may change over time. Consequently, input thatproduces a`NULL`result now may produce a non-`NULL`value in the future. **Return Data Type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT  FORMAT(\"%T\", input) AS input,  description,  FORMAT(\"%T\", NET.HOST(input)) AS host,  FORMAT(\"%T\", NET.PUBLIC_SUFFIX(input)) AS suffix,  FORMAT(\"%T\", NET.REG_DOMAIN(input)) AS domainFROM (  SELECT \"\" AS input, \"invalid input\" AS description  UNION ALL SELECT \"http://abc.xyz\", \"standard URL\"  UNION ALL SELECT \"//user:password@a.b:80/path?query\",                   \"standard URL with relative scheme, port, path and query, but no public suffix\"  UNION ALL SELECT \"https://[::1]:80\", \"standard URL with IPv6 host\"  UNION ALL SELECT \"http://例子.卷筒纸.中国\", \"standard URL with internationalized domain name\"  UNION ALL SELECT \"    www.Example.Co.UK    \",                   \"non-standard URL with spaces, upper case letters, and without scheme\"  UNION ALL SELECT \"mailto:?to=&amp;subject=&amp;body=\", \"URI rather than URL--unsupported\");\n```\n\n| input | description | host | suffix | domain |\n| --- | --- | --- | --- | --- |\n| \"\" | invalid input | NULL | NULL | NULL |\n| \"http://abc.xyz\" | standard URL | \"abc.xyz\" | \"xyz\" | \"abc.xyz\" |\n| \"//user:password@a.b:80/path?query\" | standard URL with relative scheme, port, path and query, but no public suffix | \"a.b\" | NULL | NULL |\n| \"https://[::1]:80\" | standard URL with IPv6 host | \"[::1]\" | NULL | NULL |\n| \"http://例子.卷筒纸.中国\" | standard URL with internationalized domain name | \"例子.卷筒纸.中国\" | \"中国\" | \"卷筒纸.中国\" |\n| \"    www.Example.Co.UK    \" | non-standard URL with spaces, upper case letters, and without scheme | \"www.Example.Co.UK\" | \"Co.UK\" | \"Example.Co.UK |\n| \"mailto:?to=&subject=&body=\" | URI rather than URL--unsupported | \"mailto\" | NULL | NULL |\n\n"
  },
  {
    "name": "NET.REG_DOMAIN",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.REG_DOMAIN(url)\n```\n\n **Description** \n\nTakes a URL as a string and returns the registered or registrable domain (the[public suffix](#netpublic_suffix)plus one preceding label), as astring. For best results, URL values should comply with the format as defined by[RFC 3986](https://tools.ietf.org/html/rfc3986#appendix-A). If the URL value does not complywith RFC 3986 formatting, this function makes a best effort to parse the inputand return a relevant result.\n\nThis function returns`NULL`if any of the following is true:\n\n- It cannot parse the host from the input;\n- The parsed host contains adjacent dots in the middle(not leading or trailing);\n- The parsed host does not contain any public suffix;\n- The parsed host contains only a public suffix without any preceding label.\n\nBefore looking up the public suffix, this function temporarily normalizes thehost by converting uppercase English letters to lowercase and encoding allnon-ASCII characters with[Punycode](https://en.wikipedia.org/wiki/Punycode). The function thenreturns the registered or registerable domain as part of the original hostinstead of the normalized host.\n\n **Note:** The function does not perform[Unicode normalization](https://en.wikipedia.org/wiki/Unicode_equivalence). **Note:** The public suffix data at[publicsuffix.org](https://publicsuffix.org/list/)also containsprivate domains. This function does not treat a private domain as a publicsuffix. For example, if`us.com`is a private domain in the public suffix data,`NET.REG_DOMAIN(\"foo.us.com\")`returns`us.com`(the public suffix`com`plusthe preceding label`us`) rather than`foo.us.com`(the private domain`us.com`plus the preceding label`foo`). **Note:** The public suffix data may change over time.Consequently, input that produces a`NULL`result now may produce a non-`NULL`value in the future. **Return Data Type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT  FORMAT(\"%T\", input) AS input,  description,  FORMAT(\"%T\", NET.HOST(input)) AS host,  FORMAT(\"%T\", NET.PUBLIC_SUFFIX(input)) AS suffix,  FORMAT(\"%T\", NET.REG_DOMAIN(input)) AS domainFROM (  SELECT \"\" AS input, \"invalid input\" AS description  UNION ALL SELECT \"http://abc.xyz\", \"standard URL\"  UNION ALL SELECT \"//user:password@a.b:80/path?query\",                   \"standard URL with relative scheme, port, path and query, but no public suffix\"  UNION ALL SELECT \"https://[::1]:80\", \"standard URL with IPv6 host\"  UNION ALL SELECT \"http://例子.卷筒纸.中国\", \"standard URL with internationalized domain name\"  UNION ALL SELECT \"    www.Example.Co.UK    \",                   \"non-standard URL with spaces, upper case letters, and without scheme\"  UNION ALL SELECT \"mailto:?to=&amp;subject=&amp;body=\", \"URI rather than URL--unsupported\");\n```\n\n| input | description | host | suffix | domain |\n| --- | --- | --- | --- | --- |\n| \"\" | invalid input | NULL | NULL | NULL |\n| \"http://abc.xyz\" | standard URL | \"abc.xyz\" | \"xyz\" | \"abc.xyz\" |\n| \"//user:password@a.b:80/path?query\" | standard URL with relative scheme, port, path and query, but no public suffix | \"a.b\" | NULL | NULL |\n| \"https://[::1]:80\" | standard URL with IPv6 host | \"[::1]\" | NULL | NULL |\n| \"http://例子.卷筒纸.中国\" | standard URL with internationalized domain name | \"例子.卷筒纸.中国\" | \"中国\" | \"卷筒纸.中国\" |\n| \"    www.Example.Co.UK    \" | non-standard URL with spaces, upper case letters, and without scheme | \"www.Example.Co.UK\" | \"Co.UK\" | \"Example.Co.UK\" |\n| \"mailto:?to=&subject=&body=\" | URI rather than URL--unsupported | \"mailto\" | NULL | NULL |\n\n"
  },
  {
    "name": "NET.SAFE_IP_FROM_STRING",
    "arguments": [],
    "category": "Net functions",
    "description": "```\nNET.SAFE_IP_FROM_STRING(addr_str)\n```\n\n **Description** \n\nSimilar to[NET.IP_FROM_STRING](#netip_from_string), but returns`NULL`instead of throwing an error if the input is invalid.\n\n **Return Data Type** \n\nBYTES\n\n **Example** \n\n```\nSELECT  addr_str,  FORMAT(\"%T\", NET.SAFE_IP_FROM_STRING(addr_str)) AS safe_ip_from_stringFROM UNNEST([  '48.49.50.51',  '::1',  '3031:3233:3435:3637:3839:4041:4243:4445',  '::ffff:192.0.2.128',  '48.49.50.51/32',  '48.49.50',  '::wxyz']) AS addr_str;/*---------------------------------------------------------------------------------------------------------------* | addr_str                                | safe_ip_from_string                                                 | +---------------------------------------------------------------------------------------------------------------+ | 48.49.50.51                             | b\"0123\"                                                             | | ::1                                     | b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\" | | 3031:3233:3435:3637:3839:4041:4243:4445 | b\"0123456789@ABCDE\"                                                 | | ::ffff:192.0.2.128                      | b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xff\\xc0\\x00\\x02\\x80\" | | 48.49.50.51/32                          | NULL                                                                | | 48.49.50                                | NULL                                                                | | ::wxyz                                  | NULL                                                                | *---------------------------------------------------------------------------------------------------------------*/\n```\n\n\n<span id=\"numbering_functions\">\n## Numbering functions\n\n</span>\nGoogleSQL for BigQuery supports numbering functions.Numbering functions are a subset of window functions. To create awindow function call and learn about the syntax for window functions,see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\nNumbering functions assign integer values to each row based on their positionwithin the specified window. The`OVER`clause syntax varies acrossnumbering functions.\n\n"
  },
  {
    "name": "NORMALIZE",
    "arguments": [],
    "category": "String functions",
    "description": "```\nNORMALIZE(value[, normalization_mode])\n```\n\n **Description** \n\nTakes a string value and returns it as a normalized string. If you do notprovide a normalization mode,`NFC`is used.\n\n[Normalization](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization)is used to ensure thattwo strings are equivalent. Normalization is often used in situations in whichtwo strings render the same on the screen but have different Unicode codepoints.\n\n`NORMALIZE`supports four optional normalization modes:\n\n| Value | Name | Description |\n| --- | --- | --- |\n| `NFC` | Normalization Form Canonical Composition | Decomposes and recomposes characters by canonical equivalence. |\n| `NFKC` | Normalization Form Compatibility Composition | Decomposes characters by compatibility, then recomposes them by canonical equivalence. |\n| `NFD` | Normalization Form Canonical Decomposition | Decomposes characters by canonical equivalence, and multiple combining characters are arranged in a specific order. |\n| `NFKD` | Normalization Form Compatibility Decomposition | Decomposes characters by compatibility, and multiple combining characters are arranged in a specific order. |\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n```\nSELECT a, b, a = b as normalizedFROM (SELECT NORMALIZE('\\u00ea') as a, NORMALIZE('\\u0065\\u0302') as b);/*---+---+------------* | a | b | normalized | +---+---+------------+ | ê | ê | true       | *---+---+------------*/\n```\n\nThe following example normalizes different space characters.\n\n```\nWITH EquivalentNames AS (  SELECT name  FROM UNNEST([      'Jane\\u2004Doe',      'John\\u2004Smith',      'Jane\\u2005Doe',      'Jane\\u2006Doe',      'John Smith']) AS name)SELECT  NORMALIZE(name, NFKC) AS normalized_name,  COUNT(*) AS name_countFROM EquivalentNamesGROUP BY 1;/*-----------------+------------* | normalized_name | name_count | +-----------------+------------+ | John Smith      | 2          | | Jane Doe        | 3          | *-----------------+------------*/\n```\n\n"
  },
  {
    "name": "NORMALIZE_AND_CASEFOLD",
    "arguments": [],
    "category": "String functions",
    "description": "```\nNORMALIZE_AND_CASEFOLD(value[, normalization_mode])\n```\n\n **Description** \n\nTakes a string value and returns it as a normalized string. If you do notprovide a normalization mode,`NFC`is used.\n\n[Normalization](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization)is used to ensure thattwo strings are equivalent. Normalization is often used in situations in whichtwo strings render the same on the screen but have different Unicode codepoints.\n\n[Case folding](https://en.wikipedia.org/wiki/Letter_case#Case_folding)is used for the caselesscomparison of strings. If you need to compare strings and case should not beconsidered, use`NORMALIZE_AND_CASEFOLD`, otherwise use[NORMALIZE](#normalize).\n\n`NORMALIZE_AND_CASEFOLD`supports four optional normalization modes:\n\n| Value | Name | Description |\n| --- | --- | --- |\n| `NFC` | Normalization Form Canonical Composition | Decomposes and recomposes characters by canonical equivalence. |\n| `NFKC` | Normalization Form Compatibility Composition | Decomposes characters by compatibility, then recomposes them by canonical equivalence. |\n| `NFD` | Normalization Form Canonical Decomposition | Decomposes characters by canonical equivalence, and multiple combining characters are arranged in a specific order. |\n| `NFKD` | Normalization Form Compatibility Decomposition | Decomposes characters by compatibility, and multiple combining characters are arranged in a specific order. |\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n```\nSELECT  a, b,  NORMALIZE(a) = NORMALIZE(b) as normalized,  NORMALIZE_AND_CASEFOLD(a) = NORMALIZE_AND_CASEFOLD(b) as normalized_with_case_foldingFROM (SELECT 'The red barn' AS a, 'The Red Barn' AS b);/*--------------+--------------+------------+------------------------------* | a            | b            | normalized | normalized_with_case_folding | +--------------+--------------+------------+------------------------------+ | The red barn | The Red Barn | false      | true                         | *--------------+--------------+------------+------------------------------*/\n```\n\n```\nWITH Strings AS (  SELECT '\\u2168' AS a, 'IX' AS b UNION ALL  SELECT '\\u0041\\u030A', '\\u00C5')SELECT a, b,  NORMALIZE_AND_CASEFOLD(a, NFD)=NORMALIZE_AND_CASEFOLD(b, NFD) AS nfd,  NORMALIZE_AND_CASEFOLD(a, NFC)=NORMALIZE_AND_CASEFOLD(b, NFC) AS nfc,  NORMALIZE_AND_CASEFOLD(a, NFKD)=NORMALIZE_AND_CASEFOLD(b, NFKD) AS nkfd,  NORMALIZE_AND_CASEFOLD(a, NFKC)=NORMALIZE_AND_CASEFOLD(b, NFKC) AS nkfcFROM Strings;/*---+----+-------+-------+------+------* | a | b  | nfd   | nfc   | nkfd | nkfc | +---+----+-------+-------+------+------+ | Ⅸ | IX | false | false | true | true | | Å | Å  | true  | true  | true | true | *---+----+-------+-------+------+------*/\n```\n\n"
  },
  {
    "name": "NTH_VALUE",
    "arguments": [],
    "category": "Navigation functions",
    "description": "```\nNTH_VALUE (value_expression, constant_integer_expression [{RESPECT | IGNORE} NULLS])OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the value of`value_expression`at the Nth row of the current windowframe, where Nth is defined by`constant_integer_expression`. Returns NULL ifthere is no such row.\n\nThis function includes`NULL`values in the calculation unless`IGNORE NULLS`ispresent. If`IGNORE NULLS`is present, the function excludes`NULL`values fromthe calculation.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\n- `    value_expression`can be any data type that can be returned from anexpression.\n- `    constant_integer_expression`can be any constant expression that returns aninteger.\n\n **Return Data Type** \n\nSame type as`value_expression`.\n\n **Examples** \n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 3:07:41', 'F30-34'  UNION ALL SELECT 'Carly Forte', TIMESTAMP '2016-10-18 3:08:58', 'F25-29'  UNION ALL SELECT 'Lauren Reasoner', TIMESTAMP '2016-10-18 3:10:14', 'F30-34')SELECT name,  FORMAT_TIMESTAMP('%X', finish_time) AS finish_time,  division,  FORMAT_TIMESTAMP('%X', fastest_time) AS fastest_time,  FORMAT_TIMESTAMP('%X', second_fastest) AS second_fastestFROM (  SELECT name,  finish_time,  division,finishers,  FIRST_VALUE(finish_time)    OVER w1 AS fastest_time,  NTH_VALUE(finish_time, 2)    OVER w1 as second_fastest  FROM finishers  WINDOW w1 AS (    PARTITION BY division ORDER BY finish_time ASC    ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING));/*-----------------+-------------+----------+--------------+----------------* | name            | finish_time | division | fastest_time | second_fastest | +-----------------+-------------+----------+--------------+----------------+ | Carly Forte     | 03:08:58    | F25-29   | 03:08:58     | NULL           | | Sophia Liu      | 02:51:45    | F30-34   | 02:51:45     | 02:59:01       | | Nikki Leith     | 02:59:01    | F30-34   | 02:51:45     | 02:59:01       | | Jen Edwards     | 03:06:36    | F30-34   | 02:51:45     | 02:59:01       | | Meghan Lederer  | 03:07:41    | F30-34   | 02:51:45     | 02:59:01       | | Lauren Reasoner | 03:10:14    | F30-34   | 02:51:45     | 02:59:01       | | Lisa Stelzner   | 02:54:11    | F35-39   | 02:54:11     | 03:01:17       | | Lauren Matthews | 03:01:17    | F35-39   | 02:54:11     | 03:01:17       | | Desiree Berry   | 03:05:42    | F35-39   | 02:54:11     | 03:01:17       | | Suzy Slane      | 03:06:24    | F35-39   | 02:54:11     | 03:01:17       | *-----------------+-------------+----------+--------------+----------------*/\n```\n\n"
  },
  {
    "name": "NTILE",
    "arguments": [],
    "category": "Numbering functions",
    "description": "```\nNTILE(constant_integer_expression)OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]\n```\n\n **Description** \n\nThis function divides the rows into`constant_integer_expression`buckets based on row ordering and returns the 1-based bucket number that isassigned to each row. The number of rows in the buckets can differ by at most 1.The remainder values (the remainder of number of rows divided by buckets) aredistributed one for each bucket, starting with bucket 1. If`constant_integer_expression`evaluates to NULL, 0 or negative, anerror is provided.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Type** \n\n`INT64`\n\n **Example** \n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 2:59:01', 'F30-34')SELECT name,  finish_time,  division,  NTILE(3) OVER (PARTITION BY division ORDER BY finish_time ASC) AS finish_rankFROM finishers;/*-----------------+------------------------+----------+-------------* | name            | finish_time            | division | finish_rank | +-----------------+------------------------+----------+-------------+ | Sophia Liu      | 2016-10-18 09:51:45+00 | F30-34   | 1           | | Meghan Lederer  | 2016-10-18 09:59:01+00 | F30-34   | 1           | | Nikki Leith     | 2016-10-18 09:59:01+00 | F30-34   | 2           | | Jen Edwards     | 2016-10-18 10:06:36+00 | F30-34   | 3           | | Lisa Stelzner   | 2016-10-18 09:54:11+00 | F35-39   | 1           | | Lauren Matthews | 2016-10-18 10:01:17+00 | F35-39   | 1           | | Desiree Berry   | 2016-10-18 10:05:42+00 | F35-39   | 2           | | Suzy Slane      | 2016-10-18 10:06:24+00 | F35-39   | 3           | *-----------------+------------------------+----------+-------------*/\n```\n\n"
  },
  {
    "name": "OCTET_LENGTH",
    "arguments": [],
    "category": "String functions",
    "description": "```\nOCTET_LENGTH(value)\n```\n\nAlias for[BYTE_LENGTH](#byte_length).\n\n"
  },
  {
    "name": "OFFSET AND ORDINAL",
    "arguments": [],
    "category": "Array functions",
    "description": "For information about using`OFFSET`and`ORDINAL`with arrays, see[Array subscript operator](#array_subscript_operator)and[Accessing arrayelements](/bigquery/docs/arrays#accessing_array_elements).\n\n\n<span id=\"bit_functions\">\n## Bit functions\n\n</span>\nGoogleSQL for BigQuery supports the following bit functions.\n\n"
  },
  {
    "name": "OTHER CONVERSION FUNCTIONS",
    "arguments": [],
    "category": "Conversion functions",
    "description": "You can learn more about these conversion functions elsewhere in thedocumentation:\n\n| Conversion function | From | To |\n| --- | --- | --- |\n| [ARRAY_TO_STRING](#array_to_string) | ARRAY | STRING |\n| [BOOL](#bool_for_json) | JSON | BOOL |\n| [DATE](#date) | Various data types | DATE |\n| [DATE_FROM_UNIX_DATE](#date_from_unix_date) | INT64 | DATE |\n| [DATETIME](#datetime) | Various data types | DATETIME |\n| [FLOAT64](#double_for_json) | JSON | FLOAT64 |\n| [FROM_BASE32](#from_base32) | STRING | BYTEs |\n| [FROM_BASE64](#from_base64) | STRING | BYTES |\n| [FROM_HEX](#from_hex) | STRING | BYTES |\n| [INT64](#int64_for_json) | JSON | INT64 |\n| [PARSE_DATE](#parse_date) | STRING | DATE |\n| [PARSE_DATETIME](#parse_datetime) | STRING | DATETIME |\n| [PARSE_JSON](#parse_json) | STRING | JSON |\n| [PARSE_TIME](#parse_time) | STRING | TIME |\n| [PARSE_TIMESTAMP](#parse_timestamp) | STRING | TIMESTAMP |\n| [SAFE_CONVERT_BYTES_TO_STRING](#safe_convert_bytes_to_string) | BYTES | STRING |\n| [STRING](#string) | TIMESTAMP | STRING |\n| [STRING](#string_for_json) | JSON | STRING |\n| [TIME](#time) | Various data types | TIME |\n| [TIMESTAMP](#timestamp) | Various data types | TIMESTAMP |\n| [TIMESTAMP_MICROS](#timestamp_micros) | INT64 | TIMESTAMP |\n| [TIMESTAMP_MILLIS](#timestamp_millis) | INT64 | TIMESTAMP |\n| [TIMESTAMP_SECONDS](#timestamp_seconds) | INT64 | TIMESTAMP |\n| [TO_BASE32](#to_base32) | BYTES | STRING |\n| [TO_BASE64](#to_base64) | BYTES | STRING |\n| [TO_HEX](#to_hex) | BYTES | STRING |\n| [TO_JSON](#to_json) | All data types | JSON |\n| [TO_JSON_STRING](#to_json_string) | All data types | STRING |\n\n\n<span id=\"date_functions\">\n## Date functions\n\n</span>\nGoogleSQL for BigQuery supports the following date functions.\n\n"
  },
  {
    "name": "PARSE_BIGNUMERIC",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nPARSE_BIGNUMERIC(string_expression)\n```\n\n **Description** \n\nConverts a`STRING`to a`BIGNUMERIC`value.\n\nThe numeric literal contained in the string must not exceed the[maximum precision or range](/bigquery/docs/reference/standard-sql/data-types#decimal_types)of the`BIGNUMERIC`type, or anerror occurs. If the number of digits after the decimal point exceeds 38, thenthe resulting`BIGNUMERIC`value rounds[half away from zero](https://en.wikipedia.org/wiki/Rounding#Round_half_away_from_zero)to have 38 digits after thedecimal point.\n\n```\n-- This example shows how a string with a decimal point is parsed.SELECT PARSE_BIGNUMERIC(\"123.45\") AS parsed/*--------* | parsed | +--------+ | 123.45 | *--------*/-- This example shows how a string with an exponent is parsed.SELECT PARSE_BIGNUMERIC(\"123.456E37\") AS parsed/*-----------------------------------------* | parsed                                  | +-----------------------------------------+ | 123400000000000000000000000000000000000 | *-----------------------------------------*/-- This example shows the rounding when digits after the decimal point exceeds 38.SELECT PARSE_BIGNUMERIC(\"1.123456789012345678901234567890123456789\") as parsed/*------------------------------------------* | parsed                                   | +------------------------------------------+ | 1.12345678901234567890123456789012345679 | *------------------------------------------*/\n```\n\nThis funcion is similar to using the[CAST AS BIGNUMERIC](#cast_bignumeric)function except that the`PARSE_BIGNUMERIC`function only accepts string inputsand allows the following in the string:\n\n- Spaces between the sign (+/-) and the number\n- Signs (+/-) after the number\n\nRules for valid input strings:\n\n| Rule | Example Input | Output |\n| --- | --- | --- |\n| The string can only contain digits, commas, decimal points and signs. | \"- 12,34567,89.0\" | -123456789 |\n| Whitespaces are allowed anywhere except between digits. | \"  -  12.345  \" | -12.345 |\n| Only digits and commas are allowed before the decimal point. | \" 12,345,678\" | 12345678 |\n| Only digits are allowed after the decimal point. | \"1.234 \" | 1.234 |\n| Use`E`or`e`for exponents. After the`e`, digits and a leading sign indicator are allowed. | \" 123.45e-1\" | 12.345 |\n| If the integer part is not empty, then it must contain at least one        digit. | \" 0,.12 -\" | -0.12 |\n| If the string contains a decimal point, then it must contain at least        one digit. | \" .1\" | 0.1 |\n| The string cannot contain more than one sign. | \" 0.5 +\" | 0.5 |\n\n **Return Data Type** \n\n`BIGNUMERIC`\n\n **Examples** \n\nThis example shows an input with spaces before, after, and between thesign and the number:\n\n```\nSELECT PARSE_BIGNUMERIC(\"  -  12.34 \") as parsed;/*--------* | parsed | +--------+ | -12.34 | *--------*/\n```\n\nThis example shows an input with an exponent as well as the sign after thenumber:\n\n```\nSELECT PARSE_BIGNUMERIC(\"12.34e-1-\") as parsed;/*--------* | parsed | +--------+ | -1.234 | *--------*/\n```\n\nThis example shows an input with multiple commas in the integer part of thenumber:\n\n```\nSELECT PARSE_BIGNUMERIC(\"  1,2,,3,.45 + \") as parsed;/*--------* | parsed | +--------+ | 123.45 | *--------*/\n```\n\nThis example shows an input with a decimal point and no digits in the wholenumber part:\n\n```\nSELECT PARSE_BIGNUMERIC(\".1234  \") as parsed;/*--------* | parsed | +--------+ | 0.1234 | *--------*/\n```\n\n **Examples of invalid inputs** \n\nThis example is invalid because the whole number part contains no digits:\n\n```\nSELECT PARSE_BIGNUMERIC(\",,,.1234  \") as parsed;\n```\n\nThis example is invalid because there are whitespaces between digits:\n\n```\nSELECT PARSE_BIGNUMERIC(\"1  23.4 5  \") as parsed;\n```\n\nThis example is invalid because the number is empty except for an exponent:\n\n```\nSELECT PARSE_BIGNUMERIC(\"  e1 \") as parsed;\n```\n\nThis example is invalid because the string contains multiple signs:\n\n```\nSELECT PARSE_BIGNUMERIC(\"  - 12.3 - \") as parsed;\n```\n\nThis example is invalid because the value of the number falls outside the rangeof`BIGNUMERIC`:\n\n```\nSELECT PARSE_BIGNUMERIC(\"12.34E100 \") as parsed;\n```\n\nThis example is invalid because the string contains invalid characters:\n\n```\nSELECT PARSE_BIGNUMERIC(\"$12.34\") as parsed;\n```\n\n"
  },
  {
    "name": "PARSE_DATE",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nPARSE_DATE(format_string, date_string)\n```\n\n **Description** \n\nConverts a[string representation of date](#format_date)to a`DATE`object.\n\n`format_string`contains the[format elements](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)that define how`date_string`is formatted. Each element in`date_string`must have a corresponding element in`format_string`. Thelocation of each element in`format_string`must match the location ofeach element in`date_string`.\n\n```\n-- This works because elements on both sides match.SELECT PARSE_DATE('%A %b %e %Y', 'Thursday Dec 25 2008')-- This produces an error because the year element is in different locations.SELECT PARSE_DATE('%Y %A %b %e', 'Thursday Dec 25 2008')-- This produces an error because one of the year elements is missing.SELECT PARSE_DATE('%A %b %e', 'Thursday Dec 25 2008')-- This works because %F can find all matching elements in date_string.SELECT PARSE_DATE('%F', '2000-12-30')\n```\n\nWhen using`PARSE_DATE`, keep the following in mind:\n\n-  **Unspecified fields.** Any unspecified field is initialized from`    1970-01-01`.\n-  **Case insensitivity.** Names, such as`    Monday`,`    February`, and so on, arecase insensitive.\n-  **Whitespace.** One or more consecutive white spaces in the format stringmatches zero or more consecutive white spaces in the date string. Inaddition, leading and trailing white spaces in the date string are alwaysallowed -- even if they are not in the format string.\n-  **Format precedence.** When two (or more) format elements have overlappinginformation (for example both`    %F`and`    %Y`affect the year), the last onegenerally overrides any earlier ones.\n\n **Return Data Type** \n\nDATE\n\n **Examples** \n\nThis example converts a`MM/DD/YY`formatted string to a`DATE`object:\n\n```\nSELECT PARSE_DATE('%x', '12/25/08') AS parsed;/*------------* | parsed     | +------------+ | 2008-12-25 | *------------*/\n```\n\nThis example converts a`YYYYMMDD`formatted string to a`DATE`object:\n\n```\nSELECT PARSE_DATE('%Y%m%d', '20081225') AS parsed;/*------------* | parsed     | +------------+ | 2008-12-25 | *------------*/\n```\n\n"
  },
  {
    "name": "PARSE_DATETIME",
    "arguments": [],
    "category": "Datetime functions",
    "description": "```\nPARSE_DATETIME(format_string, datetime_string)\n```\n\n **Description** \n\nConverts a[string representation of a datetime](#format_datetime)to a`DATETIME`object.\n\n`format_string`contains the[format elements](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)that define how`datetime_string`is formatted. Each element in`datetime_string`must have a corresponding element in`format_string`. Thelocation of each element in`format_string`must match the location ofeach element in`datetime_string`.\n\n```\n-- This works because elements on both sides match.SELECT PARSE_DATETIME(\"%a %b %e %I:%M:%S %Y\", \"Thu Dec 25 07:30:00 2008\")-- This produces an error because the year element is in different locations.SELECT PARSE_DATETIME(\"%a %b %e %Y %I:%M:%S\", \"Thu Dec 25 07:30:00 2008\")-- This produces an error because one of the year elements is missing.SELECT PARSE_DATETIME(\"%a %b %e %I:%M:%S\", \"Thu Dec 25 07:30:00 2008\")-- This works because %c can find all matching elements in datetime_string.SELECT PARSE_DATETIME(\"%c\", \"Thu Dec 25 07:30:00 2008\")\n```\n\nThe format string fully supports most format elements, except for`%P`.\n\n`PARSE_DATETIME`parses`string`according to the following rules:\n\n-  **Unspecified fields.** Any unspecified field is initialized from`    1970-01-01 00:00:00.0`. For example, if the year is unspecified then itdefaults to`    1970`.\n-  **Case insensitivity.** Names, such as`    Monday`and`    February`,are case insensitive.\n-  **Whitespace.** One or more consecutive white spaces in the format stringmatches zero or more consecutive white spaces in the`    DATETIME`string. Leading and trailingwhite spaces in the`    DATETIME`string are alwaysallowed, even if they are not in the format string.\n-  **Format precedence.** When two or more format elements have overlappinginformation, the last one generally overrides any earlier ones, with someexceptions. For example, both`    %F`and`    %Y`affect the year, so the earlierelement overrides the later. See the descriptionsof`    %s`,`    %C`, and`    %y`in[Supported Format Elements For DATETIME](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time).\n-  **Format divergence.** `    %p`can be used with`    am`,`    AM`,`    pm`, and`    PM`.\n\n **Return Data Type** \n\n`DATETIME`\n\n **Examples** \n\nThe following examples parse a`STRING`literal as a`DATETIME`.\n\n```\nSELECT PARSE_DATETIME('%Y-%m-%d %H:%M:%S', '1998-10-18 13:45:55') AS datetime;/*---------------------* | datetime            | +---------------------+ | 1998-10-18T13:45:55 | *---------------------*/\n```\n\n```\nSELECT PARSE_DATETIME('%m/%d/%Y %I:%M:%S %p', '8/30/2018 2:23:38 pm') AS datetime/*---------------------* | datetime            | +---------------------+ | 2018-08-30T14:23:38 | *---------------------*/\n```\n\nThe following example parses a`STRING`literalcontaining a date in a natural language format as a`DATETIME`.\n\n```\nSELECT PARSE_DATETIME('%A, %B %e, %Y','Wednesday, December 19, 2018')  AS datetime;/*---------------------* | datetime            | +---------------------+ | 2018-12-19T00:00:00 | *---------------------*/\n```\n\n\n<span id=\"debugging_functions\">\n## Debugging functions\n\n</span>\nGoogleSQL for BigQuery supports the following debugging functions.\n\n"
  },
  {
    "name": "PARSE_JSON",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nPARSE_JSON(json_string_expr[, wide_number_mode=&gt;{ 'exact' | 'round' }])\n```\n\n **Description** \n\nConverts a JSON-formatted`STRING`value to a`JSON`value.\n\nArguments:\n\n- `    json_string_expr`: A JSON-formatted string. For example:\n    \n    \n    ```\n    '{\"class\": {\"students\": [{\"name\": \"Jane\"}]}}'\n    ```\n    \n    \n- `    wide_number_mode`: Optional mandatory-named argument that determines how tohandle numbers that cannot be stored in a`    JSON`value without the loss ofprecision. If used,`    wide_number_mode`must include one of these values:\n    \n    \n    - `        exact`(default): Only accept numbers that can be stored without lossof precision. If a number that cannot be stored without loss ofprecision is encountered, the function throws an error.\n    - `        round`: If a number that cannot be stored without loss of precision isencountered, attempt to round it to a number that can be stored withoutloss of precision. If the number cannot be rounded, the function throwsan error.If a number appears in a JSON object or array, the`    wide_number_mode`argument is applied to the number in the object or array.\n    \n    \n\nNumbers from the following domains can be stored in JSON without loss ofprecision:\n\n- 64-bit signed/unsigned integers, such as`    INT64`\n- `    FLOAT64`\n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nIn the following example, a JSON-formatted string is converted to`JSON`.\n\n```\nSELECT PARSE_JSON('{\"coordinates\": [10, 20], \"id\": 1}') AS json_data;/*--------------------------------* | json_data                      | +--------------------------------+ | {\"coordinates\":[10,20],\"id\":1} | *--------------------------------*/\n```\n\nThe following queries fail because:\n\n- The number that was passed in cannot be stored without loss of precision.\n- `    wide_number_mode=&gt;'exact'`is used implicitly in the first query andexplicitly in the second query.\n\n```\nSELECT PARSE_JSON('{\"id\": 922337203685477580701}') AS json_data; -- failsSELECT PARSE_JSON('{\"id\": 922337203685477580701}', wide_number_mode=&gt;'exact') AS json_data; -- fails\n```\n\nThe following query rounds the number to a number that can be stored in JSON.\n\n```\nSELECT PARSE_JSON('{\"id\": 922337203685477580701}', wide_number_mode=&gt;'round') AS json_data;/*------------------------------* | json_data                    | +------------------------------+ | {\"id\":9.223372036854776e+20} | *------------------------------*/\n```\n\n"
  },
  {
    "name": "PARSE_NUMERIC",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nPARSE_NUMERIC(string_expression)\n```\n\n **Description** \n\nConverts a`STRING`to a`NUMERIC`value.\n\nThe numeric literal contained in the string must not exceed the[maximum precision or range](/bigquery/docs/reference/standard-sql/data-types#decimal_types)of the`NUMERIC`type, or an erroroccurs. If the number of digits after the decimal point exceeds nine, then theresulting`NUMERIC`value rounds[half away from zero](https://en.wikipedia.org/wiki/Rounding#Round_half_away_from_zero)to have nine digits after thedecimal point.\n\n```\n-- This example shows how a string with a decimal point is parsed.SELECT PARSE_NUMERIC(\"123.45\") AS parsed/*--------* | parsed | +--------+ | 123.45 | *--------*/-- This example shows how a string with an exponent is parsed.SELECT PARSE_NUMERIC(\"12.34E27\") as parsed/*-------------------------------* | parsed                        | +-------------------------------+ | 12340000000000000000000000000 | *-------------------------------*/-- This example shows the rounding when digits after the decimal point exceeds 9.SELECT PARSE_NUMERIC(\"1.0123456789\") as parsed/*-------------* | parsed      | +-------------+ | 1.012345679 | *-------------*/\n```\n\nThis function is similar to using the[CAST AS NUMERIC](#cast_numeric)functionexcept that the`PARSE_NUMERIC`function only accepts string inputs and allowsthe following in the string:\n\n- Spaces between the sign (+/-) and the number\n- Signs (+/-) after the number\n\nRules for valid input strings:\n\n| Rule | Example Input | Output |\n| --- | --- | --- |\n| The string can only contain digits, commas, decimal points and signs. | \"- 12,34567,89.0\" | -123456789 |\n| Whitespaces are allowed anywhere except between digits. | \"  -  12.345  \" | -12.345 |\n| Only digits and commas are allowed before the decimal point. | \" 12,345,678\" | 12345678 |\n| Only digits are allowed after the decimal point. | \"1.234 \" | 1.234 |\n| Use`E`or`e`for exponents. After        the`e`,        digits and a leading sign indicator are allowed. | \" 123.45e-1\" | 12.345 |\n| If the integer part is not empty, then it must contain at least one        digit. | \" 0,.12 -\" | -0.12 |\n| If the string contains a decimal point, then it must contain at least        one digit. | \" .1\" | 0.1 |\n| The string cannot contain more than one sign. | \" 0.5 +\" | 0.5 |\n\n **Return Data Type** \n\n`NUMERIC`\n\n **Examples** \n\nThis example shows an input with spaces before, after, and between thesign and the number:\n\n```\nSELECT PARSE_NUMERIC(\"  -  12.34 \") as parsed;/*--------* | parsed | +--------+ | -12.34 | *--------*/\n```\n\nThis example shows an input with an exponent as well as the sign after thenumber:\n\n```\nSELECT PARSE_NUMERIC(\"12.34e-1-\") as parsed;/*--------* | parsed | +--------+ | -1.234 | *--------*/\n```\n\nThis example shows an input with multiple commas in the integer part of thenumber:\n\n```\nSELECT PARSE_NUMERIC(\"  1,2,,3,.45 + \") as parsed;/*--------* | parsed | +--------+ | 123.45 | *--------*/\n```\n\nThis example shows an input with a decimal point and no digits in the wholenumber part:\n\n```\nSELECT PARSE_NUMERIC(\".1234  \") as parsed;/*--------* | parsed | +--------+ | 0.1234 | *--------*/\n```\n\n **Examples of invalid inputs** \n\nThis example is invalid because the whole number part contains no digits:\n\n```\nSELECT PARSE_NUMERIC(\",,,.1234  \") as parsed;\n```\n\nThis example is invalid because there are whitespaces between digits:\n\n```\nSELECT PARSE_NUMERIC(\"1  23.4 5  \") as parsed;\n```\n\nThis example is invalid because the number is empty except for an exponent:\n\n```\nSELECT PARSE_NUMERIC(\"  e1 \") as parsed;\n```\n\nThis example is invalid because the string contains multiple signs:\n\n```\nSELECT PARSE_NUMERIC(\"  - 12.3 - \") as parsed;\n```\n\nThis example is invalid because the value of the number falls outside the rangeof`BIGNUMERIC`:\n\n```\nSELECT PARSE_NUMERIC(\"12.34E100 \") as parsed;\n```\n\nThis example is invalid because the string contains invalid characters:\n\n```\nSELECT PARSE_NUMERIC(\"$12.34\") as parsed;\n```\n\n"
  },
  {
    "name": "PARSE_TIME",
    "arguments": [],
    "category": "Time functions",
    "description": "```\nPARSE_TIME(format_string, time_string)\n```\n\n **Description** \n\nConverts a[string representation of time](#format_time)to a`TIME`object.\n\n`format_string`contains the[format elements](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)that define how`time_string`is formatted. Each element in`time_string`must have a corresponding element in`format_string`. Thelocation of each element in`format_string`must match the location ofeach element in`time_string`.\n\n```\n-- This works because elements on both sides match.SELECT PARSE_TIME(\"%I:%M:%S\", \"07:30:00\")-- This produces an error because the seconds element is in different locations.SELECT PARSE_TIME(\"%S:%I:%M\", \"07:30:00\")-- This produces an error because one of the seconds elements is missing.SELECT PARSE_TIME(\"%I:%M\", \"07:30:00\")-- This works because %T can find all matching elements in time_string.SELECT PARSE_TIME(\"%T\", \"07:30:00\")\n```\n\nThe format string fully supports most format elements except for`%P`.\n\nWhen using`PARSE_TIME`, keep the following in mind:\n\n-  **Unspecified fields.** Any unspecified field is initialized from`    00:00:00.0`. For instance, if`    seconds`is unspecified then itdefaults to`    00`, and so on.\n-  **Whitespace.** One or more consecutive white spaces in the format stringmatches zero or more consecutive white spaces in the`    TIME`string. Inaddition, leading and trailing white spaces in the`    TIME`string are alwaysallowed, even if they are not in the format string.\n-  **Format precedence.** When two (or more) format elements have overlappinginformation, the last one generally overrides any earlier ones.\n-  **Format divergence.** `    %p`can be used with`    am`,`    AM`,`    pm`, and`    PM`.\n\n **Return Data Type** \n\n`TIME`\n\n **Example** \n\n```\nSELECT PARSE_TIME(\"%H\", \"15\") as parsed_time;/*-------------* | parsed_time | +-------------+ | 15:00:00    | *-------------*/\n```\n\n```\nSELECT PARSE_TIME('%I:%M:%S %p', '2:23:38 pm') AS parsed_time/*-------------* | parsed_time | +-------------+ | 14:23:38    | *-------------*/\n```\n\n"
  },
  {
    "name": "PARSE_TIMESTAMP",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nPARSE_TIMESTAMP(format_string, timestamp_string[, time_zone])\n```\n\n **Description** \n\nConverts a[string representation of a timestamp](#format_timestamp)to a`TIMESTAMP`object.\n\n`format_string`contains the[format elements](/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)that define how`timestamp_string`is formatted. Each element in`timestamp_string`must have a corresponding element in`format_string`. Thelocation of each element in`format_string`must match the location ofeach element in`timestamp_string`.\n\n```\n-- This works because elements on both sides match.SELECT PARSE_TIMESTAMP(\"%a %b %e %I:%M:%S %Y\", \"Thu Dec 25 07:30:00 2008\")-- This produces an error because the year element is in different locations.SELECT PARSE_TIMESTAMP(\"%a %b %e %Y %I:%M:%S\", \"Thu Dec 25 07:30:00 2008\")-- This produces an error because one of the year elements is missing.SELECT PARSE_TIMESTAMP(\"%a %b %e %I:%M:%S\", \"Thu Dec 25 07:30:00 2008\")-- This works because %c can find all matching elements in timestamp_string.SELECT PARSE_TIMESTAMP(\"%c\", \"Thu Dec 25 07:30:00 2008\")\n```\n\nThe format string fully supports most format elements, except for`%P`.\n\nWhen using`PARSE_TIMESTAMP`, keep the following in mind:\n\n-  **Unspecified fields.** Any unspecified field is initialized from`    1970-01-0100:00:00.0`. This initialization value uses the time zone specified by thefunction's time zone argument, if present. If not, the initialization valueuses the default time zone, UTC.  For instance, if the yearis unspecified then it defaults to`    1970`, and so on.\n-  **Case insensitivity.** Names, such as`    Monday`,`    February`, and so on, arecase insensitive.\n-  **Whitespace.** One or more consecutive white spaces in the format stringmatches zero or more consecutive white spaces in the timestamp string. Inaddition, leading and trailing white spaces in the timestamp string are alwaysallowed, even if they are not in the format string.\n-  **Format precedence.** When two (or more) format elements have overlappinginformation (for example both`    %F`and`    %Y`affect the year), the last onegenerally overrides any earlier ones, with some exceptions (see thedescriptions of`    %s`,`    %C`, and`    %y`).\n-  **Format divergence.** `    %p`can be used with`    am`,`    AM`,`    pm`, and`    PM`.\n\n **Return Data Type** \n\n`TIMESTAMP`\n\n **Example** \n\n```\nSELECT PARSE_TIMESTAMP(\"%c\", \"Thu Dec 25 07:30:00 2008\") AS parsed;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | parsed                  | +-------------------------+ | 2008-12-25 07:30:00 UTC | *-------------------------*/\n```\n\n"
  },
  {
    "name": "PERCENTILE_CONT",
    "arguments": [],
    "category": "Navigation functions",
    "description": "```\nPERCENTILE_CONT (value_expression, percentile [{RESPECT | IGNORE} NULLS])OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]\n```\n\n **Description** \n\nComputes the specified percentile value for the value_expression, with linearinterpolation.\n\nThis function ignores NULLvalues if`RESPECT NULLS`is absent.  If`RESPECT NULLS`is present:\n\n- Interpolation between two`    NULL`values returns`    NULL`.\n- Interpolation between a`    NULL`value and a non-`    NULL`value returns thenon-`    NULL`value.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n`PERCENTILE_CONT`can be used with differential privacy. To learn more, see[Differentially private aggregate functions](#aggregate-dp-functions).\n\n **Supported Argument Types** \n\n- `    value_expression`and`    percentile`must have one of the following types:\n    - `        NUMERIC`\n    - `        BIGNUMERIC`\n    - `        FLOAT64`\n- `    percentile`must be a literal in the range`    [0, 1]`.\n\n **Return Data Type** \n\nThe return data type is determined by the argument types with the followingtable.\n\n| INPUT | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- |\n| `NUMERIC` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` |\n\n **Examples** \n\nThe following example computes the value for some percentiles from a column ofvalues while ignoring nulls.\n\n```\nSELECT  PERCENTILE_CONT(x, 0) OVER() AS min,  PERCENTILE_CONT(x, 0.01) OVER() AS percentile1,  PERCENTILE_CONT(x, 0.5) OVER() AS median,  PERCENTILE_CONT(x, 0.9) OVER() AS percentile90,  PERCENTILE_CONT(x, 1) OVER() AS maxFROM UNNEST([0, 3, NULL, 1, 2]) AS x LIMIT 1; /*-----+-------------+--------+--------------+-----*  | min | percentile1 | median | percentile90 | max |  +-----+-------------+--------+--------------+-----+  | 0   | 0.03        | 1.5    | 2.7          | 3   |  *-----+-------------+--------+--------------+-----+\n```\n\nThe following example computes the value for some percentiles from a column ofvalues while respecting nulls.\n\n```\nSELECT  PERCENTILE_CONT(x, 0 RESPECT NULLS) OVER() AS min,  PERCENTILE_CONT(x, 0.01 RESPECT NULLS) OVER() AS percentile1,  PERCENTILE_CONT(x, 0.5 RESPECT NULLS) OVER() AS median,  PERCENTILE_CONT(x, 0.9 RESPECT NULLS) OVER() AS percentile90,  PERCENTILE_CONT(x, 1 RESPECT NULLS) OVER() AS maxFROM UNNEST([0, 3, NULL, 1, 2]) AS x LIMIT 1;/*------+-------------+--------+--------------+-----* | min  | percentile1 | median | percentile90 | max | +------+-------------+--------+--------------+-----+ | NULL | 0           | 1      | 2.6          | 3   | *------+-------------+--------+--------------+-----+\n```\n\n"
  },
  {
    "name": "PERCENTILE_CONT (DIFFERENTIAL_PRIVACY)",
    "arguments": [],
    "category": "Differentially private aggregate functions",
    "description": "```\nWITH DIFFERENTIAL_PRIVACY ...  PERCENTILE_CONT(    expression,    percentile,    contribution_bounds_per_row =&gt; (lower_bound, upper_bound)  )\n```\n\n **Description** \n\nTakes an expression and computes a percentile for it. The final result is anaggregation across privacy unit columns.\n\nThis function must be used with the[DIFFERENTIAL_PRIVACY clause](/bigquery/docs/reference/standard-sql/query-syntax#dp_clause)and can support these arguments:\n\n- `    expression`: The input expression. This can be most numeric input types,such as`    INT64`.`    NULL`values are always ignored.\n- `    percentile`: The percentile to compute. The percentile must be a literal inthe range`    [0, 1]`.\n- `    contribution_bounds_per_row`: The[contribution bounds named argument](#dp_clamped_named).Perform clamping per each row separately before performing intermediategrouping on the privacy unit column.\n\n`NUMERIC`and`BIGNUMERIC`arguments are not allowed. If you need them, cast them as the`FLOAT64`data type first.\n\n **Return type** \n\n`FLOAT64`\n\n **Examples** \n\nThe following differentially private query gets the percentile of itemsrequested. Smaller aggregations might not be included. This query references aview called[professors](/bigquery/docs/reference/standard-sql/query-syntax#dp_example_tables).\n\n```\n-- With noise, using the epsilon parameter.SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=10, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    PERCENTILE_CONT(quantity, 0.5, contribution_bounds_per_row =&gt; (0,100)) percentile_requestedFROM professorsGROUP BY item;-- These results will change each time you run the query.-- Smaller aggregations might be removed. /*----------+----------------------*  | item     | percentile_requested |  +----------+----------------------+  | pencil   | 72.00011444091797    |  | scissors | 8.000175476074219    |  | pen      | 23.001075744628906   |  *----------+----------------------*/\n```\n\n"
  },
  {
    "name": "PERCENTILE_DISC",
    "arguments": [],
    "category": "Navigation functions",
    "description": "```\nPERCENTILE_DISC (value_expression, percentile [{RESPECT | IGNORE} NULLS])OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]\n```\n\n **Description** \n\nComputes the specified percentile value for a discrete`value_expression`. Thereturned value is the first sorted value of`value_expression`with cumulativedistribution greater than or equal to the given`percentile`value.\n\nThis function ignores`NULL`values unless`RESPECT NULLS`is present.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\n- `    value_expression`can be any orderable type.\n- `    percentile`must be a literal in the range`    [0, 1]`, with one of thefollowing types:\n    - `        NUMERIC`\n    - `        BIGNUMERIC`\n    - `        FLOAT64`\n\n **Return Data Type** \n\nSame type as`value_expression`.\n\n **Examples** \n\nThe following example computes the value for some percentiles from a column ofvalues while ignoring nulls.\n\n```\nSELECT  x,  PERCENTILE_DISC(x, 0) OVER() AS min,  PERCENTILE_DISC(x, 0.5) OVER() AS median,  PERCENTILE_DISC(x, 1) OVER() AS maxFROM UNNEST(['c', NULL, 'b', 'a']) AS x;/*------+-----+--------+-----* | x    | min | median | max | +------+-----+--------+-----+ | c    | a   | b      | c   | | NULL | a   | b      | c   | | b    | a   | b      | c   | | a    | a   | b      | c   | *------+-----+--------+-----*/\n```\n\nThe following example computes the value for some percentiles from a column ofvalues while respecting nulls.\n\n```\nSELECT  x,  PERCENTILE_DISC(x, 0 RESPECT NULLS) OVER() AS min,  PERCENTILE_DISC(x, 0.5 RESPECT NULLS) OVER() AS median,  PERCENTILE_DISC(x, 1 RESPECT NULLS) OVER() AS maxFROM UNNEST(['c', NULL, 'b', 'a']) AS x;/*------+------+--------+-----* | x    | min  | median | max | +------+------+--------+-----+ | c    | NULL | a      | c   | | NULL | NULL | a      | c   | | b    | NULL | a      | c   | | a    | NULL | a      | c   | *------+------+--------+-----*/\n```\n\n\n<span id=\"net_functions\">\n## Net functions\n\n</span>\nGoogleSQL for BigQuery supports the following Net functions.\n\n"
  },
  {
    "name": "PERCENT_RANK",
    "arguments": [],
    "category": "Numbering functions",
    "description": "```\nPERCENT_RANK()OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]\n```\n\n **Description** \n\nReturn the percentile rank of a row defined as (RK-1)/(NR-1), where RK isthe`RANK`of the row and NR is the number of rows in the partition.Returns 0 if NR=1.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 2:59:01', 'F30-34')SELECT name,  finish_time,  division,  PERCENT_RANK() OVER (PARTITION BY division ORDER BY finish_time ASC) AS finish_rankFROM finishers;/*-----------------+------------------------+----------+---------------------* | name            | finish_time            | division | finish_rank         | +-----------------+------------------------+----------+---------------------+ | Sophia Liu      | 2016-10-18 09:51:45+00 | F30-34   | 0                   | | Meghan Lederer  | 2016-10-18 09:59:01+00 | F30-34   | 0.33333333333333331 | | Nikki Leith     | 2016-10-18 09:59:01+00 | F30-34   | 0.33333333333333331 | | Jen Edwards     | 2016-10-18 10:06:36+00 | F30-34   | 1                   | | Lisa Stelzner   | 2016-10-18 09:54:11+00 | F35-39   | 0                   | | Lauren Matthews | 2016-10-18 10:01:17+00 | F35-39   | 0.33333333333333331 | | Desiree Berry   | 2016-10-18 10:05:42+00 | F35-39   | 0.66666666666666663 | | Suzy Slane      | 2016-10-18 10:06:24+00 | F35-39   | 1                   | *-----------------+------------------------+----------+---------------------*/\n```\n\n"
  },
  {
    "name": "POW",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nPOW(X, Y)\n```\n\n **Description** \n\nReturns the value of X raised to the power of Y. If the result underflows and isnot representable, then the function returns a  value of zero.\n\n| X | Y | POW(X, Y) |\n| --- | --- | --- |\n| 2.0 | 3.0 | 8.0 |\n| 1.0 | Any value including`NaN` | 1.0 |\n| Any value including`NaN` | 0 | 1.0 |\n| -1.0 | `+inf` | 1.0 |\n| -1.0 | `-inf` | 1.0 |\n| ABS(X) < 1 | `-inf` | `+inf` |\n| ABS(X) > 1 | `-inf` | 0.0 |\n| ABS(X) < 1 | `+inf` | 0.0 |\n| ABS(X) > 1 | `+inf` | `+inf` |\n| `-inf` | Y < 0 | 0.0 |\n| `-inf` | Y > 0 | `-inf`if Y is an odd integer,`+inf`otherwise |\n| `+inf` | Y < 0 | 0 |\n| `+inf` | Y > 0 | `+inf` |\n| Finite value < 0 | Non-integer | Error |\n| 0 | Finite value < 0 | Error |\n\n **Return Data Type** \n\nThe return data type is determined by the argument types with the followingtable.\n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| `INT64` | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `NUMERIC` | `NUMERIC` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` |\n\n"
  },
  {
    "name": "POWER",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nPOWER(X, Y)\n```\n\n **Description** \n\nSynonym of[POW(X, Y)](#pow).\n\n"
  },
  {
    "name": "RAND",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nRAND()\n```\n\n **Description** \n\nGenerates a pseudo-random value of type`FLOAT64`inthe range of [0, 1), inclusive of 0 and exclusive of 1.\n\n"
  },
  {
    "name": "RANGE",
    "arguments": [],
    "category": "Range functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nRANGE(lower_bound, upper_bound)\n```\n\n **Description** \n\nConstructs a range of[DATE](/bigquery/docs/reference/standard-sql/data-types#date_type),[DATETIME](/bigquery/docs/reference/standard-sql/data-types#datetime_type), or[TIMESTAMP](/bigquery/docs/reference/standard-sql/data-types#timestamp_type)values.\n\n **Definitions** \n\n- `    lower_bound`: The range starts from this value. This can be a`    DATE`,`    DATETIME`, or`    TIMESTAMP`value. If this value is`    NULL`, the rangedoesn't include a lower bound.\n- `    upper_bound`: The range ends before this value. This can be a`    DATE`,`    DATETIME`, or`    TIMESTAMP`value. If this value is`    NULL`, the rangedoesn't include an upper bound.\n\n **Details** \n\n`lower_bound`and`upper_bound`must be of the same data type.\n\nProduces an error if`lower_bound`is greater than or equal to`upper_bound`.To return`NULL`instead, add the`SAFE.`prefix to the function name.\n\n **Return type** \n\n`RANGE&lt;T&gt;`, where`T`is the same data type as the input.\n\n **Examples** \n\nThe following query constructs a date range:\n\n```\nSELECT RANGE(DATE '2022-12-01', DATE '2022-12-31') AS results;/*--------------------------+ | results                  | +--------------------------+ | [2022-12-01, 2022-12-31) | +--------------------------*/\n```\n\nThe following query constructs a datetime range:\n\n```\nSELECT RANGE(DATETIME '2022-10-01 14:53:27',             DATETIME '2022-10-01 16:00:00') AS results;/*---------------------------------------------+ | results                                     | +---------------------------------------------+ | [2022-10-01T14:53:27, 2022-10-01T16:00:00)  | +---------------------------------------------*/\n```\n\nThe following query constructs a timestamp range:\n\n```\nSELECT RANGE(TIMESTAMP '2022-10-01 14:53:27 America/Los_Angeles',             TIMESTAMP '2022-10-01 16:00:00 America/Los_Angeles') AS results;-- Results depend upon where this query was executed./*------------------------------------------------------------------+ | results                                                          | +------------------------------------------------------------------+ | [2022-10-01 21:53:27.000000 UTC, 2022-10-01 23:00:00.000000 UTC) | +------------------------------------------------------------------*/\n```\n\nThe following query constructs a date range with no lower bound:\n\n```\nSELECT RANGE(NULL, DATE '2022-12-31') AS results;/*-------------------------+ | results                 | +-------------------------+ | [UNBOUNDED, 2022-12-31) | +-------------------------*/\n```\n\nThe following query constructs a date range with no upper bound:\n\n```\nSELECT RANGE(DATE '2022-10-01', NULL) AS results;/*--------------------------+ | results                  | +--------------------------+ | [2022-10-01, UNBOUNDED)  | +--------------------------*/\n```\n\n"
  },
  {
    "name": "RANGE_BUCKET",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nRANGE_BUCKET(point, boundaries_array)\n```\n\n **Description** \n\n`RANGE_BUCKET`scans through a sorted array and returns the 0-based positionof the point's upper bound. This can be useful if you need to group your data tobuild partitions, histograms, business-defined rules, and more.\n\n`RANGE_BUCKET`follows these rules:\n\n- If the point exists in the array, returns the index of the next larger value.\n    \n    \n    ```\n    RANGE_BUCKET(20, [0, 10, 20, 30, 40]) -- 3 is return valueRANGE_BUCKET(20, [0, 10, 20, 20, 40, 40]) -- 4 is return value\n    ```\n    \n    \n- If the point does not exist in the array, but it falls between two values,returns the index of the larger value.\n    \n    \n    ```\n    RANGE_BUCKET(25, [0, 10, 20, 30, 40]) -- 3 is return value\n    ```\n    \n    \n- If the point is smaller than the first value in the array, returns 0.\n    \n    \n    ```\n    RANGE_BUCKET(-10, [5, 10, 20, 30, 40]) -- 0 is return value\n    ```\n    \n    \n- If the point is greater than or equal to the last value in the array,returns the length of the array.\n    \n    \n    ```\n    RANGE_BUCKET(80, [0, 10, 20, 30, 40]) -- 5 is return value\n    ```\n    \n    \n- If the array is empty, returns 0.\n    \n    \n    ```\n    RANGE_BUCKET(80, []) -- 0 is return value\n    ```\n    \n    \n- If the point is`    NULL`or`    NaN`, returns`    NULL`.\n    \n    \n    ```\n    RANGE_BUCKET(NULL, [0, 10, 20, 30, 40]) -- NULL is return value\n    ```\n    \n    \n- The data type for the point and array must be compatible.\n    \n    \n    ```\n    RANGE_BUCKET('a', ['a', 'b', 'c', 'd']) -- 1 is return valueRANGE_BUCKET(1.2, [1, 1.2, 1.4, 1.6]) -- 2 is return valueRANGE_BUCKET(1.2, [1, 2, 4, 6]) -- execution failure\n    ```\n    \n    \n\nExecution failure occurs when:\n\n- The array has a`    NaN`or`    NULL`value in it.\n    \n    \n    ```\n    RANGE_BUCKET(80, [NULL, 10, 20, 30, 40]) -- execution failure\n    ```\n    \n    \n- The array is not sorted in ascending order.\n    \n    \n    ```\n    RANGE_BUCKET(30, [10, 30, 20, 40, 50]) -- execution failure\n    ```\n    \n    \n\n **Parameters** \n\n- `    point`: A generic value.\n- `    boundaries_array`: A generic array of values.\n\n **Note:** The data type for`point`and the element type of`boundaries_array`must be equivalent. The data type must be[comparable](/bigquery/docs/reference/standard-sql/data-types#data_type_properties). **Return Value** \n\n`INT64`\n\n **Examples** \n\nIn a table called`students`, check to see how many records wouldexist in each`age_group`bucket, based on a student's age:\n\n- age_group 0 (age < 10)\n- age_group 1 (age >= 10, age < 20)\n- age_group 2 (age >= 20, age < 30)\n- age_group 3 (age >= 30)\n\n```\nWITH students AS(  SELECT 9 AS age UNION ALL  SELECT 20 AS age UNION ALL  SELECT 25 AS age UNION ALL  SELECT 31 AS age UNION ALL  SELECT 32 AS age UNION ALL  SELECT 33 AS age)SELECT RANGE_BUCKET(age, [10, 20, 30]) AS age_group, COUNT(*) AS countFROM studentsGROUP BY 1/*--------------+-------* | age_group    | count | +--------------+-------+ | 0            | 1     | | 2            | 2     | | 3            | 3     | *--------------+-------*/\n```\n\n"
  },
  {
    "name": "RANGE_CONTAINS",
    "arguments": [],
    "category": "Range functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).- [Signature 1](#signature_1): Checks if every value in one range isin another range.\n- [Signature 2](#signature_2): Checks if a value is in a range.\n\n\n<span id=\"signature_1_4\">\n#### Signature 1\n\n</span>\n```\nRANGE_CONTAINS(outer_range, inner_range)\n```\n\n **Description** \n\nChecks if the inner range is in the outer range.\n\n **Definitions** \n\n- `    outer_range`: The`    RANGE&lt;T&gt;`value to search within.\n- `    inner_range`: The`    RANGE&lt;T&gt;`value to search for in`    outer_range`.\n\n **Details** \n\nReturns`TRUE`if`inner_range`exists in`outer_range`.Otherwise, returns`FALSE`.\n\n`T`must be of the same type for all inputs.\n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\nIn the following query, the inner range is in the outer range:\n\n```\nSELECT RANGE_CONTAINS(  RANGE&lt;DATE&gt; '[2022-01-01, 2023-01-01)',  RANGE&lt;DATE&gt; '[2022-04-01, 2022-07-01)') AS results;/*---------+ | results | +---------+ | TRUE    | +---------*/\n```\n\nIn the following query, the inner range is not in the outer range:\n\n```\nSELECT RANGE_CONTAINS(  RANGE&lt;DATE&gt; '[2022-01-01, 2023-01-01)',  RANGE&lt;DATE&gt; '[2023-01-01, 2023-04-01)') AS results;/*---------+ | results | +---------+ | FALSE   | +---------*/\n```\n\n\n<span id=\"signature_2_4\">\n#### Signature 2\n\n</span>\n```\nRANGE_CONTAINS(range_to_search, value_to_find)\n```\n\n **Description** \n\nChecks if a value is in a range.\n\n **Definitions** \n\n- `    range_to_search`: The`    RANGE&lt;T&gt;`value to search within.\n- `    value_to_find`: The value to search for in`    range_to_search`.\n\n **Details** \n\nReturns`TRUE`if`value_to_find`exists in`range_to_search`.Otherwise, returns`FALSE`.\n\nThe data type for`value_to_find`must be the same data type as`T`in`range_to_search`.\n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\nIn the following query, the value`2022-04-01`is found in the range`[2022-01-01, 2023-01-01)`:\n\n```\nSELECT RANGE_CONTAINS(  RANGE&lt;DATE&gt; '[2022-01-01, 2023-01-01)',  DATE '2022-04-01') AS results;/*---------+ | results | +---------+ | TRUE    | +---------*/\n```\n\nIn the following query, the value`2023-04-01`is not found in the range`[2022-01-01, 2023-01-01)`:\n\n```\nSELECT RANGE_CONTAINS(  RANGE&lt;DATE&gt; '[2022-01-01, 2023-01-01)',  DATE '2023-04-01') AS results;/*---------+ | results | +---------+ | FALSE   | +---------*/\n```\n\n"
  },
  {
    "name": "RANGE_END",
    "arguments": [],
    "category": "Range functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nRANGE_END(range_to_check)\n```\n\n **Description** \n\nGets the upper bound of a range.\n\n **Definitions** \n\n- `    range_to_check`: The`    RANGE&lt;T&gt;`value.\n\n **Details** \n\nReturns`NULL`if the upper bound in`range_value`is`UNBOUNDED`.\n\nReturns`NULL`if`range_to_check`is`NULL`.\n\n **Return type** \n\n`T`in`range_value`\n\n **Examples** \n\nIn the following query, the upper bound of the range is retrieved:\n\n```\nSELECT RANGE_END(RANGE&lt;DATE&gt; '[2022-12-01, 2022-12-31)') AS results;/*------------+ | results    | +------------+ | 2022-12-31 | +------------*/\n```\n\nIn the following query, the upper bound of the range is unbounded, so`NULL`is returned:\n\n```\nSELECT RANGE_END(RANGE&lt;DATE&gt; '[2022-12-01, UNBOUNDED)') AS results;/*------------+ | results    | +------------+ | NULL       | +------------*/\n```\n\n"
  },
  {
    "name": "RANGE_INTERSECT",
    "arguments": [],
    "category": "Range functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nRANGE_INTERSECT(range_a, range_b)\n```\n\n **Description** \n\nGets a segment of two ranges that intersect.\n\n **Definitions** \n\n- `    range_a`: The first`    RANGE&lt;T&gt;`value.\n- `    range_b`: The second`    RANGE&lt;T&gt;`value.\n\n **Details** \n\nReturns`NULL`if any input is`NULL`.\n\nProduces an error if`range_a`and`range_b`don't overlap. To return`NULL`instead, add the`SAFE.`prefix to the function name.\n\n`T`must be of the same type for all inputs.\n\n **Return type** \n\n`RANGE&lt;T&gt;`\n\n **Examples** \n\n```\nSELECT RANGE_INTERSECT(  RANGE&lt;DATE&gt; '[2022-02-01, 2022-09-01)',  RANGE&lt;DATE&gt; '[2021-06-15, 2022-04-15)') AS results;/*--------------------------+ | results                  | +--------------------------+ | [2022-02-01, 2022-04-15) | +--------------------------*/\n```\n\n```\nSELECT RANGE_INTERSECT(  RANGE&lt;DATE&gt; '[2022-02-01, UNBOUNDED)',  RANGE&lt;DATE&gt; '[2021-06-15, 2022-04-15)') AS results;/*--------------------------+ | results                  | +--------------------------+ | [2022-02-01, 2022-04-15) | +--------------------------*/\n```\n\n```\nSELECT RANGE_INTERSECT(  RANGE&lt;DATE&gt; '[2022-02-01, UNBOUNDED)',  RANGE&lt;DATE&gt; '[2021-06-15, UNBOUNDED)') AS results;/*-------------------------+ | results                 | +-------------------------+ | [2022-02-01, UNBOUNDED) | +-------------------------*/\n```\n\n"
  },
  {
    "name": "RANGE_OVERLAPS",
    "arguments": [],
    "category": "Range functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nRANGE_OVERLAPS(range_a, range_b)\n```\n\n **Description** \n\nChecks if two ranges overlap.\n\n **Definitions** \n\n- `    range_a`: The first`    RANGE&lt;T&gt;`value.\n- `    range_b`: The second`    RANGE&lt;T&gt;`value.\n\n **Details** \n\nReturns`TRUE`if a part of`range_a`intersects with`range_b`, otherwisereturns`FALSE`.\n\n`T`must be of the same type for all inputs.\n\nTo get the part of the range that overlaps, use the[RANGE_INTERSECT](#range_intersect)function.\n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\nIn the following query, the first and second ranges overlap between`2022-02-01`and`2022-04-15`:\n\n```\nSELECT RANGE_OVERLAPS(  RANGE&lt;DATE&gt; '[2022-02-01, 2022-09-01)',  RANGE&lt;DATE&gt; '[2021-06-15, 2022-04-15)') AS results;/*---------+ | results | +---------+ | TRUE    | +---------*/\n```\n\nIn the following query, the first and second ranges don't overlap:\n\n```\nSELECT RANGE_OVERLAPS(  RANGE&lt;DATE&gt; '[2020-02-01, 2020-09-01)',  RANGE&lt;DATE&gt; '[2021-06-15, 2022-04-15)') AS results;/*---------+ | results | +---------+ | FALSE   | +---------*/\n```\n\nIn the following query, the first and second ranges overlap between`2022-02-01`and`UNBOUNDED`:\n\n```\nSELECT RANGE_OVERLAPS(  RANGE&lt;DATE&gt; '[2022-02-01, UNBOUNDED)',  RANGE&lt;DATE&gt; '[2021-06-15, UNBOUNDED)') AS results;/*---------+ | results | +---------+ | TRUE    | +---------*/\n```\n\n"
  },
  {
    "name": "RANGE_START",
    "arguments": [],
    "category": "Range functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nRANGE_START(range_to_check)\n```\n\n **Description** \n\nGets the lower bound of a range.\n\n **Definitions** \n\n- `    range_to_check`: The`    RANGE&lt;T&gt;`value.\n\n **Details** \n\nReturns`NULL`if the lower bound of`range_value`is`UNBOUNDED`.\n\nReturns`NULL`if`range_to_check`is`NULL`.\n\n **Return type** \n\n`T`in`range_value`\n\n **Examples** \n\nIn the following query, the lower bound of the range is retrieved:\n\n```\nSELECT RANGE_START(RANGE&lt;DATE&gt; '[2022-12-01, 2022-12-31)') AS results;/*------------+ | results    | +------------+ | 2022-12-01 | +------------*/\n```\n\nIn the following query, the lower bound of the range is unbounded, so`NULL`is returned:\n\n```\nSELECT RANGE_START(RANGE&lt;DATE&gt; '[UNBOUNDED, 2022-12-31)') AS results;/*------------+ | results    | +------------+ | NULL       | +------------*/\n```\n\n\n<span id=\"search_functions\">\n## Search functions\n\n</span>\nGoogleSQL for BigQuery supports the following search functions.\n\n"
  },
  {
    "name": "RANK",
    "arguments": [],
    "category": "Numbering functions",
    "description": "```\nRANK()OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  ORDER BY expression [ { ASC | DESC }  ] [, ...]\n```\n\n **Description** \n\nReturns the ordinal (1-based) rank of each row within the ordered partition.All peer rows receive the same rank value. The next row or set of peer rowsreceives a rank value which increments by the number of peers with the previousrank value, instead of`DENSE_RANK`, which always increments by 1.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH Numbers AS (SELECT 1 as x  UNION ALL SELECT 2  UNION ALL SELECT 2  UNION ALL SELECT 5  UNION ALL SELECT 8  UNION ALL SELECT 10  UNION ALL SELECT 10)SELECT x,  RANK() OVER (ORDER BY x ASC) AS rankFROM Numbers/*-------------------------* | x          | rank       | +-------------------------+ | 1          | 1          | | 2          | 2          | | 2          | 2          | | 5          | 4          | | 8          | 5          | | 10         | 6          | | 10         | 6          | *-------------------------*/\n```\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 2:59:01', 'F30-34')SELECT name,  finish_time,  division,  RANK() OVER (PARTITION BY division ORDER BY finish_time ASC) AS finish_rankFROM finishers;/*-----------------+------------------------+----------+-------------* | name            | finish_time            | division | finish_rank | +-----------------+------------------------+----------+-------------+ | Sophia Liu      | 2016-10-18 09:51:45+00 | F30-34   | 1           | | Meghan Lederer  | 2016-10-18 09:59:01+00 | F30-34   | 2           | | Nikki Leith     | 2016-10-18 09:59:01+00 | F30-34   | 2           | | Jen Edwards     | 2016-10-18 10:06:36+00 | F30-34   | 4           | | Lisa Stelzner   | 2016-10-18 09:54:11+00 | F35-39   | 1           | | Lauren Matthews | 2016-10-18 10:01:17+00 | F35-39   | 2           | | Desiree Berry   | 2016-10-18 10:05:42+00 | F35-39   | 3           | | Suzy Slane      | 2016-10-18 10:06:24+00 | F35-39   | 4           | *-----------------+------------------------+----------+-------------*/\n```\n\n"
  },
  {
    "name": "REGEXP_CONTAINS",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREGEXP_CONTAINS(value, regexp)\n```\n\n **Description** \n\nReturns`TRUE`if`value`is a partial match for the regular expression,`regexp`.\n\nIf the`regexp`argument is invalid, the function returns an error.\n\nYou can search for a full match by using`^`(beginning of text) and`$`(end oftext). Due to regular expression operator precedence, it is good practice to useparentheses around everything between`^`and`$`.\n\n **Note:** GoogleSQL provides regular expression support using the[re2](https://github.com/google/re2/wiki/Syntax)library; see that documentation for itsregular expression syntax. **Return type** \n\n`BOOL`\n\n **Examples** \n\n```\nSELECT  email,  REGEXP_CONTAINS(email, r'@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+') AS is_validFROM  (SELECT    ['foo@example.com', 'bar@example.org', 'www.example.net']    AS addresses),  UNNEST(addresses) AS email;/*-----------------+----------* | email           | is_valid | +-----------------+----------+ | foo@example.com | true     | | bar@example.org | true     | | www.example.net | false    | *-----------------+----------*/-- Performs a full match, using ^ and $. Due to regular expression operator-- precedence, it is good practice to use parentheses around everything between ^-- and $.SELECT  email,  REGEXP_CONTAINS(email, r'^([\\w.+-]+@foo\\.com|[\\w.+-]+@bar\\.org)$')    AS valid_email_address,  REGEXP_CONTAINS(email, r'^[\\w.+-]+@foo\\.com|[\\w.+-]+@bar\\.org$')    AS without_parenthesesFROM  (SELECT    ['a@foo.com', 'a@foo.computer', 'b@bar.org', '!b@bar.org', 'c@buz.net']    AS addresses),  UNNEST(addresses) AS email;/*----------------+---------------------+---------------------* | email          | valid_email_address | without_parentheses | +----------------+---------------------+---------------------+ | a@foo.com      | true                | true                | | a@foo.computer | false               | true                | | b@bar.org      | true                | true                | | !b@bar.org     | false               | true                | | c@buz.net      | false               | false               | *----------------+---------------------+---------------------*/\n```\n\n"
  },
  {
    "name": "REGEXP_EXTRACT",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREGEXP_EXTRACT(value, regexp[, position[, occurrence]])\n```\n\n **Description** \n\nReturns the substring in`value`that matches the[re2 regular expression](https://github.com/google/re2/wiki/Syntax),`regexp`.Returns`NULL`if there is no match.\n\nIf the regular expression contains a capturing group (`(...)`), and there is amatch for that capturing group, that match is returned. If thereare multiple matches for a capturing group, the first match is returned.\n\nIf`position`is specified, the search starts at thisposition in`value`, otherwise it starts at the beginning of`value`. The`position`must be a positive integer and cannot be 0. If`position`is greaterthan the length of`value`,`NULL`is returned.\n\nIf`occurrence`is specified, the search returns a specific occurrence of the`regexp`in`value`, otherwise returns the first match. If`occurrence`isgreater than the number of matches found,`NULL`is returned. For`occurrence`> 1, the function searches for additional occurrences beginningwith the character following the previous occurrence.\n\nReturns an error if:\n\n- The regular expression is invalid\n- The regular expression has more than one capturing group\n- The`    position`is not a positive integer\n- The`    occurrence`is not a positive integer\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH email_addresses AS  (SELECT 'foo@example.com' as email  UNION ALL  SELECT 'bar@example.org' as email  UNION ALL  SELECT 'baz@example.net' as email)SELECT  REGEXP_EXTRACT(email, r'^[a-zA-Z0-9_.+-]+')  AS user_nameFROM email_addresses;/*-----------* | user_name | +-----------+ | foo       | | bar       | | baz       | *-----------*/\n```\n\n```\nWITH email_addresses AS  (SELECT 'foo@example.com' as email  UNION ALL  SELECT 'bar@example.org' as email  UNION ALL  SELECT 'baz@example.net' as email)SELECT  REGEXP_EXTRACT(email, r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.([a-zA-Z0-9-.]+$)')  AS top_level_domainFROM email_addresses;/*------------------* | top_level_domain | +------------------+ | com              | | org              | | net              | *------------------*/\n```\n\n```\nWITH  characters AS (    SELECT 'ab' AS value, '.b' AS regex UNION ALL    SELECT 'ab' AS value, '(.)b' AS regex UNION ALL    SELECT 'xyztb' AS value, '(.)+b' AS regex UNION ALL    SELECT 'ab' AS value, '(z)?b' AS regex  )SELECT value, regex, REGEXP_EXTRACT(value, regex) AS result FROM characters;/*-------+---------+----------* | value | regex   | result   | +-------+---------+----------+ | ab    | .b      | ab       | | ab    | (.)b    | a        | | xyztb | (.)+b   | t        | | ab    | (z)?b   | NULL     | *-------+---------+----------*/\n```\n\n```\nWITH example AS(SELECT 'Hello Helloo and Hellooo' AS value, 'H?ello+' AS regex, 1 as position,1 AS occurrence UNION ALLSELECT 'Hello Helloo and Hellooo', 'H?ello+', 1, 2 UNION ALLSELECT 'Hello Helloo and Hellooo', 'H?ello+', 1, 3 UNION ALLSELECT 'Hello Helloo and Hellooo', 'H?ello+', 1, 4 UNION ALLSELECT 'Hello Helloo and Hellooo', 'H?ello+', 2, 1 UNION ALLSELECT 'Hello Helloo and Hellooo', 'H?ello+', 3, 1 UNION ALLSELECT 'Hello Helloo and Hellooo', 'H?ello+', 3, 2 UNION ALLSELECT 'Hello Helloo and Hellooo', 'H?ello+', 3, 3 UNION ALLSELECT 'Hello Helloo and Hellooo', 'H?ello+', 20, 1 UNION ALLSELECT 'cats&amp;dogs&amp;rabbits' ,'\\\\w+&amp;', 1, 2 UNION ALLSELECT 'cats&amp;dogs&amp;rabbits', '\\\\w+&amp;', 2, 3)SELECT value, regex, position, occurrence, REGEXP_EXTRACT(value, regex,position, occurrence) AS regexp_value FROM example;/*--------------------------+---------+----------+------------+--------------* | value                    | regex   | position | occurrence | regexp_value | +--------------------------+---------+----------+------------+--------------+ | Hello Helloo and Hellooo | H?ello+ | 1        | 1          | Hello        | | Hello Helloo and Hellooo | H?ello+ | 1        | 2          | Helloo       | | Hello Helloo and Hellooo | H?ello+ | 1        | 3          | Hellooo      | | Hello Helloo and Hellooo | H?ello+ | 1        | 4          | NULL         | | Hello Helloo and Hellooo | H?ello+ | 2        | 1          | ello         | | Hello Helloo and Hellooo | H?ello+ | 3        | 1          | Helloo       | | Hello Helloo and Hellooo | H?ello+ | 3        | 2          | Hellooo      | | Hello Helloo and Hellooo | H?ello+ | 3        | 3          | NULL         | | Hello Helloo and Hellooo | H?ello+ | 20       | 1          | NULL         | | cats&amp;dogs&amp;rabbits        | \\w+&amp;    | 1        | 2          | dogs&amp;        | | cats&amp;dogs&amp;rabbits        | \\w+&amp;    | 2        | 3          | NULL         | *--------------------------+---------+----------+------------+--------------*/\n```\n\n"
  },
  {
    "name": "REGEXP_EXTRACT_ALL",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREGEXP_EXTRACT_ALL(value, regexp)\n```\n\n **Description** \n\nReturns an array of all substrings of`value`that match the[re2 regular expression](https://github.com/google/re2/wiki/Syntax),`regexp`. Returns an empty arrayif there is no match.\n\nIf the regular expression contains a capturing group (`(...)`), and there is amatch for that capturing group, that match is added to the results.\n\nThe`REGEXP_EXTRACT_ALL`function only returns non-overlapping matches. Forexample, using this function to extract`ana`from`banana`returns only onesubstring, not two.\n\nReturns an error if:\n\n- The regular expression is invalid\n- The regular expression has more than one capturing group\n\n **Return type** \n\n`ARRAY&lt;STRING&gt;`or`ARRAY&lt;BYTES&gt;`\n\n **Examples** \n\n```\nWITH code_markdown AS  (SELECT 'Try `function(x)` or `function(y)`' as code)SELECT  REGEXP_EXTRACT_ALL(code, '`(.+?)`') AS exampleFROM code_markdown;/*----------------------------* | example                    | +----------------------------+ | [function(x), function(y)] | *----------------------------*/\n```\n\n"
  },
  {
    "name": "REGEXP_INSTR",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREGEXP_INSTR(source_value, regexp [, position[, occurrence, [occurrence_position]]])\n```\n\n **Description** \n\nReturns the lowest 1-based position of a regular expression,`regexp`, in`source_value`.`source_value`and`regexp`must be the same type, either`STRING`or`BYTES`.\n\nIf`position`is specified, the search starts at this position in`source_value`, otherwise it starts at`1`, which is the beginning of`source_value`.`position`is of type`INT64`and must be positive.\n\nIf`occurrence`is specified, the search returns the position of a specificinstance of`regexp`in`source_value`. If not specified,`occurrence`defaultsto`1`and returns the position of the first occurrence.  For`occurrence`> 1,the function searches for the next, non-overlapping occurrence.`occurrence`is of type`INT64`and must be positive.\n\nYou can optionally use`occurrence_position`to specify where a positionin relation to an`occurrence`starts. Your choices are:\n\n- `    0`: Returns the start position of`    occurrence`.\n- `    1`: Returns the end position of`    occurrence`+`    1`. If theend of the occurrence is at the end of`    source_value`,`    LENGTH(source_value) + 1`is returned.\n\nReturns`0`if:\n\n- No match is found.\n- If`    occurrence`is greater than the number of matches found.\n- If`    position`is greater than the length of`    source_value`.\n- The regular expression is empty.\n\nReturns`NULL`if:\n\n- `    position`is`    NULL`.\n- `    occurrence`is`    NULL`.\n\nReturns an error if:\n\n- `    position`is`    0`or negative.\n- `    occurrence`is`    0`or negative.\n- `    occurrence_position`is neither`    0`nor`    1`.\n- The regular expression is invalid.\n- The regular expression has more than one capturing group.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH example AS (  SELECT 'ab@cd-ef' AS source_value, '@[^-]*' AS regexp UNION ALL  SELECT 'ab@d-ef', '@[^-]*' UNION ALL  SELECT 'abc@cd-ef', '@[^-]*' UNION ALL  SELECT 'abc-ef', '@[^-]*')SELECT source_value, regexp, REGEXP_INSTR(source_value, regexp) AS instrFROM example;/*--------------+--------+-------* | source_value | regexp | instr | +--------------+--------+-------+ | ab@cd-ef     | @[^-]* | 3     | | ab@d-ef      | @[^-]* | 3     | | abc@cd-ef    | @[^-]* | 4     | | abc-ef       | @[^-]* | 0     | *--------------+--------+-------*/\n```\n\n```\nWITH example AS (  SELECT 'a@cd-ef b@cd-ef' AS source_value, '@[^-]*' AS regexp, 1 AS position UNION ALL  SELECT 'a@cd-ef b@cd-ef', '@[^-]*', 2 UNION ALL  SELECT 'a@cd-ef b@cd-ef', '@[^-]*', 3 UNION ALL  SELECT 'a@cd-ef b@cd-ef', '@[^-]*', 4)SELECT  source_value, regexp, position,  REGEXP_INSTR(source_value, regexp, position) AS instrFROM example;/*-----------------+--------+----------+-------* | source_value    | regexp | position | instr | +-----------------+--------+----------+-------+ | a@cd-ef b@cd-ef | @[^-]* | 1        | 2     | | a@cd-ef b@cd-ef | @[^-]* | 2        | 2     | | a@cd-ef b@cd-ef | @[^-]* | 3        | 10    | | a@cd-ef b@cd-ef | @[^-]* | 4        | 10    | *-----------------+--------+----------+-------*/\n```\n\n```\nWITH example AS (  SELECT 'a@cd-ef b@cd-ef c@cd-ef' AS source_value,         '@[^-]*' AS regexp, 1 AS position, 1 AS occurrence UNION ALL  SELECT 'a@cd-ef b@cd-ef c@cd-ef', '@[^-]*', 1, 2 UNION ALL  SELECT 'a@cd-ef b@cd-ef c@cd-ef', '@[^-]*', 1, 3)SELECT  source_value, regexp, position, occurrence,  REGEXP_INSTR(source_value, regexp, position, occurrence) AS instrFROM example;/*-------------------------+--------+----------+------------+-------* | source_value            | regexp | position | occurrence | instr | +-------------------------+--------+----------+------------+-------+ | a@cd-ef b@cd-ef c@cd-ef | @[^-]* | 1        | 1          | 2     | | a@cd-ef b@cd-ef c@cd-ef | @[^-]* | 1        | 2          | 10    | | a@cd-ef b@cd-ef c@cd-ef | @[^-]* | 1        | 3          | 18    | *-------------------------+--------+----------+------------+-------*/\n```\n\n```\nWITH example AS (  SELECT 'a@cd-ef' AS source_value, '@[^-]*' AS regexp,         1 AS position, 1 AS occurrence, 0 AS o_position UNION ALL  SELECT 'a@cd-ef', '@[^-]*', 1, 1, 1)SELECT  source_value, regexp, position, occurrence, o_position,  REGEXP_INSTR(source_value, regexp, position, occurrence, o_position) AS instrFROM example;/*--------------+--------+----------+------------+------------+-------* | source_value | regexp | position | occurrence | o_position | instr | +--------------+--------+----------+------------+------------+-------+ | a@cd-ef      | @[^-]* | 1        | 1          | 0          | 2     | | a@cd-ef      | @[^-]* | 1        | 1          | 1          | 5     | *--------------+--------+----------+------------+------------+-------*/\n```\n\n"
  },
  {
    "name": "REGEXP_REPLACE",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREGEXP_REPLACE(value, regexp, replacement)\n```\n\n **Description** \n\nReturns a`STRING`where all substrings of`value`thatmatch regular expression`regexp`are replaced with`replacement`.\n\nYou can use backslashed-escaped digits (\\1 to \\9) within the`replacement`argument to insert text matching the corresponding parenthesized group in the`regexp`pattern. Use \\0 to refer to the entire matching text.\n\nTo add a backslash in your regular expression, you must first escape it. Forexample,`SELECT REGEXP_REPLACE('abc', 'b(.)', 'X\\\\1');`returns`aXc`. You canalso use[raw strings](/bigquery/docs/reference/standard-sql/lexical#string_and_bytes_literals)to remove one layer ofescaping, for example`SELECT REGEXP_REPLACE('abc', 'b(.)', r'X\\1');`.\n\nThe`REGEXP_REPLACE`function only replaces non-overlapping matches. Forexample, replacing`ana`within`banana`results in only one replacement, nottwo.\n\nIf the`regexp`argument is not a valid regular expression, this functionreturns an error.\n\n **Note:** GoogleSQL provides regular expression support using the[re2](https://github.com/google/re2/wiki/Syntax)library; see that documentation for itsregular expression syntax. **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH markdown AS  (SELECT '# Heading' as heading  UNION ALL  SELECT '# Another heading' as heading)SELECT  REGEXP_REPLACE(heading, r'^# ([a-zA-Z0-9\\s]+$)', '&lt;h1&gt;\\\\1&lt;/h1&gt;')  AS htmlFROM markdown;/*--------------------------* | html                     | +--------------------------+ | &lt;h1&gt;Heading&lt;/h1&gt;         | | &lt;h1&gt;Another heading&lt;/h1&gt; | *--------------------------*/\n```\n\n"
  },
  {
    "name": "REGEXP_SUBSTR",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREGEXP_SUBSTR(value, regexp[, position[, occurrence]])\n```\n\n **Description** \n\nSynonym for[REGEXP_EXTRACT](#regexp_extract).\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH example AS(SELECT 'Hello World Helloo' AS value, 'H?ello+' AS regex, 1 AS position, 1 ASoccurrence)SELECT value, regex, position, occurrence, REGEXP_SUBSTR(value, regex,position, occurrence) AS regexp_value FROM example;/*--------------------+---------+----------+------------+--------------* | value              | regex   | position | occurrence | regexp_value | +--------------------+---------+----------+------------+--------------+ | Hello World Helloo | H?ello+ | 1        | 1          | Hello        | *--------------------+---------+----------+------------+--------------*/\n```\n\n"
  },
  {
    "name": "REPEAT",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREPEAT(original_value, repetitions)\n```\n\n **Description** \n\nReturns a`STRING`or`BYTES`value that consists of`original_value`, repeated.The`repetitions`parameter specifies the number of times to repeat`original_value`. Returns`NULL`if either`original_value`or`repetitions`are`NULL`.\n\nThis function returns an error if the`repetitions`value is negative.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nSELECT t, n, REPEAT(t, n) AS REPEAT FROM UNNEST([  STRUCT('abc' AS t, 3 AS n),  ('例子', 2),  ('abc', null),  (null, 3)]);/*------+------+-----------* | t    | n    | REPEAT    | |------|------|-----------| | abc  | 3    | abcabcabc | | 例子 | 2    | 例子例子  | | abc  | NULL | NULL      | | NULL | 3    | NULL      | *------+------+-----------*/\n```\n\n"
  },
  {
    "name": "REPLACE",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREPLACE(original_value, from_pattern, to_pattern)\n```\n\n **Description** \n\nReplaces all occurrences of`from_pattern`with`to_pattern`in`original_value`. If`from_pattern`is empty, no replacement is made.\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH desserts AS  (SELECT 'apple pie' as dessert  UNION ALL  SELECT 'blackberry pie' as dessert  UNION ALL  SELECT 'cherry pie' as dessert)SELECT  REPLACE (dessert, 'pie', 'cobbler') as exampleFROM desserts;/*--------------------* | example            | +--------------------+ | apple cobbler      | | blackberry cobbler | | cherry cobbler     | *--------------------*/\n```\n\n"
  },
  {
    "name": "REVERSE",
    "arguments": [],
    "category": "String functions",
    "description": "```\nREVERSE(value)\n```\n\n **Description** \n\nReturns the reverse of the input`STRING`or`BYTES`.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH example AS (  SELECT 'foo' AS sample_string, b'bar' AS sample_bytes UNION ALL  SELECT 'абвгд' AS sample_string, b'123' AS sample_bytes)SELECT  sample_string,  REVERSE(sample_string) AS reverse_string,  sample_bytes,  REVERSE(sample_bytes) AS reverse_bytesFROM example;/*---------------+----------------+--------------+---------------* | sample_string | reverse_string | sample_bytes | reverse_bytes | +---------------+----------------+--------------+---------------+ | foo           | oof            | bar          | rab           | | абвгд         | дгвба          | 123          | 321           | *---------------+----------------+--------------+---------------*/\n```\n\n"
  },
  {
    "name": "RIGHT",
    "arguments": [],
    "category": "String functions",
    "description": "```\nRIGHT(value, length)\n```\n\n **Description** \n\nReturns a`STRING`or`BYTES`value that consists of the specifiednumber of rightmost characters or bytes from`value`. The`length`is an`INT64`that specifies the length of the returnedvalue. If`value`is`BYTES`,`length`is the number of rightmost bytes toreturn. If`value`is`STRING`,`length`is the number of rightmost charactersto return.\n\nIf`length`is 0, an empty`STRING`or`BYTES`value will bereturned. If`length`is negative, an error will be returned. If`length`exceeds the number of characters or bytes from`value`, the original`value`will be returned.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH examples AS(SELECT 'apple' as exampleUNION ALLSELECT 'banana' as exampleUNION ALLSELECT 'абвгд' as example)SELECT example, RIGHT(example, 3) AS right_exampleFROM examples;/*---------+---------------* | example | right_example | +---------+---------------+ | apple   | ple           | | banana  | ana           | | абвгд   | вгд           | *---------+---------------*/\n```\n\n```\nWITH examples AS(SELECT b'apple' as exampleUNION ALLSELECT b'banana' as exampleUNION ALLSELECT b'\\xab\\xcd\\xef\\xaa\\xbb' as example)SELECT example, RIGHT(example, 3) AS right_exampleFROM examples;-- Note that the result of RIGHT is of type BYTES, displayed as a base64-encoded string./*----------+---------------* | example  | right_example | +----------+---------------+ | YXBwbGU= | cGxl          | | YmFuYW5h | YW5h          | | q83vqrs= | 76q7          | *----------+---------------*/\n```\n\n"
  },
  {
    "name": "ROUND",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nROUND(X [, N [, rounding_mode]])\n```\n\n **Description** \n\nIf only X is present, rounds X to the nearest integer. If N is present,rounds X to N decimal places after the decimal point. If N is negative,rounds off digits to the left of the decimal point. Rounds halfway casesaway from zero. Generates an error if overflow occurs.\n\nIf X is a`NUMERIC`or`BIGNUMERIC`type, then you canexplicitly set`rounding_mode`to one of the following:\n\n- [\"ROUND_HALF_AWAY_FROM_ZERO\"](https://en.wikipedia.org/wiki/Rounding#Rounding_half_away_from_zero): (Default) Roundshalfway cases away from zero.\n- [\"ROUND_HALF_EVEN\"](https://en.wikipedia.org/wiki/Rounding#Rounding_half_to_even): Rounds halfway casestowards the nearest even digit.\n\nIf you set the`rounding_mode`and X is not a`NUMERIC`or`BIGNUMERIC`type,then the function generates an error.\n\n| Expression | Return Value |\n| --- | --- |\n| `ROUND(2.0)` | 2.0 |\n| `ROUND(2.3)` | 2.0 |\n| `ROUND(2.8)` | 3.0 |\n| `ROUND(2.5)` | 3.0 |\n| `ROUND(-2.3)` | -2.0 |\n| `ROUND(-2.8)` | -3.0 |\n| `ROUND(-2.5)` | -3.0 |\n| `ROUND(0)` | 0 |\n| `ROUND(+inf)` | `+inf` |\n| `ROUND(-inf)` | `-inf` |\n| `ROUND(NaN)` | `NaN` |\n| `ROUND(123.7, -1)` | 120.0 |\n| `ROUND(1.235, 2)` | 1.24 |\n| `ROUND(NUMERIC \"2.25\", 1, \"ROUND_HALF_EVEN\")` | 2.2 |\n| `ROUND(NUMERIC \"2.35\", 1, \"ROUND_HALF_EVEN\")` | 2.4 |\n| `ROUND(NUMERIC \"2.251\", 1, \"ROUND_HALF_EVEN\")` | 2.3 |\n| `ROUND(NUMERIC \"-2.5\", 0, \"ROUND_HALF_EVEN\")` | -2 |\n| `ROUND(NUMERIC \"2.5\", 0, \"ROUND_HALF_AWAY_FROM_ZERO\")` | 3 |\n| `ROUND(NUMERIC \"-2.5\", 0, \"ROUND_HALF_AWAY_FROM_ZERO\")` | -3 |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "ROW_NUMBER",
    "arguments": [],
    "category": "Numbering functions",
    "description": "```\nROW_NUMBER()OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]\n```\n\n **Description** \n\nDoes not require the`ORDER BY`clause. Returns the sequentialrow ordinal (1-based) of each row for each ordered partition. If the`ORDER BY`clause is unspecified then the result isnon-deterministic.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH Numbers AS (SELECT 1 as x  UNION ALL SELECT 2  UNION ALL SELECT 2  UNION ALL SELECT 5  UNION ALL SELECT 8  UNION ALL SELECT 10  UNION ALL SELECT 10)SELECT x,  ROW_NUMBER() OVER (ORDER BY x) AS row_numFROM Numbers/*-------------------------* | x          | row_num    | +-------------------------+ | 1          | 1          | | 2          | 2          | | 2          | 3          | | 5          | 4          | | 8          | 5          | | 10         | 6          | | 10         | 7          | *-------------------------*/\n```\n\n```\nWITH finishers AS (SELECT 'Sophia Liu' as name,  TIMESTAMP '2016-10-18 2:51:45' as finish_time,  'F30-34' as division  UNION ALL SELECT 'Lisa Stelzner', TIMESTAMP '2016-10-18 2:54:11', 'F35-39'  UNION ALL SELECT 'Nikki Leith', TIMESTAMP '2016-10-18 2:59:01', 'F30-34'  UNION ALL SELECT 'Lauren Matthews', TIMESTAMP '2016-10-18 3:01:17', 'F35-39'  UNION ALL SELECT 'Desiree Berry', TIMESTAMP '2016-10-18 3:05:42', 'F35-39'  UNION ALL SELECT 'Suzy Slane', TIMESTAMP '2016-10-18 3:06:24', 'F35-39'  UNION ALL SELECT 'Jen Edwards', TIMESTAMP '2016-10-18 3:06:36', 'F30-34'  UNION ALL SELECT 'Meghan Lederer', TIMESTAMP '2016-10-18 2:59:01', 'F30-34')SELECT name,  finish_time,  division,  ROW_NUMBER() OVER (PARTITION BY division ORDER BY finish_time ASC) AS finish_rankFROM finishers;/*-----------------+------------------------+----------+-------------* | name            | finish_time            | division | finish_rank | +-----------------+------------------------+----------+-------------+ | Sophia Liu      | 2016-10-18 09:51:45+00 | F30-34   | 1           | | Meghan Lederer  | 2016-10-18 09:59:01+00 | F30-34   | 2           | | Nikki Leith     | 2016-10-18 09:59:01+00 | F30-34   | 3           | | Jen Edwards     | 2016-10-18 10:06:36+00 | F30-34   | 4           | | Lisa Stelzner   | 2016-10-18 09:54:11+00 | F35-39   | 1           | | Lauren Matthews | 2016-10-18 10:01:17+00 | F35-39   | 2           | | Desiree Berry   | 2016-10-18 10:05:42+00 | F35-39   | 3           | | Suzy Slane      | 2016-10-18 10:06:24+00 | F35-39   | 4           | *-----------------+------------------------+----------+-------------*/\n```\n\n\n<span id=\"range_functions\">\n## Range functions\n\n</span>\nGoogleSQL for BigQuery supports the following range functions.\n\n"
  },
  {
    "name": "RPAD",
    "arguments": [],
    "category": "String functions",
    "description": "```\nRPAD(original_value, return_length[, pattern])\n```\n\n **Description** \n\nReturns a`STRING`or`BYTES`value that consists of`original_value`appendedwith`pattern`. The`return_length`parameter is an`INT64`that specifies the length of thereturned value. If`original_value`is`BYTES`,`return_length`is the number of bytes. If`original_value`is`STRING`,`return_length`is the number of characters.\n\nThe default value of`pattern`is a blank space.\n\nBoth`original_value`and`pattern`must be the same data type.\n\nIf`return_length`is less than or equal to the`original_value`length, thisfunction returns the`original_value`value, truncated to the value of`return_length`. For example,`RPAD('hello world', 7);`returns`'hello w'`.\n\nIf`original_value`,`return_length`, or`pattern`is`NULL`, this functionreturns`NULL`.\n\nThis function returns an error if:\n\n- `    return_length`is negative\n- `    pattern`is empty\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nSELECT t, len, FORMAT('%T', RPAD(t, len)) AS RPAD FROM UNNEST([  STRUCT('abc' AS t, 5 AS len),  ('abc', 2),  ('例子', 4)]);/*------+-----+----------* | t    | len | RPAD     | +------+-----+----------+ | abc  | 5   | \"abc  \"  | | abc  | 2   | \"ab\"     | | 例子  | 4   | \"例子  \" | *------+-----+----------*/\n```\n\n```\nSELECT t, len, pattern, FORMAT('%T', RPAD(t, len, pattern)) AS RPAD FROM UNNEST([  STRUCT('abc' AS t, 8 AS len, 'def' AS pattern),  ('abc', 5, '-'),  ('例子', 5, '中文')]);/*------+-----+---------+--------------* | t    | len | pattern | RPAD         | +------+-----+---------+--------------+ | abc  | 8   | def     | \"abcdefde\"   | | abc  | 5   | -       | \"abc--\"      | | 例子  | 5   | 中文     | \"例子中文中\"  | *------+-----+---------+--------------*/\n```\n\n```\nSELECT FORMAT('%T', t) AS t, len, FORMAT('%T', RPAD(t, len)) AS RPAD FROM UNNEST([  STRUCT(b'abc' AS t, 5 AS len),  (b'abc', 2),  (b'\\xab\\xcd\\xef', 4)]);/*-----------------+-----+------------------* | t               | len | RPAD             | +-----------------+-----+------------------+ | b\"abc\"          | 5   | b\"abc  \"         | | b\"abc\"          | 2   | b\"ab\"            | | b\"\\xab\\xcd\\xef\" | 4   | b\"\\xab\\xcd\\xef \" | *-----------------+-----+------------------*/\n```\n\n```\nSELECT  FORMAT('%T', t) AS t,  len,  FORMAT('%T', pattern) AS pattern,  FORMAT('%T', RPAD(t, len, pattern)) AS RPADFROM UNNEST([  STRUCT(b'abc' AS t, 8 AS len, b'def' AS pattern),  (b'abc', 5, b'-'),  (b'\\xab\\xcd\\xef', 5, b'\\x00')]);/*-----------------+-----+---------+-------------------------* | t               | len | pattern | RPAD                    | +-----------------+-----+---------+-------------------------+ | b\"abc\"          | 8   | b\"def\"  | b\"abcdefde\"             | | b\"abc\"          | 5   | b\"-\"    | b\"abc--\"                | | b\"\\xab\\xcd\\xef\" | 5   | b\"\\x00\" | b\"\\xab\\xcd\\xef\\x00\\x00\" | *-----------------+-----+---------+-------------------------*/\n```\n\n"
  },
  {
    "name": "RTRIM",
    "arguments": [],
    "category": "String functions",
    "description": "```\nRTRIM(value1[, value2])\n```\n\n **Description** \n\nIdentical to[TRIM](#trim), but only removes trailing characters.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH items AS  (SELECT '***apple***' as item  UNION ALL  SELECT '***banana***' as item  UNION ALL  SELECT '***orange***' as item)SELECT  RTRIM(item, '*') as exampleFROM items;/*-----------* | example   | +-----------+ | ***apple  | | ***banana | | ***orange | *-----------*/\n```\n\n```\nWITH items AS  (SELECT 'applexxx' as item  UNION ALL  SELECT 'bananayyy' as item  UNION ALL  SELECT 'orangezzz' as item  UNION ALL  SELECT 'pearxyz' as item)SELECT  RTRIM(item, 'xyz') as exampleFROM items;/*---------* | example | +---------+ | apple   | | banana  | | orange  | | pear    | *---------*/\n```\n\n"
  },
  {
    "name": "S2_CELLIDFROMPOINT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nS2_CELLIDFROMPOINT(point_geography[, level =&gt; cell_level])\n```\n\n **Description** \n\nReturns the[S2 cell ID](https://s2geometry.io/devguide/s2cell_hierarchy)covering a point`GEOGRAPHY`.\n\n- The optional`    INT64`parameter`    level`specifies the S2 cell level for thereturned cell. Naming this argument is optional.\n\nThis is advanced functionality for interoperability with systems utilizing the[S2 Geometry Library](https://s2geometry.io/).\n\n **Constraints** \n\n- Returns the cell ID as a signed`    INT64`bit-equivalent to[unsigned 64-bit integer representation](https://s2geometry.io/devguide/s2cell_hierarchy).\n- Can return negative cell IDs.\n- Valid S2 cell levels are 0 to 30.\n- `    level`defaults to 30 if not explicitly specified.\n- The function only supports a single point GEOGRAPHY. Use the`    SAFE`prefix ifthe input can be multipoint, linestring, polygon, or an empty`    GEOGRAPHY`.\n- To compute the covering of a complex`    GEOGRAPHY`, use[S2_COVERINGCELLIDS](#s2_coveringcellids).\n\n **Return type** \n\n`INT64`\n\n **Example** \n\n```\nWITH data AS (  SELECT 1 AS id, ST_GEOGPOINT(-122, 47) AS geo  UNION ALL  -- empty geography is not supported  SELECT 2 AS id, ST_GEOGFROMTEXT('POINT EMPTY') AS geo  UNION ALL  -- only points are supported  SELECT 3 AS id, ST_GEOGFROMTEXT('LINESTRING(1 2, 3 4)') AS geo)SELECT id,       SAFE.S2_CELLIDFROMPOINT(geo) cell30,       SAFE.S2_CELLIDFROMPOINT(geo, level =&gt; 10) cell10FROM data;/*----+---------------------+---------------------* | id | cell30              | cell10              | +----+---------------------+---------------------+ | 1  | 6093613931972369317 | 6093613287902019584 | | 2  | NULL                | NULL                | | 3  | NULL                | NULL                | *----+---------------------+---------------------*/\n```\n\n"
  },
  {
    "name": "S2_COVERINGCELLIDS",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nS2_COVERINGCELLIDS(    geography    [, min_level =&gt; cell_level]    [, max_level =&gt; cell_level]    [, max_cells =&gt; max_cells]    [, buffer =&gt; buffer])\n```\n\n **Description** \n\nReturns an array of[S2 cell IDs](https://s2geometry.io/devguide/s2cell_hierarchy)that cover the input`GEOGRAPHY`. The function returns at most`max_cells`cells. The optionalarguments`min_level`and`max_level`specify minimum and maximum levels forreturned S2 cells. The array size is limited by the optional`max_cells`argument. The optional`buffer`argument specifies a buffering factor inmeters; the region being covered is expanded from the extent of theinput geography by this amount.\n\nThis is advanced functionality for interoperability with systems utilizing the[S2 Geometry Library](https://s2geometry.io/).\n\n **Constraints** \n\n- Returns the cell ID as a signed`    INT64`bit-equivalent to[unsigned 64-bit integer representation](https://s2geometry.io/devguide/s2cell_hierarchy).\n- Can return negative cell IDs.\n- Valid S2 cell levels are 0 to 30.\n- `    max_cells`defaults to 8 if not explicitly specified.\n- `    buffer`should be nonnegative. It defaults to 0.0 meters if not explicitlyspecified.\n\n **Return type** \n\n`ARRAY&lt;INT64&gt;`\n\n **Example** \n\n```\nWITH data AS (  SELECT 1 AS id, ST_GEOGPOINT(-122, 47) AS geo  UNION ALL  SELECT 2 AS id, ST_GEOGFROMTEXT('POINT EMPTY') AS geo  UNION ALL  SELECT 3 AS id, ST_GEOGFROMTEXT('LINESTRING(-122.12 47.67, -122.19 47.69)') AS geo)SELECT id, S2_COVERINGCELLIDS(geo, min_level =&gt; 12) cellsFROM data;/*----+--------------------------------------------------------------------------------------* | id | cells                                                                                | +----+--------------------------------------------------------------------------------------+ | 1  | [6093613931972369317]                                                                | | 2  | []                                                                                   | | 3  | [6093384954555662336, 6093390709811838976, 6093390735581642752, 6093390740145045504, | |    |  6093390791416217600, 6093390812891054080, 6093390817187069952, 6093496378892222464] | *----+--------------------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "SAFE_ADD",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSAFE_ADD(X, Y)\n```\n\n **Description** \n\nEquivalent to the addition operator (`+`), but returns`NULL`if overflow occurs.\n\n| X | Y | SAFE_ADD(X, Y) |\n| --- | --- | --- |\n| 5 | 4 | 9 |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| `INT64` | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `NUMERIC` | `NUMERIC` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` |\n\n"
  },
  {
    "name": "SAFE_CAST",
    "arguments": [],
    "category": "Conversion functions",
    "description": "```\nSAFE_CAST(expression AS typename [format_clause])\n```\n\n **Description** \n\nWhen using`CAST`, a query can fail if GoogleSQL is unable to performthe cast. For example, the following query generates an error:\n\n```\nSELECT CAST(\"apple\" AS INT64) AS not_a_number;\n```\n\nIf you want to protect your queries from these types of errors, you can use`SAFE_CAST`.`SAFE_CAST`replaces runtime errors with`NULL`s.  However, duringstatic analysis, impossible casts between two non-castable types still producean error because the query is invalid.\n\n```\nSELECT SAFE_CAST(\"apple\" AS INT64) AS not_a_number;/*--------------* | not_a_number | +--------------+ | NULL         | *--------------*/\n```\n\nSome casts can include a[format clause](/bigquery/docs/reference/standard-sql/format-elements#formatting_syntax), which providesinstructions for how to conduct thecast. For example, you couldinstruct a cast to convert a sequence of bytes to a BASE64-encoded stringinstead of a UTF-8-encoded string.\n\nThe structure of the format clause is unique to each type of cast and moreinformation is available in the section for that cast.\n\nIf you are casting from bytes to strings, you can also use thefunction,[SAFE_CONVERT_BYTES_TO_STRING](#safe_convert_bytes_to_string). Any invalid UTF-8 charactersare replaced with the unicode replacement character,`U+FFFD`.\n\n"
  },
  {
    "name": "SAFE_CONVERT_BYTES_TO_STRING",
    "arguments": [],
    "category": "String functions",
    "description": "```\nSAFE_CONVERT_BYTES_TO_STRING(value)\n```\n\n **Description** \n\nConverts a sequence of`BYTES`to a`STRING`. Any invalid UTF-8 characters arereplaced with the Unicode replacement character,`U+FFFD`.\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\nThe following statement returns the Unicode replacement character, �.\n\n```\nSELECT SAFE_CONVERT_BYTES_TO_STRING(b'\\xc2') as safe_convert;\n```\n\n"
  },
  {
    "name": "SAFE_DIVIDE",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSAFE_DIVIDE(X, Y)\n```\n\n **Description** \n\nEquivalent to the division operator (`X / Y`), but returns`NULL`if an error occurs, such as a division by zero error.\n\n| X | Y | SAFE_DIVIDE(X, Y) |\n| --- | --- | --- |\n| 20 | 4 | 5 |\n| 0 | 20 | `0` |\n| 20 | 0 | `NULL` |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| `INT64` | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `NUMERIC` | `NUMERIC` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` |\n\n"
  },
  {
    "name": "SAFE_MULTIPLY",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSAFE_MULTIPLY(X, Y)\n```\n\n **Description** \n\nEquivalent to the multiplication operator (`*`), but returns`NULL`if overflow occurs.\n\n| X | Y | SAFE_MULTIPLY(X, Y) |\n| --- | --- | --- |\n| 20 | 4 | 80 |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| `INT64` | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `NUMERIC` | `NUMERIC` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` |\n\n"
  },
  {
    "name": "SAFE_NEGATE",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSAFE_NEGATE(X)\n```\n\n **Description** \n\nEquivalent to the unary minus operator (`-`), but returns`NULL`if overflow occurs.\n\n| X | SAFE_NEGATE(X) |\n| --- | --- |\n| +1 | -1 |\n| -1 | +1 |\n| 0 | 0 |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "SAFE_SUBTRACT",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSAFE_SUBTRACT(X, Y)\n```\n\n **Description** \n\nReturns the result of Y subtracted from X.Equivalent to the subtraction operator (`-`), but returns`NULL`if overflow occurs.\n\n| X | Y | SAFE_SUBTRACT(X, Y) |\n| --- | --- | --- |\n| 5 | 4 | 1 |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| `INT64` | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `NUMERIC` | `NUMERIC` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` | `FLOAT64` |\n\n"
  },
  {
    "name": "SEARCH",
    "arguments": [],
    "category": "Search functions",
    "description": "```\nSEARCH(  data_to_search, search_query  [, json_scope=&gt;{ 'JSON_VALUES' | 'JSON_KEYS' | 'JSON_KEYS_AND_VALUES' }]  [, analyzer=&gt;{ 'LOG_ANALYZER' | 'NO_OP_ANALYZER' | 'PATTERN_ANALYZER'}]  [, analyzer_options=&gt;analyzer_options_values])\n```\n\n **Description** \n\nThe`SEARCH`function checks to see whether a BigQuery table or othersearch data contains a set of search terms (tokens). It returns`TRUE`if allsearch terms appear in the data, based on the text analysisdescribed in the[text analyzer](/bigquery/docs/reference/standard-sql/text-analysis), and`FALSE`otherwise.\n\n **Definitions** \n\n- `    data_to_search`: The data to search over. The value can be:\n    \n    \n    - Any GoogleSQL data type literal\n    - A list of columns\n    - A table reference\n    - A column of any typeA table reference is evaluated as a`    STRUCT`whose fields are the columns ofthe table.`    data_to_search`can be any type, but`    SEARCH`will return`    FALSE`for all types except those listed here:\n    \n    \n    - `        ARRAY&lt;STRING&gt;`\n    - `        ARRAY&lt;STRUCT&gt;`\n    - `        JSON`\n    - `        STRING`\n    - `        STRUCT`You can search for string literals in columns of the preceding types.For additional rules, see[Search data rules](#data_to_search_rules).\n    \n    \n- `    search_query`: A`    STRING`literal, or a`    STRING`constant expression thatrepresents the terms of the search query. If`    search_query`is`    NULL`, anerror is returned. If`    search_query`contains no tokens and the textanalyzer is`    LOG_ANALYZER`, an error is returned.\n    \n    \n- `    json_scope`: Optional mandatory-named argument thattakes one of the following values to indicate the scope of JSON data to besearched. It has no effect if`    data_to_search`isn't a JSON value ordoesn't contain a JSON field.\n    \n    \n    - `        'JSON_VALUES'`(default): Only the JSON values are searched. If`        json_scope`isn't provided, this is used by default.\n        \n        \n    - `        'JSON_KEYS'`: Only the JSON keys are searched.\n        \n        \n    - `        'JSON_KEYS_AND_VALUES'`: The JSON keys and values are searched.\n        \n        \n- `    analyzer`: Optional mandatory-named argument that takesone of the following values to indicate the text analyzer to use:\n    \n    \n    - `        'LOG_ANALYZER'`(default): Breaks the input into terms when delimitersare encountered and then normalizes the terms.For more information, see[LOG_ANALYZER](/bigquery/docs/reference/standard-sql/text-analysis#log_analyzer).\n        \n        \n    - `        'NO_OP_ANALYZER'`: Extracts the text as a single term (token), butdoesn't apply normalization. For more information about this analyzer,see[NO_OP_ANALYZER](/bigquery/docs/reference/standard-sql/text-analysis#no_op_analyzer).\n        \n        \n    - `        'PATTERN_ANALYZER'`: Breaks the input into terms that match aregular expression. For more information, see[PATTERN_ANALYZER text analyzer](/bigquery/docs/reference/standard-sql/text-analysis#pattern_analyzer).\n        \n        \n- `    analyzer_options`: Optional mandatory-named argument that takes a list oftext analysis rules as a JSON-formatted`    STRING`. For more information,see[Text analyzer options](/bigquery/docs/reference/standard-sql/text-analysis#text_analyzer_options).\n    \n    \n\n **Details** \n\nThe`SEARCH`function is designed to work with[search indexes](/bigquery/docs/search-index)tooptimize point lookups. Although the`SEARCH`function works fortables that aren't indexed, its performance will be greatly improved with asearch index. If both the analyzer and analyzer options match the one usedto create the index, the search index will be used.\n\n<span id=\"text_analyzer\"></span>\n\n<span id=\"search_term_rules\"></span>\n\n **Rules for`search_query`** \n\nAdditional parsing rules for`search_query`:\n\n- If the`    LOG_ANALYZER`text analyzer is used, text enclosed in backticksforces an exact match.\n    \n    For example,`    `Hello World` happy days`becomes`    Hello World`,`    happy`,and`    days`.\n    \n    \n- Search terms enclosed in backticks must match exactly in`    data_to_search`,subject to the following conditions:\n    \n    \n    - It appears at the start of`        data_to_search`or is immediately precededby a delimiter.\n        \n        \n    - It appears at the end of`        data_to_search`or is immediately followed bya delimiter.\n        \n        For example,`    SEARCH('foo.bar', '`foo.`')`returns`    FALSE`because thetext enclosed in the backticks`    foo.`is immediately followed by thecharacter`    b`in the search data`    foo.bar`, rather than by a delimiter orthe end of the string. However,`    SEARCH('foo..bar', '`foo.`')`returns`    TRUE`because`    foo.`is immediately followed by the delimiter`    .`in thesearch data.\n    \n    \n- The backtick itself can be escaped using a backslash,as in`    \\`foobar\\``.\n    \n    \n- The following are reserved words and must be enclosedin backticks:\n    \n    `    AND`,`    NOT`,`    OR`,`    IN`, and`    NEAR`\n    \n    \n- Text not enclosed in backticks requires the followingreserved characters to be escaped by a double backslash`    \\\\`:\n    \n    \n    - `        [ ] &lt; &gt; ( ) { } | ! ' \" * &amp; ? + / : = - \\ ~ ^`\n        \n        \n    - If the quoted string is preceded by the character`        r`or`        R`, such as`        r\"my\\+string\"`, then it is treated as a raw string and only a singlebackslash is required to escape the reserved characters. For moreinformation about raw strings and escapesequences, see[String and byte literals](/bigquery/docs/reference/standard-sql/lexical#literals).\n        \n        \n\n<span id=\"data_to_search_rules\"></span>\n\n **Rules for`data_to_search`** \n\nAdditional rules for`data_to_search`:\n\n- `    data_to_search`must contain all terms, in any order, from the`    search_query`for the function to return`    TRUE`.\n- To perform a cross-field search,`    data_to_search`must be a`    STRUCT`,`    ARRAY`, or`    JSON`data type.\n- Each`    STRING`field in a compound data type is individuallysearched for terms.\n- If at least one field in`    data_to_search`includes all search termsin any order,`    SEARCH`returns`    TRUE`. Otherwise it has the followingbehavior:\n    \n    \n    - If at least one`        STRING`field is`        NULL`,`        SEARCH`returns`        NULL`.\n        \n        \n    - Otherwise,`        SEARCH`returns`        FALSE`.\n        \n        \n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\nThe following table shows examples of how`search_data`is broken intosearchable terms by the`LOG_ANALYZER`text analyzer. All entries are strings.\n\n| search_data | searchable terms |\n| --- | --- |\n| 127.0.0.1 | 127    \n0    \n1    \n127.0.0.1    \n.127.0.0    \n127.0    \n0.0    \n0.0.1    \n0.1 |\n| foobar@example.com | foobar    \nexample    \ncom    \nfoobar@example    \nexample.com    \nfoobar@example.com |\n| The fox. | the    \nfox    \nThe    \nThe fox    \nThe fox.    \nfox    \nfox. |\n\nThe following table shows examples of how`search_query`is broken into queryterms by the`LOG_ANALYZER`text analyzer. All entries are strings.\n\n| search_query | query terms |\n| --- | --- |\n| 127.0.0.1 | 127    \n0    \n1    \n |\n| `127.0.0.1` | 127.0.0.1 |\n| foobar@example.com | foobar    \nexample    \ncom |\n| `foobar@example.com` | foobar@example.com |\n\nThe following table shows examples of calls to the`SEARCH`function and reasonsfor various return values:\n\n| function call | returns | reason |\n| --- | --- | --- |\n| SEARCH('foobarexample', NULL) | ERROR | The search_query is NULL. |\n| SEARCH('foobarexample', '') | ERROR | The search_query contains no tokens. |\n| SEARCH('foobar-example', 'foobar example') | TRUE | '-' and ' ' are delimiters. |\n| SEARCH('foobar-example', CONCAT('foo', 'bar')) | TRUE | The search query is a constant expression evaluated to 'foobar'. |\n| SEARCH('foobar-example', 'foobarexample') | FALSE | The search_query is not split. |\n| SEARCH('foobar-example', 'foobar\\&example') | TRUE | The double backslash escapes the ampersand which is a delimiter. |\n| SEARCH('foobar-example', R'foobar&example') | TRUE | The single backslash escapes the ampersand in a raw string. |\n| SEARCH('foobar-example', '`foobar&example`') | FALSE | The backticks require an exact match for foobar&example. |\n| SEARCH('foobar&example', '`foobar&example`') | TRUE | An exact match is found. |\n| SEARCH('foobar-example', 'example foobar') | TRUE | The order of terms doesn't matter. |\n| SEARCH('foobar-example', 'foobar example') | TRUE | Tokens are made lower-case. |\n| SEARCH('foobar-example', '`foobar-example`') | TRUE | An exact match is found. |\n| SEARCH('foobar-example', '`foobar`') | FALSE | Backticks preserve capitalization. |\n| SEARCH('`foobar-example`', '`foobar-example`') | FALSE | Backticks don't have special meaning for search_data and arenot delimiters in the default LOG_ANALYZER. |\n| SEARCH('foobar@example.com', '`example.com`') | TRUE | An exact match is found after the delimiter in search_data. |\n| SEARCH('a foobar-example b', '`foobar-example`') | TRUE | An exact match is found between the space delimiters. |\n| SEARCH(['foobar', 'example'], 'foobar example') | FALSE | No single array entry matches all search terms. |\n| SEARCH('foobar=', '`foobar\\=`') | FALSE | The search_query is equivalent to foobar=. |\n| SEARCH('foobar=', R'`\\foobar=`') | FALSE | This is equivalent to the previous example. |\n| SEARCH('foobar=', 'foobar\\=') | TRUE | The equals sign is a delimiter in the data and query. |\n| SEARCH('foobar=', R'foobar=') | TRUE | This is equivalent to the previous example. |\n| SEARCH('foobar.example', '`foobar`') | TRUE | An exact match is found. |\n| SEARCH('foobar.example', '`foobar.\\') | FALSE | `foobar.` is not analyzed because of backticks; it is notfollowed by a delimiter in search_data 'foobar.example'. |\n| SEARCH('foobar..example', '`foobar.`') | TRUE | `foobar.` is not analyzed because of backticks; it is followedby the delimiter '.' in search_data 'foobar..example'. |\n\nThe following table shows examples of calls to the`SEARCH`function using the`NO_OP_ANALYZER`text analyzer and reasons for various return values:\n\n| function call | returns | reason |\n| --- | --- | --- |\n| SEARCH('foobar', 'foobar', analyzer=>'NO_OP_ANALYZER') | TRUE | An exact match is found. |\n| SEARCH('foobar', '`foobar`', analyzer=>'NO_OP_ANALYZER') | FALSE | Backticks are not special characters for NO_OP_ANALYZER. |\n| SEARCH('foobar', 'foobar', analyzer=>'NO_OP_ANALYZER') | FALSE | The capitalization does not match. |\n| SEARCH('foobar example', 'foobar', analyzer=>'NO_OP_ANALYZER') | FALSE | There are no delimiters for NO_OP_ANALYZER. |\n| SEARCH('', '', analyzer=>'NO_OP_ANALYZER') | TRUE | An exact match is found. |\n\nConsider the following table called`meals`with columns`breakfast`,`lunch`,and`dinner`:\n\n```\n/*-------------------+-------------------------+------------------* | breakfast         | lunch                   | dinner           | +-------------------+-------------------------+------------------+ | Potato pancakes   | Toasted cheese sandwich | Beef soup        | | Avocado toast     | Tomato soup             | Chicken soup     | *-------------------+-------------------------+------------------*/\n```\n\nThe following query shows how to search single columns, multiple columns, andwhole tables, using the default[LOG_ANALYZER](/bigquery/docs/reference/standard-sql/text-analysis#log_analyzer)text analyzerwith the default analyzer options:\n\n```\nWITH  meals AS (    SELECT      'Potato pancakes' AS breakfast,      'Toasted cheese sandwich' AS lunch,      'Beef soup' AS dinner    UNION ALL    SELECT      'Avocado toast' AS breakfast,      'Tomato soup' AS lunch,      'Chicken soup' AS dinner  )SELECT  SEARCH(lunch, 'soup') AS lunch_soup,  SEARCH((breakfast, dinner), 'soup') AS breakfast_or_dinner_soup,  SEARCH(meals, 'soup') AS anytime_soupFROM meals;/*------------+--------------------------+--------------* | lunch_soup | breakfast_or_dinner_soup | anytime_soup | +------------+--------------------------+--------------+ | false      | true                     | true         | | true       | true                     | true         | *------------+--------------------------+--------------*/\n```\n\nThe following query shows additional ways to search, using thedefault[LOG_ANALYZER](/bigquery/docs/reference/standard-sql/text-analysis#log_analyzer)text analyzer withdefault analyzer options:\n\n```\nWITH data AS ( SELECT 'Please use foobar@example.com as your email.' AS email )SELECT  SEARCH(email, 'exam') AS a,  SEARCH(email, 'foobar') AS b,  SEARCH(email, 'example.com') AS cFROM data;/*-------+-------+-------* | a     | b     | c     | +-------+-------+-------+ | false | true  | true  | *-------+-------+-------*/\n```\n\nThe following query shows additional ways to search, using thedefault[LOG_ANALYZER](/bigquery/docs/reference/standard-sql/text-analysis#log_analyzer)text analyzer with customanalyzer options. Terms are only split when a space or`@`symbol isencountered.\n\n```\nWITH data AS ( SELECT 'Please use foobar@example.com as your email.' AS email )SELECT  SEARCH(email, 'foobar', analyzer_options=&gt;'{\"delimiters\": [\" \", \"@\"]}') AS a,  SEARCH(email, 'example', analyzer_options=&gt;'{\"delimiters\": [\" \", \"@\"]}') AS b,  SEARCH(email, 'example.com', analyzer_options=&gt;'{\"delimiters\": [\" \", \"@\"]}') AS c,  SEARCH(email, 'foobar@example.com', analyzer_options=&gt;'{\"delimiters\": [\" \", \"@\"]}') AS dFROM data;/*-------+-------+-------+-------* | a     | b     | c     | d     | +-------+-------+-------+-------+ | true  | false | true  | true  | *-------+-------+-------+-------*/\n```\n\nThe following query shows how to search, using the[NO_OP_ANALYZER](/bigquery/docs/reference/standard-sql/text-analysis#no_op_analyzer)text analyzer:\n\n```\nWITH meals AS ( SELECT 'Tomato soup' AS lunch )SELECT  SEARCH(lunch, 'Tomato soup', analyzer=&gt;'NO_OP_ANALYZER') AS a,  SEARCH(lunch, 'soup', analyzer=&gt;'NO_OP_ANALYZER') AS b,  SEARCH(lunch, 'tomato soup', analyzer=&gt;'NO_OP_ANALYZER') AS cFROM meals;/*-------+-------+-------* | a     | b     | c     | +-------+-------+-------+ | true  | false | false | *-------+-------+-------*/\n```\n\nThe following query shows how to use the[PATTERN_ANALYZER](/bigquery/docs/reference/standard-sql/text-analysis#pattern_analyzer)text analyzer with default analyzer options:\n\n```\nWITH data AS ( SELECT 'Please use foobar@example.com as your email.' AS email )SELECT  SEARCH(email, 'exam', analyzer=&gt;'PATTERN_ANALYZER') AS a,  SEARCH(email, 'foobar', analyzer=&gt;'PATTERN_ANALYZER') AS b,  SEARCH(email, 'example.com', analyzer=&gt;'PATTERN_ANALYZER') AS cFROM data;/*-------+-------+-------* | a     | b     | c     | +-------+-------+-------+ | false | true  | true  | *-------+-------+-------*/\n```\n\nThe following query shows additional ways to search, using the[PATTERN_ANALYZER](/bigquery/docs/reference/standard-sql/text-analysis#pattern_analyzer)text analyzer withcustom analyzer options:\n\n```\nWITH data AS ( SELECT 'Please use foobar@EXAMPLE.com as your email.' AS email )SELECT  SEARCH(email, 'EXAMPLE', analyzer=&gt;'PATTERN_ANALYZER', analyzer_options=&gt;'{\"patterns\": [\"[A-Z]*\"]}') AS a,  SEARCH(email, 'example', analyzer=&gt;'PATTERN_ANALYZER', analyzer_options=&gt;'{\"patterns\": [\"[a-z]*\"]}') AS b,  SEARCH(email, 'example.com', analyzer=&gt;'PATTERN_ANALYZER', analyzer_options=&gt;'{\"patterns\": [\"[a-z]*\"]}') AS c,  SEARCH(email, 'example.com', analyzer=&gt;'PATTERN_ANALYZER', analyzer_options=&gt;'{\"patterns\": [\"[a-zA-Z.]*\"]}') AS d,FROM data;/*-------+-------+-------+-------* | a     | b     | c     | d     | +-------+-------+-------+-------+ | true  | false | false | true  | *-------+-------+-------+-------*/\n```\n\nFor additional examples that include analyzer options,see the[Text analysis](/bigquery/docs/reference/standard-sql/text-analysis)reference guide.\n\nFor helpful analyzer recipes that you can use to enhanceanalyzer-supported queries, see the[Search with text analyzers](/bigquery/docs/text-analysis-search)user guide.\n\n"
  },
  {
    "name": "SEC",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSEC(X)\n```\n\n **Description** \n\nComputes the secant for the angle of`X`, where`X`is specified in radians.`X`can be any data typethat[coerces to FLOAT64](/bigquery/docs/reference/standard-sql/conversion_rules#conversion_rules).\n\n| X | SEC(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n| `NULL` | `NULL` |\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nSELECT SEC(100) AS a, SEC(-1) AS b;/*----------------+---------------* | a              | b             | +----------------+---------------+ | 1.159663822905 | 1.85081571768 | *----------------+---------------*/\n```\n\n"
  },
  {
    "name": "SECH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSECH(X)\n```\n\n **Description** \n\nComputes the hyperbolic secant for the angle of`X`, where`X`is specifiedin radians.`X`can be any data typethat[coerces to FLOAT64](/bigquery/docs/reference/standard-sql/conversion_rules#conversion_rules).Never produces an error.\n\n| X | SECH(X) |\n| --- | --- |\n| `+inf` | `0` |\n| `-inf` | `0` |\n| `NaN` | `NaN` |\n| `NULL` | `NULL` |\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Example** \n\n```\nSELECT SECH(0.5) AS a, SECH(-2) AS b, SECH(100) AS c;/*----------------+----------------+---------------------* | a              | b              | c                   | +----------------+----------------+---------------------+ | 0.88681888397  | 0.265802228834 | 7.4401519520417E-44 | *----------------+----------------+---------------------*/\n```\n\n"
  },
  {
    "name": "SESSION_USER",
    "arguments": [],
    "category": "Security functions",
    "description": "```\nSESSION_USER()\n```\n\n **Description** \n\nFor first-party users, returns the email address of the user that is running thequery.For third-party users, returns the[principal identifier](https://cloud.google.com/iam/docs/principal-identifiers)of the user that is running the query.For more information about identities, see[Principals](https://cloud.google.com/docs/authentication#principal).\n\n **Return Data Type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT SESSION_USER() as user;/*----------------------* | user                 | +----------------------+ | jdoe@example.com     | *----------------------*/\n```\n\n\n<span id=\"statistical_aggregate_functions\">\n## Statistical aggregate functions\n\n</span>\nGoogleSQL for BigQuery supports statistical aggregate functions.To learn about the syntax for aggregate function calls, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\n"
  },
  {
    "name": "SHA1",
    "arguments": [],
    "category": "Hash functions",
    "description": "```\nSHA1(input)\n```\n\n **Description** \n\nComputes the hash of the input using the[SHA-1 algorithm](https://en.wikipedia.org/wiki/SHA-1). The input can either be`STRING`or`BYTES`. The string version treats the input as an array of bytes.\n\nThis function returns 20 bytes.\n\n **Warning:** SHA1 is no longer considered secure.For increased security, use another hashing function. **Return type** \n\n`BYTES`\n\n **Example** \n\n```\nSELECT SHA1(\"Hello World\") as sha1;-- Note that the result of SHA1 is of type BYTES, displayed as a base64-encoded string./*------------------------------* | sha1                         | +------------------------------+ | Ck1VqNd45QIvq3AZd8XYQLvEhtA= | *------------------------------*/\n```\n\n"
  },
  {
    "name": "SHA256",
    "arguments": [],
    "category": "Hash functions",
    "description": "```\nSHA256(input)\n```\n\n **Description** \n\nComputes the hash of the input using the[SHA-256 algorithm](https://en.wikipedia.org/wiki/SHA-2). The input can either be`STRING`or`BYTES`. The string version treats the input as an array of bytes.\n\nThis function returns 32 bytes.\n\n **Return type** \n\n`BYTES`\n\n **Example** \n\n```\nSELECT SHA256(\"Hello World\") as sha256;\n```\n\n"
  },
  {
    "name": "SHA512",
    "arguments": [],
    "category": "Hash functions",
    "description": "```\nSHA512(input)\n```\n\n **Description** \n\nComputes the hash of the input using the[SHA-512 algorithm](https://en.wikipedia.org/wiki/SHA-2). The input can either be`STRING`or`BYTES`. The string version treats the input as an array of bytes.\n\nThis function returns 64 bytes.\n\n **Return type** \n\n`BYTES`\n\n **Example** \n\n```\nSELECT SHA512(\"Hello World\") as sha512;\n```\n\n\n<span id=\"hll_functions\">\n## HyperLogLog++ functions\n\n</span>\nThe[HyperLogLog++ algorithm (HLL++)](/bigquery/docs/sketches#sketches_hll)estimates[cardinality](https://en.wikipedia.org/wiki/Cardinality)from[sketches](/bigquery/docs/sketches#sketches_hll).\n\nHLL++ functions are approximate aggregate functions.Approximate aggregation typically requires lessmemory than exact aggregation functions,like[COUNT(DISTINCT)](#count), but also introduces statistical error.This makes HLL++ functions appropriate for large data streams forwhich linear memory usage is impractical, as well as for data that isalready approximate.\n\nIf you do not need materialized sketches, you can alternatively use an[approximate aggregate function with system-defined precision](#approximate_aggregate_functions),such as[APPROX_COUNT_DISTINCT](#approx-count-distinct). However,`APPROX_COUNT_DISTINCT`does not allow partial aggregations, re-aggregations,and custom precision.\n\nGoogleSQL for BigQuery supports the following HLL++ functions:\n\n"
  },
  {
    "name": "SIGN",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSIGN(X)\n```\n\n **Description** \n\nReturns`-1`,`0`, or`+1`for negative, zero and positive argumentsrespectively. For floating point arguments, this function does not distinguishbetween positive and negative zero.\n\n| X | SIGN(X) |\n| --- | --- |\n| 25 | +1 |\n| 0 | 0 |\n| -25 | -1 |\n| NaN | NaN |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "SIN",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSIN(X)\n```\n\n **Description** \n\nComputes the sine of X where X is specified in radians. Never fails.\n\n| X | SIN(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n\n"
  },
  {
    "name": "SINH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSINH(X)\n```\n\n **Description** \n\nComputes the hyperbolic sine of X where X is specified in radians. Generatesan error if overflow occurs.\n\n| X | SINH(X) |\n| --- | --- |\n| `+inf` | `+inf` |\n| `-inf` | `-inf` |\n| `NaN` | `NaN` |\n\n"
  },
  {
    "name": "SOUNDEX",
    "arguments": [],
    "category": "String functions",
    "description": "```\nSOUNDEX(value)\n```\n\n **Description** \n\nReturns a`STRING`that represents the[Soundex](https://en.wikipedia.org/wiki/Soundex)code for`value`.\n\nSOUNDEX produces a phonetic representation of a string. It indexes words bysound, as pronounced in English. It is typically used to help determine whethertwo strings, such as the family names *Levine* and *Lavine* , or the words *to* and *too* , have similar English-language pronunciation.\n\nThe result of the SOUNDEX consists of a letter followed by 3 digits. Non-latincharacters are ignored. If the remaining string is empty after removingnon-Latin characters, an empty`STRING`is returned.\n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n```\nWITH example AS (  SELECT 'Ashcraft' AS value UNION ALL  SELECT 'Raven' AS value UNION ALL  SELECT 'Ribbon' AS value UNION ALL  SELECT 'apple' AS value UNION ALL  SELECT 'Hello world!' AS value UNION ALL  SELECT '  H3##!@llo w00orld!' AS value UNION ALL  SELECT '#1' AS value UNION ALL  SELECT NULL AS value)SELECT value, SOUNDEX(value) AS soundexFROM example;/*----------------------+---------* | value                | soundex | +----------------------+---------+ | Ashcraft             | A261    | | Raven                | R150    | | Ribbon               | R150    | | apple                | a140    | | Hello world!         | H464    | |   H3##!@llo w00orld! | H464    | | #1                   |         | | NULL                 | NULL    | *----------------------+---------*/\n```\n\n"
  },
  {
    "name": "SPLIT",
    "arguments": [],
    "category": "String functions",
    "description": "```\nSPLIT(value[, delimiter])\n```\n\n **Description** \n\nSplits`value`using the`delimiter`argument.\n\nFor`STRING`, the default delimiter is the comma`,`.\n\nFor`BYTES`, you must specify a delimiter.\n\nSplitting on an empty delimiter produces an array of UTF-8 characters for`STRING`values, and an array of`BYTES`for`BYTES`values.\n\nSplitting an empty`STRING`returns an`ARRAY`with a single empty`STRING`.\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Return type** \n\n`ARRAY&lt;STRING&gt;`or`ARRAY&lt;BYTES&gt;`\n\n **Examples** \n\n```\nWITH letters AS  (SELECT '' as letter_group  UNION ALL  SELECT 'a' as letter_group  UNION ALL  SELECT 'b c d' as letter_group)SELECT SPLIT(letter_group, ' ') as exampleFROM letters;/*----------------------* | example              | +----------------------+ | []                   | | [a]                  | | [b, c, d]            | *----------------------*/\n```\n\n"
  },
  {
    "name": "SQRT",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nSQRT(X)\n```\n\n **Description** \n\nComputes the square root of X. Generates an error if X is less than 0.\n\n| X | SQRT(X) |\n| --- | --- |\n| `25.0` | `5.0` |\n| `+inf` | `+inf` |\n| `X &lt; 0` | Error |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n"
  },
  {
    "name": "STARTS_WITH",
    "arguments": [],
    "category": "String functions",
    "description": "```\nSTARTS_WITH(value, prefix)\n```\n\n **Description** \n\nTakes two`STRING`or`BYTES`values. Returns`TRUE`if`prefix`is aprefix of`value`.\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Return type** \n\n`BOOL`\n\n **Examples** \n\n```\nWITH items AS  (SELECT 'foo' as item  UNION ALL  SELECT 'bar' as item  UNION ALL  SELECT 'baz' as item)SELECT  STARTS_WITH(item, 'b') as exampleFROM items;/*---------* | example | +---------+ |   False | |    True | |    True | *---------*/\n```\n\n"
  },
  {
    "name": "STDDEV",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nSTDDEV(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nAn alias of[STDDEV_SAMP](#stddev_samp).\n\n"
  },
  {
    "name": "STDDEV_POP",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nSTDDEV_POP(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the population (biased) standard deviation of the values. The returnresult is between`0`and`+Inf`.\n\nAll numeric types are supported. If theinput is`NUMERIC`or`BIGNUMERIC`then the internal aggregation isstable with the final output converted to a`FLOAT64`.Otherwise the input is converted to a`FLOAT64`before aggregation, resulting in a potentially unstable result.\n\nThis function ignores any`NULL`inputs. If all inputs are ignored, thisfunction returns`NULL`. If this function receives a single non-`NULL`input,it returns`0`.\n\n`NaN`is produced if:\n\n- Any input value is`    NaN`\n- Any input value is positive infinity or negative infinity.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nIf this function is used with the`OVER`clause, it's part of awindow function call. In a window function call,aggregate function clauses can't be used.To learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nSELECT STDDEV_POP(x) AS results FROM UNNEST([10, 14, 18]) AS x/*-------------------* | results           | +-------------------+ | 3.265986323710904 | *-------------------*/\n```\n\n```\nSELECT STDDEV_POP(x) AS results FROM UNNEST([10, 14, NULL]) AS x/*---------* | results | +---------+ | 2       | *---------*/\n```\n\n```\nSELECT STDDEV_POP(x) AS results FROM UNNEST([10, NULL]) AS x/*---------* | results | +---------+ | 0       | *---------*/\n```\n\n```\nSELECT STDDEV_POP(x) AS results FROM UNNEST([NULL]) AS x/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT STDDEV_POP(x) AS results FROM UNNEST([10, 14, CAST('Infinity' as FLOAT64)]) AS x/*---------* | results | +---------+ | NaN     | *---------*/\n```\n\n"
  },
  {
    "name": "STDDEV_SAMP",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nSTDDEV_SAMP(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the sample (unbiased) standard deviation of the values. The returnresult is between`0`and`+Inf`.\n\nAll numeric types are supported. If theinput is`NUMERIC`or`BIGNUMERIC`then the internal aggregation isstable with the final output converted to a`FLOAT64`.Otherwise the input is converted to a`FLOAT64`before aggregation, resulting in a potentially unstable result.\n\nThis function ignores any`NULL`inputs. If there are fewer than two non-`NULL`inputs, this function returns`NULL`.\n\n`NaN`is produced if:\n\n- Any input value is`    NaN`\n- Any input value is positive infinity or negative infinity.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nIf this function is used with the`OVER`clause, it's part of awindow function call. In a window function call,aggregate function clauses can't be used.To learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nSELECT STDDEV_SAMP(x) AS results FROM UNNEST([10, 14, 18]) AS x/*---------* | results | +---------+ | 4       | *---------*/\n```\n\n```\nSELECT STDDEV_SAMP(x) AS results FROM UNNEST([10, 14, NULL]) AS x/*--------------------* | results            | +--------------------+ | 2.8284271247461903 | *--------------------*/\n```\n\n```\nSELECT STDDEV_SAMP(x) AS results FROM UNNEST([10, NULL]) AS x/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT STDDEV_SAMP(x) AS results FROM UNNEST([NULL]) AS x/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT STDDEV_SAMP(x) AS results FROM UNNEST([10, 14, CAST('Infinity' as FLOAT64)]) AS x/*---------* | results | +---------+ | NaN     | *---------*/\n```\n\n"
  },
  {
    "name": "STRING",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nSTRING(json_expr)\n```\n\n **Description** \n\nConverts a JSON string to a SQL`STRING`value.\n\nArguments:\n\n- `    json_expr`: JSON. For example:\n    \n    \n    ```\n    JSON '\"purple\"'\n    ```\n    \n    If the JSON value is not a string, an error is produced. If the expressionis SQL`    NULL`, the function returns SQL`    NULL`.\n    \n    \n\n **Return type** \n\n`STRING`\n\n **Examples** \n\n```\nSELECT STRING(JSON '\"purple\"') AS color;/*--------* | color  | +--------+ | purple | *--------*/\n```\n\n```\nSELECT STRING(JSON_QUERY(JSON '{\"name\": \"sky\", \"color\": \"blue\"}', \"$.color\")) AS color;/*-------* | color | +-------+ | blue  | *-------*/\n```\n\nThe following examples show how invalid requests are handled:\n\n```\n-- An error is thrown if the JSON is not of type string.SELECT STRING(JSON '123') AS result; -- Throws an errorSELECT STRING(JSON 'null') AS result; -- Throws an errorSELECT SAFE.STRING(JSON '123') AS result; -- Returns a SQL NULL\n```\n\n"
  },
  {
    "name": "STRING",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nSTRING(timestamp_expression[, time_zone])\n```\n\n **Description** \n\nConverts a timestamp to a string. Supports an optionalparameter to specify a time zone. See[Time zone definitions](#timezone_definitions)for informationon how to specify a time zone.\n\n **Return Data Type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT STRING(TIMESTAMP \"2008-12-25 15:30:00+00\", \"UTC\") AS string;/*-------------------------------* | string                        | +-------------------------------+ | 2008-12-25 15:30:00+00        | *-------------------------------*/\n```\n\n"
  },
  {
    "name": "STRING_AGG",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nSTRING_AGG(  [ DISTINCT ]  expression [, delimiter]  [ ORDER BY key [ { ASC | DESC } ] [, ... ] ]  [ LIMIT n ])[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns a value (either`STRING`or`BYTES`) obtained by concatenatingnon-`NULL`values. Returns`NULL`if there are zero input rows or`expression`evaluates to`NULL`for all rows.\n\nIf a`delimiter`is specified, concatenated values are separated by thatdelimiter; otherwise, a comma is used as a delimiter.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nIf this function is used with the`OVER`clause, it's part of awindow function call. In a window function call,aggregate function clauses can't be used.To learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Supported Argument Types** \n\nEither`STRING`or`BYTES`.\n\n **Return Data Types** \n\nEither`STRING`or`BYTES`.\n\n **Examples** \n\n```\nSELECT STRING_AGG(fruit) AS string_aggFROM UNNEST([\"apple\", NULL, \"pear\", \"banana\", \"pear\"]) AS fruit;/*------------------------* | string_agg             | +------------------------+ | apple,pear,banana,pear | *------------------------*/\n```\n\n```\nSELECT STRING_AGG(fruit, \" &amp; \") AS string_aggFROM UNNEST([\"apple\", \"pear\", \"banana\", \"pear\"]) AS fruit;/*------------------------------* | string_agg                   | +------------------------------+ | apple &amp; pear &amp; banana &amp; pear | *------------------------------*/\n```\n\n```\nSELECT STRING_AGG(DISTINCT fruit, \" &amp; \") AS string_aggFROM UNNEST([\"apple\", \"pear\", \"banana\", \"pear\"]) AS fruit;/*-----------------------* | string_agg            | +-----------------------+ | apple &amp; pear &amp; banana | *-----------------------*/\n```\n\n```\nSELECT STRING_AGG(fruit, \" &amp; \" ORDER BY LENGTH(fruit)) AS string_aggFROM UNNEST([\"apple\", \"pear\", \"banana\", \"pear\"]) AS fruit;/*------------------------------* | string_agg                   | +------------------------------+ | pear &amp; pear &amp; apple &amp; banana | *------------------------------*/\n```\n\n```\nSELECT STRING_AGG(fruit, \" &amp; \" LIMIT 2) AS string_aggFROM UNNEST([\"apple\", \"pear\", \"banana\", \"pear\"]) AS fruit;/*--------------* | string_agg   | +--------------+ | apple &amp; pear | *--------------*/\n```\n\n```\nSELECT STRING_AGG(DISTINCT fruit, \" &amp; \" ORDER BY fruit DESC LIMIT 2) AS string_aggFROM UNNEST([\"apple\", \"pear\", \"banana\", \"pear\"]) AS fruit;/*---------------* | string_agg    | +---------------+ | pear &amp; banana | *---------------*/\n```\n\n```\nSELECT  fruit,  STRING_AGG(fruit, \" &amp; \") OVER (ORDER BY LENGTH(fruit)) AS string_aggFROM UNNEST([\"apple\", NULL, \"pear\", \"banana\", \"pear\"]) AS fruit;/*--------+------------------------------* | fruit  | string_agg                   | +--------+------------------------------+ | NULL   | NULL                         | | pear   | pear &amp; pear                  | | pear   | pear &amp; pear                  | | apple  | pear &amp; pear &amp; apple          | | banana | pear &amp; pear &amp; apple &amp; banana | *--------+------------------------------*/\n```\n\n"
  },
  {
    "name": "STRPOS",
    "arguments": [],
    "category": "String functions",
    "description": "```\nSTRPOS(value, subvalue)\n```\n\n **Description** \n\nTakes two`STRING`or`BYTES`values. Returns the 1-based position of the firstoccurrence of`subvalue`inside`value`. Returns`0`if`subvalue`is not found.\n\nThis function supports specifying[collation](/bigquery/docs/reference/standard-sql/collation-concepts#collate_about).\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nWITH email_addresses AS  (SELECT    'foo@example.com' AS email_address  UNION ALL  SELECT    'foobar@example.com' AS email_address  UNION ALL  SELECT    'foobarbaz@example.com' AS email_address  UNION ALL  SELECT    'quxexample.com' AS email_address)SELECT  STRPOS(email_address, '@') AS exampleFROM email_addresses;/*---------* | example | +---------+ |       4 | |       7 | |      10 | |       0 | *---------*/\n```\n\n"
  },
  {
    "name": "ST_ANGLE",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ANGLE(point_geography_1, point_geography_2, point_geography_3)\n```\n\n **Description** \n\nTakes three point`GEOGRAPHY`values, which represent two intersecting lines.Returns the angle between these lines. Point 2 and point 1 represent the firstline and point 2 and point 3 represent the second line. The angle betweenthese lines is in radians, in the range`[0, 2pi)`. The angle is measuredclockwise from the first line to the second line.\n\n`ST_ANGLE`has the following edge cases:\n\n- If points 2 and 3 are the same, returns`    NULL`.\n- If points 2 and 1 are the same, returns`    NULL`.\n- If points 2 and 3 are exactly antipodal, returns`    NULL`.\n- If points 2 and 1 are exactly antipodal, returns`    NULL`.\n- If any of the input geographies are not single points or are the emptygeography, then throws an error.\n\n **Return type** \n\n`FLOAT64`\n\n **Example** \n\n```\nWITH geos AS (  SELECT 1 id, ST_GEOGPOINT(1, 0) geo1, ST_GEOGPOINT(0, 0) geo2, ST_GEOGPOINT(0, 1) geo3 UNION ALL  SELECT 2 id, ST_GEOGPOINT(0, 0), ST_GEOGPOINT(1, 0), ST_GEOGPOINT(0, 1) UNION ALL  SELECT 3 id, ST_GEOGPOINT(1, 0), ST_GEOGPOINT(0, 0), ST_GEOGPOINT(1, 0) UNION ALL  SELECT 4 id, ST_GEOGPOINT(1, 0) geo1, ST_GEOGPOINT(0, 0) geo2, ST_GEOGPOINT(0, 0) geo3 UNION ALL  SELECT 5 id, ST_GEOGPOINT(0, 0), ST_GEOGPOINT(-30, 0), ST_GEOGPOINT(150, 0) UNION ALL  SELECT 6 id, ST_GEOGPOINT(0, 0), NULL, NULL UNION ALL  SELECT 7 id, NULL, ST_GEOGPOINT(0, 0), NULL UNION ALL  SELECT 8 id, NULL, NULL, ST_GEOGPOINT(0, 0))SELECT ST_ANGLE(geo1,geo2,geo3) AS angle FROM geos ORDER BY id;/*---------------------* | angle               | +---------------------+ | 4.71238898038469    | | 0.78547432161873854 | | 0                   | | NULL                | | NULL                | | NULL                | | NULL                | | NULL                | *---------------------*/\n```\n\n"
  },
  {
    "name": "ST_AREA",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_AREA(geography_expression[, use_spheroid])\n```\n\n **Description** \n\nReturns the area in square meters covered by the polygons in the input`GEOGRAPHY`.\n\nIf`geography_expression`is a point or a line, returns zero. If`geography_expression`is a collection, returns the area of the polygons in thecollection; if the collection does not contain polygons, returns zero.\n\nThe optional`use_spheroid`parameter determines how this function measuresdistance. If`use_spheroid`is`FALSE`, the function measures distance on thesurface of a perfect sphere.\n\nThe`use_spheroid`parameter currently only supportsthe value`FALSE`. The default value of`use_spheroid`is`FALSE`.\n\n **Return type** \n\n`FLOAT64`\n\n"
  },
  {
    "name": "ST_ASBINARY",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ASBINARY(geography_expression)\n```\n\n **Description** \n\nReturns the[WKB](https://en.wikipedia.org/wiki/Well-known_text#Well-known_binary)representation of an input`GEOGRAPHY`.\n\nSee[ST_GEOGFROMWKB](#st_geogfromwkb)to construct a`GEOGRAPHY`from WKB.\n\n **Return type** \n\n`BYTES`\n\n"
  },
  {
    "name": "ST_ASGEOJSON",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ASGEOJSON(geography_expression)\n```\n\n **Description** \n\nReturns the[RFC 7946](https://tools.ietf.org/html/rfc7946)compliant[GeoJSON](https://en.wikipedia.org/wiki/GeoJSON)representation of the input`GEOGRAPHY`.\n\nA GoogleSQL`GEOGRAPHY`has sphericalgeodesic edges, whereas a GeoJSON`Geometry`object explicitly has planar edges.To convert between these two types of edges, GoogleSQL adds additionalpoints to the line where necessary so that the resulting sequence of edgesremains within 10 meters of the original edge.\n\nSee[ST_GEOGFROMGEOJSON](#st_geogfromgeojson)to construct a`GEOGRAPHY`from GeoJSON.\n\n **Return type** \n\n`STRING`\n\n"
  },
  {
    "name": "ST_ASTEXT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ASTEXT(geography_expression)\n```\n\n **Description** \n\nReturns the[WKT](https://en.wikipedia.org/wiki/Well-known_text)representation of an input`GEOGRAPHY`.\n\nSee[ST_GEOGFROMTEXT](#st_geogfromtext)to construct a`GEOGRAPHY`from WKT.\n\n **Return type** \n\n`STRING`\n\n"
  },
  {
    "name": "ST_AZIMUTH",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_AZIMUTH(point_geography_1, point_geography_2)\n```\n\n **Description** \n\nTakes two point`GEOGRAPHY`values, and returns the azimuth of the line segmentformed by points 1 and 2. The azimuth is the angle in radians measured betweenthe line from point 1 facing true North to the line segment from point 1 topoint 2.\n\nThe positive angle is measured clockwise on the surface of a sphere. Forexample, the azimuth for a line segment:\n\n- Pointing North is`    0`\n- Pointing East is`    PI/2`\n- Pointing South is`    PI`\n- Pointing West is`    3PI/2`\n\n`ST_AZIMUTH`has the following edge cases:\n\n- If the two input points are the same, returns`    NULL`.\n- If the two input points are exactly antipodal, returns`    NULL`.\n- If either of the input geographies are not single points or are the emptygeography, throws an error.\n\n **Return type** \n\n`FLOAT64`\n\n **Example** \n\n```\nWITH geos AS (  SELECT 1 id, ST_GEOGPOINT(1, 0) AS geo1, ST_GEOGPOINT(0, 0) AS geo2 UNION ALL  SELECT 2, ST_GEOGPOINT(0, 0), ST_GEOGPOINT(1, 0) UNION ALL  SELECT 3, ST_GEOGPOINT(0, 0), ST_GEOGPOINT(0, 1) UNION ALL  -- identical  SELECT 4, ST_GEOGPOINT(0, 0), ST_GEOGPOINT(0, 0) UNION ALL  -- antipode  SELECT 5, ST_GEOGPOINT(-30, 0), ST_GEOGPOINT(150, 0) UNION ALL  -- nulls  SELECT 6, ST_GEOGPOINT(0, 0), NULL UNION ALL  SELECT 7, NULL, ST_GEOGPOINT(0, 0))SELECT ST_AZIMUTH(geo1, geo2) AS azimuth FROM geos ORDER BY id;/*--------------------* | azimuth            | +--------------------+ | 4.71238898038469   | | 1.5707963267948966 | | 0                  | | NULL               | | NULL               | | NULL               | | NULL               | *--------------------*/\n```\n\n"
  },
  {
    "name": "ST_BOUNDARY",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_BOUNDARY(geography_expression)\n```\n\n **Description** \n\nReturns a single`GEOGRAPHY`that contains the unionof the boundaries of each component in the given input`GEOGRAPHY`.\n\nThe boundary of each component of a`GEOGRAPHY`isdefined as follows:\n\n- The boundary of a point is empty.\n- The boundary of a linestring consists of the endpoints of the linestring.\n- The boundary of a polygon consists of the linestrings that form the polygonshell and each of the polygon's holes.\n\n **Return type** \n\n`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_BOUNDINGBOX",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_BOUNDINGBOX(geography_expression)\n```\n\n **Description** \n\nReturns a`STRUCT`that represents the bounding box for the specified geography.The bounding box is the minimal rectangle that encloses the geography. The edgesof the rectangle follow constant lines of longitude and latitude.\n\nCaveats:\n\n- Returns`    NULL`if the input is`    NULL`or an empty geography.\n- The bounding box might cross the antimeridian if this allows for a smallerrectangle. In this case, the bounding box has one of its longitudinal boundsoutside of the [-180, 180] range, so that`    xmin`is smaller than the eastmostvalue`    xmax`.\n\n **Return type** \n\n`STRUCT&lt;xmin FLOAT64, ymin FLOAT64, xmax FLOAT64, ymax FLOAT64&gt;`.\n\nBounding box parts:\n\n- `    xmin`: The westmost constant longitude line that bounds the rectangle.\n- `    xmax`: The eastmost constant longitude line that bounds the rectangle.\n- `    ymin`: The minimum constant latitude line that bounds the rectangle.\n- `    ymax`: The maximum constant latitude line that bounds the rectangle.\n\n **Example** \n\n```\nWITH data AS (  SELECT 1 id, ST_GEOGFROMTEXT('POLYGON((-125 48, -124 46, -117 46, -117 49, -125 48))') g  UNION ALL  SELECT 2 id, ST_GEOGFROMTEXT('POLYGON((172 53, -130 55, -141 70, 172 53))') g  UNION ALL  SELECT 3 id, ST_GEOGFROMTEXT('POINT EMPTY') g  UNION ALL  SELECT 4 id, ST_GEOGFROMTEXT('POLYGON((172 53, -141 70, -130 55, 172 53))', oriented =&gt; TRUE))SELECT id, ST_BOUNDINGBOX(g) AS boxFROM data/*----+------------------------------------------* | id | box                                      | +----+------------------------------------------+ | 1  | {xmin:-125, ymin:46, xmax:-117, ymax:49} | | 2  | {xmin:172, ymin:53, xmax:230, ymax:70}   | | 3  | NULL                                     | | 4  | {xmin:-180, ymin:-90, xmax:180, ymax:90} | *----+------------------------------------------*/\n```\n\nSee[ST_EXTENT](#st_extent)for the aggregate version of`ST_BOUNDINGBOX`.\n\n"
  },
  {
    "name": "ST_BUFFER",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_BUFFER(    geography,    buffer_radius    [, num_seg_quarter_circle =&gt; num_segments]    [, use_spheroid =&gt; boolean_expression]    [, endcap =&gt; endcap_style]    [, side =&gt; line_side])\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`that represents the buffer around the input`GEOGRAPHY`.This function is similar to[ST_BUFFERWITHTOLERANCE](#st_bufferwithtolerance),but you specify the number of segments instead of providing tolerance todetermine how much the resulting geography can deviate from the idealbuffer radius.\n\n- `    geography`: The input`    GEOGRAPHY`to encircle with the buffer radius.\n- `    buffer_radius`:`    FLOAT64`that represents the radius of thebuffer around the input geography. The radius is in meters. Note thatpolygons contract when buffered with a negative`    buffer_radius`. Polygonshells and holes that are contracted to a point are discarded.\n- `    num_seg_quarter_circle`: (Optional)`    FLOAT64`specifies thenumber of segments that are used to approximate a quarter circle. Thedefault value is`    8.0`. Naming this argument is optional.\n- `    endcap`: (Optional)`    STRING`allows you to specify one of two endcapstyles:`    ROUND`and`    FLAT`. The default value is`    ROUND`. This option onlyaffects the endcaps of buffered linestrings.\n- `    side`: (Optional)`    STRING`allows you to specify one of three possibilitiesfor lines:`    BOTH`,`    LEFT`, and`    RIGHT`. The default is`    BOTH`. This optiononly affects how linestrings are buffered.\n- `    use_spheroid`: (Optional)`    BOOL`determines how this function measuresdistance. If`    use_spheroid`is`    FALSE`, the function measures distance onthe surface of a perfect sphere. The`    use_spheroid`parametercurrently only supports the value`    FALSE`. The default value of`    use_spheroid`is`    FALSE`.\n\n **Return type** \n\nPolygon`GEOGRAPHY`\n\n **Example** \n\nThe following example shows the result of`ST_BUFFER`on a point. A bufferedpoint is an approximated circle. When`num_seg_quarter_circle = 2`, there aretwo line segments in a quarter circle, and therefore the buffered circle haseight sides and[ST_NUMPOINTS](#st_numpoints)returns nine vertices. When`num_seg_quarter_circle = 8`, there are eight line segments in a quarter circle,and therefore the buffered circle has thirty-two sides and[ST_NUMPOINTS](#st_numpoints)returns thirty-three vertices.\n\n```\nSELECT  -- num_seg_quarter_circle=2  ST_NUMPOINTS(ST_BUFFER(ST_GEOGFROMTEXT('POINT(1 2)'), 50, 2)) AS eight_sides,  -- num_seg_quarter_circle=8, since 8 is the default  ST_NUMPOINTS(ST_BUFFER(ST_GEOGFROMTEXT('POINT(100 2)'), 50)) AS thirty_two_sides;/*-------------+------------------* | eight_sides | thirty_two_sides | +-------------+------------------+ | 9           | 33               | *-------------+------------------*/\n```\n\n"
  },
  {
    "name": "ST_BUFFERWITHTOLERANCE",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_BUFFERWITHTOLERANCE(    geography,    buffer_radius,    tolerance_meters =&gt; tolerance    [, use_spheroid =&gt; boolean_expression]    [, endcap =&gt; endcap_style]    [, side =&gt; line_side])\n```\n\nReturns a`GEOGRAPHY`that represents the buffer around the input`GEOGRAPHY`.This function is similar to[ST_BUFFER](#st_buffer),but you provide tolerance instead of segments to determine how much theresulting geography can deviate from the ideal buffer radius.\n\n- `    geography`: The input`    GEOGRAPHY`to encircle with the buffer radius.\n- `    buffer_radius`:`    FLOAT64`that represents the radius of thebuffer around the input geography. The radius is in meters. Note thatpolygons contract when buffered with a negative`    buffer_radius`. Polygonshells and holes that are contracted to a point are discarded.\n- `    tolerance_meters`:`    FLOAT64`specifies a tolerance inmeters with which the shape is approximated. Tolerance determines how much apolygon can deviate from the ideal radius. Naming this argument is optional.\n- `    endcap`: (Optional)`    STRING`allows you to specify one of two endcapstyles:`    ROUND`and`    FLAT`. The default value is`    ROUND`. This option onlyaffects the endcaps of buffered linestrings.\n- `    side`: (Optional)`    STRING`allows you to specify one of three possible linestyles:`    BOTH`,`    LEFT`, and`    RIGHT`. The default is`    BOTH`. This option onlyaffects the endcaps of buffered linestrings.\n- `    use_spheroid`: (Optional)`    BOOL`determines how this function measuresdistance. If`    use_spheroid`is`    FALSE`, the function measures distance onthe surface of a perfect sphere. The`    use_spheroid`parametercurrently only supports the value`    FALSE`. The default value of`    use_spheroid`is`    FALSE`.\n\n **Return type** \n\nPolygon`GEOGRAPHY`\n\n **Example** \n\nThe following example shows the results of`ST_BUFFERWITHTOLERANCE`on a point,given two different values for tolerance but with the same buffer radius of`100`. A buffered point is an approximated circle. When`tolerance_meters=25`,the tolerance is a large percentage of the buffer radius, and therefore onlyfive segments are used to approximate a circle around the input point. When`tolerance_meters=1`, the tolerance is a much smaller percentage of the bufferradius, and therefore twenty-four edges are used to approximate a circle aroundthe input point.\n\n```\nSELECT  -- tolerance_meters=25, or 25% of the buffer radius.  ST_NumPoints(ST_BUFFERWITHTOLERANCE(ST_GEOGFROMTEXT('POINT(1 2)'), 100, 25)) AS five_sides,  -- tolerance_meters=1, or 1% of the buffer radius.  st_NumPoints(ST_BUFFERWITHTOLERANCE(ST_GEOGFROMTEXT('POINT(100 2)'), 100, 1)) AS twenty_four_sides;/*------------+-------------------* | five_sides | twenty_four_sides | +------------+-------------------+ | 6          | 24                | *------------+-------------------*/\n```\n\n"
  },
  {
    "name": "ST_CENTROID",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_CENTROID(geography_expression)\n```\n\n **Description** \n\nReturns the *centroid* of the input`GEOGRAPHY`as a single point`GEOGRAPHY`.\n\nThe *centroid* of a`GEOGRAPHY`is the weighted average of the centroids of thehighest-dimensional components in the`GEOGRAPHY`. The centroid for componentsin each dimension is defined as follows:\n\n- The centroid of points is the arithmetic mean of the input coordinates.\n- The centroid of linestrings is the centroid of all the edges weighted bylength. The centroid of each edge is the geodesic midpoint of the edge.\n- The centroid of a polygon is its center of mass.\n\nIf the input`GEOGRAPHY`is empty, an empty`GEOGRAPHY`is returned.\n\n **Constraints** \n\nIn the unlikely event that the centroid of a`GEOGRAPHY`cannot be defined by asingle point on the surface of the Earth, a deterministic but otherwisearbitrary point is returned. This can only happen if the centroid is exactly atthe center of the Earth, such as the centroid for a pair of antipodal points,and the likelihood of this happening is vanishingly small.\n\n **Return type** \n\nPoint`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_CENTROID_AGG",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_CENTROID_AGG(geography)\n```\n\n **Description** \n\nComputes the centroid of the set of input`GEOGRAPHY`s as a single point`GEOGRAPHY`.\n\nThe *centroid* over the set of input`GEOGRAPHY`s is the weighted average of thecentroid of each individual`GEOGRAPHY`. Only the`GEOGRAPHY`s with the highestdimension present in the input contribute to the centroid of the entire set.For example, if the input contains both`GEOGRAPHY`s  with lines and`GEOGRAPHY`s with only points,`ST_CENTROID_AGG`returns the weighted averageof the`GEOGRAPHY`s with lines, since those have maximal dimension. In thisexample,`ST_CENTROID_AGG`ignores`GEOGRAPHY`s with only points whencalculating the aggregate centroid.\n\n`ST_CENTROID_AGG`ignores`NULL`input`GEOGRAPHY`values.\n\nSee[ST_CENTROID](#st_centroid)for the non-aggregate version of`ST_CENTROID_AGG`and the definition of centroid for an individual`GEOGRAPHY`value.\n\n **Return type** \n\nPoint`GEOGRAPHY`\n\n **Example** \n\nThe following queries compute the aggregate centroid over a set of`GEOGRAPHY`values. The input to the first querycontains only points, and therefore each value contribute to the aggregatecentroid. Also notice that`ST_CENTROID_AGG`is *not* equivalent to calling`ST_CENTROID`on the result of`ST_UNION_AGG`; duplicates are removed by theunion, unlike`ST_CENTROID_AGG`. The input to the second query has mixeddimensions, and only values with the highest dimension in the set, the lines,affect the aggregate centroid.\n\n```\nSELECT ST_CENTROID_AGG(points) AS st_centroid_agg,ST_CENTROID(ST_UNION_AGG(points)) AS centroid_of_unionFROM UNNEST([ST_GEOGPOINT(1, 5),             ST_GEOGPOINT(1, 2),             ST_GEOGPOINT(1, -1),             ST_GEOGPOINT(1, -1)]) points;/*---------------------------+-------------------* | st_centroid_agg           | centroid_of_union | +---------------------------+-------------------+ | POINT(1 1.24961422620969) | POINT(1 2)        | *---------------------------+-------------------*/\n```\n\n```\nSELECT ST_CENTROID_AGG(points) AS st_centroid_aggFROM UNNEST([ST_GEOGPOINT(50, 26),             ST_GEOGPOINT(34, 33.3),             ST_GEOGFROMTEXT('LINESTRING(0 -1, 0 1)'),             ST_GEOGFROMTEXT('LINESTRING(0 1, 0 3)')]) points;/*-----------------* | st_centroid_agg | +-----------------+ | POINT(0 1)      | *-----------------*/\n```\n\n"
  },
  {
    "name": "ST_CLOSESTPOINT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_CLOSESTPOINT(geography_1, geography_2[, use_spheroid])\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`containing a point on`geography_1`with the smallest possible distance to`geography_2`. This impliesthat the distance between the point returned by`ST_CLOSESTPOINT`and`geography_2`is less than or equal to the distance between any other point on`geography_1`and`geography_2`.\n\nIf either of the input`GEOGRAPHY`s is empty,`ST_CLOSESTPOINT`returns`NULL`.\n\nThe optional`use_spheroid`parameter determines how this function measuresdistance. If`use_spheroid`is`FALSE`, the function measures distance on thesurface of a perfect sphere.\n\nThe`use_spheroid`parameter currently only supportsthe value`FALSE`. The default value of`use_spheroid`is`FALSE`.\n\n **Return type** \n\nPoint`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_CLUSTERDBSCAN",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_CLUSTERDBSCAN(geography_column, epsilon, minimum_geographies)OVER over_clauseover_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]\n```\n\nPerforms[DBSCAN clustering](https://en.wikipedia.org/wiki/DBSCAN)on a column of geographies. Returns a0-based cluster number.\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Input parameters** \n\n- `    geography_column`: A column of`    GEOGRAPHY`s thatis clustered.\n- `    epsilon`: The epsilon that specifies the radius, measured in meters, arounda core value. Non-negative`    FLOAT64`value.\n- `    minimum_geographies`: Specifies the minimum number of geographies in asingle cluster. Only dense input forms a cluster, otherwise it is classifiedas noise. Non-negative`    INT64`value.\n\n **Geography types and the DBSCAN algorithm** \n\nThe DBSCAN algorithm identifies high-density clusters of data and marks outliersin low-density areas of noise. Geographies passed in through`geography_column`are classified in one of three ways by the DBSCAN algorithm:\n\n- Core value: A geography is a core value if it is within`    epsilon`distanceof`    minimum_geographies`geographies, including itself. The core valuestarts a new cluster, or is added to the same cluster as a core value within`    epsilon`distance. Core values are grouped in a cluster together with allother core and border values that are within`    epsilon`distance.\n- Border value: A geography is a border value if it is within epsilon distanceof a core value. It is added to the same cluster as a core value within`    epsilon`distance. A border value may be within`    epsilon`distance of morethan one cluster. In this case, it may be arbitrarily assigned to eithercluster and the function will produce the same result in subsequent calls.\n- Noise: A geography is noise if it is neither a core nor a border value.Noise values are assigned to a`    NULL`cluster. An empty`    GEOGRAPHY`is always classified as noise.\n\n **Constraints** \n\n- The argument`    minimum_geographies`is a non-negative`    INT64`and`    epsilon`is a non-negative`    FLOAT64`.\n- An empty geography cannot join any cluster.\n- Multiple clustering assignments could be possible for a border value. If ageography is a border value,`    ST_CLUSTERDBSCAN`will assign it to anarbitrary valid cluster.\n\n **Return type** \n\n`INT64`for each geography in the geography column.\n\n **Examples** \n\nThis example performs DBSCAN clustering with a radius of 100,000 meters with a`minimum_geographies`argument of 1. The geographies being analyzed are amixture of points, lines, and polygons.\n\n```\nWITH Geos as  (SELECT 1 as row_id, ST_GEOGFROMTEXT('POINT EMPTY') as geo UNION ALL    SELECT 2, ST_GEOGFROMTEXT('MULTIPOINT(1 1, 2 2, 4 4, 5 2)') UNION ALL    SELECT 3, ST_GEOGFROMTEXT('POINT(14 15)') UNION ALL    SELECT 4, ST_GEOGFROMTEXT('LINESTRING(40 1, 42 34, 44 39)') UNION ALL    SELECT 5, ST_GEOGFROMTEXT('POLYGON((40 2, 40 1, 41 2, 40 2))'))SELECT row_id, geo, ST_CLUSTERDBSCAN(geo, 1e5, 1) OVER () AS cluster_num FROMGeos ORDER BY row_id/*--------+-----------------------------------+-------------* | row_id |                geo                | cluster_num | +--------+-----------------------------------+-------------+ | 1      | GEOMETRYCOLLECTION EMPTY          | NULL        | | 2      | MULTIPOINT(1 1, 2 2, 5 2, 4 4)    | 0           | | 3      | POINT(14 15)                      | 1           | | 4      | LINESTRING(40 1, 42 34, 44 39)    | 2           | | 5      | POLYGON((40 2, 40 1, 41 2, 40 2)) | 2           | *--------+-----------------------------------+-------------*/\n```\n\n"
  },
  {
    "name": "ST_CONTAINS",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_CONTAINS(geography_1, geography_2)\n```\n\n **Description** \n\nReturns`TRUE`if no point of`geography_2`is outside`geography_1`, andthe interiors intersect; returns`FALSE`otherwise.\n\nNOTE: A`GEOGRAPHY` *does not* contain its ownboundary. Compare with[ST_COVERS](#st_covers).\n\n **Return type** \n\n`BOOL`\n\n **Example** \n\nThe following query tests whether the polygon`POLYGON((1 1, 20 1, 10 20, 1 1))`contains each of the three points`(0, 0)`,`(1, 1)`, and`(10, 10)`, which lieon the exterior, the boundary, and the interior of the polygon respectively.\n\n```\nSELECT  ST_GEOGPOINT(i, i) AS p,  ST_CONTAINS(ST_GEOGFROMTEXT('POLYGON((1 1, 20 1, 10 20, 1 1))'),              ST_GEOGPOINT(i, i)) AS `contains`FROM UNNEST([0, 1, 10]) AS i;/*--------------+----------* | p            | contains | +--------------+----------+ | POINT(0 0)   | FALSE    | | POINT(1 1)   | FALSE    | | POINT(10 10) | TRUE     | *--------------+----------*/\n```\n\n"
  },
  {
    "name": "ST_CONVEXHULL",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_CONVEXHULL(geography_expression)\n```\n\n **Description** \n\nReturns the convex hull for the input`GEOGRAPHY`. The convex hull is thesmallest convex`GEOGRAPHY`that covers the input. A`GEOGRAPHY`is convex iffor every pair of points in the`GEOGRAPHY`, the geodesic edge connecting thepoints are also contained in the same`GEOGRAPHY`.\n\nIn most cases, the convex hull consists of a single polygon. Notable edge casesinclude the following:\n\n- The convex hull of a single point is also a point.\n- The convex hull of two or more collinear points is a linestring as long asthat linestring is convex.\n- If the input`    GEOGRAPHY`spans more than ahemisphere, the convex hull is the full globe. This includes any input thatcontains a pair of antipodal points.\n- `    ST_CONVEXHULL`returns`    NULL`if the input is either`    NULL`or the empty`    GEOGRAPHY`.\n\n **Return type** \n\n`GEOGRAPHY`\n\n **Examples** \n\nThe convex hull returned by`ST_CONVEXHULL`can be a point, linestring, or apolygon, depending on the input.\n\n```\nWITH Geographies AS (SELECT ST_GEOGFROMTEXT('POINT(1 1)') AS g UNION ALL  SELECT ST_GEOGFROMTEXT('LINESTRING(1 1, 2 2)') AS g UNION ALL  SELECT ST_GEOGFROMTEXT('MULTIPOINT(2 11, 4 12, 0 15, 1 9, 1 12)') AS g)SELECT  g AS input_geography,  ST_CONVEXHULL(g) AS convex_hullFROM Geographies;/*-----------------------------------------+--------------------------------------------------------* |             input_geography             |                      convex_hull                       | +-----------------------------------------+--------------------------------------------------------+ | POINT(1 1)                              | POINT(0.999999999999943 1)                             | | LINESTRING(1 1, 2 2)                    | LINESTRING(2 2, 1.49988573656168 1.5000570914792, 1 1) | | MULTIPOINT(1 9, 4 12, 2 11, 1 12, 0 15) | POLYGON((1 9, 4 12, 0 15, 1 9))                        | *-----------------------------------------+--------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_COVEREDBY",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_COVEREDBY(geography_1, geography_2)\n```\n\n **Description** \n\nReturns`FALSE`if`geography_1`or`geography_2`is empty. Returns`TRUE`if nopoints of`geography_1`lie in the exterior of`geography_2`.\n\nGiven two`GEOGRAPHY`s`a`and`b`,`ST_COVEREDBY(a, b)`returns the same result as[ST_COVERS](#st_covers)`(b, a)`. Note the opposite order of arguments.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_COVERS",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_COVERS(geography_1, geography_2)\n```\n\n **Description** \n\nReturns`FALSE`if`geography_1`or`geography_2`is empty.Returns`TRUE`if no points of`geography_2`lie in the exterior of`geography_1`.\n\n **Return type** \n\n`BOOL`\n\n **Example** \n\nThe following query tests whether the polygon`POLYGON((1 1, 20 1, 10 20, 1 1))`covers each of the three points`(0, 0)`,`(1, 1)`, and`(10, 10)`, which lieon the exterior, the boundary, and the interior of the polygon respectively.\n\n```\nSELECT  ST_GEOGPOINT(i, i) AS p,  ST_COVERS(ST_GEOGFROMTEXT('POLYGON((1 1, 20 1, 10 20, 1 1))'),            ST_GEOGPOINT(i, i)) AS `covers`FROM UNNEST([0, 1, 10]) AS i;/*--------------+--------* | p            | covers | +--------------+--------+ | POINT(0 0)   | FALSE  | | POINT(1 1)   | TRUE   | | POINT(10 10) | TRUE   | *--------------+--------*/\n```\n\n"
  },
  {
    "name": "ST_DIFFERENCE",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_DIFFERENCE(geography_1, geography_2)\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`that represents the point setdifference of`geography_1`and`geography_2`. Therefore, the result consists ofthe part of`geography_1`that does not intersect with`geography_2`.\n\nIf`geometry_1`is completely contained in`geometry_2`, then`ST_DIFFERENCE`returns an empty`GEOGRAPHY`.\n\n **Constraints** \n\nThe underlying geometric objects that a GoogleSQL`GEOGRAPHY`represents correspond to a *closed* pointset. Therefore,`ST_DIFFERENCE`is the closure of the point set difference of`geography_1`and`geography_2`. This implies that if`geography_1`and`geography_2`intersect, then a portion of the boundary of`geography_2`couldbe in the difference.\n\n **Return type** \n\n`GEOGRAPHY`\n\n **Example** \n\nThe following query illustrates the difference between`geog1`, a larger polygon`POLYGON((0 0, 10 0, 10 10, 0 0))`and`geog1`, a smaller polygon`POLYGON((4 2, 6 2, 8 6, 4 2))`that intersects with`geog1`. The result is`geog1`with a hole where`geog2`intersects with it.\n\n```\nSELECT  ST_DIFFERENCE(      ST_GEOGFROMTEXT('POLYGON((0 0, 10 0, 10 10, 0 0))'),      ST_GEOGFROMTEXT('POLYGON((4 2, 6 2, 8 6, 4 2))')  );/*--------------------------------------------------------* | difference_of_geog1_and_geog2                          | +--------------------------------------------------------+ | POLYGON((0 0, 10 0, 10 10, 0 0), (8 6, 6 2, 4 2, 8 6)) | *--------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_DIMENSION",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_DIMENSION(geography_expression)\n```\n\n **Description** \n\nReturns the dimension of the highest-dimensional element in the input`GEOGRAPHY`.\n\nThe dimension of each possible element is as follows:\n\n- The dimension of a point is`    0`.\n- The dimension of a linestring is`    1`.\n- The dimension of a polygon is`    2`.\n\nIf the input`GEOGRAPHY`is empty,`ST_DIMENSION`returns`-1`.\n\n **Return type** \n\n`INT64`\n\n"
  },
  {
    "name": "ST_DISJOINT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_DISJOINT(geography_1, geography_2)\n```\n\n **Description** \n\nReturns`TRUE`if the intersection of`geography_1`and`geography_2`is empty,that is, no point in`geography_1`also appears in`geography_2`.\n\n`ST_DISJOINT`is the logical negation of[ST_INTERSECTS](#st_intersects).\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_DISTANCE",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_DISTANCE(geography_1, geography_2[, use_spheroid])\n```\n\n **Description** \n\nReturns the shortest distance in meters between two non-empty`GEOGRAPHY`s.\n\nIf either of the input`GEOGRAPHY`s is empty,`ST_DISTANCE`returns`NULL`.\n\nThe optional`use_spheroid`parameter determines how this function measuresdistance. If`use_spheroid`is`FALSE`, the function measures distance on thesurface of a perfect sphere. If`use_spheroid`is`TRUE`, the function measuresdistance on the surface of the[WGS84](https://en.wikipedia.org/wiki/World_Geodetic_System)spheroid. The default valueof`use_spheroid`is`FALSE`.\n\n **Return type** \n\n`FLOAT64`\n\n"
  },
  {
    "name": "ST_DUMP",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_DUMP(geography[, dimension])\n```\n\n **Description** \n\nReturns an`ARRAY`of simple`GEOGRAPHY`s where each element is a component ofthe input`GEOGRAPHY`. A simple`GEOGRAPHY`consists of a single point, linestring,or polygon. If the input`GEOGRAPHY`is simple, theresult is a single element. When the input`GEOGRAPHY`is a collection,`ST_DUMP`returns an`ARRAY`with one simple`GEOGRAPHY`for each component in the collection.\n\nIf`dimension`is provided, the function only returns`GEOGRAPHY`s of the corresponding dimension. Adimension of -1 is equivalent to omitting`dimension`.\n\n **Return Type** \n\n`ARRAY&lt;GEOGRAPHY&gt;`\n\n **Examples** \n\nThe following example shows how`ST_DUMP`returns the simple geographies withina complex geography.\n\n```\nWITH example AS (  SELECT ST_GEOGFROMTEXT('POINT(0 0)') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('MULTIPOINT(0 0, 1 1)') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('GEOMETRYCOLLECTION(POINT(0 0), LINESTRING(1 2, 2 1))'))SELECT  geography AS original_geography,  ST_DUMP(geography) AS dumped_geographiesFROM example/*-------------------------------------+------------------------------------* |         original_geographies        |      dumped_geographies            | +-------------------------------------+------------------------------------+ | POINT(0 0)                          | [POINT(0 0)]                       | | MULTIPOINT(0 0, 1 1)                | [POINT(0 0), POINT(1 1)]           | | GEOMETRYCOLLECTION(POINT(0 0),      | [POINT(0 0), LINESTRING(1 2, 2 1)] | |   LINESTRING(1 2, 2 1))             |                                    | *-------------------------------------+------------------------------------*/\n```\n\nThe following example shows how`ST_DUMP`with the dimension argument onlyreturns simple geographies of the given dimension.\n\n```\nWITH example AS (  SELECT ST_GEOGFROMTEXT('GEOMETRYCOLLECTION(POINT(0 0), LINESTRING(1 2, 2 1))') AS geography)SELECT  geography AS original_geography,  ST_DUMP(geography, 1) AS dumped_geographiesFROM example/*-------------------------------------+------------------------------* |         original_geographies        |      dumped_geographies      | +-------------------------------------+------------------------------+ | GEOMETRYCOLLECTION(POINT(0 0),      | [LINESTRING(1 2, 2 1)]       | |   LINESTRING(1 2, 2 1))             |                              | *-------------------------------------+------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_DWITHIN",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_DWITHIN(geography_1, geography_2, distance[, use_spheroid])\n```\n\n **Description** \n\nReturns`TRUE`if the distance between at least one point in`geography_1`andone point in`geography_2`is less than or equal to the distance given by the`distance`argument; otherwise, returns`FALSE`. If either input`GEOGRAPHY`is empty,`ST_DWithin`returns`FALSE`. Thegiven`distance`is in meters on the surface of the Earth.\n\nThe optional`use_spheroid`parameter determines how this function measuresdistance. If`use_spheroid`is`FALSE`, the function measures distance on thesurface of a perfect sphere.\n\nThe`use_spheroid`parameter currently only supportsthe value`FALSE`. The default value of`use_spheroid`is`FALSE`.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_ENDPOINT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ENDPOINT(linestring_geography)\n```\n\n **Description** \n\nReturns the last point of a linestring geography as a point geography. Returnsan error if the input is not a linestring or if the input is empty. Use the`SAFE`prefix to obtain`NULL`for invalid input instead of an error.\n\n **Return Type** \n\nPoint`GEOGRAPHY`\n\n **Example** \n\n```\nSELECT ST_ENDPOINT(ST_GEOGFROMTEXT('LINESTRING(1 1, 2 1, 3 2, 3 3)')) last/*--------------* | last         | +--------------+ | POINT(3 3)   | *--------------*/\n```\n\n"
  },
  {
    "name": "ST_EQUALS",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_EQUALS(geography_1, geography_2)\n```\n\n **Description** \n\nReturns`TRUE`if`geography_1`and`geography_2`represent the same\n\n`GEOGRAPHY`value. More precisely, this means thatone of the following conditions holds:+`ST_COVERS(geography_1, geography_2) = TRUE`and`ST_COVERS(geography_2,    geography_1) = TRUE`+   Both`geography_1`and`geography_2`are empty.\n\nTherefore, two`GEOGRAPHY`s may be equal even if theordering of points or vertices differ, as long as they still represent the samegeometric structure.\n\n **Constraints** \n\n`ST_EQUALS`is not guaranteed to be a transitive function.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_EXTENT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_EXTENT(geography_expression)\n```\n\n **Description** \n\nReturns a`STRUCT`that represents the bounding box for the set of input`GEOGRAPHY`values. The bounding box is the minimal rectangle that encloses thegeography. The edges of the rectangle follow constant lines of longitude andlatitude.\n\nCaveats:\n\n- Returns`    NULL`if all the inputs are`    NULL`or empty geographies.\n- The bounding box might cross the antimeridian if this allows for a smallerrectangle. In this case, the bounding box has one of its longitudinal boundsoutside of the [-180, 180] range, so that`    xmin`is smaller than the eastmostvalue`    xmax`.\n- If the longitude span of the bounding box is larger than or equal to 180degrees, the function returns the bounding box with the longitude range of[-180, 180].\n\n **Return type** \n\n`STRUCT&lt;xmin FLOAT64, ymin FLOAT64, xmax FLOAT64, ymax FLOAT64&gt;`.\n\nBounding box parts:\n\n- `    xmin`: The westmost constant longitude line that bounds the rectangle.\n- `    xmax`: The eastmost constant longitude line that bounds the rectangle.\n- `    ymin`: The minimum constant latitude line that bounds the rectangle.\n- `    ymax`: The maximum constant latitude line that bounds the rectangle.\n\n **Example** \n\n```\nWITH data AS (  SELECT 1 id, ST_GEOGFROMTEXT('POLYGON((-125 48, -124 46, -117 46, -117 49, -125 48))') g  UNION ALL  SELECT 2 id, ST_GEOGFROMTEXT('POLYGON((172 53, -130 55, -141 70, 172 53))') g  UNION ALL  SELECT 3 id, ST_GEOGFROMTEXT('POINT EMPTY') g)SELECT ST_EXTENT(g) AS boxFROM data/*----------------------------------------------* | box                                          | +----------------------------------------------+ | {xmin:172, ymin:46, xmax:243, ymax:70}       | *----------------------------------------------*/\n```\n\n[ST_BOUNDINGBOX](#st_boundingbox)for the non-aggregate version of`ST_EXTENT`.\n\n"
  },
  {
    "name": "ST_EXTERIORRING",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_EXTERIORRING(polygon_geography)\n```\n\n **Description** \n\nReturns a linestring geography that corresponds to the outermost ring of apolygon geography.\n\n- If the input geography is a polygon, gets the outermost ring of the polygongeography and returns the corresponding linestring.\n- If the input is the full`    GEOGRAPHY`, returns an empty geography.\n- Returns an error if the input is not a single polygon.\n\nUse the`SAFE`prefix to return`NULL`for invalid input instead of an error.\n\n **Return type** \n\n- Linestring`    GEOGRAPHY`\n- Empty`    GEOGRAPHY`\n\n **Examples** \n\n```\nWITH geo as (SELECT ST_GEOGFROMTEXT('POLYGON((0 0, 1 4, 2 2, 0 0))') AS g UNION ALL  SELECT ST_GEOGFROMTEXT('''POLYGON((1 1, 1 10, 5 10, 5 1, 1 1),                                  (2 2, 3 4, 2 4, 2 2))''') as g)SELECT ST_EXTERIORRING(g) AS ring FROM geo;/*---------------------------------------* | ring                                  | +---------------------------------------+ | LINESTRING(2 2, 1 4, 0 0, 2 2)        | | LINESTRING(5 1, 5 10, 1 10, 1 1, 5 1) | *---------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_GEOGFROM",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_GEOGFROM(expression)\n```\n\n **Description** \n\nConverts an expression for a`STRING`or`BYTES`value into a`GEOGRAPHY`value.\n\nIf`expression`represents a`STRING`value, it must be a valid`GEOGRAPHY`representation in one of the following formats:\n\n- WKT format. To learn more about this format and the requirements to use it,see[ST_GEOGFROMTEXT](#st_geogfromtext).\n- WKB in hexadecimal text format. To learn more about this format and therequirements to use it, see[ST_GEOGFROMWKB](#st_geogfromwkb).\n- GeoJSON format. To learn more about this format and therequirements to use it, see[ST_GEOGFROMGEOJSON](#st_geogfromgeojson).\n\nIf`expression`represents a`BYTES`value, it must be a valid`GEOGRAPHY`binary expression in WKB format. To learn more about this format and therequirements to use it, see[ST_GEOGFROMWKB](#st_geogfromwkb).\n\nIf`expression`is`NULL`, the output is`NULL`.\n\n **Return type** \n\n`GEOGRAPHY`\n\n **Examples** \n\nThis takes a WKT-formatted string and returns a`GEOGRAPHY`polygon:\n\n```\nSELECT ST_GEOGFROM('POLYGON((0 0, 0 2, 2 2, 2 0, 0 0))') AS WKT_format/*------------------------------------* | WKT_format                         | +------------------------------------+ | POLYGON((2 0, 2 2, 0 2, 0 0, 2 0)) | *------------------------------------*/\n```\n\nThis takes a WKB-formatted hexadecimal-encoded string and returns a`GEOGRAPHY`point:\n\n```\nSELECT ST_GEOGFROM(FROM_HEX('010100000000000000000000400000000000001040')) AS WKB_format/*----------------* | WKB_format     | +----------------+ | POINT(2 4)     | *----------------*/\n```\n\nThis takes WKB-formatted bytes and returns a`GEOGRAPHY`point:\n\n```\nSELECT ST_GEOGFROM('010100000000000000000000400000000000001040')-AS WKB_format/*----------------* | WKB_format     | +----------------+ | POINT(2 4)     | *----------------*/\n```\n\nThis takes a GeoJSON-formatted string and returns a`GEOGRAPHY`polygon:\n\n```\nSELECT ST_GEOGFROM(  '{ \"type\": \"Polygon\", \"coordinates\": [ [ [2, 0], [2, 2], [1, 2], [0, 2], [0, 0], [2, 0] ] ] }') AS GEOJSON_format/*-----------------------------------------* | GEOJSON_format                          | +-----------------------------------------+ | POLYGON((2 0, 2 2, 1 2, 0 2, 0 0, 2 0)) | *-----------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_GEOGFROMGEOJSON",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_GEOGFROMGEOJSON(geojson_string [, make_valid =&gt; constant_expression])\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`value that corresponds to theinput[GeoJSON](https://en.wikipedia.org/wiki/GeoJSON)representation.\n\n`ST_GEOGFROMGEOJSON`accepts input that is[RFC 7946](https://tools.ietf.org/html/rfc7946)compliant.\n\nIf the parameter`make_valid`is set to`TRUE`, the function attempts to repairpolygons that don't conform to[Open Geospatial Consortium](https://www.ogc.org/standards/sfa)semantics.This parameter uses named argument syntax, and should be specified using`make_valid =&gt; argument_value`syntax.\n\nA GoogleSQL`GEOGRAPHY`has sphericalgeodesic edges, whereas a GeoJSON`Geometry`object explicitly has planar edges.To convert between these two types of edges, GoogleSQL adds additionalpoints to the line where necessary so that the resulting sequence of edgesremains within 10 meters of the original edge.\n\nSee[ST_ASGEOJSON](#st_asgeojson)to format a`GEOGRAPHY`as GeoJSON.\n\n **Constraints** \n\nThe JSON input is subject to the following constraints:\n\n- `    ST_GEOGFROMGEOJSON`only accepts JSON geometry fragments and cannot be usedto ingest a whole JSON document.\n- The input JSON fragment must consist of a GeoJSON geometry type, whichincludes`    Point`,`    MultiPoint`,`    LineString`,`    MultiLineString`,`    Polygon`,`    MultiPolygon`, and`    GeometryCollection`. Any other GeoJSON type such as`    Feature`or`    FeatureCollection`will result in an error.\n- A position in the`    coordinates`member of a GeoJSON geometry type mustconsist of exactly two elements. The first is the longitude and the secondis the latitude. Therefore,`    ST_GEOGFROMGEOJSON`does not support theoptional third element for a position in the`    coordinates`member.\n\n **Return type** \n\n`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_GEOGFROMTEXT",
    "arguments": [],
    "category": "Geography functions",
    "description": "- [Signature 1](#st_geogfromtext_signature1)\n- [Signature 2](#st_geogfromtext_signature2)\n\n\n<span id=\"st_geogfromtext_signature1\">\n#### Signature 1\n\n</span>\n```\nST_GEOGFROMTEXT(wkt_string[, oriented])\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`value that corresponds to theinput[WKT](https://en.wikipedia.org/wiki/Well-known_text)representation.\n\nThis function supports an optional parameter of type`BOOL`,`oriented`. If this parameter is set to`TRUE`, any polygons in the input are assumed to be oriented as follows:if someone walks along the boundary of the polygon in the order ofthe input vertices, the interior of the polygon is on the left. This allowsWKT to represent polygons larger than a hemisphere. If`oriented`is`FALSE`oromitted, this function returns the polygon with the smaller area.See also[ST_MAKEPOLYGONORIENTED](#st_makepolygonoriented)which is similarto`ST_GEOGFROMTEXT`with`oriented=TRUE`.\n\nTo format`GEOGRAPHY`as WKT, use[ST_ASTEXT](#st_astext).\n\n **Constraints** \n\n- All input edges are assumed to be spherical geodesics, and *not* planarstraight lines. For reading data in a planar projection, consider using[ST_GEOGFROMGEOJSON](#st_geogfromgeojson).For more information on the differences between spherical geodesics andplanar lines, see[Coordinate systems and edges](/bigquery/docs/gis-data#coordinate_systems_and_edges).\n- The function does not support three-dimensional geometries that have a`    Z`suffix, nor does it support linear referencing system geometries with an`    M`suffix.\n- The function only supports geometry primitives and multipart geometries. Inparticular it supports only point, multipoint, linestring, multilinestring,polygon, multipolygon, and geometry collection.\n\n **Return type** \n\n`GEOGRAPHY`\n\n **Example** \n\nThe following query reads the WKT string`POLYGON((0 0, 0 2, 2 2, 2 0, 0 0))`both as a non-oriented polygon and as an oriented polygon, and checks whethereach result contains the point`(1, 1)`.\n\n```\nWITH polygon AS (SELECT 'POLYGON((0 0, 0 2, 2 2, 2 0, 0 0))' AS p)SELECT  ST_CONTAINS(ST_GEOGFROMTEXT(p), ST_GEOGPOINT(1, 1)) AS fromtext_default,  ST_CONTAINS(ST_GEOGFROMTEXT(p, FALSE), ST_GEOGPOINT(1, 1)) AS non_oriented,  ST_CONTAINS(ST_GEOGFROMTEXT(p, TRUE),  ST_GEOGPOINT(1, 1)) AS orientedFROM polygon;/*-------------------+---------------+-----------* | fromtext_default  | non_oriented  | oriented  | +-------------------+---------------+-----------+ | TRUE              | TRUE          | FALSE     | *-------------------+---------------+-----------*/\n```\n\n\n<span id=\"st_geogfromtext_signature2\">\n#### Signature 2\n\n</span>\n```\nST_GEOGFROMTEXT(wkt_string[, oriented =&gt; boolean_constant_1]    [, planar =&gt; boolean_constant_2] [, make_valid =&gt; boolean_constant_3])\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`value that corresponds to theinput[WKT](https://en.wikipedia.org/wiki/Well-known_text)representation.\n\nThis function supports three optional parameters  of type`BOOL`:`oriented`,`planar`, and`make_valid`.This signature uses named arguments syntax, and the parameters should bespecified using`parameter_name =&gt; parameter_value`syntax, in any order.\n\nIf the`oriented`parameter is set to`TRUE`, any polygons in the input are assumed to be oriented as follows:if someone walks along the boundary of the polygon in the order ofthe input vertices, the interior of the polygon is on the left. This allowsWKT to represent polygons larger than a hemisphere. If`oriented`is`FALSE`oromitted, this function returns the polygon with the smaller area.See also[ST_MAKEPOLYGONORIENTED](#st_makepolygonoriented)which is similarto`ST_GEOGFROMTEXT`with`oriented=TRUE`.\n\nIf the parameter`planar`is set to`TRUE`, the edges of the line strings andpolygons are assumed to use planar map semantics, rather than GoogleSQLdefault spherical geodesics semantics. For more informationon the differences between spherical geodesics and planar lines, see[Coordinate systems and edges](/bigquery/docs/gis-data#coordinate_systems_and_edges).\n\nIf the parameter`make_valid`is set to`TRUE`, the function attempts to repairpolygons that don't conform to[Open Geospatial Consortium](https://www.ogc.org/standards/sfa)semantics.\n\nTo format`GEOGRAPHY`as WKT, use[ST_ASTEXT](#st_astext).\n\n **Constraints** \n\n- All input edges are assumed to be spherical geodesics by default, and *not* planar straight lines. For reading data in a planar projection,pass`    planar =&gt; TRUE`argument, or consider using[ST_GEOGFROMGEOJSON](#st_geogfromgeojson).For more information on the differences betweenspherical geodesics and planar lines, see[Coordinate systems and edges](/bigquery/docs/gis-data#coordinate_systems_and_edges).\n- The function does not support three-dimensional geometries that have a`    Z`suffix, nor does it support linear referencing system geometries with an`    M`suffix.\n- The function only supports geometry primitives and multipart geometries. Inparticular it supports only point, multipoint, linestring, multilinestring,polygon, multipolygon, and geometry collection.\n- `    oriented`and`    planar`cannot be equal to`    TRUE`at the same time.\n- `    oriented`and`    make_valid`cannot be equal to`    TRUE`at the same time.\n\n **Example** \n\nThe following query reads the WKT string`POLYGON((0 0, 0 2, 2 2, 0 2, 0 0))`both as a non-oriented polygon and as an oriented polygon, and checks whethereach result contains the point`(1, 1)`.\n\n```\nWITH polygon AS (SELECT 'POLYGON((0 0, 0 2, 2 2, 2 0, 0 0))' AS p)SELECT  ST_CONTAINS(ST_GEOGFROMTEXT(p), ST_GEOGPOINT(1, 1)) AS fromtext_default,  ST_CONTAINS(ST_GEOGFROMTEXT(p, oriented =&gt; FALSE), ST_GEOGPOINT(1, 1)) AS non_oriented,  ST_CONTAINS(ST_GEOGFROMTEXT(p, oriented =&gt; TRUE),  ST_GEOGPOINT(1, 1)) AS orientedFROM polygon;/*-------------------+---------------+-----------* | fromtext_default  | non_oriented  | oriented  | +-------------------+---------------+-----------+ | TRUE              | TRUE          | FALSE     | *-------------------+---------------+-----------*/\n```\n\nThe following query converts a WKT string with an invalid polygon to`GEOGRAPHY`. The WKT string violates two propertiesof a valid polygon - the loop describing the polygon is not closed, and itcontains self-intersection. With the`make_valid`option,`ST_GEOGFROMTEXT`successfully converts it to a multipolygon shape.\n\n```\nWITH data AS (  SELECT 'POLYGON((0 -1, 2 1, 2 -1, 0 1))' wkt)SELECT  SAFE.ST_GEOGFROMTEXT(wkt) as geom,  SAFE.ST_GEOGFROMTEXT(wkt, make_valid =&gt; TRUE) as valid_geomFROM data/*------+-----------------------------------------------------------------* | geom | valid_geom                                                      | +------+-----------------------------------------------------------------+ | NULL | MULTIPOLYGON(((0 -1, 1 0, 0 1, 0 -1)), ((1 0, 2 -1, 2 1, 1 0))) | *------+-----------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_GEOGFROMWKB",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_GEOGFROMWKB(wkb_bytes_expression)\n```\n\n```\nST_GEOGFROMWKB(wkb_hex_string_expression)\n```\n\n **Description** \n\nConverts an expression for a hexadecimal-text`STRING`or`BYTES`value into a`GEOGRAPHY`value. The expression must be in[WKB](https://en.wikipedia.org/wiki/Well-known_text#Well-known_binary)format.\n\nTo format`GEOGRAPHY`as WKB, use[ST_ASBINARY](#st_asbinary).\n\n **Constraints** \n\nAll input edges are assumed to be spherical geodesics, and *not* planar straightlines. For reading data in a planar projection, consider using[ST_GEOGFROMGEOJSON](#st_geogfromgeojson).\n\n **Return type** \n\n`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_GEOGPOINT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_GEOGPOINT(longitude, latitude)\n```\n\n **Description** \n\nCreates a`GEOGRAPHY`with a single point.`ST_GEOGPOINT`creates a point fromthe specified`FLOAT64`longitude (in degrees,negative west of the Prime Meridian, positive east) and latitude (in degrees,positive north of the Equator, negative south) parameters and returns that pointin a`GEOGRAPHY`value.\n\nNOTE: Some systems present latitude first; take care with argument order.\n\n **Constraints** \n\n- Longitudes outside the range [-180, 180] are allowed;`    ST_GEOGPOINT`usesthe input longitude modulo 360 to obtain a longitude within [-180, 180].\n- Latitudes must be in the range [-90, 90]. Latitudes outside this rangewill result in an error.\n\n **Return type** \n\nPoint`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_GEOGPOINTFROMGEOHASH",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_GEOGPOINTFROMGEOHASH(geohash)\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`value that corresponds to apoint in the middle of a bounding box defined in the[GeoHash](https://en.wikipedia.org/wiki/Geohash).\n\n **Return type** \n\nPoint`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_GEOHASH",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_GEOHASH(geography_expression[, maxchars])\n```\n\n **Description** \n\nTakes a single-point`GEOGRAPHY`and returns a[GeoHash](https://en.wikipedia.org/wiki/Geohash)representation of that`GEOGRAPHY`object.\n\n- `    geography_expression`: Represents a`    GEOGRAPHY`object. Only a`    GEOGRAPHY`object that represents a single point is supported. If`    ST_GEOHASH`is usedover an empty`    GEOGRAPHY`object, returns`    NULL`.\n- `    maxchars`: This optional`    INT64`parameter specifies the maximum number ofcharacters the hash will contain. Fewer characters corresponds to lowerprecision (or, described differently, to a bigger bounding box).`    maxchars`defaults to 20 if not explicitly specified. A valid`    maxchars`value is 1to 20. Any value below or above is considered unspecified and the default of20 is used.\n\n **Return type** \n\n`STRING`\n\n **Example** \n\nReturns a GeoHash of the Seattle Center with 10 characters of precision.\n\n```\nSELECT ST_GEOHASH(ST_GEOGPOINT(-122.35, 47.62), 10) geohash/*--------------* | geohash      | +--------------+ | c22yzugqw7   | *--------------*/\n```\n\n"
  },
  {
    "name": "ST_GEOMETRYTYPE",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_GEOMETRYTYPE(geography_expression)\n```\n\n **Description** \n\nReturns the[Open Geospatial Consortium](https://www.ogc.org/standards/sfa)(OGC) geometry type thatdescribes the input`GEOGRAPHY`. The OGC geometry type matches thetypes that are used in[WKT](https://en.wikipedia.org/wiki/Well-known_text)and[GeoJSON](https://en.wikipedia.org/wiki/GeoJSON)formats andprinted for[ST_ASTEXT](#st_astext)and[ST_ASGEOJSON](#st_asgeojson).`ST_GEOMETRYTYPE`returns the OGC geometry type with the \"ST_\" prefix.\n\n`ST_GEOMETRYTYPE`returns the following given the type on the input:\n\n- Single point geography: Returns`    ST_Point`.\n- Collection of only points: Returns`    ST_MultiPoint`.\n- Single linestring geography: Returns`    ST_LineString`.\n- Collection of only linestrings: Returns`    ST_MultiLineString`.\n- Single polygon geography: Returns`    ST_Polygon`.\n- Collection of only polygons: Returns`    ST_MultiPolygon`.\n- Collection with elements of different dimensions, or the input is the emptygeography: Returns`    ST_GeometryCollection`.\n\n **Return type** \n\n`STRING`\n\n **Example** \n\nThe following example shows how`ST_GEOMETRYTYPE`takes geographies and returnsthe names of their OGC geometry types.\n\n```\nWITH example AS(  SELECT ST_GEOGFROMTEXT('POINT(0 1)') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('MULTILINESTRING((2 2, 3 4), (5 6, 7 7))')  UNION ALL  SELECT ST_GEOGFROMTEXT('GEOMETRYCOLLECTION(MULTIPOINT(-1 2, 0 12), LINESTRING(-2 4, 0 6))')  UNION ALL  SELECT ST_GEOGFROMTEXT('GEOMETRYCOLLECTION EMPTY'))SELECT  geography AS WKT,  ST_GEOMETRYTYPE(geography) AS geometry_type_nameFROM example;/*-------------------------------------------------------------------+-----------------------* | WKT                                                               | geometry_type_name    | +-------------------------------------------------------------------+-----------------------+ | POINT(0 1)                                                        | ST_Point              | | MULTILINESTRING((2 2, 3 4), (5 6, 7 7))                           | ST_MultiLineString    | | GEOMETRYCOLLECTION(MULTIPOINT(-1 2, 0 12), LINESTRING(-2 4, 0 6)) | ST_GeometryCollection | | GEOMETRYCOLLECTION EMPTY                                          | ST_GeometryCollection | *-------------------------------------------------------------------+-----------------------*/\n```\n\n"
  },
  {
    "name": "ST_HAUSDORFFDISTANCE",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_HAUSDORFFDISTANCE(geography_1, geography_2)\n```\n\n```\nST_HAUSDORFFDISTANCE(geography_1, geography_2, directed=&gt;{ TRUE | FALSE })\n```\n\n **Description** \n\nGets the discrete[Hausdorff distance](http://en.wikipedia.org/wiki/Hausdorff_distance), which is the greatest of allthe distances from a discrete point in one geography to the closestdiscrete point in another geography.\n\n **Definitions** \n\n- `    geography_1`: A`    GEOGRAPHY`value that represents the first geography.\n- `    geography_2`: A`    GEOGRAPHY`value that represents the second geography.\n- `    directed`: Optional, required named argument that represents the type ofcomputation to use on the input geographies. If this argument is notspecified,`    directed=&gt;FALSE`is used by default.\n    \n    \n    - `        FALSE`: The largest Hausdorff distance found in(`        geography_1`,`        geography_2`) and(`        geography_2`,`        geography_1`).\n        \n        \n    - `        TRUE`(default): The Hausdorff distance for(`        geography_1`,`        geography_2`).\n        \n        \n\n **Details** \n\nIf an input geography is`NULL`, the function returns`NULL`.\n\n **Return type** \n\n`FLOAT64`\n\n **Example** \n\nThe following query gets the Hausdorff distance between`geo1`and`geo2`:\n\n```\nWITH data AS (  SELECT    ST_GEOGFROMTEXT('LINESTRING(20 70, 70 60, 10 70, 70 70)') AS geo1,    ST_GEOGFROMTEXT('LINESTRING(20 90, 30 90, 60 10, 90 10)') AS geo2)SELECT ST_HAUSDORFFDISTANCE(geo1, geo2, directed=&gt;TRUE) AS distanceFROM data;/*--------------------+ | distance           | +--------------------+ | 1688933.9832041925 | +--------------------*/\n```\n\nThe following query gets the Hausdorff distance between`geo2`and`geo1`:\n\n```\nWITH data AS (  SELECT    ST_GEOGFROMTEXT('LINESTRING(20 70, 70 60, 10 70, 70 70)') AS geo1,    ST_GEOGFROMTEXT('LINESTRING(20 90, 30 90, 60 10, 90 10)') AS geo2)SELECT ST_HAUSDORFFDISTANCE(geo2, geo1, directed=&gt;TRUE) AS distanceFROM data;/*--------------------+ | distance           | +--------------------+ | 5802892.745488612  | +--------------------*/\n```\n\nThe following query gets the largest Hausdorff distance between(`geo1`and`geo2`) and (`geo2`and`geo1`):\n\n```\nWITH data AS (  SELECT    ST_GEOGFROMTEXT('LINESTRING(20 70, 70 60, 10 70, 70 70)') AS geo1,    ST_GEOGFROMTEXT('LINESTRING(20 90, 30 90, 60 10, 90 10)') AS geo2)SELECT ST_HAUSDORFFDISTANCE(geo1, geo2, directed=&gt;FALSE) AS distanceFROM data;/*--------------------+ | distance           | +--------------------+ | 5802892.745488612  | +--------------------*/\n```\n\nThe following query produces the same results as the previous query because`ST_HAUSDORFFDISTANCE`uses`directed=&gt;FALSE`by default.\n\n```\nWITH data AS (  SELECT    ST_GEOGFROMTEXT('LINESTRING(20 70, 70 60, 10 70, 70 70)') AS geo1,    ST_GEOGFROMTEXT('LINESTRING(20 90, 30 90, 60 10, 90 10)') AS geo2)SELECT ST_HAUSDORFFDISTANCE(geo1, geo2) AS distanceFROM data;\n```\n\n"
  },
  {
    "name": "ST_INTERIORRINGS",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_INTERIORRINGS(polygon_geography)\n```\n\n **Description** \n\nReturns an array of linestring geographies that corresponds to the interiorrings of a polygon geography. Each interior ring is the border of a hole withinthe input polygon.\n\n- If the input geography is a polygon, excludes the outermost ring of thepolygon geography and returns the linestrings corresponding to the interiorrings.\n- If the input is the full`    GEOGRAPHY`, returns an empty array.\n- If the input polygon has no holes, returns an empty array.\n- Returns an error if the input is not a single polygon.\n\nUse the`SAFE`prefix to return`NULL`for invalid input instead of an error.\n\n **Return type** \n\n`ARRAY&lt;LineString GEOGRAPHY&gt;`\n\n **Examples** \n\n```\nWITH geo AS (  SELECT ST_GEOGFROMTEXT('POLYGON((0 0, 1 1, 1 2, 0 0))') AS g UNION ALL  SELECT ST_GEOGFROMTEXT('POLYGON((1 1, 1 10, 5 10, 5 1, 1 1), (2 2, 3 4, 2 4, 2 2))') UNION ALL  SELECT ST_GEOGFROMTEXT('POLYGON((1 1, 1 10, 5 10, 5 1, 1 1), (2 2.5, 3.5 3, 2.5 2, 2 2.5), (3.5 7, 4 6, 3 3, 3.5 7))') UNION ALL  SELECT ST_GEOGFROMTEXT('fullglobe') UNION ALL  SELECT NULL)SELECT ST_INTERIORRINGS(g) AS rings FROM geo;/*----------------------------------------------------------------------------* | rings                                                                      | +----------------------------------------------------------------------------+ | []                                                                         | | [LINESTRING(2 2, 3 4, 2 4, 2 2)]                                           | | [LINESTRING(2.5 2, 3.5 3, 2 2.5, 2.5 2), LINESTRING(3 3, 4 6, 3.5 7, 3 3)] | | []                                                                         | | NULL                                                                       | *----------------------------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_INTERSECTION",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_INTERSECTION(geography_1, geography_2)\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`that represents the point setintersection of the two input`GEOGRAPHY`s. Thus,every point in the intersection appears in both`geography_1`and`geography_2`.\n\nIf the two input`GEOGRAPHY`s are disjoint, that is,there are no points that appear in both input`geometry_1`and`geometry_2`,then an empty`GEOGRAPHY`is returned.\n\nSee[ST_INTERSECTS](#st_intersects),[ST_DISJOINT](#st_disjoint)for relatedpredicate functions.\n\n **Return type** \n\n`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_INTERSECTS",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_INTERSECTS(geography_1, geography_2)\n```\n\n **Description** \n\nReturns`TRUE`if the point set intersection of`geography_1`and`geography_2`is non-empty. Thus, this function returns`TRUE`if there is at least one pointthat appears in both input`GEOGRAPHY`s.\n\nIf`ST_INTERSECTS`returns`TRUE`, it implies that[ST_DISJOINT](#st_disjoint)returns`FALSE`.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_INTERSECTSBOX",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_INTERSECTSBOX(geography, lng1, lat1, lng2, lat2)\n```\n\n **Description** \n\nReturns`TRUE`if`geography`intersects the rectangle between`[lng1, lng2]`and`[lat1, lat2]`. The edges of the rectangle follow constant lines oflongitude and latitude.`lng1`and`lng2`specify the westmost and eastmostconstant longitude lines that bound the rectangle, and`lat1`and`lat2`specifythe minimum and maximum constant latitude lines that bound the rectangle.\n\nSpecify all longitude and latitude arguments in degrees.\n\n **Constraints** \n\nThe input arguments are subject to the following constraints:\n\n- Latitudes should be in the`    [-90, 90]`degree range.\n- Longitudes should follow either of the following rules:\n    - Both longitudes are in the`        [-180, 180]`degree range.\n    - One of the longitudes is in the`        [-180, 180]`degree range, and`        lng2 - lng1`is in the`        [0, 360]`interval.\n\n **Return type** \n\n`BOOL`\n\n **Example** \n\n```\nSELECT p, ST_INTERSECTSBOX(p, -90, 0, 90, 20) AS box1,       ST_INTERSECTSBOX(p, 90, 0, -90, 20) AS box2FROM UNNEST([ST_GEOGPOINT(10, 10), ST_GEOGPOINT(170, 10),             ST_GEOGPOINT(30, 30)]) p/*----------------+--------------+--------------* | p              | box1         | box2         | +----------------+--------------+--------------+ | POINT(10 10)   | TRUE         | FALSE        | | POINT(170 10)  | FALSE        | TRUE         | | POINT(30 30)   | FALSE        | FALSE        | *----------------+--------------+--------------*/\n```\n\n"
  },
  {
    "name": "ST_ISCLOSED",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ISCLOSED(geography_expression)\n```\n\n **Description** \n\nReturns`TRUE`for a non-empty Geography, where each element in the Geographyhas an empty boundary. The boundary for each element can be defined with[ST_BOUNDARY](#st_boundary).\n\n- A point is closed.\n- A linestring is closed if the start and end points of the linestring arethe same.\n- A polygon is closed only if it is a full polygon.\n- A collection is closed if and only if every element in the collection isclosed.\n\nAn empty`GEOGRAPHY`is not closed.\n\n **Return type** \n\n`BOOL`\n\n **Example** \n\n```\nWITH example AS(  SELECT ST_GEOGFROMTEXT('POINT(5 0)') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('LINESTRING(0 1, 4 3, 2 6, 0 1)') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('LINESTRING(2 6, 1 3, 3 9)') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('GEOMETRYCOLLECTION(POINT(0 0), LINESTRING(1 2, 2 1))') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('GEOMETRYCOLLECTION EMPTY'))SELECT  geography,  ST_ISCLOSED(geography) AS is_closed,FROM example;/*------------------------------------------------------+-----------* | geography                                            | is_closed | +------------------------------------------------------+-----------+ | POINT(5 0)                                           | TRUE      | | LINESTRING(0 1, 4 3, 2 6, 0 1)                       | TRUE      | | LINESTRING(2 6, 1 3, 3 9)                            | FALSE     | | GEOMETRYCOLLECTION(POINT(0 0), LINESTRING(1 2, 2 1)) | FALSE     | | GEOMETRYCOLLECTION EMPTY                             | FALSE     | *------------------------------------------------------+-----------*/\n```\n\n"
  },
  {
    "name": "ST_ISCOLLECTION",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ISCOLLECTION(geography_expression)\n```\n\n **Description** \n\nReturns`TRUE`if the total number of points, linestrings, and polygons isgreater than one.\n\nAn empty`GEOGRAPHY`is not a collection.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_ISEMPTY",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ISEMPTY(geography_expression)\n```\n\n **Description** \n\nReturns`TRUE`if the given`GEOGRAPHY`is empty; that is, the`GEOGRAPHY`doesnot contain any points, lines, or polygons.\n\nNOTE: An empty`GEOGRAPHY`is not associated with a particular geometry shape.For example, the results of expressions`ST_GEOGFROMTEXT('POINT EMPTY')`and`ST_GEOGFROMTEXT('GEOMETRYCOLLECTION EMPTY')`are identical.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_ISRING",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_ISRING(geography_expression)\n```\n\n **Description** \n\nReturns`TRUE`if the input`GEOGRAPHY`is a linestring and if thelinestring is both[ST_ISCLOSED](#st_isclosed)andsimple. A linestring is considered simple if it does not pass through thesame point twice (with the exception of the start and endpoint, which mayoverlap to form a ring).\n\nAn empty`GEOGRAPHY`is not a ring.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_LENGTH",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_LENGTH(geography_expression[, use_spheroid])\n```\n\n **Description** \n\nReturns the total length in meters of the lines in the input`GEOGRAPHY`.\n\nIf`geography_expression`is a point or a polygon, returns zero. If`geography_expression`is a collection, returns the length of the lines in thecollection; if the collection does not contain lines, returns zero.\n\nThe optional`use_spheroid`parameter determines how this function measuresdistance. If`use_spheroid`is`FALSE`, the function measures distance on thesurface of a perfect sphere.\n\nThe`use_spheroid`parameter currently only supportsthe value`FALSE`. The default value of`use_spheroid`is`FALSE`.\n\n **Return type** \n\n`FLOAT64`\n\n"
  },
  {
    "name": "ST_LINEINTERPOLATEPOINT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_LINEINTERPOLATEPOINT(linestring_geography, fraction)\n```\n\n **Description** \n\nGets a point at a specific fraction in a linestring`GEOGRAPHY`value.\n\n **Definitions** \n\n- `    linestring_geography`: A linestring`    GEOGRAPHY`on which the target pointis located.\n- `    fraction`: A`    FLOAT64`value that represents a fractionalong the linestring`    GEOGRAPHY`where the target point is located.This should be an inclusive value between`    0`(start of thelinestring) and`    1`(end of the linestring).\n\n **Details** \n\n- Returns`    NULL`if any input argument is`    NULL`.\n- Returns an empty geography if`    linestring_geography`is an empty geography.\n- Returns an error if`    linestring_geography`is not a linestring or an emptygeography, or if`    fraction`is outside the`    [0, 1]`range.\n\n **Return Type** \n\n`GEOGRAPHY`\n\n **Example** \n\nThe following query returns a few points on a linestring. Notice that the midpoint of the linestring`LINESTRING(1 1, 5 5)`is slightly different from`POINT(3 3)`because the`GEOGRAPHY`type uses geodesic line segments.\n\n```\nWITH fractions AS (    SELECT 0 AS fraction UNION ALL    SELECT 0.5 UNION ALL    SELECT 1 UNION ALL    SELECT NULL  )SELECT  fraction,  ST_LINEINTERPOLATEPOINT(ST_GEOGFROMTEXT('LINESTRING(1 1, 5 5)'), fraction)    AS pointFROM fractions/*-------------+-------------------------------------------* | fraction    | point                                     | +-------------+-------------------------------------------+ | 0           | POINT(1 1)                                | | 0.5         | POINT(2.99633827268976 3.00182528336078)  | | 1           | POINT(5 5)                                | | NULL        | NULL                                      | *-------------+-------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_LINELOCATEPOINT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_LINELOCATEPOINT(linestring_geography, point_geography)\n```\n\n **Description** \n\nGets a section of a linestring between the start point and a selected point (apoint on the linestring closest to the`point_geography`argument). Returns thepercentage that this section represents in the linestring.\n\nDetails:\n\n- To select a point on the linestring`    GEOGRAPHY`(`    linestring_geography`),this function takes a point`    GEOGRAPHY`(`    point_geography`) and finds the[closest point](#st_closestpoint)to it on the linestring.\n- If two points on`    linestring_geography`are an equal distance away from`    point_geography`, it is not guaranteed which one will be selected.\n- The return value is an inclusive value between 0 and 1 (0-100%).\n- If the selected point is the start point on the linestring, function returns0 (0%).\n- If the selected point is the end point on the linestring, function returns 1(100%).\n\n`NULL`and error handling:\n\n- Returns`    NULL`if any input argument is`    NULL`.\n- Returns an error if`    linestring_geography`is not a linestring or if`    point_geography`is not a point. Use the`    SAFE`prefixto obtain`    NULL`for invalid input instead of an error.\n\n **Return Type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nWITH geos AS (    SELECT ST_GEOGPOINT(0, 0) AS point UNION ALL    SELECT ST_GEOGPOINT(1, 0) UNION ALL    SELECT ST_GEOGPOINT(1, 1) UNION ALL    SELECT ST_GEOGPOINT(2, 2) UNION ALL    SELECT ST_GEOGPOINT(3, 3) UNION ALL    SELECT ST_GEOGPOINT(4, 4) UNION ALL    SELECT ST_GEOGPOINT(5, 5) UNION ALL    SELECT ST_GEOGPOINT(6, 5) UNION ALL    SELECT NULL  )SELECT  point AS input_point,  ST_LINELOCATEPOINT(ST_GEOGFROMTEXT('LINESTRING(1 1, 5 5)'), point)    AS percentage_from_beginningFROM geos/*-------------+---------------------------* | input_point | percentage_from_beginning | +-------------+---------------------------+ | POINT(0 0)  | 0                         | | POINT(1 0)  | 0                         | | POINT(1 1)  | 0                         | | POINT(2 2)  | 0.25015214685147907       | | POINT(3 3)  | 0.5002284283637185        | | POINT(4 4)  | 0.7501905913884388        | | POINT(5 5)  | 1                         | | POINT(6 5)  | 1                         | | NULL        | NULL                      | *-------------+---------------------------*/\n```\n\n"
  },
  {
    "name": "ST_LINESUBSTRING",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_LINESUBSTRING(linestring_geography, start_fraction, end_fraction);\n```\n\n **Description** \n\nGets a segment of a linestring at a specific starting and ending fraction.\n\n **Definitions** \n\n- `    linestring_geography`: The LineString`    GEOGRAPHY`value that represents thelinestring from which to extract a segment.\n- `    start_fraction`:`    FLOAT64`value that representsthe starting fraction of the total length of`    linestring_geography`.This must be an inclusive value between 0 and 1 (0-100%).\n- `    end_fraction`:`    FLOAT64`value that representsthe ending fraction of the total length of`    linestring_geography`.This must be an inclusive value between 0 and 1 (0-100%).\n\n **Details** \n\n`end_fraction`must be greater than or equal to`start_fraction`.\n\nIf`start_fraction`and`end_fraction`are equal, a linestring with onlyone point is produced.\n\n **Return type** \n\n- LineString`    GEOGRAPHY`if the resulting geography has more than one point.\n- Point`    GEOGRAPHY`if the resulting geography has only one point.\n\n **Example** \n\nThe following query returns the second half of the linestring:\n\n```\nWITH data AS (  SELECT ST_GEOGFROMTEXT('LINESTRING(20 70, 70 60, 10 70, 70 70)') AS geo1)SELECT ST_LINESUBSTRING(geo1, 0.5, 1) AS segmentFROM data;/*-------------------------------------------------------------+ | segment                                                     | +-------------------------------------------------------------+ | LINESTRING(49.4760661523471 67.2419539103851, 10 70, 70 70) | +-------------------------------------------------------------*/\n```\n\nThe following query returns a linestring that only contains one point:\n\n```\nWITH data AS (  SELECT ST_GEOGFROMTEXT('LINESTRING(20 70, 70 60, 10 70, 70 70)') AS geo1)SELECT ST_LINESUBSTRING(geo1, 0.5, 0.5) AS segmentFROM data;/*------------------------------------------+ | segment                                  | +------------------------------------------+ | POINT(49.4760661523471 67.2419539103851) | +------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_MAKELINE",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_MAKELINE(geography_1, geography_2)\n```\n\n```\nST_MAKELINE(array_of_geography)\n```\n\n **Description** \n\nCreates a`GEOGRAPHY`with a single linestring byconcatenating the point or line vertices of each of the input`GEOGRAPHY`s in the order they are given.\n\n`ST_MAKELINE`comes in two variants. For the first variant, input must be two`GEOGRAPHY`s. For the second, input must be an`ARRAY`of type`GEOGRAPHY`. Ineither variant, each input`GEOGRAPHY`must consist of one of the followingvalues:\n\n- Exactly one point.\n- Exactly one linestring.\n\nFor the first variant of`ST_MAKELINE`, if either input`GEOGRAPHY`is`NULL`,`ST_MAKELINE`returns`NULL`. For the second variant, if input`ARRAY`or anyelement in the input`ARRAY`is`NULL`,`ST_MAKELINE`returns`NULL`.\n\n **Constraints** \n\nEvery edge must span strictly less than 180 degrees.\n\nNOTE: The GoogleSQL snapping process may discard sufficiently shortedges and snap the two endpoints together. For instance, if two input`GEOGRAPHY`s each contain a point and the two points are separated by a distanceless than the snap radius, the points will be snapped together. In such a casethe result will be a`GEOGRAPHY`with exactly one point.\n\n **Return type** \n\nLineString`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_MAKEPOLYGON",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_MAKEPOLYGON(polygon_shell[, array_of_polygon_holes])\n```\n\n **Description** \n\nCreates a`GEOGRAPHY`containing a single polygonfrom linestring inputs, where each input linestring is used to construct apolygon ring.\n\n`ST_MAKEPOLYGON`comes in two variants. For the first variant, the inputlinestring is provided by a single`GEOGRAPHY`containing exactly onelinestring. For the second variant, the input consists of a single`GEOGRAPHY`and an array of`GEOGRAPHY`s, each containing exactly one linestring.\n\nThe first`GEOGRAPHY`in either variant is used to construct the polygon shell.Additional`GEOGRAPHY`s provided in the input`ARRAY`specify a polygon hole.For every input`GEOGRAPHY`containing exactly one linestring, the followingmust be true:\n\n- The linestring must consist of at least three distinct vertices.\n- The linestring must be closed: that is, the first and last vertex have to bethe same. If the first and last vertex differ, the function constructs afinal edge from the first vertex to the last.\n\nFor the first variant of`ST_MAKEPOLYGON`, if either input`GEOGRAPHY`is`NULL`,`ST_MAKEPOLYGON`returns`NULL`. For the second variant, ifinput`ARRAY`or any element in the`ARRAY`is`NULL`,`ST_MAKEPOLYGON`returns`NULL`.\n\nNOTE:`ST_MAKEPOLYGON`accepts an empty`GEOGRAPHY`as input.`ST_MAKEPOLYGON`interprets an empty`GEOGRAPHY`as having an empty linestring, which willcreate a full loop: that is, a polygon that covers the entire Earth.\n\n **Constraints** \n\nTogether, the input rings must form a valid polygon:\n\n- The polygon shell must cover each of the polygon holes.\n- There can be only one polygon shell (which has to be the first input ring).This implies that polygon holes cannot be nested.\n- Polygon rings may only intersect in a vertex on the boundary of both rings.\n\nEvery edge must span strictly less than 180 degrees.\n\nEach polygon ring divides the sphere into two regions. The first input linestingto`ST_MAKEPOLYGON`forms the polygon shell, and the interior is chosen to bethe smaller of the two regions. Each subsequent input linestring specifies apolygon hole, so the interior of the polygon is already well-defined. In orderto define a polygon shell such that the interior of the polygon is the larger ofthe two regions, see[ST_MAKEPOLYGONORIENTED](#st_makepolygonoriented).\n\nNOTE: The GoogleSQL snapping process may discard sufficientlyshort edges and snap the two endpoints together. Hence, when vertices aresnapped together, it is possible that a polygon hole that is sufficiently smallmay disappear, or the output`GEOGRAPHY`may contain only a line or apoint.\n\n **Return type** \n\n`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_MAKEPOLYGONORIENTED",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_MAKEPOLYGONORIENTED(array_of_geography)\n```\n\n **Description** \n\nLike`ST_MAKEPOLYGON`, but the vertex ordering of each input linestringdetermines the orientation of each polygon ring. The orientation of a polygonring defines the interior of the polygon as follows: if someone walks along theboundary of the polygon in the order of the input vertices, the interior of thepolygon is on the left. This applies for each polygon ring provided.\n\nThis variant of the polygon constructor is more flexible since`ST_MAKEPOLYGONORIENTED`can construct a polygon such that the interior is oneither side of the polygon ring. However, proper orientation of polygon rings iscritical in order to construct the desired polygon.\n\nIf the input`ARRAY`or any element in the`ARRAY`is`NULL`,`ST_MAKEPOLYGONORIENTED`returns`NULL`.\n\nNOTE: The input argument for`ST_MAKEPOLYGONORIENTED`may contain an empty`GEOGRAPHY`.`ST_MAKEPOLYGONORIENTED`interprets an empty`GEOGRAPHY`as havingan empty linestring, which will create a full loop: that is, a polygon thatcovers the entire Earth.\n\n **Constraints** \n\nTogether, the input rings must form a valid polygon:\n\n- The polygon shell must cover each of the polygon holes.\n- There must be only one polygon shell, which must to be the first input ring.This implies that polygon holes cannot be nested.\n- Polygon rings may only intersect in a vertex on the boundary of both rings.\n\nEvery edge must span strictly less than 180 degrees.\n\n`ST_MAKEPOLYGONORIENTED`relies on the ordering of the input vertices of eachlinestring to determine the orientation of the polygon. This applies to thepolygon shell and any polygon holes.`ST_MAKEPOLYGONORIENTED`expects allpolygon holes to have the opposite orientation of the shell. See[ST_MAKEPOLYGON](#st_makepolygon)for an alternate polygon constructor, andother constraints on building a valid polygon.\n\nNOTE: Due to the GoogleSQL snapping process, edges with a sufficientlyshort length will be discarded and the two endpoints will be snapped to a singlepoint. Therefore, it is possible that vertices in a linestring may be snappedtogether such that one or more edge disappears. Hence, it is possible that apolygon hole that is sufficiently small may disappear, or the resulting`GEOGRAPHY`may contain only a line or a point.\n\n **Return type** \n\n`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_MAXDISTANCE",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_MAXDISTANCE(geography_1, geography_2[, use_spheroid])\n```\n\nReturns the longest distance in meters between two non-empty`GEOGRAPHY`s; that is, the distance between twovertices where the first vertex is in the first`GEOGRAPHY`, and the second vertex is in the second`GEOGRAPHY`. If`geography_1`and`geography_2`are thesame`GEOGRAPHY`, the function returns the distancebetween the two most distant vertices in that`GEOGRAPHY`.\n\nIf either of the input`GEOGRAPHY`s is empty,`ST_MAXDISTANCE`returns`NULL`.\n\nThe optional`use_spheroid`parameter determines how this function measuresdistance. If`use_spheroid`is`FALSE`, the function measures distance on thesurface of a perfect sphere.\n\nThe`use_spheroid`parameter currently only supportsthe value`FALSE`. The default value of`use_spheroid`is`FALSE`.\n\n **Return type** \n\n`FLOAT64`\n\n"
  },
  {
    "name": "ST_NPOINTS",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_NPOINTS(geography_expression)\n```\n\n **Description** \n\nAn alias of[ST_NUMPOINTS](#st_numpoints).\n\n"
  },
  {
    "name": "ST_NUMGEOMETRIES",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_NUMGEOMETRIES(geography_expression)\n```\n\n **Description** \n\nReturns the number of geometries in the input`GEOGRAPHY`. For a single point,linestring, or polygon,`ST_NUMGEOMETRIES`returns`1`. For any collection ofgeometries,`ST_NUMGEOMETRIES`returns the number of geometries making up thecollection.`ST_NUMGEOMETRIES`returns`0`if the input is the empty`GEOGRAPHY`.\n\n **Return type** \n\n`INT64`\n\n **Example** \n\nThe following example computes`ST_NUMGEOMETRIES`for a single point geography,two collections, and an empty geography.\n\n```\nWITH example AS(  SELECT ST_GEOGFROMTEXT('POINT(5 0)') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('MULTIPOINT(0 1, 4 3, 2 6)') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('GEOMETRYCOLLECTION(POINT(0 0), LINESTRING(1 2, 2 1))') AS geography  UNION ALL  SELECT ST_GEOGFROMTEXT('GEOMETRYCOLLECTION EMPTY'))SELECT  geography,  ST_NUMGEOMETRIES(geography) AS num_geometries,FROM example;/*------------------------------------------------------+----------------* | geography                                            | num_geometries | +------------------------------------------------------+----------------+ | POINT(5 0)                                           | 1              | | MULTIPOINT(0 1, 4 3, 2 6)                            | 3              | | GEOMETRYCOLLECTION(POINT(0 0), LINESTRING(1 2, 2 1)) | 2              | | GEOMETRYCOLLECTION EMPTY                             | 0              | *------------------------------------------------------+----------------*/\n```\n\n"
  },
  {
    "name": "ST_NUMPOINTS",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_NUMPOINTS(geography_expression)\n```\n\n **Description** \n\nReturns the number of vertices in the input`GEOGRAPHY`. This includes the number of points, thenumber of linestring vertices, and the number of polygon vertices.\n\nNOTE: The first and last vertex of a polygon ring are counted as distinctvertices.\n\n **Return type** \n\n`INT64`\n\n"
  },
  {
    "name": "ST_PERIMETER",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_PERIMETER(geography_expression[, use_spheroid])\n```\n\n **Description** \n\nReturns the length in meters of the boundary of the polygons in the input`GEOGRAPHY`.\n\nIf`geography_expression`is a point or a line, returns zero. If`geography_expression`is a collection, returns the perimeter of the polygonsin the collection; if the collection does not contain polygons, returns zero.\n\nThe optional`use_spheroid`parameter determines how this function measuresdistance. If`use_spheroid`is`FALSE`, the function measures distance on thesurface of a perfect sphere.\n\nThe`use_spheroid`parameter currently only supportsthe value`FALSE`. The default value of`use_spheroid`is`FALSE`.\n\n **Return type** \n\n`FLOAT64`\n\n"
  },
  {
    "name": "ST_POINTN",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_POINTN(linestring_geography, index)\n```\n\n **Description** \n\nReturns the Nth point of a linestring geography as a point geography, where N isthe index. The index is 1-based. Negative values are counted backwards from theend of the linestring, so that -1 is the last point. Returns an error if theinput is not a linestring, if the input is empty, or if there is no vertex atthe given index. Use the`SAFE`prefix to obtain`NULL`for invalid inputinstead of an error.\n\n **Return Type** \n\nPoint`GEOGRAPHY`\n\n **Example** \n\nThe following example uses`ST_POINTN`,[ST_STARTPOINT](#st_startpoint)and[ST_ENDPOINT](#st_endpoint)to extract points from a linestring.\n\n```\nWITH linestring AS (    SELECT ST_GEOGFROMTEXT('LINESTRING(1 1, 2 1, 3 2, 3 3)') g)SELECT ST_POINTN(g, 1) AS first, ST_POINTN(g, -1) AS last,    ST_POINTN(g, 2) AS second, ST_POINTN(g, -2) AS second_to_lastFROM linestring;/*--------------+--------------+--------------+----------------* | first        | last         | second       | second_to_last | +--------------+--------------+--------------+----------------+ | POINT(1 1)   | POINT(3 3)   | POINT(2 1)   | POINT(3 2)     | *--------------+--------------+--------------+----------------*/\n```\n\n"
  },
  {
    "name": "ST_SIMPLIFY",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_SIMPLIFY(geography, tolerance_meters)\n```\n\n **Description** \n\nReturns a simplified version of`geography`, the given input`GEOGRAPHY`. The input`GEOGRAPHY`is simplified by replacing nearly straightchains of short edges with a single long edge. The input`geography`will notchange by more than the tolerance specified by`tolerance_meters`. Thus,simplified edges are guaranteed to pass within`tolerance_meters`of the *original* positions of all vertices that were removed from that edge. The given`tolerance_meters`is in meters on the surface of the Earth.\n\nNote that`ST_SIMPLIFY`preserves topological relationships, which means thatno new crossing edges will be created and the output will be valid. For a largeenough tolerance, adjacent shapes may collapse into a single object, or a shapecould be simplified to a shape with a smaller dimension.\n\n **Constraints** \n\nFor`ST_SIMPLIFY`to have any effect,`tolerance_meters`must be non-zero.\n\n`ST_SIMPLIFY`returns an error if the tolerance specified by`tolerance_meters`is one of the following:\n\n- A negative tolerance.\n- Greater than ~7800 kilometers.\n\n **Return type** \n\n`GEOGRAPHY`\n\n **Examples** \n\nThe following example shows how`ST_SIMPLIFY`simplifies the input line`GEOGRAPHY`by removing intermediate vertices.\n\n```\nWITH example AS (SELECT ST_GEOGFROMTEXT('LINESTRING(0 0, 0.05 0, 0.1 0, 0.15 0, 2 0)') AS line)SELECT   line AS original_line,   ST_SIMPLIFY(line, 1) AS simplified_lineFROM example;/*---------------------------------------------+----------------------* |                original_line                |   simplified_line    | +---------------------------------------------+----------------------+ | LINESTRING(0 0, 0.05 0, 0.1 0, 0.15 0, 2 0) | LINESTRING(0 0, 2 0) | *---------------------------------------------+----------------------*/\n```\n\nThe following example illustrates how the result of`ST_SIMPLIFY`can have alower dimension than the original shape.\n\n```\nWITH example AS (SELECT    ST_GEOGFROMTEXT('POLYGON((0 0, 0.1 0, 0.1 0.1, 0 0))') AS polygon,    t AS tolerance  FROM UNNEST([1000, 10000, 100000]) AS t)SELECT  polygon AS original_triangle,  tolerance AS tolerance_meters,  ST_SIMPLIFY(polygon, tolerance) AS simplified_resultFROM example/*-------------------------------------+------------------+-------------------------------------* |          original_triangle          | tolerance_meters |          simplified_result          | +-------------------------------------+------------------+-------------------------------------+ | POLYGON((0 0, 0.1 0, 0.1 0.1, 0 0)) |             1000 | POLYGON((0 0, 0.1 0, 0.1 0.1, 0 0)) | | POLYGON((0 0, 0.1 0, 0.1 0.1, 0 0)) |            10000 |            LINESTRING(0 0, 0.1 0.1) | | POLYGON((0 0, 0.1 0, 0.1 0.1, 0 0)) |           100000 |                          POINT(0 0) | *-------------------------------------+------------------+-------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_SNAPTOGRID",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_SNAPTOGRID(geography_expression, grid_size)\n```\n\n **Description** \n\nReturns the input`GEOGRAPHY`, where each vertex hasbeen snapped to a longitude/latitude grid. The grid size is determined by the`grid_size`parameter which is given in degrees.\n\n **Constraints** \n\nArbitrary grid sizes are not supported. The`grid_size`parameter is rounded sothat it is of the form`10^n`, where`-10 &lt; n &lt; 0`.\n\n **Return type** \n\n`GEOGRAPHY`\n\n"
  },
  {
    "name": "ST_STARTPOINT",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_STARTPOINT(linestring_geography)\n```\n\n **Description** \n\nReturns the first point of a linestring geography as a point geography. Returnsan error if the input is not a linestring or if the input is empty. Use the`SAFE`prefix to obtain`NULL`for invalid input instead of an error.\n\n **Return Type** \n\nPoint`GEOGRAPHY`\n\n **Example** \n\n```\nSELECT ST_STARTPOINT(ST_GEOGFROMTEXT('LINESTRING(1 1, 2 1, 3 2, 3 3)')) first/*--------------* | first        | +--------------+ | POINT(1 1)   | *--------------*/\n```\n\n"
  },
  {
    "name": "ST_TOUCHES",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_TOUCHES(geography_1, geography_2)\n```\n\n **Description** \n\nReturns`TRUE`provided the following two conditions are satisfied:\n\n1. `    geography_1`intersects`    geography_2`.\n1. The interior of`    geography_1`and the interior of`    geography_2`aredisjoint.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_UNION",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_UNION(geography_1, geography_2)\n```\n\n```\nST_UNION(array_of_geography)\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`that represents the point setunion of all input`GEOGRAPHY`s.\n\n`ST_UNION`comes in two variants. For the first variant, input must be two`GEOGRAPHY`s. For the second, the input is an`ARRAY`of type`GEOGRAPHY`.\n\nFor the first variant of`ST_UNION`, if an input`GEOGRAPHY`is`NULL`,`ST_UNION`returns`NULL`.For the second variant, if the input`ARRAY`valueis`NULL`,`ST_UNION`returns`NULL`.For a non-`NULL`input`ARRAY`, the union is computedand`NULL`elements are ignored so that they do not affect the output.\n\nSee[ST_UNION_AGG](#st_union_agg)for the aggregate version of`ST_UNION`.\n\n **Return type** \n\n`GEOGRAPHY`\n\n **Example** \n\n```\nSELECT ST_UNION(  ST_GEOGFROMTEXT('LINESTRING(-122.12 47.67, -122.19 47.69)'),  ST_GEOGFROMTEXT('LINESTRING(-122.12 47.67, -100.19 47.69)')) AS results/*---------------------------------------------------------* | results                                                 | +---------------------------------------------------------+ | LINESTRING(-100.19 47.69, -122.12 47.67, -122.19 47.69) | *---------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_UNION_AGG",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_UNION_AGG(geography)\n```\n\n **Description** \n\nReturns a`GEOGRAPHY`that represents the point setunion of all input`GEOGRAPHY`s.\n\n`ST_UNION_AGG`ignores`NULL`input`GEOGRAPHY`values.\n\nSee[ST_UNION](#st_union)for the non-aggregate version of`ST_UNION_AGG`.\n\n **Return type** \n\n`GEOGRAPHY`\n\n **Example** \n\n```\nSELECT ST_UNION_AGG(items) AS resultsFROM UNNEST([  ST_GEOGFROMTEXT('LINESTRING(-122.12 47.67, -122.19 47.69)'),  ST_GEOGFROMTEXT('LINESTRING(-122.12 47.67, -100.19 47.69)'),  ST_GEOGFROMTEXT('LINESTRING(-122.12 47.67, -122.19 47.69)')]) as items;/*---------------------------------------------------------* | results                                                 | +---------------------------------------------------------+ | LINESTRING(-100.19 47.69, -122.12 47.67, -122.19 47.69) | *---------------------------------------------------------*/\n```\n\n"
  },
  {
    "name": "ST_WITHIN",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_WITHIN(geography_1, geography_2)\n```\n\n **Description** \n\nReturns`TRUE`if no point of`geography_1`is outside of`geography_2`andthe interiors of`geography_1`and`geography_2`intersect.\n\nGiven two geographies`a`and`b`,`ST_WITHIN(a, b)`returns the same resultas[ST_CONTAINS](#st_contains)`(b, a)`. Note the opposite order of arguments.\n\n **Return type** \n\n`BOOL`\n\n"
  },
  {
    "name": "ST_X",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_X(point_geography_expression)\n```\n\n **Description** \n\nReturns the longitude in degrees of the single-point input`GEOGRAPHY`.\n\nFor any input`GEOGRAPHY`that is not a single point,including an empty`GEOGRAPHY`,`ST_X`returns anerror. Use the`SAFE.`prefix to obtain`NULL`.\n\n **Return type** \n\n`FLOAT64`\n\n **Example** \n\nThe following example uses`ST_X`and`ST_Y`to extract coordinates fromsingle-point geographies.\n\n```\nWITH points AS   (SELECT ST_GEOGPOINT(i, i + 1) AS p FROM UNNEST([0, 5, 12]) AS i) SELECT   p,   ST_X(p) as longitude,   ST_Y(p) as latitudeFROM points;/*--------------+-----------+----------* | p            | longitude | latitude | +--------------+-----------+----------+ | POINT(0 1)   | 0.0       | 1.0      | | POINT(5 6)   | 5.0       | 6.0      | | POINT(12 13) | 12.0      | 13.0     | *--------------+-----------+----------*/\n```\n\n"
  },
  {
    "name": "ST_Y",
    "arguments": [],
    "category": "Geography functions",
    "description": "```\nST_Y(point_geography_expression)\n```\n\n **Description** \n\nReturns the latitude in degrees of the single-point input`GEOGRAPHY`.\n\nFor any input`GEOGRAPHY`that is not a single point,including an empty`GEOGRAPHY`,`ST_Y`returns anerror. Use the`SAFE.`prefix to return`NULL`instead.\n\n **Return type** \n\n`FLOAT64`\n\n **Example** \n\nSee[ST_X](#st_x)for example usage.\n\n\n<span id=\"hash_functions\">\n## Hash functions\n\n</span>\nGoogleSQL for BigQuery supports the following hash functions.\n\n"
  },
  {
    "name": "SUBSTR",
    "arguments": [],
    "category": "String functions",
    "description": "```\nSUBSTR(value, position[, length])\n```\n\n **Description** \n\nGets a portion (substring) of the supplied`STRING`or`BYTES`value.\n\nThe`position`argument is an integer specifying the starting position of thesubstring.\n\n- If`    position`is`    1`, the substring starts from the first character or byte.\n- If`    position`is`    0`or less than`    -LENGTH(value)`,`    position`is set to`    1`,and the substring starts from the first character or byte.\n- If`    position`is greater than the length of`    value`, the function producesan empty substring.\n- If`    position`is negative, the function counts from the end of`    value`,with`    -1`indicating the last character or byte.\n\nThe`length`argument specifies the maximum number of characters or bytes toreturn.\n\n- If`    length`is not specified, the function produces a substring that startsat the specified position and ends at the last character or byte of`    value`.\n- If`    length`is`    0`, the function produces an empty substring.\n- If`    length`is negative, the function produces an error.\n- The returned substring may be shorter than`    length`, for example, when`    length`exceeds the length of`    value`, or when the starting position of thesubstring plus`    length`is greater than the length of`    value`.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH items AS  (SELECT 'apple' as item  UNION ALL  SELECT 'banana' as item  UNION ALL  SELECT 'orange' as item)SELECT  SUBSTR(item, 2) as exampleFROM items;/*---------* | example | +---------+ | pple    | | anana   | | range   | *---------*/\n```\n\n```\nWITH items AS  (SELECT 'apple' as item  UNION ALL  SELECT 'banana' as item  UNION ALL  SELECT 'orange' as item)SELECT  SUBSTR(item, 2, 2) as exampleFROM items;/*---------* | example | +---------+ | pp      | | an      | | ra      | *---------*/\n```\n\n```\nWITH items AS  (SELECT 'apple' as item  UNION ALL  SELECT 'banana' as item  UNION ALL  SELECT 'orange' as item)SELECT  SUBSTR(item, -2) as exampleFROM items;/*---------* | example | +---------+ | le      | | na      | | ge      | *---------*/\n```\n\n```\nWITH items AS  (SELECT 'apple' as item  UNION ALL  SELECT 'banana' as item  UNION ALL  SELECT 'orange' as item)SELECT  SUBSTR(item, 1, 123) as exampleFROM items;/*---------* | example | +---------+ | apple   | | banana  | | orange  | *---------*/\n```\n\n```\nWITH items AS  (SELECT 'apple' as item  UNION ALL  SELECT 'banana' as item  UNION ALL  SELECT 'orange' as item)SELECT  SUBSTR(item, 123) as exampleFROM items;/*---------* | example | +---------+ |         | |         | |         | *---------*/\n```\n\n```\nWITH items AS  (SELECT 'apple' as item  UNION ALL  SELECT 'banana' as item  UNION ALL  SELECT 'orange' as item)SELECT  SUBSTR(item, 123, 5) as exampleFROM items;/*---------* | example | +---------+ |         | |         | |         | *---------*/\n```\n\n"
  },
  {
    "name": "SUBSTRING",
    "arguments": [],
    "category": "String functions",
    "description": "```\nSUBSTRING(value, position[, length])\n```\n\nAlias for[SUBSTR](#substr).\n\n"
  },
  {
    "name": "SUM",
    "arguments": [],
    "category": "Aggregate functions",
    "description": "```\nSUM(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the sum of non-`NULL`values in an aggregated group.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nTo learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n`SUM`can be used with differential privacy. For more information, see[Differentially private aggregate functions](#aggregate-dp-functions).\n\nCaveats:\n\n- If the aggregated group is empty or the argument is`    NULL`for all rows inthe group, returns`    NULL`.\n- If the argument is`    NaN`for any row in the group, returns`    NaN`.\n- If the argument is`    [+|-]Infinity`for any row in the group, returns either`    [+|-]Infinity`or`    NaN`.\n- If there is numeric overflow, produces an error.\n- If a[floating-point type](/bigquery/docs/reference/standard-sql/data-types#floating_point_types)is returned, the result is[non-deterministic](/bigquery/docs/reference/standard-sql/data-types#floating-point-semantics), which means you might receive adifferent result each time you use this function.\n\n **Supported Argument Types** \n\n- Any supported numeric data type\n- `    INTERVAL`\n\n **Return Data Types** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` | `INTERVAL` |\n| --- | --- | --- | --- | --- | --- |\n| OUTPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` | `INTERVAL` |\n\n **Examples** \n\n```\nSELECT SUM(x) AS sumFROM UNNEST([1, 2, 3, 4, 5, 4, 3, 2, 1]) AS x;/*-----* | sum | +-----+ | 25  | *-----*/\n```\n\n```\nSELECT SUM(DISTINCT x) AS sumFROM UNNEST([1, 2, 3, 4, 5, 4, 3, 2, 1]) AS x;/*-----* | sum | +-----+ | 15  | *-----*/\n```\n\n```\nSELECT  x,  SUM(x) OVER (PARTITION BY MOD(x, 3)) AS sumFROM UNNEST([1, 2, 3, 4, 5, 4, 3, 2, 1]) AS x;/*---+-----* | x | sum | +---+-----+ | 3 | 6   | | 3 | 6   | | 1 | 10  | | 4 | 10  | | 4 | 10  | | 1 | 10  | | 2 | 9   | | 5 | 9   | | 2 | 9   | *---+-----*/\n```\n\n```\nSELECT  x,  SUM(DISTINCT x) OVER (PARTITION BY MOD(x, 3)) AS sumFROM UNNEST([1, 2, 3, 4, 5, 4, 3, 2, 1]) AS x;/*---+-----* | x | sum | +---+-----+ | 3 | 3   | | 3 | 3   | | 1 | 5   | | 4 | 5   | | 4 | 5   | | 1 | 5   | | 2 | 7   | | 5 | 7   | | 2 | 7   | *---+-----*/\n```\n\n```\nSELECT SUM(x) AS sumFROM UNNEST([]) AS x;/*------* | sum  | +------+ | NULL | *------*/\n```\n\n\n<span id=\"approximate_aggregate_functions\">\n## Approximate aggregate functions\n\n</span>\nGoogleSQL for BigQuery supports approximate aggregate functions.To learn about the syntax for aggregate function calls, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nApproximate aggregate functions are scalable in terms of memory usage and time,but produce approximate results instead of exact results. These functionstypically require less memory than[exact aggregation functions](#aggregate_functions)like`COUNT(DISTINCT ...)`, but also introduce statistical uncertainty.This makes approximate aggregation appropriate for large data streams forwhich linear memory usage is impractical, as well as for data that isalready approximate.\n\nThe approximate aggregate functions in this section work directly on theinput data, rather than an intermediate estimation of the data. These functions *do not allow* users to specify the precision for the estimation withsketches. If you would like to specify precision with sketches, see:\n\n- [HyperLogLog++ functions](#hyperloglog_functions)to estimate cardinality.\n\n"
  },
  {
    "name": "SUM (DIFFERENTIAL_PRIVACY)",
    "arguments": [],
    "category": "Differentially private aggregate functions",
    "description": "```\nWITH DIFFERENTIAL_PRIVACY ...  SUM(    expression,    [contribution_bounds_per_group =&gt; (lower_bound, upper_bound)]  )\n```\n\n **Description** \n\nReturns the sum of non-`NULL`, non-`NaN`values in the expression. The finalresult is an aggregation across privacy unit columns.\n\nThis function must be used with the[DIFFERENTIAL_PRIVACY clause](/bigquery/docs/reference/standard-sql/query-syntax#dp_clause)and can support these arguments:\n\n- `    expression`: The input expression. This can be any numeric input type,such as`    INT64`.`    NULL`values are always ignored.\n- `    contribution_bounds_per_group`: The[contribution bounds named argument](#dp_clamped_named).Perform clamping per each group separately before performing intermediategrouping on the privacy unit column.\n\n **Return type** \n\nOne of the following[supertypes](/bigquery/docs/reference/standard-sql/conversion_rules#supertypes):\n\n- `    INT64`\n- `    FLOAT64`\n\n **Examples** \n\nThe following differentially private query gets the sum of items requested.Smaller aggregations might not be included. This query references a view called[professors](/bigquery/docs/reference/standard-sql/query-syntax#dp_example_tables).\n\n```\n-- With noise, using the epsilon parameter.SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=10, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    SUM(quantity, contribution_bounds_per_group =&gt; (0,100)) quantityFROM professorsGROUP BY item;-- These results will change each time you run the query.-- Smaller aggregations might be removed./*----------+-----------* | item     | quantity  | +----------+-----------+ | pencil   | 143       | | pen      | 59        | *----------+-----------*/\n```\n\n```\n-- Without noise, using the epsilon parameter.-- (this un-noised version is for demonstration only)SELECT  WITH DIFFERENTIAL_PRIVACY    OPTIONS(epsilon=1e20, delta=.01, max_groups_contributed=1, privacy_unit_column=id)    item,    SUM(quantity) quantityFROM professorsGROUP BY item;-- These results will not change when you run the query./*----------+----------* | item     | quantity | +----------+----------+ | scissors | 8        | | pencil   | 144      | | pen      | 58       | *----------+----------*/\n```\n\n **Note:** For more information about when and when not to usenoise, see[Use differential privacy](/bigquery/docs/reference/standard-sql/query-syntax#eliminate_noise)."
  },
  {
    "name": "TAN",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nTAN(X)\n```\n\n **Description** \n\nComputes the tangent of X where X is specified in radians. Generates an error ifoverflow occurs.\n\n| X | TAN(X) |\n| --- | --- |\n| `+inf` | `NaN` |\n| `-inf` | `NaN` |\n| `NaN` | `NaN` |\n\n"
  },
  {
    "name": "TANH",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nTANH(X)\n```\n\n **Description** \n\nComputes the hyperbolic tangent of X where X is specified in radians. Does notfail.\n\n| X | TANH(X) |\n| --- | --- |\n| `+inf` | 1.0 |\n| `-inf` | -1.0 |\n| `NaN` | `NaN` |\n\n"
  },
  {
    "name": "TIME",
    "arguments": [],
    "category": "Time functions",
    "description": "```\n1. TIME(hour, minute, second)2. TIME(timestamp, [time_zone])3. TIME(datetime)\n```\n\n **Description** \n\n1. Constructs a`    TIME`object using`    INT64`values representing the hour, minute, and second.\n1. Constructs a`    TIME`object using a`    TIMESTAMP`object. It supports anoptionalparameter to[specify a time zone](#timezone_definitions). If notime zone is specified, the default time zone, UTC, isused.\n1. Constructs a`    TIME`object using a`    DATETIME`object.\n\n **Return Data Type** \n\n`TIME`\n\n **Example** \n\n```\nSELECT  TIME(15, 30, 00) as time_hms,  TIME(TIMESTAMP \"2008-12-25 15:30:00+08\", \"America/Los_Angeles\") as time_tstz;/*----------+-----------* | time_hms | time_tstz | +----------+-----------+ | 15:30:00 | 23:30:00  | *----------+-----------*/\n```\n\n```\nSELECT TIME(DATETIME \"2008-12-25 15:30:00.000000\") AS time_dt;/*----------* | time_dt  | +----------+ | 15:30:00 | *----------*/\n```\n\n"
  },
  {
    "name": "TIMESTAMP",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nTIMESTAMP(string_expression[, time_zone])TIMESTAMP(date_expression[, time_zone])TIMESTAMP(datetime_expression[, time_zone])\n```\n\n **Description** \n\n- `    string_expression[, time_zone]`: Converts a string to atimestamp.`    string_expression`must include atimestamp literal.If`    string_expression`includes a time zone in the timestamp literal, donot include an explicit`    time_zone`argument.\n- `    date_expression[, time_zone]`: Converts a date to a timestamp.The value returned is the earliest timestamp that falls withinthe given date.\n- `    datetime_expression[, time_zone]`: Converts adatetime to a timestamp.\n\nThis function supports an optionalparameter to[specify a time zone](#timezone_definitions). Ifno time zone is specified, the default time zone, UTC,is used.\n\n **Return Data Type** \n\n`TIMESTAMP`\n\n **Examples** \n\n```\nSELECT TIMESTAMP(\"2008-12-25 15:30:00+00\") AS timestamp_str;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | timestamp_str           | +-------------------------+ | 2008-12-25 15:30:00 UTC | *-------------------------*/\n```\n\n```\nSELECT TIMESTAMP(\"2008-12-25 15:30:00\", \"America/Los_Angeles\") AS timestamp_str;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | timestamp_str           | +-------------------------+ | 2008-12-25 23:30:00 UTC | *-------------------------*/\n```\n\n```\nSELECT TIMESTAMP(\"2008-12-25 15:30:00 UTC\") AS timestamp_str;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | timestamp_str           | +-------------------------+ | 2008-12-25 15:30:00 UTC | *-------------------------*/\n```\n\n```\nSELECT TIMESTAMP(DATETIME \"2008-12-25 15:30:00\") AS timestamp_datetime;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | timestamp_datetime      | +-------------------------+ | 2008-12-25 15:30:00 UTC | *-------------------------*/\n```\n\n```\nSELECT TIMESTAMP(DATE \"2008-12-25\") AS timestamp_date;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | timestamp_date          | +-------------------------+ | 2008-12-25 00:00:00 UTC | *-------------------------*/\n```\n\n"
  },
  {
    "name": "TIMESTAMP_ADD",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nTIMESTAMP_ADD(timestamp_expression, INTERVAL int64_expression date_part)\n```\n\n **Description** \n\nAdds`int64_expression`units of`date_part`to the timestamp, independent ofany time zone.\n\n`TIMESTAMP_ADD`supports the following values for`date_part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`. Equivalent to 60`    MINUTE`parts.\n- `    DAY`. Equivalent to 24`    HOUR`parts.\n\n **Return Data Types** \n\n`TIMESTAMP`\n\n **Example** \n\n```\nSELECT  TIMESTAMP(\"2008-12-25 15:30:00+00\") AS original,  TIMESTAMP_ADD(TIMESTAMP \"2008-12-25 15:30:00+00\", INTERVAL 10 MINUTE) AS later;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------+-------------------------* | original                | later                   | +-------------------------+-------------------------+ | 2008-12-25 15:30:00 UTC | 2008-12-25 15:40:00 UTC | *-------------------------+-------------------------*/\n```\n\n"
  },
  {
    "name": "TIMESTAMP_BUCKET",
    "arguments": [],
    "category": "Time series functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\n **Note:** To request feedback or support for this feature, send an email to[bigquery-time-series-preview-support@google.com](mailto:bigquery-time-series-preview-support@google.com).```\nTIMESTAMP_BUCKET(timestamp_in_bucket, bucket_width)\n```\n\n```\nTIMESTAMP_BUCKET(timestamp_in_bucket, bucket_width, bucket_origin_timestamp)\n```\n\n **Description** \n\nGets the lower bound of the timestamp bucket that contains a timestamp.\n\n **Definitions** \n\n- `    timestamp_in_bucket`: A`    TIMESTAMP`value that you can use to look up atimestamp bucket.\n- `    bucket_width`: An`    INTERVAL`value that represents the width ofa timestamp bucket. A[single interval](/bigquery/docs/reference/standard-sql/data-types#single_datetime_part_interval)with[date and time parts](/bigquery/docs/reference/standard-sql/data-types#interval_datetime_parts)is supported.\n- `    bucket_origin_timestamp`: A`    TIMESTAMP`value that represents a point intime. All buckets expand left and right from this point. If this argumentis not set,`    1950-01-01 00:00:00`is used by default.\n\n **Return type** \n\n`TIMESTAMP`\n\n **Examples** \n\nIn the following example, the origin is omitted and the default origin,`1950-01-01 00:00:00`is used. All buckets expand in both directions from theorigin, and the size of each bucket is 12 hours. The lower bound of the bucketin which`my_timestamp`belongs is returned:\n\n```\nWITH some_timestamps AS (  SELECT TIMESTAMP '1949-12-30 13:00:00.00' AS my_timestamp UNION ALL  SELECT TIMESTAMP '1949-12-31 00:00:00.00' UNION ALL  SELECT TIMESTAMP '1949-12-31 13:00:00.00' UNION ALL  SELECT TIMESTAMP '1950-01-01 00:00:00.00' UNION ALL  SELECT TIMESTAMP '1950-01-01 13:00:00.00' UNION ALL  SELECT TIMESTAMP '1950-01-02 00:00:00.00')SELECT TIMESTAMP_BUCKET(my_timestamp, INTERVAL 12 HOUR) AS bucket_lower_boundFROM some_timestamps;-- Display of results may differ, depending upon the environment and-- time zone where this query was executed. /*------------------------+ | bucket_lower_bound      | +-------------------------+ | 2000-12-30 12:00:00 UTC | | 2000-12-31 00:00:00 UTC | | 2000-12-31 12:00:00 UTC | | 2000-01-01 00:00:00 UTC | | 2000-01-01 12:00:00 UTC | | 2000-01-01 00:00:00 UTC | +-------------------------*/-- Some timestamp buckets that originate from 1950-01-01 00:00:00:-- + Bucket: ...-- + Bucket: [1949-12-30 00:00:00.00 UTC, 1949-12-30 12:00:00.00 UTC)-- + Bucket: [1949-12-30 12:00:00.00 UTC, 1950-01-01 00:00:00.00 UTC)-- + Origin: [1950-01-01 00:00:00.00 UTC]-- + Bucket: [1950-01-01 00:00:00.00 UTC, 1950-01-01 12:00:00.00 UTC)-- + Bucket: [1950-01-01 12:00:00.00 UTC, 1950-02-00 00:00:00.00 UTC)-- + Bucket: ...\n```\n\nIn the following example, the origin has been changed to`2000-12-24 12:00:00`,and all buckets expand in both directions from this point. The size of eachbucket is seven days. The lower bound of the bucket in which`my_timestamp`belongs is returned:\n\n```\nWITH some_timestamps AS (  SELECT TIMESTAMP '2000-12-20 00:00:00.00' AS my_timestamp UNION ALL  SELECT TIMESTAMP '2000-12-21 00:00:00.00' UNION ALL  SELECT TIMESTAMP '2000-12-22 00:00:00.00' UNION ALL  SELECT TIMESTAMP '2000-12-23 00:00:00.00' UNION ALL  SELECT TIMESTAMP '2000-12-24 00:00:00.00' UNION ALL  SELECT TIMESTAMP '2000-12-25 00:00:00.00')SELECT TIMESTAMP_BUCKET(  my_timestamp,  INTERVAL 7 DAY,  TIMESTAMP '2000-12-22 12:00:00.00') AS bucket_lower_boundFROM some_timestamps;-- Display of results may differ, depending upon the environment and-- time zone where this query was executed. /*------------------------+ | bucket_lower_bound      | +-------------------------+ | 2000-12-15 12:00:00 UTC | | 2000-12-15 12:00:00 UTC | | 2000-12-15 12:00:00 UTC | | 2000-12-22 12:00:00 UTC | | 2000-12-22 12:00:00 UTC | | 2000-12-22 12:00:00 UTC | +-------------------------*/-- Some timestamp buckets that originate from 2000-12-22 12:00:00:-- + Bucket: ...-- + Bucket: [2000-12-08 12:00:00.00 UTC, 2000-12-15 12:00:00.00 UTC)-- + Bucket: [2000-12-15 12:00:00.00 UTC, 2000-12-22 12:00:00.00 UTC)-- + Origin: [2000-12-22 12:00:00.00 UTC]-- + Bucket: [2000-12-22 12:00:00.00 UTC, 2000-12-29 12:00:00.00 UTC)-- + Bucket: [2000-12-29 12:00:00.00 UTC, 2000-01-05 12:00:00.00 UTC)-- + Bucket: ...\n```\n\n\n<span id=\"timestamp_functions\">\n## Timestamp functions\n\n</span>\nGoogleSQL for BigQuery supports the following timestamp functions.\n\nIMPORTANT: Before working with these functions, you need to understandthe difference between the formats in which timestamps are stored and displayed,and how time zones are used for the conversion between these formats.To learn more, see[How time zones work with timestamp functions](#timezone_definitions).\n\nNOTE: These functions return a runtime error if overflow occurs; resultvalues are bounded by the defined[DATE range](/bigquery/docs/reference/standard-sql/data-types#date_type)and[TIMESTAMP range](/bigquery/docs/reference/standard-sql/data-types#timestamp_type).\n\n"
  },
  {
    "name": "TIMESTAMP_DIFF",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nTIMESTAMP_DIFF(timestamp_expression_a, timestamp_expression_b, date_part)\n```\n\n **Description** \n\nReturns the whole number of specified`date_part`intervals between twotimestamps (`timestamp_expression_a`-`timestamp_expression_b`).If the first timestamp is earlier than the second one,the output is negative. Produces an error if the computation overflows theresult type, such as if the difference inmicrosecondsbetween the two timestamps would overflow an`INT64`value.\n\n`TIMESTAMP_DIFF`supports the following values for`date_part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`. Equivalent to 60`    MINUTE`s.\n- `    DAY`. Equivalent to 24`    HOUR`s.\n\n **Note:** The behavior of the this function follows the type of arguments passed in.For example,`TIMESTAMP_DIFF(DATE, DATE, PART)`behaves like`DATE_DIFF(DATE, DATE, PART)`. **Return Data Type** \n\n`INT64`\n\n **Example** \n\n```\nSELECT  TIMESTAMP(\"2010-07-07 10:20:00+00\") AS later_timestamp,  TIMESTAMP(\"2008-12-25 15:30:00+00\") AS earlier_timestamp,  TIMESTAMP_DIFF(TIMESTAMP \"2010-07-07 10:20:00+00\", TIMESTAMP \"2008-12-25 15:30:00+00\", HOUR) AS hours;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------+-------------------------+-------* | later_timestamp         | earlier_timestamp       | hours | +-------------------------+-------------------------+-------+ | 2010-07-07 10:20:00 UTC | 2008-12-25 15:30:00 UTC | 13410 | *-------------------------+-------------------------+-------*/\n```\n\nIn the following example, the first timestamp occurs before thesecond timestamp, resulting in a negative output.\n\n```\nSELECT TIMESTAMP_DIFF(TIMESTAMP \"2018-08-14\", TIMESTAMP \"2018-10-14\", DAY) AS negative_diff;/*---------------* | negative_diff | +---------------+ | -61           | *---------------+\n```\n\nIn this example, the result is 0 because only the number of whole specified`HOUR`intervals are included.\n\n```\nSELECT TIMESTAMP_DIFF(\"2001-02-01 01:00:00\", \"2001-02-01 00:00:01\", HOUR) AS diff;/*---------------* | diff          | +---------------+ | 0             | *---------------+\n```\n\n"
  },
  {
    "name": "TIMESTAMP_MICROS",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nTIMESTAMP_MICROS(int64_expression)\n```\n\n **Description** \n\nInterprets`int64_expression`as the number of microseconds since 1970-01-0100:00:00 UTC and returns a timestamp.\n\n **Return Data Type** \n\n`TIMESTAMP`\n\n **Example** \n\n```\nSELECT TIMESTAMP_MICROS(1230219000000000) AS timestamp_value;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | timestamp_value         | +-------------------------+ | 2008-12-25 15:30:00 UTC | *-------------------------*/\n```\n\n"
  },
  {
    "name": "TIMESTAMP_MILLIS",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nTIMESTAMP_MILLIS(int64_expression)\n```\n\n **Description** \n\nInterprets`int64_expression`as the number of milliseconds since 1970-01-0100:00:00 UTC and returns a timestamp.\n\n **Return Data Type** \n\n`TIMESTAMP`\n\n **Example** \n\n```\nSELECT TIMESTAMP_MILLIS(1230219000000) AS timestamp_value;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | timestamp_value         | +-------------------------+ | 2008-12-25 15:30:00 UTC | *-------------------------*/\n```\n\n"
  },
  {
    "name": "TIMESTAMP_SECONDS",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nTIMESTAMP_SECONDS(int64_expression)\n```\n\n **Description** \n\nInterprets`int64_expression`as the number of seconds since 1970-01-01 00:00:00UTC and returns a timestamp.\n\n **Return Data Type** \n\n`TIMESTAMP`\n\n **Example** \n\n```\nSELECT TIMESTAMP_SECONDS(1230219000) AS timestamp_value;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------* | timestamp_value         | +-------------------------+ | 2008-12-25 15:30:00 UTC | *-------------------------*/\n```\n\n"
  },
  {
    "name": "TIMESTAMP_SUB",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nTIMESTAMP_SUB(timestamp_expression, INTERVAL int64_expression date_part)\n```\n\n **Description** \n\nSubtracts`int64_expression`units of`date_part`from the timestamp,independent of any time zone.\n\n`TIMESTAMP_SUB`supports the following values for`date_part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`. Equivalent to 60`    MINUTE`parts.\n- `    DAY`. Equivalent to 24`    HOUR`parts.\n\n **Return Data Type** \n\n`TIMESTAMP`\n\n **Example** \n\n```\nSELECT  TIMESTAMP(\"2008-12-25 15:30:00+00\") AS original,  TIMESTAMP_SUB(TIMESTAMP \"2008-12-25 15:30:00+00\", INTERVAL 10 MINUTE) AS earlier;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------+-------------------------* | original                | earlier                 | +-------------------------+-------------------------+ | 2008-12-25 15:30:00 UTC | 2008-12-25 15:20:00 UTC | *-------------------------+-------------------------*/\n```\n\n"
  },
  {
    "name": "TIMESTAMP_TRUNC",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nTIMESTAMP_TRUNC(timestamp_expression, date_time_part[, time_zone])\n```\n\n **Description** \n\nTruncates a timestamp to the granularity of`date_time_part`.The timestamp is always rounded to the beginning of`date_time_part`,which can be one of the following:\n\n- `    MICROSECOND`: If used, nothing is truncated from the value.\n- `    MILLISECOND`: The nearest lessor or equal millisecond.\n- `    SECOND`: The nearest lessor or equal second.\n- `    MINUTE`: The nearest lessor or equal minute.\n- `    HOUR`: The nearest lessor or equal hour.\n- `    DAY`: The day in the Gregorian calendar year that contains the`    TIMESTAMP`value.\n- `    WEEK`: The first day of the week in the week that contains the`    TIMESTAMP`value. Weeks begin on Sundays.`    WEEK`is equivalent to`    WEEK(SUNDAY)`.\n- `    WEEK(WEEKDAY)`: The first day of the week in the week that contains the`    TIMESTAMP`value. Weeks begin on`    WEEKDAY`.`    WEEKDAY`must be one of thefollowing:`    SUNDAY`,`    MONDAY`,`    TUESDAY`,`    WEDNESDAY`,`    THURSDAY`,`    FRIDAY`,or`    SATURDAY`.\n- `    ISOWEEK`: The first day of the[ISO 8601 week](https://en.wikipedia.org/wiki/ISO_week_date)in theISO week that contains the`    TIMESTAMP`value. The ISO week begins onMonday. The first ISO week of each ISO year contains the first Thursday of thecorresponding Gregorian calendar year.\n- `    MONTH`: The first day of the month in the month that contains the`    TIMESTAMP`value.\n- `    QUARTER`: The first day of the quarter in the quarter that contains the`    TIMESTAMP`value.\n- `    YEAR`: The first day of the year in the year that contains the`    TIMESTAMP`value.\n- `    ISOYEAR`: The first day of the[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)week-numbering yearin the ISO year that contains the`    TIMESTAMP`value. The ISO year is theMonday of the first week whose Thursday belongs to the correspondingGregorian calendar year.\n\n`TIMESTAMP_TRUNC`function supports an optional`time_zone`parameter. Thisparameter applies to the following`date_time_part`:\n\n- `    MINUTE`\n- `    HOUR`\n- `    DAY`\n- `    WEEK`\n- `    WEEK(&lt;WEEKDAY&gt;)`\n- `    ISOWEEK`\n- `    MONTH`\n- `    QUARTER`\n- `    YEAR`\n- `    ISOYEAR`\n\nUse this parameter if you want to use a time zone other than thedefault time zone, UTC, as part of thetruncate operation.\n\nWhen truncating a timestamp to`MINUTE`or`HOUR`parts,`TIMESTAMP_TRUNC`determines the civil time of thetimestamp in the specified (or default) time zoneand subtracts the minutes and seconds (when truncating to`HOUR`) or the seconds(when truncating to`MINUTE`) from that timestamp.While this provides intuitive results in most cases, the result isnon-intuitive near daylight savings transitions that are not hour-aligned.\n\n **Return Data Type** \n\n`TIMESTAMP`\n\n **Examples** \n\n```\nSELECT  TIMESTAMP_TRUNC(TIMESTAMP \"2008-12-25 15:30:00+00\", DAY, \"UTC\") AS utc,  TIMESTAMP_TRUNC(TIMESTAMP \"2008-12-25 15:30:00+00\", DAY, \"America/Los_Angeles\") AS la;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------+-------------------------* | utc                     | la                      | +-------------------------+-------------------------+ | 2008-12-25 00:00:00 UTC | 2008-12-25 08:00:00 UTC | *-------------------------+-------------------------*/\n```\n\nIn the following example,`timestamp_expression`has a time zone offset of +12.The first column shows the`timestamp_expression`in UTC time. The secondcolumn shows the output of`TIMESTAMP_TRUNC`using weeks that start on Monday.Because the`timestamp_expression`falls on a Sunday in UTC,`TIMESTAMP_TRUNC`truncates it to the preceding Monday. The third column shows the same functionwith the optional[Time zone definition](#timezone_definitions)argument 'Pacific/Auckland'. Here, the function truncates the`timestamp_expression`using New Zealand Daylight Time, where it falls on aMonday.\n\n```\nSELECT  timestamp_value AS timestamp_value,  TIMESTAMP_TRUNC(timestamp_value, WEEK(MONDAY), \"UTC\") AS utc_truncated,  TIMESTAMP_TRUNC(timestamp_value, WEEK(MONDAY), \"Pacific/Auckland\") AS nzdt_truncatedFROM (SELECT TIMESTAMP(\"2017-11-06 00:00:00+12\") AS timestamp_value);-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------+-------------------------+-------------------------* | timestamp_value         | utc_truncated           | nzdt_truncated          | +-------------------------+-------------------------+-------------------------+ | 2017-11-05 12:00:00 UTC | 2017-10-30 00:00:00 UTC | 2017-11-05 11:00:00 UTC | *-------------------------+-------------------------+-------------------------*/\n```\n\nIn the following example, the original`timestamp_expression`is in theGregorian calendar year 2015. However,`TIMESTAMP_TRUNC`with the`ISOYEAR`datepart truncates the`timestamp_expression`to the beginning of the ISO year, notthe Gregorian calendar year. The first Thursday of the 2015 calendar year was2015-01-01, so the ISO year 2015 begins on the preceding Monday, 2014-12-29.Therefore the ISO year boundary preceding the`timestamp_expression`2015-06-15 00:00:00+00 is 2014-12-29.\n\n```\nSELECT  TIMESTAMP_TRUNC(\"2015-06-15 00:00:00+00\", ISOYEAR) AS isoyear_boundary,  EXTRACT(ISOYEAR FROM TIMESTAMP \"2015-06-15 00:00:00+00\") AS isoyear_number;-- Display of results may differ, depending upon the environment and time zone where this query was executed./*-------------------------+----------------* | isoyear_boundary        | isoyear_number | +-------------------------+----------------+ | 2014-12-29 00:00:00 UTC | 2015           | *-------------------------+----------------*/\n```\n\n"
  },
  {
    "name": "TIME_ADD",
    "arguments": [],
    "category": "Time functions",
    "description": "```\nTIME_ADD(time_expression, INTERVAL int64_expression part)\n```\n\n **Description** \n\nAdds`int64_expression`units of`part`to the`TIME`object.\n\n`TIME_ADD`supports the following values for`part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n\nThis function automatically adjusts when values fall outside of the 00:00:00 to24:00:00 boundary. For example, if you add an hour to`23:30:00`, the returnedvalue is`00:30:00`.\n\n **Return Data Types** \n\n`TIME`\n\n **Example** \n\n```\nSELECT  TIME \"15:30:00\" as original_time,  TIME_ADD(TIME \"15:30:00\", INTERVAL 10 MINUTE) as later;/*-----------------------------+------------------------* | original_time               | later                  | +-----------------------------+------------------------+ | 15:30:00                    | 15:40:00               | *-----------------------------+------------------------*/\n```\n\n"
  },
  {
    "name": "TIME_DIFF",
    "arguments": [],
    "category": "Time functions",
    "description": "```\nTIME_DIFF(time_expression_a, time_expression_b, part)\n```\n\n **Description** \n\nReturns the whole number of specified`part`intervals between two`TIME`objects (`time_expression_a`-`time_expression_b`). If the first`TIME`is earlier than the second one, the output is negative. Throws an errorif the computation overflows the result type, such as if the difference inmicrosecondsbetween the two`TIME`objects would overflow an`INT64`value.\n\n`TIME_DIFF`supports the following values for`part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n\n **Note:** The behavior of the this function follows the type of arguments passed in.For example,`TIME_DIFF(TIMESTAMP, TIMESTAMP, PART)`behaves like`TIMESTAMP_DIFF(TIMESTAMP, TIMESTAMP, PART)`. **Return Data Type** \n\n`INT64`\n\n **Example** \n\n```\nSELECT  TIME \"15:30:00\" as first_time,  TIME \"14:35:00\" as second_time,  TIME_DIFF(TIME \"15:30:00\", TIME \"14:35:00\", MINUTE) as difference;/*----------------------------+------------------------+------------------------* | first_time                 | second_time            | difference             | +----------------------------+------------------------+------------------------+ | 15:30:00                   | 14:35:00               | 55                     | *----------------------------+------------------------+------------------------*/\n```\n\n"
  },
  {
    "name": "TIME_SUB",
    "arguments": [],
    "category": "Time functions",
    "description": "```\nTIME_SUB(time_expression, INTERVAL int64_expression part)\n```\n\n **Description** \n\nSubtracts`int64_expression`units of`part`from the`TIME`object.\n\n`TIME_SUB`supports the following values for`part`:\n\n- `    MICROSECOND`\n- `    MILLISECOND`\n- `    SECOND`\n- `    MINUTE`\n- `    HOUR`\n\nThis function automatically adjusts when values fall outside of the 00:00:00 to24:00:00 boundary. For example, if you subtract an hour from`00:30:00`, thereturned value is`23:30:00`.\n\n **Return Data Type** \n\n`TIME`\n\n **Example** \n\n```\nSELECT  TIME \"15:30:00\" as original_date,  TIME_SUB(TIME \"15:30:00\", INTERVAL 10 MINUTE) as earlier;/*-----------------------------+------------------------* | original_date               | earlier                | +-----------------------------+------------------------+ | 15:30:00                    | 15:20:00               | *-----------------------------+------------------------*/\n```\n\n"
  },
  {
    "name": "TIME_TRUNC",
    "arguments": [],
    "category": "Time functions",
    "description": "```\nTIME_TRUNC(time_expression, time_part)\n```\n\n **Description** \n\nTruncates a`TIME`value to the granularity of`time_part`. The`TIME`valueis always rounded to the beginning of`time_part`, which can be one of thefollowing:\n\n- `    MICROSECOND`: If used, nothing is truncated from the value.\n- `    MILLISECOND`: The nearest lessor or equal millisecond.\n- `    SECOND`: The nearest lessor or equal second.\n- `    MINUTE`: The nearest lessor or equal minute.\n- `    HOUR`: The nearest lessor or equal hour.\n\n **Return Data Type** \n\n`TIME`\n\n **Example** \n\n```\nSELECT  TIME \"15:30:00\" as original,  TIME_TRUNC(TIME \"15:30:00\", HOUR) as truncated;/*----------------------------+------------------------* | original                   | truncated              | +----------------------------+------------------------+ | 15:30:00                   | 15:00:00               | *----------------------------+------------------------*/\n```\n\n\n<span id=\"time_series_functions\">\n## Time series functions\n\n</span>\nGoogleSQL for BigQuery supports the following time series functions.\n\n"
  },
  {
    "name": "TO_BASE32",
    "arguments": [],
    "category": "String functions",
    "description": "```\nTO_BASE32(bytes_expr)\n```\n\n **Description** \n\nConverts a sequence of`BYTES`into a base32-encoded`STRING`. To convert abase32-encoded`STRING`into`BYTES`, use[FROM_BASE32](#from_base32).\n\n **Return type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT TO_BASE32(b'abcde\\xFF') AS base32_string;/*------------------* | base32_string    | +------------------+ | MFRGGZDF74====== | *------------------*/\n```\n\n"
  },
  {
    "name": "TO_BASE64",
    "arguments": [],
    "category": "String functions",
    "description": "```\nTO_BASE64(bytes_expr)\n```\n\n **Description** \n\nConverts a sequence of`BYTES`into a base64-encoded`STRING`. To convert abase64-encoded`STRING`into`BYTES`, use[FROM_BASE64](#from_base64).\n\nThere are several base64 encodings in common use that vary in exactly whichalphabet of 65 ASCII characters are used to encode the 64 digits and padding.See[RFC 4648](https://tools.ietf.org/html/rfc4648#section-4)for details. Thisfunction adds padding and uses the alphabet`[A-Za-z0-9+/=]`.\n\n **Return type** \n\n`STRING`\n\n **Example** \n\n```\nSELECT TO_BASE64(b'\\377\\340') AS base64_string;/*---------------* | base64_string | +---------------+ | /+A=          | *---------------*/\n```\n\nTo work with an encoding using a different base64 alphabet, you might need tocompose`TO_BASE64`with the`REPLACE`function. For instance, the`base64url`url-safe and filename-safe encoding commonly used in web programminguses`-_=`as the last characters rather than`+/=`. To encode a`base64url`-encoded string, replace`+`and`/`with`-`and`_`respectively.\n\n```\nSELECT REPLACE(REPLACE(TO_BASE64(b'\\377\\340'), '+', '-'), '/', '_') as websafe_base64;/*----------------* | websafe_base64 | +----------------+ | _-A=           | *----------------*/\n```\n\n"
  },
  {
    "name": "TO_CODE_POINTS",
    "arguments": [],
    "category": "String functions",
    "description": "```\nTO_CODE_POINTS(value)\n```\n\n **Description** \n\nTakes a`STRING`or`BYTES`value and returns an array of`INT64`values thatrepresent code points or extended ASCII character values.\n\n- If`    value`is a`    STRING`, each element in the returned array represents a[code point](https://en.wikipedia.org/wiki/Code_point). Each code point fallswithin the range of [0, 0xD7FF] and [0xE000, 0x10FFFF].\n- If`    value`is`    BYTES`, each element in the array is an extended ASCIIcharacter value in the range of [0, 255].\n\nTo convert from an array of code points to a`STRING`or`BYTES`, see[CODE_POINTS_TO_STRING](#code_points_to_string)or[CODE_POINTS_TO_BYTES](#code_points_to_bytes).\n\n **Return type** \n\n`ARRAY&lt;INT64&gt;`\n\n **Examples** \n\nThe following example gets the code points for each element in an array ofwords.\n\n```\nSELECT word, TO_CODE_POINTS(word) AS code_pointsFROM UNNEST(['foo', 'bar', 'baz', 'giraffe', 'llama']) AS word;/*---------+------------------------------------* | word    | code_points                        | +---------+------------------------------------+ | foo     | [102, 111, 111]                    | | bar     | [98, 97, 114]                      | | baz     | [98, 97, 122]                      | | giraffe | [103, 105, 114, 97, 102, 102, 101] | | llama   | [108, 108, 97, 109, 97]            | *---------+------------------------------------*/\n```\n\nThe following example converts integer representations of`BYTES`to theircorresponding ASCII character values.\n\n```\nSELECT word, TO_CODE_POINTS(word) AS bytes_value_as_integerFROM UNNEST([b'\\x00\\x01\\x10\\xff', b'\\x66\\x6f\\x6f']) AS word;/*------------------+------------------------* | word             | bytes_value_as_integer | +------------------+------------------------+ | \\x00\\x01\\x10\\xff | [0, 1, 16, 255]        | | foo              | [102, 111, 111]        | *------------------+------------------------*/\n```\n\nThe following example demonstrates the difference between a`BYTES`result and a`STRING`result.\n\n```\nSELECT TO_CODE_POINTS(b'Ā') AS b_result, TO_CODE_POINTS('Ā') AS s_result;/*------------+----------* | b_result   | s_result | +------------+----------+ | [196, 128] | [256]    | *------------+----------*/\n```\n\nNotice that the character, Ā, is represented as a two-byte Unicode sequence. Asa result, the`BYTES`version of`TO_CODE_POINTS`returns an array with twoelements, while the`STRING`version returns an array with a single element.\n\n"
  },
  {
    "name": "TO_HEX",
    "arguments": [],
    "category": "String functions",
    "description": "```\nTO_HEX(bytes)\n```\n\n **Description** \n\nConverts a sequence of`BYTES`into a hexadecimal`STRING`. Converts each bytein the`STRING`as two hexadecimal characters in the range`(0..9, a..f)`. To convert a hexadecimal-encoded`STRING`to`BYTES`, use[FROM_HEX](#from_hex).\n\n **Return type** \n\n`STRING`\n\n **Example** \n\n```\nWITH Input AS (  SELECT b'\\x00\\x01\\x02\\x03\\xAA\\xEE\\xEF\\xFF' AS byte_str UNION ALL  SELECT b'foobar')SELECT byte_str, TO_HEX(byte_str) AS hex_strFROM Input;/*----------------------------------+------------------* | byte_string                      | hex_string       | +----------------------------------+------------------+ | \\x00\\x01\\x02\\x03\\xaa\\xee\\xef\\xff | 00010203aaeeefff | | foobar                           | 666f6f626172     | *----------------------------------+------------------*/\n```\n\n"
  },
  {
    "name": "TO_JSON",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nTO_JSON(sql_value[, stringify_wide_numbers=&gt;{ TRUE | FALSE }])\n```\n\n **Description** \n\nConverts a SQL value to a JSON value.\n\nArguments:\n\n- `    sql_value`: The SQL value to convert to a JSON value. You can review theGoogleSQL data types that this function supports and theirJSON encodings[here](#json_encodings).\n- `    stringify_wide_numbers`: Optional mandatory-named argument that is either`    TRUE`or`    FALSE`(default).\n    \n    \n    - If`        TRUE`, numeric values outside of the`        FLOAT64`type domain are encoded as strings.\n    - If`        FALSE`(default), numeric values outside of the`        FLOAT64`type domain are not encoded as strings,but are stored as JSON numbers. If a numerical value cannot be stored inJSON without loss of precision, an error is thrown.The following numerical data types are affected by the`    stringify_wide_numbers`argument:\n    \n    \n- `    INT64`\n    \n    \n- `    NUMERIC`\n    \n    \n- `    BIGNUMERIC`\n    \n    If one of these numerical data types appears in a container data typesuch as an`    ARRAY`or`    STRUCT`, the`    stringify_wide_numbers`argument isapplied to the numerical data types in the container data type.\n    \n    \n\n **Return type** \n\n`JSON`\n\n **Examples** \n\nIn the following example, the query converts rows in a table to JSON values.\n\n```\nWith CoordinatesTable AS (    (SELECT 1 AS id, [10, 20] AS coordinates) UNION ALL    (SELECT 2 AS id, [30, 40] AS coordinates) UNION ALL    (SELECT 3 AS id, [50, 60] AS coordinates))SELECT TO_JSON(t) AS json_objectsFROM CoordinatesTable AS t;/*--------------------------------* | json_objects                   | +--------------------------------+ | {\"coordinates\":[10,20],\"id\":1} | | {\"coordinates\":[30,40],\"id\":2} | | {\"coordinates\":[50,60],\"id\":3} | *--------------------------------*/\n```\n\nIn the following example, the query returns a large numerical value as aJSON string.\n\n```\nSELECT TO_JSON(9007199254740993, stringify_wide_numbers=&gt;TRUE) as stringify_on/*--------------------* | stringify_on       | +--------------------+ | \"9007199254740993\" | *--------------------*/\n```\n\nIn the following example, both queries return a large numerical value as aJSON number.\n\n```\nSELECT TO_JSON(9007199254740993, stringify_wide_numbers=&gt;FALSE) as stringify_offSELECT TO_JSON(9007199254740993) as stringify_off/*------------------* | stringify_off    | +------------------+ | 9007199254740993 | *------------------*/\n```\n\nIn the following example, only large numeric values are converted toJSON strings.\n\n```\nWith T1 AS (  (SELECT 9007199254740993 AS id) UNION ALL  (SELECT 2 AS id))SELECT TO_JSON(t, stringify_wide_numbers=&gt;TRUE) AS json_objectsFROM T1 AS t;/*---------------------------* | json_objects              | +---------------------------+ | {\"id\":\"9007199254740993\"} | | {\"id\":2}                  | *---------------------------*/\n```\n\nIn this example, the values`9007199254740993`(`INT64`)and`2.1`(`FLOAT64`) are convertedto the common supertype`FLOAT64`, which is notaffected by the`stringify_wide_numbers`argument.\n\n```\nWith T1 AS (  (SELECT 9007199254740993 AS id) UNION ALL  (SELECT 2.1 AS id))SELECT TO_JSON(t, stringify_wide_numbers=&gt;TRUE) AS json_objectsFROM T1 AS t;/*------------------------------* | json_objects                 | +------------------------------+ | {\"id\":9.007199254740992e+15} | | {\"id\":2.1}                   | *------------------------------*/\n```\n\n"
  },
  {
    "name": "TO_JSON_STRING",
    "arguments": [],
    "category": "JSON functions",
    "description": "```\nTO_JSON_STRING(value[, pretty_print])\n```\n\n **Description** \n\nConverts a SQL value to a JSON-formatted`STRING`value.\n\nArguments:\n\n- `    value`: A SQL value. You can review the GoogleSQL data types thatthis function supports and their JSON encodings[here](#json_encodings).\n- `    pretty_print`: Optional boolean parameter. If`    pretty_print`is`    true`, the`returned value is formatted for easy readability.\n\n **Return type** \n\nA JSON-formatted`STRING`\n\n **Examples** \n\nConvert rows in a table to JSON-formatted strings.\n\n```\nWith CoordinatesTable AS (    (SELECT 1 AS id, [10, 20] AS coordinates) UNION ALL    (SELECT 2 AS id, [30, 40] AS coordinates) UNION ALL    (SELECT 3 AS id, [50, 60] AS coordinates))SELECT id, coordinates, TO_JSON_STRING(t) AS json_dataFROM CoordinatesTable AS t;/*----+-------------+--------------------------------* | id | coordinates | json_data                      | +----+-------------+--------------------------------+ | 1  | [10, 20]    | {\"id\":1,\"coordinates\":[10,20]} | | 2  | [30, 40]    | {\"id\":2,\"coordinates\":[30,40]} | | 3  | [50, 60]    | {\"id\":3,\"coordinates\":[50,60]} | *----+-------------+--------------------------------*/\n```\n\nConvert rows in a table to JSON-formatted strings that are easy to read.\n\n```\nWith CoordinatesTable AS (    (SELECT 1 AS id, [10, 20] AS coordinates) UNION ALL    (SELECT 2 AS id, [30, 40] AS coordinates))SELECT id, coordinates, TO_JSON_STRING(t, true) AS json_dataFROM CoordinatesTable AS t;/*----+-------------+--------------------* | id | coordinates | json_data          | +----+-------------+--------------------+ | 1  | [10, 20]    | {                  | |    |             |   \"id\": 1,         | |    |             |   \"coordinates\": [ | |    |             |     10,            | |    |             |     20             | |    |             |   ]                | |    |             | }                  | +----+-------------+--------------------+ | 2  | [30, 40]    | {                  | |    |             |   \"id\": 2,         | |    |             |   \"coordinates\": [ | |    |             |     30,            | |    |             |     40             | |    |             |   ]                | |    |             | }                  | *----+-------------+--------------------*/\n```\n\n"
  },
  {
    "name": "TRANSLATE",
    "arguments": [],
    "category": "String functions",
    "description": "```\nTRANSLATE(expression, source_characters, target_characters)\n```\n\n **Description** \n\nIn`expression`, replaces each character in`source_characters`with thecorresponding character in`target_characters`. All inputs must be the sametype, either`STRING`or`BYTES`.\n\n- Each character in`    expression`is translated at most once.\n- A character in`    expression`that is not present in`    source_characters`is leftunchanged in`    expression`.\n- A character in`    source_characters`without a corresponding character in`    target_characters`is omitted from the result.\n- A duplicate character in`    source_characters`results in an error.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH example AS (  SELECT 'This is a cookie' AS expression, 'sco' AS source_characters, 'zku' AS  target_characters UNION ALL  SELECT 'A coaster' AS expression, 'co' AS source_characters, 'k' as  target_characters)SELECT expression, source_characters, target_characters, TRANSLATE(expression,source_characters, target_characters) AS translateFROM example;/*------------------+-------------------+-------------------+------------------* | expression       | source_characters | target_characters | translate        | +------------------+-------------------+-------------------+------------------+ | This is a cookie | sco               | zku               | Thiz iz a kuukie | | A coaster        | co                | k                 | A kaster         | *------------------+-------------------+-------------------+------------------*/\n```\n\n"
  },
  {
    "name": "TRIM",
    "arguments": [],
    "category": "String functions",
    "description": "```\nTRIM(value_to_trim[, set_of_characters_to_remove])\n```\n\n **Description** \n\nTakes a`STRING`or`BYTES`value to trim.\n\nIf the value to trim is a`STRING`, removes from this value all leading andtrailing Unicode code points in`set_of_characters_to_remove`.The set of code points is optional. If it is not specified, allwhitespace characters are removed from the beginning and end of thevalue to trim.\n\nIf the value to trim is`BYTES`, removes from this value all leading andtrailing bytes in`set_of_characters_to_remove`. The set of bytes is required.\n\n **Return type** \n\n- `    STRING`if`    value_to_trim`is a`    STRING`value.\n- `    BYTES`if`    value_to_trim`is a`    BYTES`value.\n\n **Examples** \n\nIn the following example, all leading and trailing whitespace characters areremoved from`item`because`set_of_characters_to_remove`is not specified.\n\n```\nWITH items AS  (SELECT '   apple   ' as item  UNION ALL  SELECT '   banana   ' as item  UNION ALL  SELECT '   orange   ' as item)SELECT  CONCAT('#', TRIM(item), '#') as exampleFROM items;/*----------* | example  | +----------+ | #apple#  | | #banana# | | #orange# | *----------*/\n```\n\nIn the following example, all leading and trailing`*`characters are removedfrom`item`.\n\n```\nWITH items AS  (SELECT '***apple***' as item  UNION ALL  SELECT '***banana***' as item  UNION ALL  SELECT '***orange***' as item)SELECT  TRIM(item, '*') as exampleFROM items;/*---------* | example | +---------+ | apple   | | banana  | | orange  | *---------*/\n```\n\nIn the following example, all leading and trailing`x`,`y`, and`z`charactersare removed from`item`.\n\n```\nWITH items AS  (SELECT 'xxxapplexxx' as item  UNION ALL  SELECT 'yyybananayyy' as item  UNION ALL  SELECT 'zzzorangezzz' as item  UNION ALL  SELECT 'xyzpearxyz' as item)SELECT  TRIM(item, 'xyz') as exampleFROM items;/*---------* | example | +---------+ | apple   | | banana  | | orange  | | pear    | *---------*/\n```\n\nIn the following example, examine how`TRIM`interprets characters asUnicode code-points. If your trailing character set contains a combiningdiacritic mark over a particular letter,`TRIM`might strip thesame diacritic mark from a different letter.\n\n```\nSELECT  TRIM('abaW̊', 'Y̊') AS a,  TRIM('W̊aba', 'Y̊') AS b,  TRIM('abaŪ̊', 'Y̊') AS c,  TRIM('Ū̊aba', 'Y̊') AS d;/*------+------+------+------* | a    | b    | c    | d    | +------+------+------+------+ | abaW | W̊aba | abaŪ | Ūaba | *------+------+------+------*/\n```\n\nIn the following example, all leading and trailing`b'n'`,`b'a'`,`b'\\xab'`bytes are removed from`item`.\n\n```\nWITH items AS(  SELECT b'apple' as item UNION ALL  SELECT b'banana' as item UNION ALL  SELECT b'\\xab\\xcd\\xef\\xaa\\xbb' as item)SELECT item, TRIM(item, b'na\\xab') AS examplesFROM items;-- Note that the result of TRIM is of type BYTES, displayed as a base64-encoded string./*----------------------+------------------* | item                 | example          | +----------------------+------------------+ | YXBwbGU=             | cHBsZQ==         | | YmFuYW5h             | Yg==             | | q83vqrs=             | ze+quw==         | *----------------------+------------------*/\n```\n\n"
  },
  {
    "name": "TRUNC",
    "arguments": [],
    "category": "Mathematical functions",
    "description": "```\nTRUNC(X [, N])\n```\n\n **Description** \n\nIf only X is present,`TRUNC`rounds X to the nearest integer whose absolutevalue is not greater than the absolute value of X. If N is also present,`TRUNC`behaves like`ROUND(X, N)`, but always rounds towards zero and never overflows.\n\n| X | TRUNC(X) |\n| --- | --- |\n| 2.0 | 2.0 |\n| 2.3 | 2.0 |\n| 2.8 | 2.0 |\n| 2.5 | 2.0 |\n| -2.3 | -2.0 |\n| -2.8 | -2.0 |\n| -2.5 | -2.0 |\n| 0 | 0 |\n| `+inf` | `+inf` |\n| `-inf` | `-inf` |\n| `NaN` | `NaN` |\n\n **Return Data Type** \n\n| INPUT | `INT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n| --- | --- | --- | --- | --- |\n| OUTPUT | `FLOAT64` | `NUMERIC` | `BIGNUMERIC` | `FLOAT64` |\n\n\n<span id=\"navigation_functions\">\n## Navigation functions\n\n</span>\nGoogleSQL for BigQuery supports navigation functions.Navigation functions are a subset of window functions. To create awindow function call and learn about the syntax for window functions,see[Window function_calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\nNavigation functions generally compute some`value_expression`over a different row in the window frame from thecurrent row. The`OVER`clause syntax varies across navigation functions.\n\nFor all navigation functions, the result data type is the same type as`value_expression`.\n\n"
  },
  {
    "name": "UNICODE",
    "arguments": [],
    "category": "String functions",
    "description": "```\nUNICODE(value)\n```\n\n **Description** \n\nReturns the Unicode[code point](https://en.wikipedia.org/wiki/Code_point)for the first character in`value`. Returns`0`if`value`is empty, or if the resulting Unicode codepoint is`0`.\n\n **Return type** \n\n`INT64`\n\n **Examples** \n\n```\nSELECT UNICODE('âbcd') as A, UNICODE('â') as B, UNICODE('') as C, UNICODE(NULL) as D;/*-------+-------+-------+-------* | A     | B     | C     | D     | +-------+-------+-------+-------+ | 226   | 226   | 0     | NULL  | *-------+-------+-------+-------*/\n```\n\n"
  },
  {
    "name": "UNIX_DATE",
    "arguments": [],
    "category": "Date functions",
    "description": "```\nUNIX_DATE(date_expression)\n```\n\n **Description** \n\nReturns the number of days since`1970-01-01`.\n\n **Return Data Type** \n\nINT64\n\n **Example** \n\n```\nSELECT UNIX_DATE(DATE '2008-12-25') AS days_from_epoch;/*-----------------* | days_from_epoch | +-----------------+ | 14238           | *-----------------*/\n```\n\n\n<span id=\"datetime_functions\">\n## Datetime functions\n\n</span>\nGoogleSQL for BigQuery supports the following datetime functions.\n\nAll outputs are automatically formatted as per[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601),separating date and time with a`T`.\n\n"
  },
  {
    "name": "UNIX_MICROS",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nUNIX_MICROS(timestamp_expression)\n```\n\n **Description** \n\nReturns the number of microseconds since`1970-01-01 00:00:00 UTC`.\n\n **Return Data Type** \n\n`INT64`\n\n **Examples** \n\n```\nSELECT UNIX_MICROS(TIMESTAMP \"2008-12-25 15:30:00+00\") AS micros;/*------------------* | micros           | +------------------+ | 1230219000000000 | *------------------*/\n```\n\n"
  },
  {
    "name": "UNIX_MILLIS",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nUNIX_MILLIS(timestamp_expression)\n```\n\n **Description** \n\nReturns the number of milliseconds since`1970-01-01 00:00:00 UTC`. Truncateshigher levels of precision by rounding down to the beginning of the millisecond.\n\n **Return Data Type** \n\n`INT64`\n\n **Examples** \n\n```\nSELECT UNIX_MILLIS(TIMESTAMP \"2008-12-25 15:30:00+00\") AS millis;/*---------------* | millis        | +---------------+ | 1230219000000 | *---------------*/\n```\n\n```\nSELECT UNIX_MILLIS(TIMESTAMP \"1970-01-01 00:00:00.0018+00\") AS millis;/*---------------* | millis        | +---------------+ | 1             | *---------------*/\n```\n\n"
  },
  {
    "name": "UNIX_SECONDS",
    "arguments": [],
    "category": "Timestamp functions",
    "description": "```\nUNIX_SECONDS(timestamp_expression)\n```\n\n **Description** \n\nReturns the number of seconds since`1970-01-01 00:00:00 UTC`. Truncates higherlevels of precision by rounding down to the beginning of the second.\n\n **Return Data Type** \n\n`INT64`\n\n **Examples** \n\n```\nSELECT UNIX_SECONDS(TIMESTAMP \"2008-12-25 15:30:00+00\") AS seconds;/*------------* | seconds    | +------------+ | 1230219000 | *------------*/\n```\n\n```\nSELECT UNIX_SECONDS(TIMESTAMP \"1970-01-01 00:00:01.8+00\") AS seconds;/*------------* | seconds    | +------------+ | 1          | *------------*/\n```\n\n"
  },
  {
    "name": "UPPER",
    "arguments": [],
    "category": "String functions",
    "description": "```\nUPPER(value)\n```\n\n **Description** \n\nFor`STRING`arguments, returns the original string with all alphabeticcharacters in uppercase. Mapping between uppercase and lowercase is doneaccording to the[Unicode Character Database](http://unicode.org/ucd/)without taking into account language-specific mappings.\n\nFor`BYTES`arguments, the argument is treated as ASCII text, with all bytesgreater than 127 left intact.\n\n **Return type** \n\n`STRING`or`BYTES`\n\n **Examples** \n\n```\nWITH items AS  (SELECT    'foo' as item  UNION ALL  SELECT    'bar' as item  UNION ALL  SELECT    'baz' as item)SELECT  UPPER(item) AS exampleFROM items;/*---------* | example | +---------+ | FOO     | | BAR     | | BAZ     | *---------*/\n```\n\n\n<span id=\"table_functions_built_in\">\n## Table functions (built in)\n\n</span>\nGoogleSQL for BigQuery supports built-in table functions.\n\nThis topic includes functions that produce columns of a table.You can only use these functions in the`FROM`clause.\n\n"
  },
  {
    "name": "VARIANCE",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nVARIANCE(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nAn alias of[VAR_SAMP](#var_samp).\n\n\n<span id=\"string_functions\">\n## String functions\n\n</span>\nGoogleSQL for BigQuery supports string functions.These string functions work on two different values:`STRING`and`BYTES`data types.`STRING`values must be well-formed UTF-8.\n\nFunctions that return position values, such as[STRPOS](#strpos),encode those positions as`INT64`. The value`1`refers to the first character (or byte),`2`refers to the second, and so on.The value`0`indicates an invalid position. When working on`STRING`types, thereturned positions refer to character positions.\n\nAll string comparisons are done byte-by-byte, without regard to Unicodecanonical equivalence.\n\n"
  },
  {
    "name": "VAR_POP",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nVAR_POP(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the population (biased) variance of the values. The return result isbetween`0`and`+Inf`.\n\nAll numeric types are supported. If theinput is`NUMERIC`or`BIGNUMERIC`then the internal aggregation isstable with the final output converted to a`FLOAT64`.Otherwise the input is converted to a`FLOAT64`before aggregation, resulting in a potentially unstable result.\n\nThis function ignores any`NULL`inputs. If all inputs are ignored, thisfunction returns`NULL`. If this function receives a single non-`NULL`input,it returns`0`.\n\n`NaN`is produced if:\n\n- Any input value is`    NaN`\n- Any input value is positive infinity or negative infinity.\n\nIf this function is used with the`OVER`clause, it's part of awindow function call. In a window function call,aggregate function clauses can't be used.To learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nSELECT VAR_POP(x) AS results FROM UNNEST([10, 14, 18]) AS x/*--------------------* | results            | +--------------------+ | 10.666666666666666 | *--------------------*/\n```\n\n```\nSELECT VAR_POP(x) AS results FROM UNNEST([10, 14, NULL]) AS x/*----------* | results | +---------+ | 4       | *---------*/\n```\n\n```\nSELECT VAR_POP(x) AS results FROM UNNEST([10, NULL]) AS x/*----------* | results | +---------+ | 0       | *---------*/\n```\n\n```\nSELECT VAR_POP(x) AS results FROM UNNEST([NULL]) AS x/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT VAR_POP(x) AS results FROM UNNEST([10, 14, CAST('Infinity' as FLOAT64)]) AS x/*---------* | results | +---------+ | NaN     | *---------*/\n```\n\n"
  },
  {
    "name": "VAR_SAMP",
    "arguments": [],
    "category": "Statistical aggregate functions",
    "description": "```\nVAR_SAMP(  [ DISTINCT ]  expression)[ OVER over_clause ]over_clause:  { named_window | ( [ window_specification ] ) }window_specification:  [ named_window ]  [ PARTITION BY partition_expression [, ...] ]  [ ORDER BY expression [ { ASC | DESC }  ] [, ...] ]  [ window_frame_clause ]\n```\n\n **Description** \n\nReturns the sample (unbiased) variance of the values. The return result isbetween`0`and`+Inf`.\n\nAll numeric types are supported. If theinput is`NUMERIC`or`BIGNUMERIC`then the internal aggregation isstable with the final output converted to a`FLOAT64`.Otherwise the input is converted to a`FLOAT64`before aggregation, resulting in a potentially unstable result.\n\nThis function ignores any`NULL`inputs. If there are fewer than two non-`NULL`inputs, this function returns`NULL`.\n\n`NaN`is produced if:\n\n- Any input value is`    NaN`\n- Any input value is positive infinity or negative infinity.\n\nTo learn more about the optional aggregate clauses that you can passinto this function, see[Aggregate function calls](/bigquery/docs/reference/standard-sql/aggregate-function-calls).\n\nThis function can be used with the[AGGREGATION_THRESHOLD clause](/bigquery/docs/reference/standard-sql/query-syntax#agg_threshold_clause).\n\nIf this function is used with the`OVER`clause, it's part of awindow function call. In a window function call,aggregate function clauses can't be used.To learn more about the`OVER`clause and how to use it, see[Window function calls](/bigquery/docs/reference/standard-sql/window-function-calls).\n\n **Return Data Type** \n\n`FLOAT64`\n\n **Examples** \n\n```\nSELECT VAR_SAMP(x) AS results FROM UNNEST([10, 14, 18]) AS x/*---------* | results | +---------+ | 16      | *---------*/\n```\n\n```\nSELECT VAR_SAMP(x) AS results FROM UNNEST([10, 14, NULL]) AS x/*---------* | results | +---------+ | 8       | *---------*/\n```\n\n```\nSELECT VAR_SAMP(x) AS results FROM UNNEST([10, NULL]) AS x/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT VAR_SAMP(x) AS results FROM UNNEST([NULL]) AS x/*---------* | results | +---------+ | NULL    | *---------*/\n```\n\n```\nSELECT VAR_SAMP(x) AS results FROM UNNEST([10, 14, CAST('Infinity' as FLOAT64)]) AS x/*---------* | results | +---------+ | NaN     | *---------*/\n```\n\n"
  },
  {
    "name": "VECTOR_SEARCH",
    "arguments": [],
    "category": "Search functions",
    "description": " **Preview** \n\nThis product or feature is subject to the \"Pre-GA Offerings Terms\"    in the General Service Terms section of the[Service Specific Terms](/terms/service-terms).    Pre-GA products and features are available \"as is\" and might have    limited support. For more information, see the[launch stage descriptions](/products#product-launch-stages).\n\nTo provide feedback or request support for this feature, send email to[bq-vector-search@google.com](mailto:bq-vector-search@google.com).\n\n```\nVECTOR_SEARCH(  TABLE base_table,  column_to_search,  TABLE query_table  [, query_column_to_search =&gt; query_column_to_search_value]  [, top_k =&gt; top_k_value ]  [, distance_type =&gt; distance_type_value ]  [, options =&gt; options_value ])\n```\n\n```\nVECTOR_SEARCH(  TABLE base_table,  column_to_search,  (query_statement)  [, query_column_to_search =&gt; query_column_to_search_value]  [, top_k =&gt; top_k_value ]  [, distance_type =&gt; distance_type_value ]  [, options =&gt; options_value ])\n```\n\n **Description** \n\nThe`VECTOR_SEARCH`function lets you search embeddings to find semanticallysimilar entities.\n\nEmbeddings are high-dimensional numerical vectors that represent a given entity,like a piece of text or an audio file. Machine learning (ML) models useembeddings to encode semantics about such entities to make it easier toreason about and compare them. For example, a common operation in clustering,classification, and recommendation models is to measure the distance betweenvectors in an[embedding space](https://en.wikipedia.org/wiki/Latent_space)tofind items that are most semantically similar.\n\n **Definitions** \n\n- `    base_table`: The table to search for nearest neighbor embeddings.\n- `    column_to_search`: The name of the base table columnto search for nearest neighbor embeddings. The column must havea type of`    ARRAY&lt;FLOAT64&gt;`. All elements in the array must be non-`    NULL`, andall values in the column must have the same array dimensions.If the column has a vector index, BigQuery attempts to use it.To determine if an index was used in the vector search, see[Vector index usage](/bigquery/docs/vector-index#vector_index_usage).\n- `    query_table`: The table that provides theembeddings for which to find nearest neighbors. All columns are passedthrough as output columns.\n- `    query_statement`: A query that provides theembeddings for which to find nearest neighbors. All columns are passedthrough as output columns.\n- `    query_column_to_search`: An optional`    STRING`positional-named argument.`    query_column_to_search_value`specifies the name of the column in the querytable or statement that contains the embeddings for which to find nearestneighbors. The column must have a type of`    ARRAY&lt;FLOAT64&gt;`. All elements inthe array must be non-`    NULL`and all values in the column must have the samearray dimensions as the values in the`    column_to_search`column. If you don'tspecify`    query_column_to_search_value`, the function uses the`    column_to_search`value.\n- `    top_k`: An optional`    INT64`mandatory-named argument.`    top_k_value`specifies the number of nearest neighbors toreturn. The default is`    10`. A negative value is treated as infinity, meaningthat all values are counted as neighbors and returned.\n- `    distance_type`: An optional`    STRING`mandatory-named argument.`    distance_type_value`specifies the type of metric to use tocompute the distance between two vectors. Supported distance types are[EUCLIDEAN](https://en.wikipedia.org/wiki/Euclidean_distance)and[COSINE](https://en.wikipedia.org/wiki/Cosine_similarity#Cosine_Distance). The default is`    EUCLIDEAN`.\n    \n    If you don't specify`    distance_type_value`and the`    column_to_search`column has a vector index that is used,`    VECTOR_SEARCH`uses the distancetype specified in the[distance_type option](/bigquery/docs/reference/standard-sql/data-definition-language#vector_index_option_list)of the`    CREATE VECTOR INDEX`statement.\n    \n    \n- `    options`: An optional JSON-formatted`    STRING`mandatory-named argument.`    options_value`is a literal that specifies the following vector searchoptions:\n    \n    \n    - `        fraction_lists_to_search`: A JSON number that specifies thepercentage of lists to search. For example,`        options =&gt; '{\"fraction_lists_to_search\":0.15}'`. The`        fraction_lists_to_search`value must be in the range`        0.0`to`        1.0`,exclusive.\n        \n        Specifying a higher percentage leads to higher recall and slowerperformance, and the converse is true when specifying a lower percentage.\n        \n        `        fraction_lists_to_search`is only used when a vector index is also used.If you don't specify a`        fraction_lists_to_search`value but an index ismatched, the default number of lists to scan is calculated as`        min(0.002 * number_of_lists, 10)`.\n        \n        The number of available lists to search is determined by the[num_lists option](/bigquery/docs/reference/standard-sql/data-definition-language#vector_index_option_list)in the`        ivf_options`option of the`        CREATE VECTOR INDEX`statement if that is specified. Otherwise,BigQuery calculates an appropriate number.\n        \n        You can't specify`        fraction_lists_to_search`when`        use_brute_force`isset to`        true`.\n        \n        \n    - `        use_brute_force`: A JSON boolean that determines whether to use bruteforce search by skipping the vector index if one is available. Forexample,`        options =&gt; '{\"use_brute_force\":true}'`. Thedefault is`        false`. If you specify`        use_brute_force=false`and there isno useable vector index available, brute force is used anyway.\n        \n        `    options`defaults to`    '{}'`to denote that all underlying options use theircorresponding default values.\n    \n    \n\n **Details** \n\nYou can optionally use`VECTOR_SEARCH`with a[vector index](/bigquery/docs/vector-index). Whena vector index is used,`VECTOR_SEARCH`uses the[Approximate NearestNeighbor](https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximation_methods)search technique to help improve vector search performance, withthe trade-off of reducing[recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall#recallsearch_term_rules)and so returning more approximateresults. Brute force is used to return exact results when a vector index isn'tavailable, and you can choose to use brute force to get exact results even whena vector index is available.\n\n **Output** \n\nFor each row in the query data, the output contains multiple rows from thebase table that satisfy the search criteria. The number of results rows perquery table row is either 10 or the`top_k`value if it is specified. Theorder of the output isn't guaranteed.\n\nThe output includes the following columns:\n\n- `    query`: A`    STRUCT`value that contains all selected columns from the querydata.\n- `    base`: A`    STRUCT`value that contains all columns from the base table.\n- `    distance`: A`    FLOAT64`value that represents the distance between the basedata and the query data.\n\n **Limitations** \n\nWhen`VECTOR_SEARCH`uses a vector index, if there is newly ingested data thatisn't covered by the index yet, that data isn't included in the results.If there is newly deleted data, the final results might be missing entries.\n\nBigQuery data security and governance rules apply to the use of`VECTOR_SEARCH`, which results in the following behavior:\n\n- If the base table has[row-level security policies](/bigquery/docs/row-level-security-intro),`    VECTOR_SEARCH`applies the row-levelaccess policies to the query results.\n- If the indexed column from the base table has[data masking policies](/bigquery/docs/column-data-masking-intro),`    VECTOR_SEARCH`succeeds only if the userrunning the query has the[Fine-Grained Reader](/iam/docs/understanding-roles#datacatalog.categoryFineGrainedReader)role on the policy tagsthat are used. Otherwise,`    VECTOR_SEARCH`fails with an invalid query error.\n- If any base table column or any column in the query table or statement has[column-level security policies](/bigquery/docs/column-level-security)and you don't have appropriatepermissions to access the column,`    VECTOR_SEARCH`fails with a permissiondenied error.\n\n **Examples** \n\nThe following queries create test tables`table1`and`table2`to use insubsequent query examples :\n\n```\nCREATE OR REPLACE TABLE mydataset.table1(  id INT64,  my_embedding ARRAY&lt;FLOAT64&gt;)INSERT mydataset.table1 (id, my_embedding)VALUES(1, [1.0, 2.0]),(2, [2.0, 4.0]),(3, [1.5, 7.0]),(4, [1.0, 3.2]),(5, [5.0, 5.4]),(6, [3.7, 1.8]),(7, [4.4, 2.9])\n```\n\n```\nCREATE OR REPLACE TABLE mydataset.table2(  query_id STRING,  embedding ARRAY&lt;FLOAT64&gt;)INSERT mydataset.table2 (query_id, embedding)VALUES('dog', [1.0, 2.0]),('cat', [3.0, 5.2])\n```\n\nThe following example searches the`my_embedding`column of`table1`for the toptwo embeddings that match each row of data in the`embedding`column of`table2`:\n\n```\nSELECT *FROM  VECTOR_SEARCH(    TABLE mydataset.table1,    'my_embedding',    (SELECT query_id, embedding FROM mydataset.table2),    'embedding',    top_k =&gt; 2);/*------  --------+-----------------+---------+----------------------------------------* | query.query_id | query.embedding | base.id | base.my_embedding | distance           | +----------------+-----------------+---------+-------------------+--------------------+ | dog            | 1.0             | 1       | 1.0               | 0                  | |                | 2.0             |         | 2.0               |                    | +----------------+-----------------+---------+-------------------+--------------------+ | dog            | 1.0             | 4       | 1.0               | 1.2000000000000002 | |                | 2.0             |         | 3.2               |                    | +----------------+-----------------+---------+-------------------+--------------------+ | cat            | 3.0             | 2       | 2.0               | 1.5620499351813311 | |                | 5.2             |         | 4.0               |                    | +----------------+-----------------+---------+-------------------+--------------------+ | cat            | 3.0             | 5       | 5.0               | 2.0099751242241779 | |                | 5.2             |         | 5.4               |                    | *----------------+-----------------+---------+-------------------+--------------------*/\n```\n\nThe following example searches the`my_embedding`column of`table1`for the toptwo embeddings that match each row of data in the`embedding`column of`table2`, and uses the`COSINE`distance type to measure the distance betweenthe embeddings:\n\n```\nSELECT *FROM  VECTOR_SEARCH(    TABLE mydataset.table1,    'my_embedding',    TABLE mydataset.table2,    'embedding',    top_k =&gt; 2,    distance_type =&gt; 'COSINE');/*------  --------+-----------------+---------+-------------------------------------------+ | query.query_id | query.embedding | base.id | base.my_embedding | distance              | +----------------+-----------------+---------+-------------------+-----------------------+ | dog            | 1.0             | 2       | 2.0               | 0                     | |                | 2.0             |         | 4.0               |                       | +----------------+-----------------+---------+-------------------+-----------------------+ | dog            | 1.0             | 1       | 1.0               | 0                     | |                | 2.0             |         | 2.0               |                       | +----------------+-----------------+---------+-------------------+-----------------------+ | cat            | 3.0             | 2       | 2.0               | 0.0017773842088002478 | |                | 5.2             |         | 4.0               |                       | +----------------+-----------------+---------+-------------------+-----------------------+ | cat            | 3.0             | 1       | 1.0               | 0.0017773842088002478 | |                | 5.2             |         | 2.0               |                       | *----------------+-----------------+---------+-------------------+-----------------------*/\n```\n\n\n<span id=\"security_functions\">\n## Security functions\n\n</span>\nGoogleSQL for BigQuery supports the following security functions.\n\n"
  }
]